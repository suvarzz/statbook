## Handling missing data

* **Ignore**: Discard samples with missing values.  
* **Impute**: 'Fill in' the missing values with other values.  
* **Accept**: Apply methods that are unaffected by the missing data.  

```{r, eval=FALSE}
library(naniar)
any_na(biopsy)
```

**Vizualysing missing data**  
```{r, eval = FALSE}
library(ggpubr)

a <- vis_miss(biopsy)
# comulative
b <- vis_miss(biopsy, cluster=TRUE)
c <- gg_miss_case(biopsy)

ggarrange(a, b, c + rremove("x.text"), 
          labels = c("frame view", "cumulative", "missing"),
          ncol = 3, nrow = 1)
```

**Missing data types**  
- **MCAR**: Missing Completely At Random  
- **MAR**: Missing At Random  
- **MNAR**: Missing Not At Random  

| **Type** | **Imputation**    | **Deletion**          | **Visual cues**                                                              |
|----------|-------------------|-----------------------|------------------------------------------------------------------------------|
| **MCAR** | Recommended       | Will not lead to bias | Random or noisy patterns in missingness clusters                             |
| **MAR**  | Recommended       | May lead to bias      | Well-defined missingness clusters when arrangin for a particular variable(s) |
| **MNAR** | Will lead to bias | Will lead to bias     | Neither visual pattern above holds                                           |

It can be difficult to ascertain the missingness type using visual inspection!  

**Internal evaluation**  
Compair distributions with/without imputed values:  

* Mean  
* Variance  
* Scale  

**Exterlan evaluation**
Build ML models with/without imputated values and evaluate impact of imputation method on ML model performance:  

* Classification  
* Regression  
* Clustering  
* etc.  

Ideally imputation should not bring big differences.  

**Mean and linear imputations**  
```{r, eval=FALSE}
library(naniar)

# Mean imputation
imp_mean <- mammographic %>%
    bind_shadow(only_miss = TRUE) %>%
    add_label_shadow() %>%
    impute_mean_all()

library(simputation)
imp_lm <- ... %>% impute_lm(Y~ X1 + X2)
```

**Combining multiple imputation models**  
```{r, eval=FALSE}
# Aggregate the imputation models
imp_models <- bind_rows(mean = imp_mean,
                        lm = lmp_lm,
                        .id = "imp_model")
head(imp_models)
```

```{r, eval=FALSE}
any(is.na(bands))
any_na(bands)

# Impute with the mean
imp_mean <- bands %>%
  bind_shadow(only_miss = TRUE) %>% 
  add_label_shadow() %>% 
  impute_mean_all()


```

## Dealing with outliers

* The 3-sigma rule (for normally distributed data)  
* The 1.5*IQR rule (more general)  

Outliers:  

+ any value lower that $Q1 - 1.5 x IQR$  
+ or any higher than $Q3 + 1.5 x IQR$

**Multivariate methods**  
* **Distance-based**: K-nearest neighbors (kNN) distance  
* **Density-based**: Local outlier factor (LOF)  

**1.5*IQR rule**  
Outliers:  

+ any value lower that $Q1 - 1.5 x IQR$  
+ or any higher than $Q3 + 1.5 x IQR$


**Distance-based methods**  

* Average distance to the K-nearest neighbors  

**Density-based methods**  

* Number of the neighboring points within a certain distance  

Assumption: outliers often lie far from their neighbors  

Local Outlier Factor (LOF)  
* Measures the local deviation of a data point with respect to its neighbors.  
* Outliers are observations with substantially lower density than their neighbors.  
`get.knn()` from FNN package  

* Each observation $x$ has an associated score LOF($x$)  
LOF($x$) $\approx$ 1 similar density to its neighbors  
LOF($x$) < 1 higher density than neighbors (inlier)  
LOF($x$) > 1 lower density than neighbors (outlier)   

`lof()` function from `dbscan` package

**What to do with outlier observations?**  
1. **Retention**: Keep them in your dataset and, if possible, use algorithms that are robust to outliers.
- e.g. K nearest-neighbors (kNN), tree-based methods (decision tree, random forest)  
2. **Imputation**: Use an imputation method to replace their value with a less extreme observation.  
- e.g. mode imputation, linear imputation, kNN imputation.  
3. **Capping**: Replace them with the value of the 5-th percentile (lower limit) or 95-th percentile (upper limit).  
4. **Exclusion**: Not recommended, especially in small datasets or those where a normal distribution cannot be assumed.  

