# Principal component analysis
## Basic statistics

**Standard deviation** (SD) and **Variance** (\(s^2\) are measures of the spread of data in a data set.

**Standard deviation** (SD):  
$$s = \sqrt{\frac{\sum_{i=1}^{n} (X_i - \overline{X})^2}{(n-1)}}$$

**Variance** (\(s^2, var(X)\)):
$$s^2 = \frac{\sum_{i=1}^{n} (X_i - \overline{X})^2}{(n-1)} = \frac{\sum_{i=1}^{n} (X_i - \overline{X})(X_i - \overline{X})}{(n-1)}$$

**Covariance** (\(cov(X,Y)\)):
$$cov(X,Y) = \frac{\sum_{i=1}^{n} (X_i - \overline{X})(Y_i - \overline{Y})}{(n-1)}$$
**Covariance matrix** for a set of data with n dimensions:
$$C^{n \times n} = (C_{i,j}, c_{i,j} = cov(Dim_{i}, Dim_{j})),$$
where \(C^{n \times n}\) is a matrix with \(n\) rows and \(n\) columns, and \(Dim_x\) is the \(x\)th dimension.  
For n-dimentional data set, the matrix has n rows and columns and each entry in the matrix is the result of calculating the covariance between two separate dimensions. Eg. the entry on row 2, column 3, is the covariance value calculated between the 2nd dimension and the 3rd dimension.  
Example for 3 dimensional data set, using dimensions \(x\), \(y\) and \(z\):

\[
C =
  \begin{pmatrix}
    cov(x,x) & cov(x,y) & cov(x,z)\\
    cov(y,x) & cov(y,y) & cov(y,z)\\
    cov(z,x) & cov(z,y) & cov(z,z)
  \end{pmatrix}
\]
Covariations of the main diagonal turn to variance: \(cov(a,a) = var(a)\)  
The matrix is symmetrical about the main diagonal since \(cov(a,b) = cov(b,a)\).  

## Basic linear algebra (matrices)
Example of non-eigenvector:
\[
  \begin{pmatrix}
    2 & 3\\
    2 & 1\\
  \end{pmatrix} \times \begin{pmatrix}
  1\\
  3
  \end{pmatrix} = \begin{pmatrix}
  2\cdot1+3\cdot3\\
  2\cdot1+1\cdot3
  \end{pmatrix} = \begin{pmatrix}
  11\\
  5
  \end{pmatrix}
\]

