<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 29 Clustering | R statistics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 29 Clustering | R statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 29 Clustering | R statistics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Mark Goldberg" />


<meta name="date" content="2021-05-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic-regression.html"/>
<link rel="next" href="learning-vector-quantization.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html"><i class="fa fa-check"></i><b>2</b> Statistics R functions reference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#get-data"><i class="fa fa-check"></i><b>2.1</b> Get data</a></li>
<li class="chapter" data-level="2.2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#data-inspection"><i class="fa fa-check"></i><b>2.2</b> Data inspection</a></li>
<li class="chapter" data-level="2.3" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#plots"><i class="fa fa-check"></i><b>2.3</b> Plots</a></li>
<li class="chapter" data-level="2.4" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#analysis-of-the-distribution"><i class="fa fa-check"></i><b>2.4</b> Analysis of the distribution</a></li>
<li class="chapter" data-level="2.5" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#distributions"><i class="fa fa-check"></i><b>2.5</b> Distributions</a></li>
<li class="chapter" data-level="2.6" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#t-test"><i class="fa fa-check"></i><b>2.6</b> t-Test</a></li>
<li class="chapter" data-level="2.7" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#anova"><i class="fa fa-check"></i><b>2.7</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>3</b> Basic Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="basic-statistics.html"><a href="basic-statistics.html#definitions"><i class="fa fa-check"></i><b>3.1</b> Definitions</a></li>
<li class="chapter" data-level="3.2" data-path="basic-statistics.html"><a href="basic-statistics.html#probability"><i class="fa fa-check"></i><b>3.2</b> Probability</a></li>
<li class="chapter" data-level="3.3" data-path="basic-statistics.html"><a href="basic-statistics.html#analysis-of-sample-distribution"><i class="fa fa-check"></i><b>3.3</b> Analysis of sample distribution</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="basic-statistics.html"><a href="basic-statistics.html#histogram"><i class="fa fa-check"></i><b>3.3.1</b> Histogram</a></li>
<li class="chapter" data-level="3.3.2" data-path="basic-statistics.html"><a href="basic-statistics.html#outliers"><i class="fa fa-check"></i><b>3.3.2</b> Outliers</a></li>
<li class="chapter" data-level="3.3.3" data-path="basic-statistics.html"><a href="basic-statistics.html#normality"><i class="fa fa-check"></i><b>3.3.3</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="basic-statistics.html"><a href="basic-statistics.html#confidence-interval"><i class="fa fa-check"></i><b>3.4</b> Confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="primary-data-analysis-case-studies.html"><a href="primary-data-analysis-case-studies.html"><i class="fa fa-check"></i><b>4</b> Primary data analysis - Case studies</a></li>
<li class="chapter" data-level="5" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html"><i class="fa fa-check"></i><b>5</b> Primary data analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#handling-missing-data"><i class="fa fa-check"></i><b>5.1</b> Handling missing data</a></li>
<li class="chapter" data-level="5.2" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#dealing-with-outliers"><i class="fa fa-check"></i><b>5.2</b> Dealing with outliers</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-normalization.html"><a href="data-normalization.html"><i class="fa fa-check"></i><b>6</b> Data normalization</a></li>
<li class="chapter" data-level="7" data-path="statistical-distributions.html"><a href="statistical-distributions.html"><i class="fa fa-check"></i><b>7</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="statistical-distributions.html"><a href="statistical-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>7.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="7.2" data-path="statistical-distributions.html"><a href="statistical-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>7.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="7.3" data-path="statistical-distributions.html"><a href="statistical-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>7.3</b> Binomial Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="statistical-distributions.html"><a href="statistical-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>7.4</b> Beta distribution</a></li>
<li class="chapter" data-level="7.5" data-path="statistical-distributions.html"><a href="statistical-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>7.5</b> Geometric Distribution</a></li>
<li class="chapter" data-level="7.6" data-path="statistical-distributions.html"><a href="statistical-distributions.html#uniform-distributions"><i class="fa fa-check"></i><b>7.6</b> Uniform Distributions</a></li>
<li class="chapter" data-level="7.7" data-path="statistical-distributions.html"><a href="statistical-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>7.7</b> Poisson Distribution</a></li>
<li class="chapter" data-level="7.8" data-path="statistical-distributions.html"><a href="statistical-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>7.8</b> Exponential Distribution</a></li>
<li class="chapter" data-level="7.9" data-path="statistical-distributions.html"><a href="statistical-distributions.html#chi-squared-distribution"><i class="fa fa-check"></i><b>7.9</b> Chi-squared Distribution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>8</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-theory"><i class="fa fa-check"></i><b>8.1</b> Hypothesis testing theory</a></li>
<li class="chapter" data-level="8.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-practice"><i class="fa fa-check"></i><b>8.2</b> Hypothesis test (Practice)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="t-procedures.html"><a href="t-procedures.html"><i class="fa fa-check"></i><b>9</b> t-Procedures</a>
<ul>
<li class="chapter" data-level="9.1" data-path="t-procedures.html"><a href="t-procedures.html#t-test-and-normal-distribution"><i class="fa fa-check"></i><b>9.1</b> t-test and normal distribution</a></li>
<li class="chapter" data-level="9.2" data-path="t-procedures.html"><a href="t-procedures.html#one-sample-t-test"><i class="fa fa-check"></i><b>9.2</b> One-sample t-test</a></li>
<li class="chapter" data-level="9.3" data-path="t-procedures.html"><a href="t-procedures.html#practical-example-t-test-in-r"><i class="fa fa-check"></i><b>9.3</b> Practical example: t-test in R</a></li>
<li class="chapter" data-level="9.4" data-path="t-procedures.html"><a href="t-procedures.html#two-samples-t-test"><i class="fa fa-check"></i><b>9.4</b> Two samples t-test</a></li>
<li class="chapter" data-level="9.5" data-path="t-procedures.html"><a href="t-procedures.html#compare-students-t-and-normal-distributions"><i class="fa fa-check"></i><b>9.5</b> Compare Studentâ€™s t and normal distributions</a></li>
<li class="chapter" data-level="9.6" data-path="t-procedures.html"><a href="t-procedures.html#non-parametric-tests"><i class="fa fa-check"></i><b>9.6</b> Non-parametric tests</a></li>
<li class="chapter" data-level="9.7" data-path="t-procedures.html"><a href="t-procedures.html#mann-whitney-u-rank-sum-test"><i class="fa fa-check"></i><b>9.7</b> Mann-Whitney U Rank Sum Test</a></li>
<li class="chapter" data-level="9.8" data-path="t-procedures.html"><a href="t-procedures.html#wilcoxon-test"><i class="fa fa-check"></i><b>9.8</b> Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html"><i class="fa fa-check"></i><b>10</b> Tests for categorical variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html#chi-squared-tests"><i class="fa fa-check"></i><b>10.1</b> Chi-squared tests</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>11</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="11.1" data-path="multiple-testing.html"><a href="multiple-testing.html#the-bonferroni-correction"><i class="fa fa-check"></i><b>11.1</b> The Bonferroni correction</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="sources.html"><a href="sources.html"><i class="fa fa-check"></i><b>12</b> Sources</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sources.html"><a href="sources.html#t-test-1"><i class="fa fa-check"></i><b>12.1</b> t-test</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="sources.html"><a href="sources.html#two-tailed-test"><i class="fa fa-check"></i><b>12.1.1</b> Two-tailed test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>13</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="13.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>13.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="13.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#sources-1"><i class="fa fa-check"></i><b>13.2</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="t-test-anova-difference.html"><a href="t-test-anova-difference.html"><i class="fa fa-check"></i><b>14</b> t-test ANOVA difference</a></li>
<li class="chapter" data-level="15" data-path="chi-squared-test.html"><a href="chi-squared-test.html"><i class="fa fa-check"></i><b>15</b> Chi-squared test</a>
<ul>
<li class="chapter" data-level="15.1" data-path="chi-squared-test.html"><a href="chi-squared-test.html#multinomial-goodness-of-fit"><i class="fa fa-check"></i><b>15.1</b> Multinomial Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html"><i class="fa fa-check"></i><b>16</b> Non-parametric Methods</a>
<ul>
<li class="chapter" data-level="16.1" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#sign-test"><i class="fa fa-check"></i><b>16.1</b> Sign Test</a></li>
<li class="chapter" data-level="16.2" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>16.2</b> Wilcoxon Signed-Rank Test</a></li>
<li class="chapter" data-level="16.3" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#mann-whitney-wilcoxon-test"><i class="fa fa-check"></i><b>16.3</b> Mann-Whitney-Wilcoxon Test</a></li>
<li class="chapter" data-level="16.4" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>16.4</b> Kruskal-Wallis Test</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="wilcoxon-signed-rank-test-1.html"><a href="wilcoxon-signed-rank-test-1.html"><i class="fa fa-check"></i><b>17</b> Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="18" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>18</b> Support Vector Machine</a></li>
<li class="chapter" data-level="19" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>19</b> Correlation</a></li>
<li class="chapter" data-level="20" data-path="methods-and-algorithms-of-machine-learning.html"><a href="methods-and-algorithms-of-machine-learning.html"><i class="fa fa-check"></i><b>20</b> Methods and algorithms of machine learning</a></li>
<li class="chapter" data-level="21" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html"><i class="fa fa-check"></i><b>21</b> Machine Learning Functions Reference</a>
<ul>
<li class="chapter" data-level="21.1" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html#linear-regression"><i class="fa fa-check"></i><b>21.1</b> Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="split-data-into-train-and-test-subsets.html"><a href="split-data-into-train-and-test-subsets.html"><i class="fa fa-check"></i><b>22</b> Split data into train and test subsets</a></li>
<li class="chapter" data-level="23" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>23</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="23.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression---theory"><i class="fa fa-check"></i><b>23.1</b> Linear regression - theory</a></li>
<li class="chapter" data-level="23.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-random-data-set-for-the-linear-model"><i class="fa fa-check"></i><b>23.2</b> Generate random data set for the linear model</a></li>
<li class="chapter" data-level="23.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-example"><i class="fa fa-check"></i><b>23.3</b> Practical example</a></li>
<li class="chapter" data-level="23.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#mean-squared-error-mse"><i class="fa fa-check"></i><b>23.4</b> Mean squared error (MSE)</a></li>
<li class="chapter" data-level="23.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-model-in-r"><i class="fa fa-check"></i><b>23.5</b> Linear model in R</a></li>
<li class="chapter" data-level="23.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression-model-for-multiple-parameters"><i class="fa fa-check"></i><b>23.6</b> Linear regression model for multiple parameters</a></li>
<li class="chapter" data-level="23.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#choosing-explanatory-variables-for-the-model"><i class="fa fa-check"></i><b>23.7</b> Choosing explanatory variables for the model</a></li>
<li class="chapter" data-level="23.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#assessment-of-model-performance-for-categorical-data."><i class="fa fa-check"></i><b>23.8</b> Assessment of model performance for categorical data.</a></li>
<li class="chapter" data-level="23.9" data-path="linear-regression-1.html"><a href="linear-regression-1.html#confidence-intervals-for-linear-model"><i class="fa fa-check"></i><b>23.9</b> Confidence intervals for linear model</a></li>
<li class="chapter" data-level="23.10" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression"><i class="fa fa-check"></i><b>23.10</b> Practical examples for linear model regression</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html"><i class="fa fa-check"></i><b>24</b> Linear regression complex cases</a>
<ul>
<li class="chapter" data-level="24.1" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#cars"><i class="fa fa-check"></i><b>24.1</b> Cars</a></li>
<li class="chapter" data-level="24.2" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#linear-regression-modeling-compair-with-knn"><i class="fa fa-check"></i><b>24.2</b> Linear regression modeling, compair with kNN</a></li>
<li class="chapter" data-level="24.3" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#more-complex-example"><i class="fa fa-check"></i><b>24.3</b> More complex example</a></li>
<li class="chapter" data-level="24.4" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part"><i class="fa fa-check"></i><b>24.4</b> NEXT part</a></li>
<li class="chapter" data-level="24.5" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part-1"><i class="fa fa-check"></i><b>24.5</b> NEXT Part</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="nonlinear-regression.html"><a href="nonlinear-regression.html"><i class="fa fa-check"></i><b>25</b> Nonlinear regression</a></li>
<li class="chapter" data-level="26" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>26</b> Multiple linear regression</a></li>
<li class="chapter" data-level="27" data-path="spline-model.html"><a href="spline-model.html"><i class="fa fa-check"></i><b>27</b> Spline model</a>
<ul>
<li class="chapter" data-level="27.1" data-path="spline-model.html"><a href="spline-model.html#generate-dataset-from-a-given-function"><i class="fa fa-check"></i><b>27.1</b> Generate dataset from a given function</a></li>
<li class="chapter" data-level="27.2" data-path="spline-model.html"><a href="spline-model.html#split-data-for-train-and-test"><i class="fa fa-check"></i><b>27.2</b> Split data for train and test</a></li>
<li class="chapter" data-level="27.3" data-path="spline-model.html"><a href="spline-model.html#diagram-of-the-given-function-and-generated-datasets"><i class="fa fa-check"></i><b>27.3</b> Diagram of the given function and generated datasets</a></li>
<li class="chapter" data-level="27.4" data-path="spline-model.html"><a href="spline-model.html#build-a-model-using-splines"><i class="fa fa-check"></i><b>27.4</b> Build a model using splines</a></li>
<li class="chapter" data-level="27.5" data-path="spline-model.html"><a href="spline-model.html#diagram-of-mse-for-train-and-test-data"><i class="fa fa-check"></i><b>27.5</b> Diagram of MSE for train and test data</a></li>
<li class="chapter" data-level="27.6" data-path="spline-model.html"><a href="spline-model.html#build-optimal-model-and-plot-for-the-model"><i class="fa fa-check"></i><b>27.6</b> Build optimal model and plot for the model</a></li>
<li class="chapter" data-level="27.7" data-path="spline-model.html"><a href="spline-model.html#bibliograpy"><i class="fa fa-check"></i><b>27.7</b> Bibliograpy</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>28</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="28.1" data-path="logistic-regression.html"><a href="logistic-regression.html#confusion-matrix"><i class="fa fa-check"></i><b>28.1</b> Confusion matrix</a></li>
<li class="chapter" data-level="28.2" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-2"><i class="fa fa-check"></i><b>28.2</b> Next part</a></li>
<li class="chapter" data-level="28.3" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-3"><i class="fa fa-check"></i><b>28.3</b> NExt part</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>29</b> Clustering</a>
<ul>
<li class="chapter" data-level="29.1" data-path="clustering.html"><a href="clustering.html#next-part-4"><i class="fa fa-check"></i><b>29.1</b> Next part</a></li>
<li class="chapter" data-level="29.2" data-path="clustering.html"><a href="clustering.html#example"><i class="fa fa-check"></i><b>29.2</b> Example</a></li>
<li class="chapter" data-level="29.3" data-path="clustering.html"><a href="clustering.html#next-part-5"><i class="fa fa-check"></i><b>29.3</b> NEXT PART</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="learning-vector-quantization.html"><a href="learning-vector-quantization.html"><i class="fa fa-check"></i><b>30</b> Learning Vector Quantization</a></li>
<li class="chapter" data-level="31" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>31</b> Bayesian Statistics</a>
<ul>
<li class="chapter" data-level="31.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#simple-model-with-one-binary-parameter"><i class="fa fa-check"></i><b>31.1</b> Simple model with one binary parameter</a></li>
<li class="chapter" data-level="31.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#website-visitors-model"><i class="fa fa-check"></i><b>31.2</b> Website visitors model</a></li>
<li class="chapter" data-level="31.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#the-best-models"><i class="fa fa-check"></i><b>31.3</b> The BEST models</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>32</b> Naive Bayes</a></li>
<li class="chapter" data-level="33" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>33</b> Markov Chain Monte Carlo (MCMC)</a></li>
<li class="chapter" data-level="34" data-path="simple-markov-process.html"><a href="simple-markov-process.html"><i class="fa fa-check"></i><b>34</b> Simple Markov process</a>
<ul>
<li class="chapter" data-level="34.0.1" data-path="simple-markov-process.html"><a href="simple-markov-process.html#sources-2"><i class="fa fa-check"></i><b>34.0.1</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>35</b> Tree-based models</a>
<ul>
<li class="chapter" data-level="35.1" data-path="tree-based-models.html"><a href="tree-based-models.html#classification-tree-example"><i class="fa fa-check"></i><b>35.1</b> Classification Tree example</a></li>
<li class="chapter" data-level="35.2" data-path="tree-based-models.html"><a href="tree-based-models.html#regression-tree-example"><i class="fa fa-check"></i><b>35.2</b> Regression Tree example</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="clustering" class="section level1" number="29">
<h1><span class="header-section-number">Chapter 29</span> Clustering</h1>
<p>5 classes of clustering methods:<br />
1. <strong>Partitioning methods</strong> - split into k-groups (k-means, k-dedoids (PAM), CLARA)<br />
2. <strong>Hierarchical clustering</strong><br />
3. <strong>Fuzzy clustering</strong><br />
4. <strong>Density-based clustering</strong><br />
5. <strong>Model-based clustering</strong></p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="clustering.html#cb222-1" aria-hidden="true" tabindex="-1"></a>bv <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;./DATA/beverage.csv&quot;</span>, <span class="at">header=</span>T, <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)  </span>
<span id="cb222-2"><a href="clustering.html#cb222-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bv)  </span>
<span id="cb222-3"><a href="clustering.html#cb222-3" aria-hidden="true" tabindex="-1"></a><span class="co"># no needs to normalize because all data is binary (0,1)</span></span>
<span id="cb222-4"><a href="clustering.html#cb222-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-5"><a href="clustering.html#cb222-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Hierarchical clustering</span></span>
<span id="cb222-6"><a href="clustering.html#cb222-6" aria-hidden="true" tabindex="-1"></a><span class="co"># dist - calculate distances</span></span>
<span id="cb222-7"><a href="clustering.html#cb222-7" aria-hidden="true" tabindex="-1"></a><span class="co"># hclust - hierarchical clustering</span></span>
<span id="cb222-8"><a href="clustering.html#cb222-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-9"><a href="clustering.html#cb222-9" aria-hidden="true" tabindex="-1"></a>clust.bv <span class="ot">&lt;-</span> <span class="fu">hclust</span>(<span class="fu">dist</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>]), <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb222-10"><a href="clustering.html#cb222-10" aria-hidden="true" tabindex="-1"></a>clust.bv</span>
<span id="cb222-11"><a href="clustering.html#cb222-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-12"><a href="clustering.html#cb222-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot clusters</span></span>
<span id="cb222-13"><a href="clustering.html#cb222-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(clust.bv)</span>
<span id="cb222-14"><a href="clustering.html#cb222-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(clust.bv, <span class="at">hang =</span> <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb222-15"><a href="clustering.html#cb222-15" aria-hidden="true" tabindex="-1"></a><span class="fu">rect.hclust</span>(clust.bv, <span class="at">k=</span><span class="dv">3</span>, <span class="at">border=</span><span class="st">&quot;red&quot;</span>) </span>
<span id="cb222-16"><a href="clustering.html#cb222-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-17"><a href="clustering.html#cb222-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Group data by clusters</span></span>
<span id="cb222-18"><a href="clustering.html#cb222-18" aria-hidden="true" tabindex="-1"></a>groups <span class="ot">&lt;-</span> <span class="fu">cutree</span>(clust.bv, <span class="at">k=</span><span class="dv">3</span>)</span>
<span id="cb222-19"><a href="clustering.html#cb222-19" aria-hidden="true" tabindex="-1"></a>groups</span>
<span id="cb222-20"><a href="clustering.html#cb222-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-21"><a href="clustering.html#cb222-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Percentage in broups by drinking different beverages</span></span>
<span id="cb222-22"><a href="clustering.html#cb222-22" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(bv[groups<span class="sc">==</span><span class="dv">1</span>, <span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb222-23"><a href="clustering.html#cb222-23" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(bv[groups<span class="sc">==</span><span class="dv">2</span>, <span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb222-24"><a href="clustering.html#cb222-24" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(bv[groups<span class="sc">==</span><span class="dv">3</span>, <span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb222-25"><a href="clustering.html#cb222-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-26"><a href="clustering.html#cb222-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpretation</span></span>
<span id="cb222-27"><a href="clustering.html#cb222-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. People who does not have specific preference</span></span>
<span id="cb222-28"><a href="clustering.html#cb222-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. People who prefers cola and pepsi</span></span>
<span id="cb222-29"><a href="clustering.html#cb222-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Not clear (others)</span></span>
<span id="cb222-30"><a href="clustering.html#cb222-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-31"><a href="clustering.html#cb222-31" aria-hidden="true" tabindex="-1"></a><span class="co"># atributes of cluster analysis</span></span>
<span id="cb222-32"><a href="clustering.html#cb222-32" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(clust.bv)</span>
<span id="cb222-33"><a href="clustering.html#cb222-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-34"><a href="clustering.html#cb222-34" aria-hidden="true" tabindex="-1"></a><span class="co"># chronic of combining</span></span>
<span id="cb222-35"><a href="clustering.html#cb222-35" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>merge</span>
<span id="cb222-36"><a href="clustering.html#cb222-36" aria-hidden="true" tabindex="-1"></a>clust.bv[<span class="dv">1</span>]</span>
<span id="cb222-37"><a href="clustering.html#cb222-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-38"><a href="clustering.html#cb222-38" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>height</span>
<span id="cb222-39"><a href="clustering.html#cb222-39" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>order</span>
<span id="cb222-40"><a href="clustering.html#cb222-40" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>labels</span>
<span id="cb222-41"><a href="clustering.html#cb222-41" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>method</span>
<span id="cb222-42"><a href="clustering.html#cb222-42" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>call</span>
<span id="cb222-43"><a href="clustering.html#cb222-43" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>dist.method</span>
<span id="cb222-44"><a href="clustering.html#cb222-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-45"><a href="clustering.html#cb222-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Detect the best choice for number of cluster by elbow-plot</span></span>
<span id="cb222-46"><a href="clustering.html#cb222-46" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">33</span>, clust.bv<span class="sc">$</span>height, <span class="at">type=</span><span class="st">&quot;l&quot;</span>)</span>
<span id="cb222-47"><a href="clustering.html#cb222-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-48"><a href="clustering.html#cb222-48" aria-hidden="true" tabindex="-1"></a><span class="do">### Task. Analyse data and find groups of people</span></span>
<span id="cb222-49"><a href="clustering.html#cb222-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Scores (0,10) of 10 tests for candidates to get a job.</span></span>
<span id="cb222-50"><a href="clustering.html#cb222-50" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Memorizing numbers</span></span>
<span id="cb222-51"><a href="clustering.html#cb222-51" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Math task</span></span>
<span id="cb222-52"><a href="clustering.html#cb222-52" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Solving tasks in dialoge</span></span>
<span id="cb222-53"><a href="clustering.html#cb222-53" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Algorithms</span></span>
<span id="cb222-54"><a href="clustering.html#cb222-54" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Self confidence</span></span>
<span id="cb222-55"><a href="clustering.html#cb222-55" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Work in group</span></span>
<span id="cb222-56"><a href="clustering.html#cb222-56" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Find solution</span></span>
<span id="cb222-57"><a href="clustering.html#cb222-57" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. Collaboration</span></span>
<span id="cb222-58"><a href="clustering.html#cb222-58" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. Acceptance by others</span></span>
<span id="cb222-59"><a href="clustering.html#cb222-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-60"><a href="clustering.html#cb222-60" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;~/DataAnalysis&quot;</span>)</span>
<span id="cb222-61"><a href="clustering.html#cb222-61" aria-hidden="true" tabindex="-1"></a>job <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;DATA/assess.dat&quot;</span>, <span class="at">header=</span>T, <span class="at">sep=</span><span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>)</span>
<span id="cb222-62"><a href="clustering.html#cb222-62" aria-hidden="true" tabindex="-1"></a>job</span>
<span id="cb222-63"><a href="clustering.html#cb222-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-64"><a href="clustering.html#cb222-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb222-65"><a href="clustering.html#cb222-65" aria-hidden="true" tabindex="-1"></a>clust.job <span class="ot">&lt;-</span> <span class="fu">hclust</span>(<span class="fu">dist</span>(job[,<span class="dv">3</span><span class="sc">:</span><span class="fu">ncol</span>(job)]), <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb222-66"><a href="clustering.html#cb222-66" aria-hidden="true" tabindex="-1"></a><span class="co"># no needs to normalize, because all numbers have the same min, max</span></span>
<span id="cb222-67"><a href="clustering.html#cb222-67" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(clust.job)  <span class="co"># visual number of clusters is 4</span></span>
<span id="cb222-68"><a href="clustering.html#cb222-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-69"><a href="clustering.html#cb222-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Group data by clusters</span></span>
<span id="cb222-70"><a href="clustering.html#cb222-70" aria-hidden="true" tabindex="-1"></a>groups <span class="ot">&lt;-</span> <span class="fu">cutree</span>(clust.job, <span class="at">k=</span><span class="dv">4</span>)</span>
<span id="cb222-71"><a href="clustering.html#cb222-71" aria-hidden="true" tabindex="-1"></a>groups</span>
<span id="cb222-72"><a href="clustering.html#cb222-72" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(job[groups<span class="sc">==</span><span class="dv">1</span>, <span class="dv">3</span><span class="sc">:</span><span class="dv">12</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb222-73"><a href="clustering.html#cb222-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-74"><a href="clustering.html#cb222-74" aria-hidden="true" tabindex="-1"></a><span class="do">### Find clusters using k-means method</span></span>
<span id="cb222-75"><a href="clustering.html#cb222-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-76"><a href="clustering.html#cb222-76" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;~/DataAnalysis&quot;</span>)</span>
<span id="cb222-77"><a href="clustering.html#cb222-77" aria-hidden="true" tabindex="-1"></a>bv <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;DATA/beverage.csv&quot;</span>, <span class="at">header=</span>T, <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)</span>
<span id="cb222-78"><a href="clustering.html#cb222-78" aria-hidden="true" tabindex="-1"></a>bv</span>
<span id="cb222-79"><a href="clustering.html#cb222-79" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(bv)</span>
<span id="cb222-80"><a href="clustering.html#cb222-80" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(bv)</span>
<span id="cb222-81"><a href="clustering.html#cb222-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-82"><a href="clustering.html#cb222-82" aria-hidden="true" tabindex="-1"></a><span class="co"># k-means clustering, with initial 3 clusters</span></span>
<span id="cb222-83"><a href="clustering.html#cb222-83" aria-hidden="true" tabindex="-1"></a><span class="co"># nstart = x - run x times with different initial clusters</span></span>
<span id="cb222-84"><a href="clustering.html#cb222-84" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>], <span class="dv">3</span>, <span class="at">iter.max =</span> <span class="dv">100</span>)</span>
<span id="cb222-85"><a href="clustering.html#cb222-85" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(summ<span class="fl">.1</span>)</span>
<span id="cb222-86"><a href="clustering.html#cb222-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-87"><a href="clustering.html#cb222-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Objects by clusters</span></span>
<span id="cb222-88"><a href="clustering.html#cb222-88" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>cluster</span>
<span id="cb222-89"><a href="clustering.html#cb222-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-90"><a href="clustering.html#cb222-90" aria-hidden="true" tabindex="-1"></a><span class="co"># Centers of clusters</span></span>
<span id="cb222-91"><a href="clustering.html#cb222-91" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>centers</span>
<span id="cb222-92"><a href="clustering.html#cb222-92" aria-hidden="true" tabindex="-1"></a><span class="co"># 2 digits after point</span></span>
<span id="cb222-93"><a href="clustering.html#cb222-93" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits=</span><span class="dv">2</span>)</span>
<span id="cb222-94"><a href="clustering.html#cb222-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-95"><a href="clustering.html#cb222-95" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(summ<span class="fl">.1</span><span class="sc">$</span>centers)</span>
<span id="cb222-96"><a href="clustering.html#cb222-96" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits=</span><span class="dv">7</span>)</span>
<span id="cb222-97"><a href="clustering.html#cb222-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-98"><a href="clustering.html#cb222-98" aria-hidden="true" tabindex="-1"></a><span class="co"># Square summs</span></span>
<span id="cb222-99"><a href="clustering.html#cb222-99" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>withinss</span>
<span id="cb222-100"><a href="clustering.html#cb222-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-101"><a href="clustering.html#cb222-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Summ of elements of vector</span></span>
<span id="cb222-102"><a href="clustering.html#cb222-102" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>tot.withinss</span>
<span id="cb222-103"><a href="clustering.html#cb222-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-104"><a href="clustering.html#cb222-104" aria-hidden="true" tabindex="-1"></a><span class="co"># sum(33*(apply(bv[,2:9], 2, sd))^2)</span></span>
<span id="cb222-105"><a href="clustering.html#cb222-105" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>totss</span>
<span id="cb222-106"><a href="clustering.html#cb222-106" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>tot.betweenss</span>
<span id="cb222-107"><a href="clustering.html#cb222-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-108"><a href="clustering.html#cb222-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Size of clusters</span></span>
<span id="cb222-109"><a href="clustering.html#cb222-109" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>size</span>
<span id="cb222-110"><a href="clustering.html#cb222-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-111"><a href="clustering.html#cb222-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Elbow plot to detect optimal number of clusters</span></span>
<span id="cb222-112"><a href="clustering.html#cb222-112" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],<span class="dv">2</span>,var))</span>
<span id="cb222-113"><a href="clustering.html#cb222-113" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>) { wss[i] <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],</span>
<span id="cb222-114"><a href="clustering.html#cb222-114" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span>i)<span class="sc">$</span>tot.withinss }</span>
<span id="cb222-115"><a href="clustering.html#cb222-115" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, wss, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Number of Clusters&quot;</span>,</span>
<span id="cb222-116"><a href="clustering.html#cb222-116" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Within groups sum of squares&quot;</span>)</span>
<span id="cb222-117"><a href="clustering.html#cb222-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-118"><a href="clustering.html#cb222-118" aria-hidden="true" tabindex="-1"></a><span class="co"># We can see that diagram is rough. This is because clusters are not allways optimal</span></span>
<span id="cb222-119"><a href="clustering.html#cb222-119" aria-hidden="true" tabindex="-1"></a><span class="co"># To improve situation, we have to run many initiall start coordinates and choose the best</span></span>
<span id="cb222-120"><a href="clustering.html#cb222-120" aria-hidden="true" tabindex="-1"></a><span class="co"># option (add nstart=500):</span></span>
<span id="cb222-121"><a href="clustering.html#cb222-121" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],<span class="dv">2</span>,var))</span>
<span id="cb222-122"><a href="clustering.html#cb222-122" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>) { wss[i] <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],</span>
<span id="cb222-123"><a href="clustering.html#cb222-123" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">centers=</span>i, <span class="at">nstart=</span><span class="dv">500</span>)<span class="sc">$</span>tot.withinss }</span>
<span id="cb222-124"><a href="clustering.html#cb222-124" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, wss, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Number of Clusters&quot;</span>,</span>
<span id="cb222-125"><a href="clustering.html#cb222-125" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Within groups sum of squares&quot;</span>)</span>
<span id="cb222-126"><a href="clustering.html#cb222-126" aria-hidden="true" tabindex="-1"></a><span class="co"># Warnings means that iterations were not finished for some cases.</span></span>
<span id="cb222-127"><a href="clustering.html#cb222-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-128"><a href="clustering.html#cb222-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s compair results for 3 and 4 clusters</span></span>
<span id="cb222-129"><a href="clustering.html#cb222-129" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>], <span class="dv">3</span>, <span class="at">iter.max=</span><span class="dv">100</span>)</span>
<span id="cb222-130"><a href="clustering.html#cb222-130" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.2</span> <span class="ot">=</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>], <span class="dv">4</span>, <span class="at">iter.max=</span><span class="dv">100</span>)</span>
<span id="cb222-131"><a href="clustering.html#cb222-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-132"><a href="clustering.html#cb222-132" aria-hidden="true" tabindex="-1"></a><span class="co"># Compair clusters. How many elements in each cluster</span></span>
<span id="cb222-133"><a href="clustering.html#cb222-133" aria-hidden="true" tabindex="-1"></a><span class="co"># We can see how elements move if we take more clusters</span></span>
<span id="cb222-134"><a href="clustering.html#cb222-134" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(summ<span class="fl">.1</span><span class="sc">$</span>cluster, summ<span class="fl">.2</span><span class="sc">$</span>cluster)</span>
<span id="cb222-135"><a href="clustering.html#cb222-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-136"><a href="clustering.html#cb222-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Multidimentional scaling</span></span>
<span id="cb222-137"><a href="clustering.html#cb222-137" aria-hidden="true" tabindex="-1"></a><span class="co"># Project multidimentional data to 2d</span></span>
<span id="cb222-138"><a href="clustering.html#cb222-138" aria-hidden="true" tabindex="-1"></a>bv.dist <span class="ot">&lt;-</span> <span class="fu">dist</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])</span>
<span id="cb222-139"><a href="clustering.html#cb222-139" aria-hidden="true" tabindex="-1"></a>bv.mds <span class="ot">&lt;-</span> <span class="fu">cmdscale</span>(bv.dist)</span>
<span id="cb222-140"><a href="clustering.html#cb222-140" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bv.mds, <span class="at">col =</span> summ<span class="fl">.1</span><span class="sc">$</span>cluster, <span class="at">xlab=</span><span class="st">&quot;Index&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb222-141"><a href="clustering.html#cb222-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-142"><a href="clustering.html#cb222-142" aria-hidden="true" tabindex="-1"></a><span class="co"># Detect optimal number of clusters</span></span>
<span id="cb222-143"><a href="clustering.html#cb222-143" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;NbClust&quot;</span>)</span>
<span id="cb222-144"><a href="clustering.html#cb222-144" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;NbClust&quot;</span>)</span>
<span id="cb222-145"><a href="clustering.html#cb222-145" aria-hidden="true" tabindex="-1"></a>Best <span class="ot">&lt;-</span> <span class="fu">NbClust</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],              <span class="co"># data </span></span>
<span id="cb222-146"><a href="clustering.html#cb222-146" aria-hidden="true" tabindex="-1"></a>                <span class="at">distance=</span><span class="st">&quot;euclidean&quot;</span>,  <span class="co"># distance method</span></span>
<span id="cb222-147"><a href="clustering.html#cb222-147" aria-hidden="true" tabindex="-1"></a>                <span class="at">min.nc=</span><span class="dv">2</span>,              <span class="co"># min number of clusters</span></span>
<span id="cb222-148"><a href="clustering.html#cb222-148" aria-hidden="true" tabindex="-1"></a>                <span class="at">max.nc=</span><span class="dv">8</span>,             <span class="co"># max number of clusters</span></span>
<span id="cb222-149"><a href="clustering.html#cb222-149" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">&quot;ward.D&quot;</span>,       <span class="co"># ward methodes </span></span>
<span id="cb222-150"><a href="clustering.html#cb222-150" aria-hidden="true" tabindex="-1"></a>                <span class="at">index =</span> <span class="st">&quot;alllong&quot;</span> )    <span class="co"># choose indices</span></span></code></pre></div>
<div id="next-part-4" class="section level2" number="29.1">
<h2><span class="header-section-number">29.1</span> Next part</h2>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="clustering.html#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb223-2"><a href="clustering.html#cb223-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb223-3"><a href="clustering.html#cb223-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-4"><a href="clustering.html#cb223-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-5"><a href="clustering.html#cb223-5" aria-hidden="true" tabindex="-1"></a>Distances<span class="sc">:</span></span>
<span id="cb223-6"><a href="clustering.html#cb223-6" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">dist</span>()</span>
<span id="cb223-7"><a href="clustering.html#cb223-7" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">get_dist</span>()   <span class="co"># compute a distance matrix between the rows of a data matrix</span></span>
<span id="cb223-8"><a href="clustering.html#cb223-8" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_dist</span>()  <span class="co"># visualize distance matrix</span></span>
<span id="cb223-9"><a href="clustering.html#cb223-9" aria-hidden="true" tabindex="-1"></a>cluster<span class="sc">::</span><span class="fu">daisy</span>()         <span class="co"># handle both numeric and not numeric (nominal, ordinal,...) data types</span></span>
<span id="cb223-10"><a href="clustering.html#cb223-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-11"><a href="clustering.html#cb223-11" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> factoextra<span class="sc">::</span><span class="fu">get_dist</span>(USArrests, <span class="at">stand =</span> <span class="cn">TRUE</span>, <span class="at">method =</span> <span class="st">&#39;pearson&#39;</span>)</span>
<span id="cb223-12"><a href="clustering.html#cb223-12" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_dist</span>(d, <span class="at">gradient =</span> <span class="fu">list</span>(<span class="at">low=</span><span class="st">&#39;blue&#39;</span>, <span class="at">mid=</span><span class="st">&#39;white&#39;</span>, <span class="at">high=</span><span class="st">&#39;red&#39;</span>))</span>
<span id="cb223-13"><a href="clustering.html#cb223-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-14"><a href="clustering.html#cb223-14" aria-hidden="true" tabindex="-1"></a><span class="do">#####</span></span>
<span id="cb223-15"><a href="clustering.html#cb223-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb223-16"><a href="clustering.html#cb223-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb223-17"><a href="clustering.html#cb223-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb223-18"><a href="clustering.html#cb223-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-19"><a href="clustering.html#cb223-19" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> USArrests <span class="sc">%&gt;%</span> <span class="fu">na.omit</span>() <span class="sc">%&gt;%</span> <span class="fu">scale</span>()</span>
<span id="cb223-20"><a href="clustering.html#cb223-20" aria-hidden="true" tabindex="-1"></a>data</span>
<span id="cb223-21"><a href="clustering.html#cb223-21" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_nbclust</span>(data, kmeans, <span class="at">method =</span> <span class="st">&#39;gap_stat&#39;</span>)</span>
<span id="cb223-22"><a href="clustering.html#cb223-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-23"><a href="clustering.html#cb223-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-24"><a href="clustering.html#cb223-24" aria-hidden="true" tabindex="-1"></a>km.res <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(data, <span class="dv">3</span>, <span class="at">nstart =</span> <span class="dv">25</span>)</span>
<span id="cb223-25"><a href="clustering.html#cb223-25" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_cluster</span>(km.res, <span class="at">data =</span> data,</span>
<span id="cb223-26"><a href="clustering.html#cb223-26" aria-hidden="true" tabindex="-1"></a>                         <span class="at">ellipse.type =</span> <span class="st">&#39;convex&#39;</span>,</span>
<span id="cb223-27"><a href="clustering.html#cb223-27" aria-hidden="true" tabindex="-1"></a>                         <span class="at">palette =</span> <span class="st">&#39;jco&#39;</span>,</span>
<span id="cb223-28"><a href="clustering.html#cb223-28" aria-hidden="true" tabindex="-1"></a>                         <span class="at">repel =</span> <span class="cn">TRUE</span>,</span>
<span id="cb223-29"><a href="clustering.html#cb223-29" aria-hidden="true" tabindex="-1"></a>                         <span class="at">ggtheme =</span> <span class="fu">theme_minimal</span>())</span>
<span id="cb223-30"><a href="clustering.html#cb223-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-31"><a href="clustering.html#cb223-31" aria-hidden="true" tabindex="-1"></a><span class="co"># PAM clustering</span></span>
<span id="cb223-32"><a href="clustering.html#cb223-32" aria-hidden="true" tabindex="-1"></a>pam.res <span class="ot">&lt;-</span> cluster<span class="sc">::</span><span class="fu">pam</span>(data, <span class="dv">4</span>)</span>
<span id="cb223-33"><a href="clustering.html#cb223-33" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_cluster</span>(pam.res)</span>
<span id="cb223-34"><a href="clustering.html#cb223-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-35"><a href="clustering.html#cb223-35" aria-hidden="true" tabindex="-1"></a><span class="co"># CLARA clustering</span></span>
<span id="cb223-36"><a href="clustering.html#cb223-36" aria-hidden="true" tabindex="-1"></a>clara.res <span class="ot">&lt;-</span> <span class="fu">clara</span>(df, <span class="dv">2</span>, <span class="at">samples =</span> <span class="dv">50</span>, <span class="at">pamLike =</span> <span class="cn">TRUE</span>)</span>
<span id="cb223-37"><a href="clustering.html#cb223-37" aria-hidden="true" tabindex="-1"></a>clara.res</span>
<span id="cb223-38"><a href="clustering.html#cb223-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-39"><a href="clustering.html#cb223-39" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">&lt;-</span> <span class="fu">cbind</span>(df, <span class="at">cluster =</span> clara.res<span class="sc">$</span>cluster)</span>
<span id="cb223-40"><a href="clustering.html#cb223-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-41"><a href="clustering.html#cb223-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Medoids</span></span>
<span id="cb223-42"><a href="clustering.html#cb223-42" aria-hidden="true" tabindex="-1"></a>clara.res<span class="sc">$</span>medoids</span>
<span id="cb223-43"><a href="clustering.html#cb223-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb223-44"><a href="clustering.html#cb223-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb223-45"><a href="clustering.html#cb223-45" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(clara.res<span class="sc">$</span>clustering,<span class="dv">10</span>)</span></code></pre></div>
</div>
<div id="example" class="section level2" number="29.2">
<h2><span class="header-section-number">29.2</span> Example</h2>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="clustering.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(datasets)</span>
<span id="cb224-2"><a href="clustering.html#cb224-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code></pre></div>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species id
## 1          5.1         3.5          1.4         0.2  setosa  1
## 2          4.9         3.0          1.4         0.2  setosa  2
## 3          4.7         3.2          1.3         0.2  setosa  3
## 4          4.6         3.1          1.5         0.2  setosa  4
## 5          5.0         3.6          1.4         0.2  setosa  5
## 6          5.4         3.9          1.7         0.4  setosa  6</code></pre>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="clustering.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Petal.Length ~ Petal.Width data</span></span>
<span id="cb226-2"><a href="clustering.html#cb226-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Petal.Length <span class="sc">~</span> iris<span class="sc">$</span>Petal.Width)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/setup-1.png" width="672" /></p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="clustering.html#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20</span>)</span>
<span id="cb227-2"><a href="clustering.html#cb227-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb227-3"><a href="clustering.html#cb227-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Find number of clusters using wss</span></span>
<span id="cb227-4"><a href="clustering.html#cb227-4" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>])<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>],<span class="dv">2</span>,var))</span>
<span id="cb227-5"><a href="clustering.html#cb227-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>) wss[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">kmeans</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>], i)<span class="sc">$</span>withinss)</span>
<span id="cb227-6"><a href="clustering.html#cb227-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, wss, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Number of Clusters&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Within groups sum of squares&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/setup-2.png" width="672" /></p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="clustering.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="co">#More than 3 clusters give no obvious advantages</span></span>
<span id="cb228-2"><a href="clustering.html#cb228-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb228-3"><a href="clustering.html#cb228-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Make k-means with 3 clasters</span></span>
<span id="cb228-4"><a href="clustering.html#cb228-4" aria-hidden="true" tabindex="-1"></a>ncl <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb228-5"><a href="clustering.html#cb228-5" aria-hidden="true" tabindex="-1"></a>irisCluster <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>], ncl, <span class="at">nstart =</span> <span class="dv">20</span>)</span>
<span id="cb228-6"><a href="clustering.html#cb228-6" aria-hidden="true" tabindex="-1"></a>irisCluster</span></code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 48, 50, 52
## 
## Cluster means:
##   Petal.Length Petal.Width
## 1     5.595833    2.037500
## 2     1.462000    0.246000
## 3     4.269231    1.342308
## 
## Clustering vector:
##   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 1
##  [85] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1
## 
## Within cluster sum of squares by cluster:
## [1] 16.29167  2.02200 13.05769
##  (between_SS / total_SS =  94.3 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;         &quot;ifault&quot;</code></pre>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="clustering.html#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compair result of clustering with real data (3 species of iris are in analysis)</span></span>
<span id="cb230-2"><a href="clustering.html#cb230-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(irisCluster<span class="sc">$</span>cluster, iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>##    
##     setosa versicolor virginica
##   1      0          2        46
##   2     50          0         0
##   3      0         48         4</code></pre>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="clustering.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot data</span></span>
<span id="cb232-2"><a href="clustering.html#cb232-2" aria-hidden="true" tabindex="-1"></a>clusters <span class="ot">&lt;-</span> <span class="fu">split.data.frame</span>(iris, irisCluster<span class="sc">$</span>cluster)</span>
<span id="cb232-3"><a href="clustering.html#cb232-3" aria-hidden="true" tabindex="-1"></a>xlim <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">min</span>(iris<span class="sc">$</span>Petal.Width), <span class="fu">max</span>(iris<span class="sc">$</span>Petal.Width))</span>
<span id="cb232-4"><a href="clustering.html#cb232-4" aria-hidden="true" tabindex="-1"></a>ylim <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">min</span>(iris<span class="sc">$</span>Petal.Length), <span class="fu">max</span>(iris<span class="sc">$</span>Petal.Length))</span>
<span id="cb232-5"><a href="clustering.html#cb232-5" aria-hidden="true" tabindex="-1"></a>col <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;green&#39;</span>, <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb232-6"><a href="clustering.html#cb232-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span>, <span class="at">xlab=</span><span class="st">&#39;Petal width&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;Petal length&#39;</span>, <span class="at">xlim=</span>xlim, <span class="at">ylim=</span>ylim)</span>
<span id="cb232-7"><a href="clustering.html#cb232-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>ncl ) {</span>
<span id="cb232-8"><a href="clustering.html#cb232-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(clusters[[i]]<span class="sc">$</span>Petal.Length <span class="sc">~</span> clusters[[i]]<span class="sc">$</span>Petal.Width, <span class="at">col=</span>col[i], <span class="at">xlim=</span>xlim, <span class="at">ylim=</span>ylim)</span>
<span id="cb232-9"><a href="clustering.html#cb232-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/setup-3.png" width="672" /></p>
</div>
<div id="next-part-5" class="section level2" number="29.3">
<h2><span class="header-section-number">29.3</span> NEXT PART</h2>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="clustering.html#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="co"># K-Nearest Neighbors or KNN is a clustering algorithm</span></span>
<span id="cb233-2"><a href="clustering.html#cb233-2" aria-hidden="true" tabindex="-1"></a><span class="co"># k is known number of clusters (usually sqrt(N), between 3-10, but may be different)</span></span>
<span id="cb233-3"><a href="clustering.html#cb233-3" aria-hidden="true" tabindex="-1"></a><span class="co"># samples must be normalized x = (x - min(x))/(max(x)-min(x))</span></span>
<span id="cb233-4"><a href="clustering.html#cb233-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-5"><a href="clustering.html#cb233-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span>
<span id="cb233-6"><a href="clustering.html#cb233-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris)   <span class="co"># detailed view of the data set</span></span>
<span id="cb233-7"><a href="clustering.html#cb233-7" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(iris)   <span class="co"># view data types, sample values, categorical values, etc</span></span>
<span id="cb233-8"><a href="clustering.html#cb233-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris)</span>
<span id="cb233-9"><a href="clustering.html#cb233-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-10"><a href="clustering.html#cb233-10" aria-hidden="true" tabindex="-1"></a><span class="co">#normalization function</span></span>
<span id="cb233-11"><a href="clustering.html#cb233-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-12"><a href="clustering.html#cb233-12" aria-hidden="true" tabindex="-1"></a>min_max_normalizer <span class="ot">&lt;-</span> <span class="cf">function</span>(x)</span>
<span id="cb233-13"><a href="clustering.html#cb233-13" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb233-14"><a href="clustering.html#cb233-14" aria-hidden="true" tabindex="-1"></a>    num <span class="ot">&lt;-</span> x <span class="sc">-</span> <span class="fu">min</span>(x) </span>
<span id="cb233-15"><a href="clustering.html#cb233-15" aria-hidden="true" tabindex="-1"></a>    denom <span class="ot">&lt;-</span> <span class="fu">max</span>(x) <span class="sc">-</span> <span class="fu">min</span>(x)</span>
<span id="cb233-16"><a href="clustering.html#cb233-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span> (num<span class="sc">/</span>denom)</span>
<span id="cb233-17"><a href="clustering.html#cb233-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb233-18"><a href="clustering.html#cb233-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-19"><a href="clustering.html#cb233-19" aria-hidden="true" tabindex="-1"></a><span class="co">#normalizing iris data set</span></span>
<span id="cb233-20"><a href="clustering.html#cb233-20" aria-hidden="true" tabindex="-1"></a>normalized_iris <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">lapply</span>(iris[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], min_max_normalizer))</span>
<span id="cb233-21"><a href="clustering.html#cb233-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-22"><a href="clustering.html#cb233-22" aria-hidden="true" tabindex="-1"></a><span class="co">#viewing normalized data</span></span>
<span id="cb233-23"><a href="clustering.html#cb233-23" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(normalized_iris)</span>
<span id="cb233-24"><a href="clustering.html#cb233-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-25"><a href="clustering.html#cb233-25" aria-hidden="true" tabindex="-1"></a><span class="co">#checking the data constituency</span></span>
<span id="cb233-26"><a href="clustering.html#cb233-26" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species)</span>
<span id="cb233-27"><a href="clustering.html#cb233-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-28"><a href="clustering.html#cb233-28" aria-hidden="true" tabindex="-1"></a><span class="co">#set seed for randomization</span></span>
<span id="cb233-29"><a href="clustering.html#cb233-29" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb233-30"><a href="clustering.html#cb233-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-31"><a href="clustering.html#cb233-31" aria-hidden="true" tabindex="-1"></a><span class="co"># setting the training-test split to 67% and 33% respectively</span></span>
<span id="cb233-32"><a href="clustering.html#cb233-32" aria-hidden="true" tabindex="-1"></a>random_samples <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">2</span>, <span class="fu">nrow</span>(iris), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.67</span>, <span class="fl">0.33</span>))</span>
<span id="cb233-33"><a href="clustering.html#cb233-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-34"><a href="clustering.html#cb233-34" aria-hidden="true" tabindex="-1"></a><span class="co"># training data set</span></span>
<span id="cb233-35"><a href="clustering.html#cb233-35" aria-hidden="true" tabindex="-1"></a>iris.training <span class="ot">&lt;-</span> iris[</span>
<span id="cb233-36"><a href="clustering.html#cb233-36" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] </span>
<span id="cb233-37"><a href="clustering.html#cb233-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-38"><a href="clustering.html#cb233-38" aria-hidden="true" tabindex="-1"></a><span class="co">#training labels</span></span>
<span id="cb233-39"><a href="clustering.html#cb233-39" aria-hidden="true" tabindex="-1"></a>iris.trainLabels <span class="ot">&lt;-</span> iris[</span>
<span id="cb233-40"><a href="clustering.html#cb233-40" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">1</span>, <span class="dv">5</span>]</span>
<span id="cb233-41"><a href="clustering.html#cb233-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-42"><a href="clustering.html#cb233-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-43"><a href="clustering.html#cb233-43" aria-hidden="true" tabindex="-1"></a><span class="co"># test data set</span></span>
<span id="cb233-44"><a href="clustering.html#cb233-44" aria-hidden="true" tabindex="-1"></a>iris.test <span class="ot">&lt;-</span> iris[</span>
<span id="cb233-45"><a href="clustering.html#cb233-45" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">2</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb233-46"><a href="clustering.html#cb233-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-47"><a href="clustering.html#cb233-47" aria-hidden="true" tabindex="-1"></a><span class="co">#testing labels</span></span>
<span id="cb233-48"><a href="clustering.html#cb233-48" aria-hidden="true" tabindex="-1"></a>iris.testLabels <span class="ot">&lt;-</span> iris[</span>
<span id="cb233-49"><a href="clustering.html#cb233-49" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">2</span>, <span class="dv">5</span>]</span>
<span id="cb233-50"><a href="clustering.html#cb233-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-51"><a href="clustering.html#cb233-51" aria-hidden="true" tabindex="-1"></a><span class="co">#setting library</span></span>
<span id="cb233-52"><a href="clustering.html#cb233-52" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb233-53"><a href="clustering.html#cb233-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-54"><a href="clustering.html#cb233-54" aria-hidden="true" tabindex="-1"></a><span class="co">#executing knn for k=3</span></span>
<span id="cb233-55"><a href="clustering.html#cb233-55" aria-hidden="true" tabindex="-1"></a>iris_model <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> iris.training, <span class="at">test =</span> iris.test, <span class="at">cl =</span> iris.trainLabels, <span class="at">k=</span><span class="dv">3</span>)</span>
<span id="cb233-56"><a href="clustering.html#cb233-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-57"><a href="clustering.html#cb233-57" aria-hidden="true" tabindex="-1"></a><span class="co">#summary of the model learnt</span></span>
<span id="cb233-58"><a href="clustering.html#cb233-58" aria-hidden="true" tabindex="-1"></a>iris_model</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="learning-vector-quantization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/30_clustering.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
