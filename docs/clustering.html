<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 26 Clustering | R statistics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 26 Clustering | R statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 26 Clustering | R statistics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Mark Goldberg" />


<meta name="date" content="2021-04-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic-regression.html"/>
<link rel="next" href="learning-vector-quantization.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html"><i class="fa fa-check"></i><b>2</b> Statistics R functions reference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#get-data"><i class="fa fa-check"></i><b>2.1</b> Get data</a></li>
<li class="chapter" data-level="2.2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#data-inspection"><i class="fa fa-check"></i><b>2.2</b> Data inspection</a></li>
<li class="chapter" data-level="2.3" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#plots"><i class="fa fa-check"></i><b>2.3</b> Plots</a></li>
<li class="chapter" data-level="2.4" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#analysis-of-the-distribution"><i class="fa fa-check"></i><b>2.4</b> Analysis of the distribution</a></li>
<li class="chapter" data-level="2.5" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#distributions"><i class="fa fa-check"></i><b>2.5</b> Distributions</a></li>
<li class="chapter" data-level="2.6" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#t-test"><i class="fa fa-check"></i><b>2.6</b> t-Test</a></li>
<li class="chapter" data-level="2.7" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#anova"><i class="fa fa-check"></i><b>2.7</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>3</b> Basic Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="basic-statistics.html"><a href="basic-statistics.html#definitions"><i class="fa fa-check"></i><b>3.1</b> Definitions</a></li>
<li class="chapter" data-level="3.2" data-path="basic-statistics.html"><a href="basic-statistics.html#analysis-of-sample-distribution"><i class="fa fa-check"></i><b>3.2</b> Analysis of sample distribution</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="basic-statistics.html"><a href="basic-statistics.html#histogram"><i class="fa fa-check"></i><b>3.2.1</b> Histogram</a></li>
<li class="chapter" data-level="3.2.2" data-path="basic-statistics.html"><a href="basic-statistics.html#outliers"><i class="fa fa-check"></i><b>3.2.2</b> Outliers</a></li>
<li class="chapter" data-level="3.2.3" data-path="basic-statistics.html"><a href="basic-statistics.html#normality"><i class="fa fa-check"></i><b>3.2.3</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="basic-statistics.html"><a href="basic-statistics.html#confidence-interval"><i class="fa fa-check"></i><b>3.3</b> Confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="primary-analysis.html"><a href="primary-analysis.html"><i class="fa fa-check"></i><b>4</b> Primary analysis</a></li>
<li class="chapter" data-level="5" data-path="statistical-distributions.html"><a href="statistical-distributions.html"><i class="fa fa-check"></i><b>5</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="statistical-distributions.html"><a href="statistical-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>5.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="5.2" data-path="statistical-distributions.html"><a href="statistical-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="statistical-distributions.html"><a href="statistical-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>5.3</b> Binomial Distribution</a></li>
<li class="chapter" data-level="5.4" data-path="statistical-distributions.html"><a href="statistical-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>5.4</b> Geometric Distribution</a></li>
<li class="chapter" data-level="5.5" data-path="statistical-distributions.html"><a href="statistical-distributions.html#uniform-distributions"><i class="fa fa-check"></i><b>5.5</b> Uniform Distributions</a></li>
<li class="chapter" data-level="5.6" data-path="statistical-distributions.html"><a href="statistical-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>5.6</b> Poisson Distribution</a></li>
<li class="chapter" data-level="5.7" data-path="statistical-distributions.html"><a href="statistical-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>5.7</b> Exponential Distribution</a></li>
<li class="chapter" data-level="5.8" data-path="statistical-distributions.html"><a href="statistical-distributions.html#chi-squared-distribution"><i class="fa fa-check"></i><b>5.8</b> Chi-squared Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-theory"><i class="fa fa-check"></i><b>6.1</b> Hypothesis testing theory</a></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-practice"><i class="fa fa-check"></i><b>6.2</b> Hypothesis test (Practice)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="t-procedures.html"><a href="t-procedures.html"><i class="fa fa-check"></i><b>7</b> t-Procedures</a>
<ul>
<li class="chapter" data-level="7.1" data-path="t-procedures.html"><a href="t-procedures.html#t-test-and-normal-distribution"><i class="fa fa-check"></i><b>7.1</b> t-test and normal distribution</a></li>
<li class="chapter" data-level="7.2" data-path="t-procedures.html"><a href="t-procedures.html#one-sample-t-test"><i class="fa fa-check"></i><b>7.2</b> One-sample t-test</a></li>
<li class="chapter" data-level="7.3" data-path="t-procedures.html"><a href="t-procedures.html#practical-example-t-test-in-r"><i class="fa fa-check"></i><b>7.3</b> Practical example: t-test in R</a></li>
<li class="chapter" data-level="7.4" data-path="t-procedures.html"><a href="t-procedures.html#two-samples-t-test"><i class="fa fa-check"></i><b>7.4</b> Two samples t-test</a></li>
<li class="chapter" data-level="7.5" data-path="t-procedures.html"><a href="t-procedures.html#compare-students-t-and-normal-distributions"><i class="fa fa-check"></i><b>7.5</b> Compare Student’s t and normal distributions</a></li>
<li class="chapter" data-level="7.6" data-path="t-procedures.html"><a href="t-procedures.html#non-parametric-tests"><i class="fa fa-check"></i><b>7.6</b> Non-parametric tests</a></li>
<li class="chapter" data-level="7.7" data-path="t-procedures.html"><a href="t-procedures.html#mann-whitney-u-rank-sum-test"><i class="fa fa-check"></i><b>7.7</b> Mann-Whitney U Rank Sum Test</a></li>
<li class="chapter" data-level="7.8" data-path="t-procedures.html"><a href="t-procedures.html#wilcoxon-test"><i class="fa fa-check"></i><b>7.8</b> Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html"><i class="fa fa-check"></i><b>8</b> Tests for categorical variables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html#chi-squared-tests"><i class="fa fa-check"></i><b>8.1</b> Chi-squared tests</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>9</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="9.1" data-path="multiple-testing.html"><a href="multiple-testing.html#the-bonferroni-correction"><i class="fa fa-check"></i><b>9.1</b> The Bonferroni correction</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sources.html"><a href="sources.html"><i class="fa fa-check"></i><b>10</b> Sources</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sources.html"><a href="sources.html#t-test-1"><i class="fa fa-check"></i><b>10.1</b> t-test</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="sources.html"><a href="sources.html#two-tailed-test"><i class="fa fa-check"></i><b>10.1.1</b> Two-tailed test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>11</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>11.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="11.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#sources-1"><i class="fa fa-check"></i><b>11.2</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="t-test-anova-difference.html"><a href="t-test-anova-difference.html"><i class="fa fa-check"></i><b>12</b> t-test ANOVA difference</a></li>
<li class="chapter" data-level="13" data-path="chi-squared-test.html"><a href="chi-squared-test.html"><i class="fa fa-check"></i><b>13</b> Chi-squared test</a>
<ul>
<li class="chapter" data-level="13.1" data-path="chi-squared-test.html"><a href="chi-squared-test.html#multinomial-goodness-of-fit"><i class="fa fa-check"></i><b>13.1</b> Multinomial Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html"><i class="fa fa-check"></i><b>14</b> Non-parametric Methods</a>
<ul>
<li class="chapter" data-level="14.1" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#sign-test"><i class="fa fa-check"></i><b>14.1</b> Sign Test</a></li>
<li class="chapter" data-level="14.2" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>14.2</b> Wilcoxon Signed-Rank Test</a></li>
<li class="chapter" data-level="14.3" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#mann-whitney-wilcoxon-test"><i class="fa fa-check"></i><b>14.3</b> Mann-Whitney-Wilcoxon Test</a></li>
<li class="chapter" data-level="14.4" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>14.4</b> Kruskal-Wallis Test</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="wilcoxon-signed-rank-test-1.html"><a href="wilcoxon-signed-rank-test-1.html"><i class="fa fa-check"></i><b>15</b> Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="16" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>16</b> Support Vector Machine</a></li>
<li class="chapter" data-level="17" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>17</b> Correlation</a></li>
<li class="chapter" data-level="18" data-path="methods-and-algorithms-of-machine-learning.html"><a href="methods-and-algorithms-of-machine-learning.html"><i class="fa fa-check"></i><b>18</b> Methods and algorithms of machine learning</a></li>
<li class="chapter" data-level="19" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html"><i class="fa fa-check"></i><b>19</b> Machine Learning Functions Reference</a>
<ul>
<li class="chapter" data-level="19.1" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html#linear-regression"><i class="fa fa-check"></i><b>19.1</b> Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="split-data-into-train-and-test-subsets.html"><a href="split-data-into-train-and-test-subsets.html"><i class="fa fa-check"></i><b>20</b> Split data into train and test subsets</a></li>
<li class="chapter" data-level="21" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>21</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="21.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression---theory"><i class="fa fa-check"></i><b>21.1</b> Linear regression - theory</a></li>
<li class="chapter" data-level="21.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-random-data-set-for-the-linear-model"><i class="fa fa-check"></i><b>21.2</b> Generate random data set for the linear model</a></li>
<li class="chapter" data-level="21.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-example"><i class="fa fa-check"></i><b>21.3</b> Practical example</a></li>
<li class="chapter" data-level="21.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#mean-squared-error-mse"><i class="fa fa-check"></i><b>21.4</b> Mean squared error (MSE)</a></li>
<li class="chapter" data-level="21.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression-model-for-multiple-parameters"><i class="fa fa-check"></i><b>21.5</b> Linear regression model for multiple parameters</a></li>
<li class="chapter" data-level="21.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression-modeling-compair-with-knn"><i class="fa fa-check"></i><b>21.6</b> Linear regression modeling, compair with kNN</a></li>
<li class="chapter" data-level="21.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#more-complex-example"><i class="fa fa-check"></i><b>21.7</b> More complex example</a></li>
<li class="chapter" data-level="21.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#next-part"><i class="fa fa-check"></i><b>21.8</b> NEXT part</a></li>
<li class="chapter" data-level="21.9" data-path="linear-regression-1.html"><a href="linear-regression-1.html#next-part-1"><i class="fa fa-check"></i><b>21.9</b> NEXT Part</a></li>
<li class="chapter" data-level="21.10" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression"><i class="fa fa-check"></i><b>21.10</b> Practical examples for linear model regression</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="nonlinear-regression.html"><a href="nonlinear-regression.html"><i class="fa fa-check"></i><b>22</b> Nonlinear regression</a></li>
<li class="chapter" data-level="23" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>23</b> Multiple linear regression</a></li>
<li class="chapter" data-level="24" data-path="spline-model.html"><a href="spline-model.html"><i class="fa fa-check"></i><b>24</b> Spline model</a>
<ul>
<li class="chapter" data-level="24.1" data-path="spline-model.html"><a href="spline-model.html#generate-dataset-from-a-given-function"><i class="fa fa-check"></i><b>24.1</b> Generate dataset from a given function</a></li>
<li class="chapter" data-level="24.2" data-path="spline-model.html"><a href="spline-model.html#split-data-for-train-and-test"><i class="fa fa-check"></i><b>24.2</b> Split data for train and test</a></li>
<li class="chapter" data-level="24.3" data-path="spline-model.html"><a href="spline-model.html#diagram-of-the-given-function-and-generated-datasets"><i class="fa fa-check"></i><b>24.3</b> Diagram of the given function and generated datasets</a></li>
<li class="chapter" data-level="24.4" data-path="spline-model.html"><a href="spline-model.html#build-a-model-using-splines"><i class="fa fa-check"></i><b>24.4</b> Build a model using splines</a></li>
<li class="chapter" data-level="24.5" data-path="spline-model.html"><a href="spline-model.html#diagram-of-mse-for-train-and-test-data"><i class="fa fa-check"></i><b>24.5</b> Diagram of MSE for train and test data</a></li>
<li class="chapter" data-level="24.6" data-path="spline-model.html"><a href="spline-model.html#build-optimal-model-and-plot-for-the-model"><i class="fa fa-check"></i><b>24.6</b> Build optimal model and plot for the model</a></li>
<li class="chapter" data-level="24.7" data-path="spline-model.html"><a href="spline-model.html#bibliograpy"><i class="fa fa-check"></i><b>24.7</b> Bibliograpy</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>25</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="25.1" data-path="logistic-regression.html"><a href="logistic-regression.html#confusion-matrix"><i class="fa fa-check"></i><b>25.1</b> Confusion matrix</a></li>
<li class="chapter" data-level="25.2" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-2"><i class="fa fa-check"></i><b>25.2</b> Next part</a></li>
<li class="chapter" data-level="25.3" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-3"><i class="fa fa-check"></i><b>25.3</b> NExt part</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>26</b> Clustering</a>
<ul>
<li class="chapter" data-level="26.1" data-path="clustering.html"><a href="clustering.html#next-part-4"><i class="fa fa-check"></i><b>26.1</b> Next part</a></li>
<li class="chapter" data-level="26.2" data-path="clustering.html"><a href="clustering.html#example"><i class="fa fa-check"></i><b>26.2</b> Example</a></li>
<li class="chapter" data-level="26.3" data-path="clustering.html"><a href="clustering.html#next-part-5"><i class="fa fa-check"></i><b>26.3</b> NEXT PART</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="learning-vector-quantization.html"><a href="learning-vector-quantization.html"><i class="fa fa-check"></i><b>27</b> Learning Vector Quantization</a></li>
<li class="chapter" data-level="28" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>28</b> Naive Bayes</a></li>
<li class="chapter" data-level="29" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>29</b> Markov Chain Monte Carlo (MCMC)</a></li>
<li class="chapter" data-level="30" data-path="simple-markov-process.html"><a href="simple-markov-process.html"><i class="fa fa-check"></i><b>30</b> Simple Markov process</a>
<ul>
<li class="chapter" data-level="30.0.1" data-path="simple-markov-process.html"><a href="simple-markov-process.html#sources-2"><i class="fa fa-check"></i><b>30.0.1</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>31</b> Tree-based models</a>
<ul>
<li class="chapter" data-level="31.1" data-path="tree-based-models.html"><a href="tree-based-models.html#classification-tree-example"><i class="fa fa-check"></i><b>31.1</b> Classification Tree example</a></li>
<li class="chapter" data-level="31.2" data-path="tree-based-models.html"><a href="tree-based-models.html#regression-tree-example"><i class="fa fa-check"></i><b>31.2</b> Regression Tree example</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="clustering" class="section level1" number="26">
<h1><span class="header-section-number">Chapter 26</span> Clustering</h1>
<p>5 classes of clustering methods:<br />
1. <strong>Partitioning methods</strong> - split into k-groups (k-means, k-dedoids (PAM), CLARA)<br />
2. <strong>Hierarchical clustering</strong><br />
3. <strong>Fuzzy clustering</strong><br />
4. <strong>Density-based clustering</strong><br />
5. <strong>Model-based clustering</strong></p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="clustering.html#cb172-1" aria-hidden="true" tabindex="-1"></a>bv <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;./DATA/beverage.csv&quot;</span>, <span class="at">header=</span>T, <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)  </span>
<span id="cb172-2"><a href="clustering.html#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bv)  </span>
<span id="cb172-3"><a href="clustering.html#cb172-3" aria-hidden="true" tabindex="-1"></a><span class="co"># no needs to normalize because all data is binary (0,1)</span></span>
<span id="cb172-4"><a href="clustering.html#cb172-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-5"><a href="clustering.html#cb172-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Hierarchical clustering</span></span>
<span id="cb172-6"><a href="clustering.html#cb172-6" aria-hidden="true" tabindex="-1"></a><span class="co"># dist - calculate distances</span></span>
<span id="cb172-7"><a href="clustering.html#cb172-7" aria-hidden="true" tabindex="-1"></a><span class="co"># hclust - hierarchical clustering</span></span>
<span id="cb172-8"><a href="clustering.html#cb172-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-9"><a href="clustering.html#cb172-9" aria-hidden="true" tabindex="-1"></a>clust.bv <span class="ot">&lt;-</span> <span class="fu">hclust</span>(<span class="fu">dist</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>]), <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb172-10"><a href="clustering.html#cb172-10" aria-hidden="true" tabindex="-1"></a>clust.bv</span>
<span id="cb172-11"><a href="clustering.html#cb172-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-12"><a href="clustering.html#cb172-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot clusters</span></span>
<span id="cb172-13"><a href="clustering.html#cb172-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(clust.bv)</span>
<span id="cb172-14"><a href="clustering.html#cb172-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(clust.bv, <span class="at">hang =</span> <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb172-15"><a href="clustering.html#cb172-15" aria-hidden="true" tabindex="-1"></a><span class="fu">rect.hclust</span>(clust.bv, <span class="at">k=</span><span class="dv">3</span>, <span class="at">border=</span><span class="st">&quot;red&quot;</span>) </span>
<span id="cb172-16"><a href="clustering.html#cb172-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-17"><a href="clustering.html#cb172-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Group data by clusters</span></span>
<span id="cb172-18"><a href="clustering.html#cb172-18" aria-hidden="true" tabindex="-1"></a>groups <span class="ot">&lt;-</span> <span class="fu">cutree</span>(clust.bv, <span class="at">k=</span><span class="dv">3</span>)</span>
<span id="cb172-19"><a href="clustering.html#cb172-19" aria-hidden="true" tabindex="-1"></a>groups</span>
<span id="cb172-20"><a href="clustering.html#cb172-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-21"><a href="clustering.html#cb172-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Percentage in broups by drinking different beverages</span></span>
<span id="cb172-22"><a href="clustering.html#cb172-22" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(bv[groups<span class="sc">==</span><span class="dv">1</span>, <span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb172-23"><a href="clustering.html#cb172-23" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(bv[groups<span class="sc">==</span><span class="dv">2</span>, <span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb172-24"><a href="clustering.html#cb172-24" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(bv[groups<span class="sc">==</span><span class="dv">3</span>, <span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb172-25"><a href="clustering.html#cb172-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-26"><a href="clustering.html#cb172-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Interpretation</span></span>
<span id="cb172-27"><a href="clustering.html#cb172-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. People who does not have specific preference</span></span>
<span id="cb172-28"><a href="clustering.html#cb172-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. People who prefers cola and pepsi</span></span>
<span id="cb172-29"><a href="clustering.html#cb172-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Not clear (others)</span></span>
<span id="cb172-30"><a href="clustering.html#cb172-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-31"><a href="clustering.html#cb172-31" aria-hidden="true" tabindex="-1"></a><span class="co"># atributes of cluster analysis</span></span>
<span id="cb172-32"><a href="clustering.html#cb172-32" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(clust.bv)</span>
<span id="cb172-33"><a href="clustering.html#cb172-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-34"><a href="clustering.html#cb172-34" aria-hidden="true" tabindex="-1"></a><span class="co"># chronic of combining</span></span>
<span id="cb172-35"><a href="clustering.html#cb172-35" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>merge</span>
<span id="cb172-36"><a href="clustering.html#cb172-36" aria-hidden="true" tabindex="-1"></a>clust.bv[<span class="dv">1</span>]</span>
<span id="cb172-37"><a href="clustering.html#cb172-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-38"><a href="clustering.html#cb172-38" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>height</span>
<span id="cb172-39"><a href="clustering.html#cb172-39" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>order</span>
<span id="cb172-40"><a href="clustering.html#cb172-40" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>labels</span>
<span id="cb172-41"><a href="clustering.html#cb172-41" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>method</span>
<span id="cb172-42"><a href="clustering.html#cb172-42" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>call</span>
<span id="cb172-43"><a href="clustering.html#cb172-43" aria-hidden="true" tabindex="-1"></a>clust.bv<span class="sc">$</span>dist.method</span>
<span id="cb172-44"><a href="clustering.html#cb172-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-45"><a href="clustering.html#cb172-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Detect the best choice for number of cluster by elbow-plot</span></span>
<span id="cb172-46"><a href="clustering.html#cb172-46" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">33</span>, clust.bv<span class="sc">$</span>height, <span class="at">type=</span><span class="st">&quot;l&quot;</span>)</span>
<span id="cb172-47"><a href="clustering.html#cb172-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-48"><a href="clustering.html#cb172-48" aria-hidden="true" tabindex="-1"></a><span class="do">### Task. Analyse data and find groups of people</span></span>
<span id="cb172-49"><a href="clustering.html#cb172-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Scores (0,10) of 10 tests for candidates to get a job.</span></span>
<span id="cb172-50"><a href="clustering.html#cb172-50" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Memorizing numbers</span></span>
<span id="cb172-51"><a href="clustering.html#cb172-51" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Math task</span></span>
<span id="cb172-52"><a href="clustering.html#cb172-52" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Solving tasks in dialoge</span></span>
<span id="cb172-53"><a href="clustering.html#cb172-53" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Algorithms</span></span>
<span id="cb172-54"><a href="clustering.html#cb172-54" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Self confidence</span></span>
<span id="cb172-55"><a href="clustering.html#cb172-55" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Work in group</span></span>
<span id="cb172-56"><a href="clustering.html#cb172-56" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Find solution</span></span>
<span id="cb172-57"><a href="clustering.html#cb172-57" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. Collaboration</span></span>
<span id="cb172-58"><a href="clustering.html#cb172-58" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. Acceptance by others</span></span>
<span id="cb172-59"><a href="clustering.html#cb172-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-60"><a href="clustering.html#cb172-60" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;~/DataAnalysis&quot;</span>)</span>
<span id="cb172-61"><a href="clustering.html#cb172-61" aria-hidden="true" tabindex="-1"></a>job <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;DATA/assess.dat&quot;</span>, <span class="at">header=</span>T, <span class="at">sep=</span><span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>)</span>
<span id="cb172-62"><a href="clustering.html#cb172-62" aria-hidden="true" tabindex="-1"></a>job</span>
<span id="cb172-63"><a href="clustering.html#cb172-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-64"><a href="clustering.html#cb172-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb172-65"><a href="clustering.html#cb172-65" aria-hidden="true" tabindex="-1"></a>clust.job <span class="ot">&lt;-</span> <span class="fu">hclust</span>(<span class="fu">dist</span>(job[,<span class="dv">3</span><span class="sc">:</span><span class="fu">ncol</span>(job)]), <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb172-66"><a href="clustering.html#cb172-66" aria-hidden="true" tabindex="-1"></a><span class="co"># no needs to normalize, because all numbers have the same min, max</span></span>
<span id="cb172-67"><a href="clustering.html#cb172-67" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(clust.job)  <span class="co"># visual number of clusters is 4</span></span>
<span id="cb172-68"><a href="clustering.html#cb172-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-69"><a href="clustering.html#cb172-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Group data by clusters</span></span>
<span id="cb172-70"><a href="clustering.html#cb172-70" aria-hidden="true" tabindex="-1"></a>groups <span class="ot">&lt;-</span> <span class="fu">cutree</span>(clust.job, <span class="at">k=</span><span class="dv">4</span>)</span>
<span id="cb172-71"><a href="clustering.html#cb172-71" aria-hidden="true" tabindex="-1"></a>groups</span>
<span id="cb172-72"><a href="clustering.html#cb172-72" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(job[groups<span class="sc">==</span><span class="dv">1</span>, <span class="dv">3</span><span class="sc">:</span><span class="dv">12</span>])<span class="sc">*</span><span class="dv">100</span></span>
<span id="cb172-73"><a href="clustering.html#cb172-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-74"><a href="clustering.html#cb172-74" aria-hidden="true" tabindex="-1"></a><span class="do">### Find clusters using k-means method</span></span>
<span id="cb172-75"><a href="clustering.html#cb172-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-76"><a href="clustering.html#cb172-76" aria-hidden="true" tabindex="-1"></a><span class="fu">setwd</span>(<span class="st">&quot;~/DataAnalysis&quot;</span>)</span>
<span id="cb172-77"><a href="clustering.html#cb172-77" aria-hidden="true" tabindex="-1"></a>bv <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;DATA/beverage.csv&quot;</span>, <span class="at">header=</span>T, <span class="at">sep=</span><span class="st">&quot;;&quot;</span>)</span>
<span id="cb172-78"><a href="clustering.html#cb172-78" aria-hidden="true" tabindex="-1"></a>bv</span>
<span id="cb172-79"><a href="clustering.html#cb172-79" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(bv)</span>
<span id="cb172-80"><a href="clustering.html#cb172-80" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(bv)</span>
<span id="cb172-81"><a href="clustering.html#cb172-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-82"><a href="clustering.html#cb172-82" aria-hidden="true" tabindex="-1"></a><span class="co"># k-means clustering, with initial 3 clusters</span></span>
<span id="cb172-83"><a href="clustering.html#cb172-83" aria-hidden="true" tabindex="-1"></a><span class="co"># nstart = x - run x times with different initial clusters</span></span>
<span id="cb172-84"><a href="clustering.html#cb172-84" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>], <span class="dv">3</span>, <span class="at">iter.max =</span> <span class="dv">100</span>)</span>
<span id="cb172-85"><a href="clustering.html#cb172-85" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(summ<span class="fl">.1</span>)</span>
<span id="cb172-86"><a href="clustering.html#cb172-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-87"><a href="clustering.html#cb172-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Objects by clusters</span></span>
<span id="cb172-88"><a href="clustering.html#cb172-88" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>cluster</span>
<span id="cb172-89"><a href="clustering.html#cb172-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-90"><a href="clustering.html#cb172-90" aria-hidden="true" tabindex="-1"></a><span class="co"># Centers of clusters</span></span>
<span id="cb172-91"><a href="clustering.html#cb172-91" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>centers</span>
<span id="cb172-92"><a href="clustering.html#cb172-92" aria-hidden="true" tabindex="-1"></a><span class="co"># 2 digits after point</span></span>
<span id="cb172-93"><a href="clustering.html#cb172-93" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits=</span><span class="dv">2</span>)</span>
<span id="cb172-94"><a href="clustering.html#cb172-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-95"><a href="clustering.html#cb172-95" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(summ<span class="fl">.1</span><span class="sc">$</span>centers)</span>
<span id="cb172-96"><a href="clustering.html#cb172-96" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits=</span><span class="dv">7</span>)</span>
<span id="cb172-97"><a href="clustering.html#cb172-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-98"><a href="clustering.html#cb172-98" aria-hidden="true" tabindex="-1"></a><span class="co"># Square summs</span></span>
<span id="cb172-99"><a href="clustering.html#cb172-99" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>withinss</span>
<span id="cb172-100"><a href="clustering.html#cb172-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-101"><a href="clustering.html#cb172-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Summ of elements of vector</span></span>
<span id="cb172-102"><a href="clustering.html#cb172-102" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>tot.withinss</span>
<span id="cb172-103"><a href="clustering.html#cb172-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-104"><a href="clustering.html#cb172-104" aria-hidden="true" tabindex="-1"></a><span class="co"># sum(33*(apply(bv[,2:9], 2, sd))^2)</span></span>
<span id="cb172-105"><a href="clustering.html#cb172-105" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>totss</span>
<span id="cb172-106"><a href="clustering.html#cb172-106" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>tot.betweenss</span>
<span id="cb172-107"><a href="clustering.html#cb172-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-108"><a href="clustering.html#cb172-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Size of clusters</span></span>
<span id="cb172-109"><a href="clustering.html#cb172-109" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span><span class="sc">$</span>size</span>
<span id="cb172-110"><a href="clustering.html#cb172-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-111"><a href="clustering.html#cb172-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Elbow plot to detect optimal number of clusters</span></span>
<span id="cb172-112"><a href="clustering.html#cb172-112" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],<span class="dv">2</span>,var))</span>
<span id="cb172-113"><a href="clustering.html#cb172-113" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>) { wss[i] <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],</span>
<span id="cb172-114"><a href="clustering.html#cb172-114" aria-hidden="true" tabindex="-1"></a>                <span class="at">centers=</span>i)<span class="sc">$</span>tot.withinss }</span>
<span id="cb172-115"><a href="clustering.html#cb172-115" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, wss, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Number of Clusters&quot;</span>,</span>
<span id="cb172-116"><a href="clustering.html#cb172-116" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Within groups sum of squares&quot;</span>)</span>
<span id="cb172-117"><a href="clustering.html#cb172-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-118"><a href="clustering.html#cb172-118" aria-hidden="true" tabindex="-1"></a><span class="co"># We can see that diagram is rough. This is because clusters are not allways optimal</span></span>
<span id="cb172-119"><a href="clustering.html#cb172-119" aria-hidden="true" tabindex="-1"></a><span class="co"># To improve situation, we have to run many initiall start coordinates and choose the best</span></span>
<span id="cb172-120"><a href="clustering.html#cb172-120" aria-hidden="true" tabindex="-1"></a><span class="co"># option (add nstart=500):</span></span>
<span id="cb172-121"><a href="clustering.html#cb172-121" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],<span class="dv">2</span>,var))</span>
<span id="cb172-122"><a href="clustering.html#cb172-122" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>) { wss[i] <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],</span>
<span id="cb172-123"><a href="clustering.html#cb172-123" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">centers=</span>i, <span class="at">nstart=</span><span class="dv">500</span>)<span class="sc">$</span>tot.withinss }</span>
<span id="cb172-124"><a href="clustering.html#cb172-124" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, wss, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Number of Clusters&quot;</span>,</span>
<span id="cb172-125"><a href="clustering.html#cb172-125" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Within groups sum of squares&quot;</span>)</span>
<span id="cb172-126"><a href="clustering.html#cb172-126" aria-hidden="true" tabindex="-1"></a><span class="co"># Warnings means that iterations were not finished for some cases.</span></span>
<span id="cb172-127"><a href="clustering.html#cb172-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-128"><a href="clustering.html#cb172-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s compair results for 3 and 4 clusters</span></span>
<span id="cb172-129"><a href="clustering.html#cb172-129" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.1</span> <span class="ot">=</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>], <span class="dv">3</span>, <span class="at">iter.max=</span><span class="dv">100</span>)</span>
<span id="cb172-130"><a href="clustering.html#cb172-130" aria-hidden="true" tabindex="-1"></a>summ<span class="fl">.2</span> <span class="ot">=</span> <span class="fu">kmeans</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>], <span class="dv">4</span>, <span class="at">iter.max=</span><span class="dv">100</span>)</span>
<span id="cb172-131"><a href="clustering.html#cb172-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-132"><a href="clustering.html#cb172-132" aria-hidden="true" tabindex="-1"></a><span class="co"># Compair clusters. How many elements in each cluster</span></span>
<span id="cb172-133"><a href="clustering.html#cb172-133" aria-hidden="true" tabindex="-1"></a><span class="co"># We can see how elements move if we take more clusters</span></span>
<span id="cb172-134"><a href="clustering.html#cb172-134" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(summ<span class="fl">.1</span><span class="sc">$</span>cluster, summ<span class="fl">.2</span><span class="sc">$</span>cluster)</span>
<span id="cb172-135"><a href="clustering.html#cb172-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-136"><a href="clustering.html#cb172-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Multidimentional scaling</span></span>
<span id="cb172-137"><a href="clustering.html#cb172-137" aria-hidden="true" tabindex="-1"></a><span class="co"># Project multidimentional data to 2d</span></span>
<span id="cb172-138"><a href="clustering.html#cb172-138" aria-hidden="true" tabindex="-1"></a>bv.dist <span class="ot">&lt;-</span> <span class="fu">dist</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>])</span>
<span id="cb172-139"><a href="clustering.html#cb172-139" aria-hidden="true" tabindex="-1"></a>bv.mds <span class="ot">&lt;-</span> <span class="fu">cmdscale</span>(bv.dist)</span>
<span id="cb172-140"><a href="clustering.html#cb172-140" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bv.mds, <span class="at">col =</span> summ<span class="fl">.1</span><span class="sc">$</span>cluster, <span class="at">xlab=</span><span class="st">&quot;Index&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb172-141"><a href="clustering.html#cb172-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-142"><a href="clustering.html#cb172-142" aria-hidden="true" tabindex="-1"></a><span class="co"># Detect optimal number of clusters</span></span>
<span id="cb172-143"><a href="clustering.html#cb172-143" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;NbClust&quot;</span>)</span>
<span id="cb172-144"><a href="clustering.html#cb172-144" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;NbClust&quot;</span>)</span>
<span id="cb172-145"><a href="clustering.html#cb172-145" aria-hidden="true" tabindex="-1"></a>Best <span class="ot">&lt;-</span> <span class="fu">NbClust</span>(bv[,<span class="dv">2</span><span class="sc">:</span><span class="dv">9</span>],              <span class="co"># data </span></span>
<span id="cb172-146"><a href="clustering.html#cb172-146" aria-hidden="true" tabindex="-1"></a>                <span class="at">distance=</span><span class="st">&quot;euclidean&quot;</span>,  <span class="co"># distance method</span></span>
<span id="cb172-147"><a href="clustering.html#cb172-147" aria-hidden="true" tabindex="-1"></a>                <span class="at">min.nc=</span><span class="dv">2</span>,              <span class="co"># min number of clusters</span></span>
<span id="cb172-148"><a href="clustering.html#cb172-148" aria-hidden="true" tabindex="-1"></a>                <span class="at">max.nc=</span><span class="dv">8</span>,             <span class="co"># max number of clusters</span></span>
<span id="cb172-149"><a href="clustering.html#cb172-149" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">&quot;ward.D&quot;</span>,       <span class="co"># ward methodes </span></span>
<span id="cb172-150"><a href="clustering.html#cb172-150" aria-hidden="true" tabindex="-1"></a>                <span class="at">index =</span> <span class="st">&quot;alllong&quot;</span> )    <span class="co"># choose indices</span></span></code></pre></div>
<div id="next-part-4" class="section level2" number="26.1">
<h2><span class="header-section-number">26.1</span> Next part</h2>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="clustering.html#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb173-2"><a href="clustering.html#cb173-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb173-3"><a href="clustering.html#cb173-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-4"><a href="clustering.html#cb173-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-5"><a href="clustering.html#cb173-5" aria-hidden="true" tabindex="-1"></a>Distances<span class="sc">:</span></span>
<span id="cb173-6"><a href="clustering.html#cb173-6" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">dist</span>()</span>
<span id="cb173-7"><a href="clustering.html#cb173-7" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">get_dist</span>()   <span class="co"># compute a distance matrix between the rows of a data matrix</span></span>
<span id="cb173-8"><a href="clustering.html#cb173-8" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_dist</span>()  <span class="co"># visualize distance matrix</span></span>
<span id="cb173-9"><a href="clustering.html#cb173-9" aria-hidden="true" tabindex="-1"></a>cluster<span class="sc">::</span><span class="fu">daisy</span>()         <span class="co"># handle both numeric and not numeric (nominal, ordinal,...) data types</span></span>
<span id="cb173-10"><a href="clustering.html#cb173-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-11"><a href="clustering.html#cb173-11" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> factoextra<span class="sc">::</span><span class="fu">get_dist</span>(USArrests, <span class="at">stand =</span> <span class="cn">TRUE</span>, <span class="at">method =</span> <span class="st">&#39;pearson&#39;</span>)</span>
<span id="cb173-12"><a href="clustering.html#cb173-12" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_dist</span>(d, <span class="at">gradient =</span> <span class="fu">list</span>(<span class="at">low=</span><span class="st">&#39;blue&#39;</span>, <span class="at">mid=</span><span class="st">&#39;white&#39;</span>, <span class="at">high=</span><span class="st">&#39;red&#39;</span>))</span>
<span id="cb173-13"><a href="clustering.html#cb173-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-14"><a href="clustering.html#cb173-14" aria-hidden="true" tabindex="-1"></a><span class="do">#####</span></span>
<span id="cb173-15"><a href="clustering.html#cb173-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb173-16"><a href="clustering.html#cb173-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb173-17"><a href="clustering.html#cb173-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb173-18"><a href="clustering.html#cb173-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-19"><a href="clustering.html#cb173-19" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> USArrests <span class="sc">%&gt;%</span> <span class="fu">na.omit</span>() <span class="sc">%&gt;%</span> <span class="fu">scale</span>()</span>
<span id="cb173-20"><a href="clustering.html#cb173-20" aria-hidden="true" tabindex="-1"></a>data</span>
<span id="cb173-21"><a href="clustering.html#cb173-21" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_nbclust</span>(data, kmeans, <span class="at">method =</span> <span class="st">&#39;gap_stat&#39;</span>)</span>
<span id="cb173-22"><a href="clustering.html#cb173-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-23"><a href="clustering.html#cb173-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-24"><a href="clustering.html#cb173-24" aria-hidden="true" tabindex="-1"></a>km.res <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(data, <span class="dv">3</span>, <span class="at">nstart =</span> <span class="dv">25</span>)</span>
<span id="cb173-25"><a href="clustering.html#cb173-25" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_cluster</span>(km.res, <span class="at">data =</span> data,</span>
<span id="cb173-26"><a href="clustering.html#cb173-26" aria-hidden="true" tabindex="-1"></a>                         <span class="at">ellipse.type =</span> <span class="st">&#39;convex&#39;</span>,</span>
<span id="cb173-27"><a href="clustering.html#cb173-27" aria-hidden="true" tabindex="-1"></a>                         <span class="at">palette =</span> <span class="st">&#39;jco&#39;</span>,</span>
<span id="cb173-28"><a href="clustering.html#cb173-28" aria-hidden="true" tabindex="-1"></a>                         <span class="at">repel =</span> <span class="cn">TRUE</span>,</span>
<span id="cb173-29"><a href="clustering.html#cb173-29" aria-hidden="true" tabindex="-1"></a>                         <span class="at">ggtheme =</span> <span class="fu">theme_minimal</span>())</span>
<span id="cb173-30"><a href="clustering.html#cb173-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-31"><a href="clustering.html#cb173-31" aria-hidden="true" tabindex="-1"></a><span class="co"># PAM clustering</span></span>
<span id="cb173-32"><a href="clustering.html#cb173-32" aria-hidden="true" tabindex="-1"></a>pam.res <span class="ot">&lt;-</span> cluster<span class="sc">::</span><span class="fu">pam</span>(data, <span class="dv">4</span>)</span>
<span id="cb173-33"><a href="clustering.html#cb173-33" aria-hidden="true" tabindex="-1"></a>factoextra<span class="sc">::</span><span class="fu">fviz_cluster</span>(pam.res)</span>
<span id="cb173-34"><a href="clustering.html#cb173-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-35"><a href="clustering.html#cb173-35" aria-hidden="true" tabindex="-1"></a><span class="co"># CLARA clustering</span></span>
<span id="cb173-36"><a href="clustering.html#cb173-36" aria-hidden="true" tabindex="-1"></a>clara.res <span class="ot">&lt;-</span> <span class="fu">clara</span>(df, <span class="dv">2</span>, <span class="at">samples =</span> <span class="dv">50</span>, <span class="at">pamLike =</span> <span class="cn">TRUE</span>)</span>
<span id="cb173-37"><a href="clustering.html#cb173-37" aria-hidden="true" tabindex="-1"></a>clara.res</span>
<span id="cb173-38"><a href="clustering.html#cb173-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-39"><a href="clustering.html#cb173-39" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">&lt;-</span> <span class="fu">cbind</span>(df, <span class="at">cluster =</span> clara.res<span class="sc">$</span>cluster)</span>
<span id="cb173-40"><a href="clustering.html#cb173-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-41"><a href="clustering.html#cb173-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Medoids</span></span>
<span id="cb173-42"><a href="clustering.html#cb173-42" aria-hidden="true" tabindex="-1"></a>clara.res<span class="sc">$</span>medoids</span>
<span id="cb173-43"><a href="clustering.html#cb173-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-44"><a href="clustering.html#cb173-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Clustering</span></span>
<span id="cb173-45"><a href="clustering.html#cb173-45" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(clara.res<span class="sc">$</span>clustering,<span class="dv">10</span>)</span></code></pre></div>
</div>
<div id="example" class="section level2" number="26.2">
<h2><span class="header-section-number">26.2</span> Example</h2>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="clustering.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(datasets)</span>
<span id="cb174-2"><a href="clustering.html#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span></code></pre></div>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species id
## 1          5.1         3.5          1.4         0.2  setosa  1
## 2          4.9         3.0          1.4         0.2  setosa  2
## 3          4.7         3.2          1.3         0.2  setosa  3
## 4          4.6         3.1          1.5         0.2  setosa  4
## 5          5.0         3.6          1.4         0.2  setosa  5
## 6          5.4         3.9          1.7         0.4  setosa  6</code></pre>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="clustering.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Petal.Length ~ Petal.Width data</span></span>
<span id="cb176-2"><a href="clustering.html#cb176-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Petal.Length <span class="sc">~</span> iris<span class="sc">$</span>Petal.Width)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/setup-1.png" width="672" /></p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="clustering.html#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20</span>)</span>
<span id="cb177-2"><a href="clustering.html#cb177-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb177-3"><a href="clustering.html#cb177-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Find number of clusters using wss</span></span>
<span id="cb177-4"><a href="clustering.html#cb177-4" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> (<span class="fu">nrow</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>])<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>],<span class="dv">2</span>,var))</span>
<span id="cb177-5"><a href="clustering.html#cb177-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">15</span>) wss[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">kmeans</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>], i)<span class="sc">$</span>withinss)</span>
<span id="cb177-6"><a href="clustering.html#cb177-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, wss, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Number of Clusters&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Within groups sum of squares&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/setup-2.png" width="672" /></p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="clustering.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="co">#More than 3 clusters give no obvious advantages</span></span>
<span id="cb178-2"><a href="clustering.html#cb178-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-3"><a href="clustering.html#cb178-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Make k-means with 3 clasters</span></span>
<span id="cb178-4"><a href="clustering.html#cb178-4" aria-hidden="true" tabindex="-1"></a>ncl <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb178-5"><a href="clustering.html#cb178-5" aria-hidden="true" tabindex="-1"></a>irisCluster <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>], ncl, <span class="at">nstart =</span> <span class="dv">20</span>)</span>
<span id="cb178-6"><a href="clustering.html#cb178-6" aria-hidden="true" tabindex="-1"></a>irisCluster</span></code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 48, 50, 52
## 
## Cluster means:
##   Petal.Length Petal.Width
## 1     5.595833    2.037500
## 2     1.462000    0.246000
## 3     4.269231    1.342308
## 
## Clustering vector:
##   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3
##  [64] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1
## [127] 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1
## 
## Within cluster sum of squares by cluster:
## [1] 16.29167  2.02200 13.05769
##  (between_SS / total_SS =  94.3 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;        
## [9] &quot;ifault&quot;</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="clustering.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compair result of clustering with real data (3 species of iris are in analysis)</span></span>
<span id="cb180-2"><a href="clustering.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(irisCluster<span class="sc">$</span>cluster, iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>##    
##     setosa versicolor virginica
##   1      0          2        46
##   2     50          0         0
##   3      0         48         4</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="clustering.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot data</span></span>
<span id="cb182-2"><a href="clustering.html#cb182-2" aria-hidden="true" tabindex="-1"></a>clusters <span class="ot">&lt;-</span> <span class="fu">split.data.frame</span>(iris, irisCluster<span class="sc">$</span>cluster)</span>
<span id="cb182-3"><a href="clustering.html#cb182-3" aria-hidden="true" tabindex="-1"></a>xlim <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">min</span>(iris<span class="sc">$</span>Petal.Width), <span class="fu">max</span>(iris<span class="sc">$</span>Petal.Width))</span>
<span id="cb182-4"><a href="clustering.html#cb182-4" aria-hidden="true" tabindex="-1"></a>ylim <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">min</span>(iris<span class="sc">$</span>Petal.Length), <span class="fu">max</span>(iris<span class="sc">$</span>Petal.Length))</span>
<span id="cb182-5"><a href="clustering.html#cb182-5" aria-hidden="true" tabindex="-1"></a>col <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;green&#39;</span>, <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb182-6"><a href="clustering.html#cb182-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span>, <span class="at">xlab=</span><span class="st">&#39;Petal width&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;Petal length&#39;</span>, <span class="at">xlim=</span>xlim, <span class="at">ylim=</span>ylim)</span>
<span id="cb182-7"><a href="clustering.html#cb182-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>ncl ) {</span>
<span id="cb182-8"><a href="clustering.html#cb182-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(clusters[[i]]<span class="sc">$</span>Petal.Length <span class="sc">~</span> clusters[[i]]<span class="sc">$</span>Petal.Width, <span class="at">col=</span>col[i], <span class="at">xlim=</span>xlim, <span class="at">ylim=</span>ylim)</span>
<span id="cb182-9"><a href="clustering.html#cb182-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/setup-3.png" width="672" /></p>
</div>
<div id="next-part-5" class="section level2" number="26.3">
<h2><span class="header-section-number">26.3</span> NEXT PART</h2>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="clustering.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co"># K-Nearest Neighbors or KNN is a clustering algorithm</span></span>
<span id="cb183-2"><a href="clustering.html#cb183-2" aria-hidden="true" tabindex="-1"></a><span class="co"># k is known number of clusters (usually sqrt(N), between 3-10, but may be different)</span></span>
<span id="cb183-3"><a href="clustering.html#cb183-3" aria-hidden="true" tabindex="-1"></a><span class="co"># samples must be normalized x = (x - min(x))/(max(x)-min(x))</span></span>
<span id="cb183-4"><a href="clustering.html#cb183-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-5"><a href="clustering.html#cb183-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris)</span>
<span id="cb183-6"><a href="clustering.html#cb183-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris)   <span class="co"># detailed view of the data set</span></span>
<span id="cb183-7"><a href="clustering.html#cb183-7" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(iris)   <span class="co"># view data types, sample values, categorical values, etc</span></span>
<span id="cb183-8"><a href="clustering.html#cb183-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris)</span>
<span id="cb183-9"><a href="clustering.html#cb183-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-10"><a href="clustering.html#cb183-10" aria-hidden="true" tabindex="-1"></a><span class="co">#normalization function</span></span>
<span id="cb183-11"><a href="clustering.html#cb183-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-12"><a href="clustering.html#cb183-12" aria-hidden="true" tabindex="-1"></a>min_max_normalizer <span class="ot">&lt;-</span> <span class="cf">function</span>(x)</span>
<span id="cb183-13"><a href="clustering.html#cb183-13" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb183-14"><a href="clustering.html#cb183-14" aria-hidden="true" tabindex="-1"></a>    num <span class="ot">&lt;-</span> x <span class="sc">-</span> <span class="fu">min</span>(x) </span>
<span id="cb183-15"><a href="clustering.html#cb183-15" aria-hidden="true" tabindex="-1"></a>    denom <span class="ot">&lt;-</span> <span class="fu">max</span>(x) <span class="sc">-</span> <span class="fu">min</span>(x)</span>
<span id="cb183-16"><a href="clustering.html#cb183-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span> (num<span class="sc">/</span>denom)</span>
<span id="cb183-17"><a href="clustering.html#cb183-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb183-18"><a href="clustering.html#cb183-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-19"><a href="clustering.html#cb183-19" aria-hidden="true" tabindex="-1"></a><span class="co">#normalizing iris data set</span></span>
<span id="cb183-20"><a href="clustering.html#cb183-20" aria-hidden="true" tabindex="-1"></a>normalized_iris <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">lapply</span>(iris[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], min_max_normalizer))</span>
<span id="cb183-21"><a href="clustering.html#cb183-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-22"><a href="clustering.html#cb183-22" aria-hidden="true" tabindex="-1"></a><span class="co">#viewing normalized data</span></span>
<span id="cb183-23"><a href="clustering.html#cb183-23" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(normalized_iris)</span>
<span id="cb183-24"><a href="clustering.html#cb183-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-25"><a href="clustering.html#cb183-25" aria-hidden="true" tabindex="-1"></a><span class="co">#checking the data constituency</span></span>
<span id="cb183-26"><a href="clustering.html#cb183-26" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(iris<span class="sc">$</span>Species)</span>
<span id="cb183-27"><a href="clustering.html#cb183-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-28"><a href="clustering.html#cb183-28" aria-hidden="true" tabindex="-1"></a><span class="co">#set seed for randomization</span></span>
<span id="cb183-29"><a href="clustering.html#cb183-29" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb183-30"><a href="clustering.html#cb183-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-31"><a href="clustering.html#cb183-31" aria-hidden="true" tabindex="-1"></a><span class="co"># setting the training-test split to 67% and 33% respectively</span></span>
<span id="cb183-32"><a href="clustering.html#cb183-32" aria-hidden="true" tabindex="-1"></a>random_samples <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">2</span>, <span class="fu">nrow</span>(iris), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.67</span>, <span class="fl">0.33</span>))</span>
<span id="cb183-33"><a href="clustering.html#cb183-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-34"><a href="clustering.html#cb183-34" aria-hidden="true" tabindex="-1"></a><span class="co"># training data set</span></span>
<span id="cb183-35"><a href="clustering.html#cb183-35" aria-hidden="true" tabindex="-1"></a>iris.training <span class="ot">&lt;-</span> iris[</span>
<span id="cb183-36"><a href="clustering.html#cb183-36" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>] </span>
<span id="cb183-37"><a href="clustering.html#cb183-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-38"><a href="clustering.html#cb183-38" aria-hidden="true" tabindex="-1"></a><span class="co">#training labels</span></span>
<span id="cb183-39"><a href="clustering.html#cb183-39" aria-hidden="true" tabindex="-1"></a>iris.trainLabels <span class="ot">&lt;-</span> iris[</span>
<span id="cb183-40"><a href="clustering.html#cb183-40" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">1</span>, <span class="dv">5</span>]</span>
<span id="cb183-41"><a href="clustering.html#cb183-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-42"><a href="clustering.html#cb183-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-43"><a href="clustering.html#cb183-43" aria-hidden="true" tabindex="-1"></a><span class="co"># test data set</span></span>
<span id="cb183-44"><a href="clustering.html#cb183-44" aria-hidden="true" tabindex="-1"></a>iris.test <span class="ot">&lt;-</span> iris[</span>
<span id="cb183-45"><a href="clustering.html#cb183-45" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">2</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb183-46"><a href="clustering.html#cb183-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-47"><a href="clustering.html#cb183-47" aria-hidden="true" tabindex="-1"></a><span class="co">#testing labels</span></span>
<span id="cb183-48"><a href="clustering.html#cb183-48" aria-hidden="true" tabindex="-1"></a>iris.testLabels <span class="ot">&lt;-</span> iris[</span>
<span id="cb183-49"><a href="clustering.html#cb183-49" aria-hidden="true" tabindex="-1"></a>    random_samples <span class="sc">==</span><span class="dv">2</span>, <span class="dv">5</span>]</span>
<span id="cb183-50"><a href="clustering.html#cb183-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-51"><a href="clustering.html#cb183-51" aria-hidden="true" tabindex="-1"></a><span class="co">#setting library</span></span>
<span id="cb183-52"><a href="clustering.html#cb183-52" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb183-53"><a href="clustering.html#cb183-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-54"><a href="clustering.html#cb183-54" aria-hidden="true" tabindex="-1"></a><span class="co">#executing knn for k=3</span></span>
<span id="cb183-55"><a href="clustering.html#cb183-55" aria-hidden="true" tabindex="-1"></a>iris_model <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> iris.training, <span class="at">test =</span> iris.test, <span class="at">cl =</span> iris.trainLabels, <span class="at">k=</span><span class="dv">3</span>)</span>
<span id="cb183-56"><a href="clustering.html#cb183-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-57"><a href="clustering.html#cb183-57" aria-hidden="true" tabindex="-1"></a><span class="co">#summary of the model learnt</span></span>
<span id="cb183-58"><a href="clustering.html#cb183-58" aria-hidden="true" tabindex="-1"></a>iris_model</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="learning-vector-quantization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/30_clustering.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
