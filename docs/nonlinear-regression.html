<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 27 Nonlinear regression | R statistics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 27 Nonlinear regression | R statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 27 Nonlinear regression | R statistics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Mark Goldberg" />


<meta name="date" content="2021-05-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-regression-complex-cases.html"/>
<link rel="next" href="multiple-linear-regression.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html"><i class="fa fa-check"></i><b>2</b> Statistics R functions reference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#get-data"><i class="fa fa-check"></i><b>2.1</b> Get data</a></li>
<li class="chapter" data-level="2.2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#data-inspection"><i class="fa fa-check"></i><b>2.2</b> Data inspection</a></li>
<li class="chapter" data-level="2.3" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#plots"><i class="fa fa-check"></i><b>2.3</b> Plots</a></li>
<li class="chapter" data-level="2.4" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#analysis-of-the-distribution"><i class="fa fa-check"></i><b>2.4</b> Analysis of the distribution</a></li>
<li class="chapter" data-level="2.5" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#distributions"><i class="fa fa-check"></i><b>2.5</b> Distributions</a></li>
<li class="chapter" data-level="2.6" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#t-test"><i class="fa fa-check"></i><b>2.6</b> t-Test</a></li>
<li class="chapter" data-level="2.7" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#anova"><i class="fa fa-check"></i><b>2.7</b> ANOVA</a></li>
<li class="chapter" data-level="2.8" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#machine-learning-functions-reference"><i class="fa fa-check"></i><b>2.8</b> Machine Learning Functions Reference</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#linear-regression"><i class="fa fa-check"></i><b>2.8.1</b> Linear Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="combinatorics.html"><a href="combinatorics.html"><i class="fa fa-check"></i><b>3</b> Combinatorics</a></li>
<li class="chapter" data-level="4" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>4</b> Regularization</a></li>
<li class="chapter" data-level="5" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>5</b> Probability</a></li>
<li class="chapter" data-level="6" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>6</b> Basic Statistics</a>
<ul>
<li class="chapter" data-level="6.1" data-path="basic-statistics.html"><a href="basic-statistics.html#definitions"><i class="fa fa-check"></i><b>6.1</b> Definitions</a></li>
<li class="chapter" data-level="6.2" data-path="basic-statistics.html"><a href="basic-statistics.html#probability-1"><i class="fa fa-check"></i><b>6.2</b> Probability</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistical-distributions.html"><a href="statistical-distributions.html"><i class="fa fa-check"></i><b>7</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="statistical-distributions.html"><a href="statistical-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>7.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="7.2" data-path="statistical-distributions.html"><a href="statistical-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>7.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="7.3" data-path="statistical-distributions.html"><a href="statistical-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>7.3</b> Binomial Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="statistical-distributions.html"><a href="statistical-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>7.4</b> Beta distribution</a></li>
<li class="chapter" data-level="7.5" data-path="statistical-distributions.html"><a href="statistical-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>7.5</b> Geometric Distribution</a></li>
<li class="chapter" data-level="7.6" data-path="statistical-distributions.html"><a href="statistical-distributions.html#uniform-distributions"><i class="fa fa-check"></i><b>7.6</b> Uniform Distributions</a></li>
<li class="chapter" data-level="7.7" data-path="statistical-distributions.html"><a href="statistical-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>7.7</b> Poisson Distribution</a></li>
<li class="chapter" data-level="7.8" data-path="statistical-distributions.html"><a href="statistical-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>7.8</b> Exponential Distribution</a></li>
<li class="chapter" data-level="7.9" data-path="statistical-distributions.html"><a href="statistical-distributions.html#chi-squared-distribution"><i class="fa fa-check"></i><b>7.9</b> Chi-squared Distribution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html"><i class="fa fa-check"></i><b>8</b> Primary data analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#analysis-of-sample-distribution"><i class="fa fa-check"></i><b>8.1</b> Analysis of sample distribution</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#histogram"><i class="fa fa-check"></i><b>8.1.1</b> Histogram</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#handling-missing-data"><i class="fa fa-check"></i><b>8.2</b> Handling missing data</a></li>
<li class="chapter" data-level="8.3" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#dealing-with-outliers"><i class="fa fa-check"></i><b>8.3</b> Dealing with outliers</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-normalization.html"><a href="data-normalization.html"><i class="fa fa-check"></i><b>9</b> Data normalization</a>
<ul>
<li class="chapter" data-level="9.1" data-path="data-normalization.html"><a href="data-normalization.html#normality-test"><i class="fa fa-check"></i><b>9.1</b> Normality test</a></li>
<li class="chapter" data-level="9.2" data-path="data-normalization.html"><a href="data-normalization.html#finding-confidence-intervals"><i class="fa fa-check"></i><b>9.2</b> Finding Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="primary-data-analysis-case-studies.html"><a href="primary-data-analysis-case-studies.html"><i class="fa fa-check"></i><b>10</b> Primary data analysis - Case studies</a></li>
<li class="chapter" data-level="11" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="11.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-theory"><i class="fa fa-check"></i><b>11.1</b> Hypothesis testing theory</a></li>
<li class="chapter" data-level="11.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-practice"><i class="fa fa-check"></i><b>11.2</b> Hypothesis test (Practice)</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="t-procedures.html"><a href="t-procedures.html"><i class="fa fa-check"></i><b>12</b> t-Procedures</a>
<ul>
<li class="chapter" data-level="12.1" data-path="t-procedures.html"><a href="t-procedures.html#t-test-and-normal-distribution"><i class="fa fa-check"></i><b>12.1</b> t-test and normal distribution</a></li>
<li class="chapter" data-level="12.2" data-path="t-procedures.html"><a href="t-procedures.html#one-sample-t-test"><i class="fa fa-check"></i><b>12.2</b> One-sample t-test</a></li>
<li class="chapter" data-level="12.3" data-path="t-procedures.html"><a href="t-procedures.html#practical-example-t-test-in-r"><i class="fa fa-check"></i><b>12.3</b> Practical example: t-test in R</a></li>
<li class="chapter" data-level="12.4" data-path="t-procedures.html"><a href="t-procedures.html#two-samples-t-test"><i class="fa fa-check"></i><b>12.4</b> Two samples t-test</a></li>
<li class="chapter" data-level="12.5" data-path="t-procedures.html"><a href="t-procedures.html#compare-students-t-and-normal-distributions"><i class="fa fa-check"></i><b>12.5</b> Compare Student’s t and normal distributions</a></li>
<li class="chapter" data-level="12.6" data-path="t-procedures.html"><a href="t-procedures.html#non-parametric-tests"><i class="fa fa-check"></i><b>12.6</b> Non-parametric tests</a></li>
<li class="chapter" data-level="12.7" data-path="t-procedures.html"><a href="t-procedures.html#mann-whitney-u-rank-sum-test"><i class="fa fa-check"></i><b>12.7</b> Mann-Whitney U Rank Sum Test</a></li>
<li class="chapter" data-level="12.8" data-path="t-procedures.html"><a href="t-procedures.html#wilcoxon-test"><i class="fa fa-check"></i><b>12.8</b> Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html"><i class="fa fa-check"></i><b>13</b> Tests for categorical variables</a>
<ul>
<li class="chapter" data-level="13.1" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html#chi-squared-tests"><i class="fa fa-check"></i><b>13.1</b> Chi-squared tests</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>14</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="multiple-testing.html"><a href="multiple-testing.html#the-bonferroni-correction"><i class="fa fa-check"></i><b>14.1</b> The Bonferroni correction</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="sources.html"><a href="sources.html"><i class="fa fa-check"></i><b>15</b> Sources</a>
<ul>
<li class="chapter" data-level="15.1" data-path="sources.html"><a href="sources.html#t-test-1"><i class="fa fa-check"></i><b>15.1</b> t-test</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="sources.html"><a href="sources.html#two-tailed-test"><i class="fa fa-check"></i><b>15.1.1</b> Two-tailed test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="wilcoxon-signed-rank-test.html"><a href="wilcoxon-signed-rank-test.html"><i class="fa fa-check"></i><b>16</b> Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="17" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>17</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="17.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>17.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="17.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#sources-1"><i class="fa fa-check"></i><b>17.2</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="t-test-anova-difference.html"><a href="t-test-anova-difference.html"><i class="fa fa-check"></i><b>18</b> t-test ANOVA difference</a></li>
<li class="chapter" data-level="19" data-path="chi-squared-test.html"><a href="chi-squared-test.html"><i class="fa fa-check"></i><b>19</b> Chi-squared test</a>
<ul>
<li class="chapter" data-level="19.1" data-path="chi-squared-test.html"><a href="chi-squared-test.html#multinomial-goodness-of-fit"><i class="fa fa-check"></i><b>19.1</b> Multinomial Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html"><i class="fa fa-check"></i><b>20</b> Non-parametric Methods</a>
<ul>
<li class="chapter" data-level="20.1" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#sign-test"><i class="fa fa-check"></i><b>20.1</b> Sign Test</a></li>
<li class="chapter" data-level="20.2" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#wilcoxon-signed-rank-test-1"><i class="fa fa-check"></i><b>20.2</b> Wilcoxon Signed-Rank Test</a></li>
<li class="chapter" data-level="20.3" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#mann-whitney-wilcoxon-test"><i class="fa fa-check"></i><b>20.3</b> Mann-Whitney-Wilcoxon Test</a></li>
<li class="chapter" data-level="20.4" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>20.4</b> Kruskal-Wallis Test</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>21</b> Correlation</a></li>
<li class="chapter" data-level="22" data-path="methods-and-algorithms-of-machine-learning.html"><a href="methods-and-algorithms-of-machine-learning.html"><i class="fa fa-check"></i><b>22</b> Methods and algorithms of machine learning</a></li>
<li class="chapter" data-level="23" data-path="split-data-into-train-and-test-subsets.html"><a href="split-data-into-train-and-test-subsets.html"><i class="fa fa-check"></i><b>23</b> Split data into train and test subsets</a></li>
<li class="chapter" data-level="24" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>24</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="24.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression---theory"><i class="fa fa-check"></i><b>24.1</b> Linear regression - theory</a></li>
<li class="chapter" data-level="24.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-random-data-set-for-the-linear-model"><i class="fa fa-check"></i><b>24.2</b> Generate random data set for the linear model</a></li>
<li class="chapter" data-level="24.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-example"><i class="fa fa-check"></i><b>24.3</b> Practical example</a></li>
<li class="chapter" data-level="24.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#mean-squared-error-mse"><i class="fa fa-check"></i><b>24.4</b> Mean squared error (MSE)</a></li>
<li class="chapter" data-level="24.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-model-in-r"><i class="fa fa-check"></i><b>24.5</b> Linear model in R</a></li>
<li class="chapter" data-level="24.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression-model-for-multiple-parameters"><i class="fa fa-check"></i><b>24.6</b> Linear regression model for multiple parameters</a></li>
<li class="chapter" data-level="24.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#choosing-explanatory-variables-for-the-model"><i class="fa fa-check"></i><b>24.7</b> Choosing explanatory variables for the model</a></li>
<li class="chapter" data-level="24.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#assessment-of-model-performance-for-categorical-data."><i class="fa fa-check"></i><b>24.8</b> Assessment of model performance for categorical data.</a></li>
<li class="chapter" data-level="24.9" data-path="linear-regression-1.html"><a href="linear-regression-1.html#confidence-intervals-for-linear-model"><i class="fa fa-check"></i><b>24.9</b> Confidence intervals for linear model</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="model-evaluation.html"><a href="model-evaluation.html"><i class="fa fa-check"></i><b>25</b> Model evaluation</a>
<ul>
<li class="chapter" data-level="25.1" data-path="model-evaluation.html"><a href="model-evaluation.html#practical-examples-for-linear-model-regression"><i class="fa fa-check"></i><b>25.1</b> Practical examples for linear model regression</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html"><i class="fa fa-check"></i><b>26</b> Linear regression complex cases</a>
<ul>
<li class="chapter" data-level="26.1" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#cars"><i class="fa fa-check"></i><b>26.1</b> Cars</a></li>
<li class="chapter" data-level="26.2" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#linear-regression-modeling-compair-with-knn"><i class="fa fa-check"></i><b>26.2</b> Linear regression modeling, compair with kNN</a></li>
<li class="chapter" data-level="26.3" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#more-complex-example"><i class="fa fa-check"></i><b>26.3</b> More complex example</a></li>
<li class="chapter" data-level="26.4" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part"><i class="fa fa-check"></i><b>26.4</b> NEXT part</a></li>
<li class="chapter" data-level="26.5" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part-1"><i class="fa fa-check"></i><b>26.5</b> NEXT Part</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="nonlinear-regression.html"><a href="nonlinear-regression.html"><i class="fa fa-check"></i><b>27</b> Nonlinear regression</a></li>
<li class="chapter" data-level="28" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>28</b> Multiple linear regression</a></li>
<li class="chapter" data-level="29" data-path="spline-model.html"><a href="spline-model.html"><i class="fa fa-check"></i><b>29</b> Spline model</a>
<ul>
<li class="chapter" data-level="29.1" data-path="spline-model.html"><a href="spline-model.html#generate-dataset-from-a-given-function"><i class="fa fa-check"></i><b>29.1</b> Generate dataset from a given function</a></li>
<li class="chapter" data-level="29.2" data-path="spline-model.html"><a href="spline-model.html#split-data-for-train-and-test"><i class="fa fa-check"></i><b>29.2</b> Split data for train and test</a></li>
<li class="chapter" data-level="29.3" data-path="spline-model.html"><a href="spline-model.html#diagram-of-the-given-function-and-generated-datasets"><i class="fa fa-check"></i><b>29.3</b> Diagram of the given function and generated datasets</a></li>
<li class="chapter" data-level="29.4" data-path="spline-model.html"><a href="spline-model.html#build-a-model-using-splines"><i class="fa fa-check"></i><b>29.4</b> Build a model using splines</a></li>
<li class="chapter" data-level="29.5" data-path="spline-model.html"><a href="spline-model.html#diagram-of-mse-for-train-and-test-data"><i class="fa fa-check"></i><b>29.5</b> Diagram of MSE for train and test data</a></li>
<li class="chapter" data-level="29.6" data-path="spline-model.html"><a href="spline-model.html#build-optimal-model-and-plot-for-the-model"><i class="fa fa-check"></i><b>29.6</b> Build optimal model and plot for the model</a></li>
<li class="chapter" data-level="29.7" data-path="spline-model.html"><a href="spline-model.html#bibliograpy"><i class="fa fa-check"></i><b>29.7</b> Bibliograpy</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>30</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="30.1" data-path="logistic-regression.html"><a href="logistic-regression.html#confusion-matrix"><i class="fa fa-check"></i><b>30.1</b> Confusion matrix</a></li>
<li class="chapter" data-level="30.2" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-2"><i class="fa fa-check"></i><b>30.2</b> Next part</a></li>
<li class="chapter" data-level="30.3" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-3"><i class="fa fa-check"></i><b>30.3</b> NExt part</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="models-for-binary-data.html"><a href="models-for-binary-data.html"><i class="fa fa-check"></i><b>31</b> Models for binary Data</a></li>
<li class="chapter" data-level="32" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>32</b> Support Vector Machine</a></li>
<li class="chapter" data-level="33" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>33</b> Clustering</a>
<ul>
<li class="chapter" data-level="33.1" data-path="clustering.html"><a href="clustering.html#finding-distances-using-factoextra"><i class="fa fa-check"></i><b>33.1</b> Finding distances using factoextra</a></li>
<li class="chapter" data-level="33.2" data-path="clustering.html"><a href="clustering.html#example-of-choosing-clustering-model"><i class="fa fa-check"></i><b>33.2</b> Example of choosing clustering model</a></li>
<li class="chapter" data-level="33.3" data-path="clustering.html"><a href="clustering.html#k-means-clustering"><i class="fa fa-check"></i><b>33.3</b> K-means clustering</a></li>
<li class="chapter" data-level="33.4" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>33.4</b> k-Means</a></li>
<li class="chapter" data-level="33.5" data-path="clustering.html"><a href="clustering.html#hierarchical-clustering"><i class="fa fa-check"></i><b>33.5</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="33.6" data-path="clustering.html"><a href="clustering.html#knn"><i class="fa fa-check"></i><b>33.6</b> KNN</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="learning-vector-quantization.html"><a href="learning-vector-quantization.html"><i class="fa fa-check"></i><b>34</b> Learning Vector Quantization</a></li>
<li class="chapter" data-level="35" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>35</b> Tree-based models</a>
<ul>
<li class="chapter" data-level="35.1" data-path="tree-based-models.html"><a href="tree-based-models.html#classification-tree-example"><i class="fa fa-check"></i><b>35.1</b> Classification Tree example</a></li>
<li class="chapter" data-level="35.2" data-path="tree-based-models.html"><a href="tree-based-models.html#regression-tree-example"><i class="fa fa-check"></i><b>35.2</b> Regression Tree example</a></li>
</ul></li>
<li class="chapter" data-level="36" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>36</b> Markov Chain Monte Carlo (MCMC)</a></li>
<li class="chapter" data-level="37" data-path="simple-markov-process.html"><a href="simple-markov-process.html"><i class="fa fa-check"></i><b>37</b> Simple Markov process</a>
<ul>
<li class="chapter" data-level="37.0.1" data-path="simple-markov-process.html"><a href="simple-markov-process.html#sources-2"><i class="fa fa-check"></i><b>37.0.1</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>38</b> Bayesian inference</a>
<ul>
<li class="chapter" data-level="38.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#simple-model-with-one-binary-parameter"><i class="fa fa-check"></i><b>38.1</b> Simple model with one binary parameter</a></li>
<li class="chapter" data-level="38.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#grid-approximation"><i class="fa fa-check"></i><b>38.2</b> Grid approximation</a></li>
<li class="chapter" data-level="38.3" data-path="bayesian-inference.html"><a href="bayesian-inference.html#grid-approximation-1"><i class="fa fa-check"></i><b>38.3</b> Grid approximation</a></li>
<li class="chapter" data-level="38.4" data-path="bayesian-inference.html"><a href="bayesian-inference.html#model-of-birth-weights-using-normal-distribution"><i class="fa fa-check"></i><b>38.4</b> Model of birth weights using normal distribution</a></li>
<li class="chapter" data-level="38.5" data-path="bayesian-inference.html"><a href="bayesian-inference.html#a-bayesian-model-of-zombie-iq"><i class="fa fa-check"></i><b>38.5</b> A Bayesian model of Zombie IQ</a></li>
<li class="chapter" data-level="38.6" data-path="bayesian-inference.html"><a href="bayesian-inference.html#the-best-models"><i class="fa fa-check"></i><b>38.6</b> The BEST models</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="naive-bayes-classifiers.html"><a href="naive-bayes-classifiers.html"><i class="fa fa-check"></i><b>39</b> Naive Bayes classifiers</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonlinear-regression" class="section level1" number="27">
<h1><span class="header-section-number">Chapter 27</span> Nonlinear regression</h1>
<p>Nonlinear regression is a form of regression analysis in which observational data are modeled by a function which is a nonlinear combination of the model parameters and <strong>depends on one or more independent variables</strong>.<br />
Some nonlinear data sets can be transformed to a linear model.<br />
Sone can not be transformed. For such modeling methods of Numerical analysis should be applied such as Newton’s method, Gauss-Newton method and Levenberg–Marquardt method.</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="nonlinear-regression.html#cb203-1" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb203-2"><a href="nonlinear-regression.html#cb203-2" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">7</span></span>
<span id="cb203-3"><a href="nonlinear-regression.html#cb203-3" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb203-4"><a href="nonlinear-regression.html#cb203-4" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb203-5"><a href="nonlinear-regression.html#cb203-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb203-6"><a href="nonlinear-regression.html#cb203-6" aria-hidden="true" tabindex="-1"></a>    оценивать полиномиальную регрессию;</span>
<span id="cb203-7"><a href="nonlinear-regression.html#cb203-7" aria-hidden="true" tabindex="-1"></a>аппроксимировать нелинейные модели ступенчатыми функциями;</span>
<span id="cb203-8"><a href="nonlinear-regression.html#cb203-8" aria-hidden="true" tabindex="-1"></a>строить сплайны;</span>
<span id="cb203-9"><a href="nonlinear-regression.html#cb203-9" aria-hidden="true" tabindex="-1"></a>работать с локальной регрессией;</span>
<span id="cb203-10"><a href="nonlinear-regression.html#cb203-10" aria-hidden="true" tabindex="-1"></a>строить обобщённые линейные модели (GAM).</span>
<span id="cb203-11"><a href="nonlinear-regression.html#cb203-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> полиномиальная регрессия, полиномиальная логистическая регрессия, ступенчатая модель, обобщённая линейная модель.</span>
<span id="cb203-12"><a href="nonlinear-regression.html#cb203-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Wage {ISLR}</span>
<span id="cb203-13"><a href="nonlinear-regression.html#cb203-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-14"><a href="nonlinear-regression.html#cb203-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">7.</span></span>
<span id="cb203-15"><a href="nonlinear-regression.html#cb203-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-16"><a href="nonlinear-regression.html#cb203-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># набор данных Auto</span></span>
<span id="cb203-17"><a href="nonlinear-regression.html#cb203-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;splines&#39;</span>)           <span class="co"># сплайны</span></span>
<span id="cb203-18"><a href="nonlinear-regression.html#cb203-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gam&#39;</span>)               <span class="co"># обобщённые аддитивные модели</span></span>
<span id="cb203-19"><a href="nonlinear-regression.html#cb203-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gam&#39; was built under R version 3.3.3</span></span>
<span id="cb203-20"><a href="nonlinear-regression.html#cb203-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: foreach</span></span>
<span id="cb203-21"><a href="nonlinear-regression.html#cb203-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;foreach&#39; was built under R version 3.3.3</span></span>
<span id="cb203-22"><a href="nonlinear-regression.html#cb203-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gam 1.14</span></span>
<span id="cb203-23"><a href="nonlinear-regression.html#cb203-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;akima&#39;</span>)             <span class="co"># график двумерной плоскости</span></span>
<span id="cb203-24"><a href="nonlinear-regression.html#cb203-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;akima&#39; was built under R version 3.3.3</span></span>
<span id="cb203-25"><a href="nonlinear-regression.html#cb203-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ggplot2&#39;</span>)           <span class="co"># красивые графики</span></span>
<span id="cb203-26"><a href="nonlinear-regression.html#cb203-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;ggplot2&#39; was built under R version 3.3.3</span></span>
<span id="cb203-27"><a href="nonlinear-regression.html#cb203-27" aria-hidden="true" tabindex="-1"></a>my.seed <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb203-28"><a href="nonlinear-regression.html#cb203-28" aria-hidden="true" tabindex="-1"></a>Работаем с набором данных по зарплатам <span class="dv">3000</span> работников<span class="sc">-</span>мужчин среднеатлантического региона Wage. Присоединяем его к пространству имён функцией <span class="fu">attach</span>(), и дальше обращаемся напрямую к столбцам таблицы.</span>
<span id="cb203-29"><a href="nonlinear-regression.html#cb203-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-30"><a href="nonlinear-regression.html#cb203-30" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Wage)</span>
<span id="cb203-31"><a href="nonlinear-regression.html#cb203-31" aria-hidden="true" tabindex="-1"></a>Работаем со столбцами<span class="sc">:</span></span>
<span id="cb203-32"><a href="nonlinear-regression.html#cb203-32" aria-hidden="true" tabindex="-1"></a>    <span class="er">*</span> wage – заработная плата работника до уплаты налогов;</span>
<span id="cb203-33"><a href="nonlinear-regression.html#cb203-33" aria-hidden="true" tabindex="-1"></a><span class="sc">*</span> age – возраст работника в годах.</span>
<span id="cb203-34"><a href="nonlinear-regression.html#cb203-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-35"><a href="nonlinear-regression.html#cb203-35" aria-hidden="true" tabindex="-1"></a>Полиномиальная регрессия</span>
<span id="cb203-36"><a href="nonlinear-regression.html#cb203-36" aria-hidden="true" tabindex="-1"></a>Зависимость зарплаты от возраста</span>
<span id="cb203-37"><a href="nonlinear-regression.html#cb203-37" aria-hidden="true" tabindex="-1"></a>Судя по графику ниже, ззаимосвязь заработной платы и возраста нелинейна. Наблюдается также группа наблюдений с высоким значением wage, граница проходит примерно на уровне <span class="fl">250.</span></span>
<span id="cb203-38"><a href="nonlinear-regression.html#cb203-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-39"><a href="nonlinear-regression.html#cb203-39" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> Wage, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> wage))</span>
<span id="cb203-40"><a href="nonlinear-regression.html#cb203-40" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> gp <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">0</span>, <span class="at">intercept =</span> <span class="dv">250</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb203-41"><a href="nonlinear-regression.html#cb203-41" aria-hidden="true" tabindex="-1"></a>gp</span>
<span id="cb203-42"><a href="nonlinear-regression.html#cb203-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-43"><a href="nonlinear-regression.html#cb203-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-44"><a href="nonlinear-regression.html#cb203-44" aria-hidden="true" tabindex="-1"></a>Подгоняем полином четвёртой степени для зависимости заработной платы от возраста.</span>
<span id="cb203-45"><a href="nonlinear-regression.html#cb203-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-46"><a href="nonlinear-regression.html#cb203-46" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb203-47"><a href="nonlinear-regression.html#cb203-47" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb203-48"><a href="nonlinear-regression.html#cb203-48" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb203-49"><a href="nonlinear-regression.html#cb203-49" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)     111.70       0.73  153.28     0.00</span></span>
<span id="cb203-50"><a href="nonlinear-regression.html#cb203-50" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)1   447.07      39.91   11.20     0.00</span></span>
<span id="cb203-51"><a href="nonlinear-regression.html#cb203-51" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)2  -478.32      39.91  -11.98     0.00</span></span>
<span id="cb203-52"><a href="nonlinear-regression.html#cb203-52" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)3   125.52      39.91    3.14     0.00</span></span>
<span id="cb203-53"><a href="nonlinear-regression.html#cb203-53" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)4   -77.91      39.91   -1.95     0.05</span></span>
<span id="cb203-54"><a href="nonlinear-regression.html#cb203-54" aria-hidden="true" tabindex="-1"></a>Функция <span class="fu">poly</span>(age, <span class="dv">4</span>) создаёт таблицу с базисом ортогональных полиномов<span class="sc">:</span> линейные комбинации значений переменной age в степенях от <span class="dv">1</span> до <span class="fl">4.</span></span>
<span id="cb203-55"><a href="nonlinear-regression.html#cb203-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-56"><a href="nonlinear-regression.html#cb203-56" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>)), <span class="dv">3</span>)</span>
<span id="cb203-57"><a href="nonlinear-regression.html#cb203-57" aria-hidden="true" tabindex="-1"></a><span class="do">##           1      2      3      4</span></span>
<span id="cb203-58"><a href="nonlinear-regression.html#cb203-58" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] -0.039  0.056 -0.072  0.087</span></span>
<span id="cb203-59"><a href="nonlinear-regression.html#cb203-59" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] -0.029  0.026 -0.015 -0.003</span></span>
<span id="cb203-60"><a href="nonlinear-regression.html#cb203-60" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,]  0.004 -0.015  0.000  0.014</span></span>
<span id="cb203-61"><a href="nonlinear-regression.html#cb203-61" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,]  0.001 -0.015  0.005  0.013</span></span>
<span id="cb203-62"><a href="nonlinear-regression.html#cb203-62" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,]  0.012 -0.010 -0.011  0.010</span></span>
<span id="cb203-63"><a href="nonlinear-regression.html#cb203-63" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,]  0.018 -0.002 -0.017 -0.001</span></span>
<span id="cb203-64"><a href="nonlinear-regression.html#cb203-64" aria-hidden="true" tabindex="-1"></a><span class="co"># можно получить сами значения age в заданных степенях</span></span>
<span id="cb203-65"><a href="nonlinear-regression.html#cb203-65" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T)), <span class="dv">3</span>)</span>
<span id="cb203-66"><a href="nonlinear-regression.html#cb203-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       1    2      3       4</span></span>
<span id="cb203-67"><a href="nonlinear-regression.html#cb203-67" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] 18  324   5832  104976</span></span>
<span id="cb203-68"><a href="nonlinear-regression.html#cb203-68" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] 24  576  13824  331776</span></span>
<span id="cb203-69"><a href="nonlinear-regression.html#cb203-69" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,] 45 2025  91125 4100625</span></span>
<span id="cb203-70"><a href="nonlinear-regression.html#cb203-70" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,] 43 1849  79507 3418801</span></span>
<span id="cb203-71"><a href="nonlinear-regression.html#cb203-71" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,] 50 2500 125000 6250000</span></span>
<span id="cb203-72"><a href="nonlinear-regression.html#cb203-72" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,] 54 2916 157464 8503056</span></span>
<span id="cb203-73"><a href="nonlinear-regression.html#cb203-73" aria-hidden="true" tabindex="-1"></a><span class="co"># на прогноз не повлияет, но оценки параметров изменяются</span></span>
<span id="cb203-74"><a href="nonlinear-regression.html#cb203-74" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T), <span class="at">data =</span> Wage)</span>
<span id="cb203-75"><a href="nonlinear-regression.html#cb203-75" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit<span class="fl">.2</span>)), <span class="dv">2</span>)</span>
<span id="cb203-76"><a href="nonlinear-regression.html#cb203-76" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb203-77"><a href="nonlinear-regression.html#cb203-77" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)             -184.15      60.04   -3.07     0.00</span></span>
<span id="cb203-78"><a href="nonlinear-regression.html#cb203-78" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)1    21.25       5.89    3.61     0.00</span></span>
<span id="cb203-79"><a href="nonlinear-regression.html#cb203-79" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)2    -0.56       0.21   -2.74     0.01</span></span>
<span id="cb203-80"><a href="nonlinear-regression.html#cb203-80" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)3     0.01       0.00    2.22     0.03</span></span>
<span id="cb203-81"><a href="nonlinear-regression.html#cb203-81" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)4     0.00       0.00   -1.95     0.05</span></span>
<span id="cb203-82"><a href="nonlinear-regression.html#cb203-82" aria-hidden="true" tabindex="-1"></a><span class="co"># границы изменения переменной age</span></span>
<span id="cb203-83"><a href="nonlinear-regression.html#cb203-83" aria-hidden="true" tabindex="-1"></a>agelims <span class="ot">&lt;-</span> <span class="fu">range</span>(age)</span>
<span id="cb203-84"><a href="nonlinear-regression.html#cb203-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-85"><a href="nonlinear-regression.html#cb203-85" aria-hidden="true" tabindex="-1"></a><span class="co"># значения age, для которых делаем прогноз (от min до max с шагом 1)</span></span>
<span id="cb203-86"><a href="nonlinear-regression.html#cb203-86" aria-hidden="true" tabindex="-1"></a>age.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> agelims[<span class="dv">1</span>], <span class="at">to =</span> agelims[<span class="dv">2</span>])</span>
<span id="cb203-87"><a href="nonlinear-regression.html#cb203-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-88"><a href="nonlinear-regression.html#cb203-88" aria-hidden="true" tabindex="-1"></a><span class="co"># рассчитать прогнозы и их стандартные ошибки</span></span>
<span id="cb203-89"><a href="nonlinear-regression.html#cb203-89" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb203-90"><a href="nonlinear-regression.html#cb203-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-91"><a href="nonlinear-regression.html#cb203-91" aria-hidden="true" tabindex="-1"></a><span class="co"># границы доверительного интервала для заработной платы</span></span>
<span id="cb203-92"><a href="nonlinear-regression.html#cb203-92" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb203-93"><a href="nonlinear-regression.html#cb203-93" aria-hidden="true" tabindex="-1"></a>                  <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb203-94"><a href="nonlinear-regression.html#cb203-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-95"><a href="nonlinear-regression.html#cb203-95" aria-hidden="true" tabindex="-1"></a><span class="co"># смотрим результат</span></span>
<span id="cb203-96"><a href="nonlinear-regression.html#cb203-96" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">2</span>)</span>
<span id="cb203-97"><a href="nonlinear-regression.html#cb203-97" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb203-98"><a href="nonlinear-regression.html#cb203-98" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       41.33       62.53</span></span>
<span id="cb203-99"><a href="nonlinear-regression.html#cb203-99" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       49.76       67.24</span></span>
<span id="cb203-100"><a href="nonlinear-regression.html#cb203-100" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       57.39       71.76</span></span>
<span id="cb203-101"><a href="nonlinear-regression.html#cb203-101" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       64.27       76.09</span></span>
<span id="cb203-102"><a href="nonlinear-regression.html#cb203-102" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       70.44       80.27</span></span>
<span id="cb203-103"><a href="nonlinear-regression.html#cb203-103" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       75.94       84.28</span></span>
<span id="cb203-104"><a href="nonlinear-regression.html#cb203-104" aria-hidden="true" tabindex="-1"></a>Рисуем левую панель графика со слайда <span class="dv">4</span> презентации (рис. <span class="fl">7.1</span> книги). Функция <span class="fu">matlines</span>() рисует грфик столбцов одной матрицы против столбцов другой.</span>
<span id="cb203-105"><a href="nonlinear-regression.html#cb203-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-106"><a href="nonlinear-regression.html#cb203-106" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb203-107"><a href="nonlinear-regression.html#cb203-107" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb203-108"><a href="nonlinear-regression.html#cb203-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-109"><a href="nonlinear-regression.html#cb203-109" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb203-110"><a href="nonlinear-regression.html#cb203-110" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb203-111"><a href="nonlinear-regression.html#cb203-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-112"><a href="nonlinear-regression.html#cb203-112" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb203-113"><a href="nonlinear-regression.html#cb203-113" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb203-114"><a href="nonlinear-regression.html#cb203-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-115"><a href="nonlinear-regression.html#cb203-115" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb203-116"><a href="nonlinear-regression.html#cb203-116" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb203-117"><a href="nonlinear-regression.html#cb203-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-118"><a href="nonlinear-regression.html#cb203-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-119"><a href="nonlinear-regression.html#cb203-119" aria-hidden="true" tabindex="-1"></a>Убедимся, что прогнозы по моделям с различными вызовами <span class="fu">poly</span>() совпадают.</span>
<span id="cb203-120"><a href="nonlinear-regression.html#cb203-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-121"><a href="nonlinear-regression.html#cb203-121" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы по второму вызову модели</span></span>
<span id="cb203-122"><a href="nonlinear-regression.html#cb203-122" aria-hidden="true" tabindex="-1"></a>preds2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit<span class="fl">.2</span>, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb203-123"><a href="nonlinear-regression.html#cb203-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-124"><a href="nonlinear-regression.html#cb203-124" aria-hidden="true" tabindex="-1"></a><span class="co"># максимальное расхождение между прогнозами по двум вариантам вызова модели</span></span>
<span id="cb203-125"><a href="nonlinear-regression.html#cb203-125" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(preds<span class="sc">$</span>fit <span class="sc">-</span> preds2<span class="sc">$</span>fit))</span>
<span id="cb203-126"><a href="nonlinear-regression.html#cb203-126" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 7.389644e-13</span></span>
<span id="cb203-127"><a href="nonlinear-regression.html#cb203-127" aria-hidden="true" tabindex="-1"></a>Теперь подбираем степень полинома, сравнивая модели со степенями от <span class="dv">1</span> до <span class="dv">5</span> с помощью дисперсионного анализа (ANOVA).</span>
<span id="cb203-128"><a href="nonlinear-regression.html#cb203-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-129"><a href="nonlinear-regression.html#cb203-129" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> age, <span class="at">data =</span> Wage)</span>
<span id="cb203-130"><a href="nonlinear-regression.html#cb203-130" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">2</span>), <span class="at">data =</span> Wage)</span>
<span id="cb203-131"><a href="nonlinear-regression.html#cb203-131" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">3</span>), <span class="at">data =</span> Wage)</span>
<span id="cb203-132"><a href="nonlinear-regression.html#cb203-132" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb203-133"><a href="nonlinear-regression.html#cb203-133" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">5</span>), <span class="at">data =</span> Wage)</span>
<span id="cb203-134"><a href="nonlinear-regression.html#cb203-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-135"><a href="nonlinear-regression.html#cb203-135" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">anova</span>(fit<span class="fl">.1</span>, fit<span class="fl">.2</span>, fit<span class="fl">.3</span>, fit<span class="fl">.4</span>, fit<span class="fl">.5</span>), <span class="dv">2</span>)</span>
<span id="cb203-136"><a href="nonlinear-regression.html#cb203-136" aria-hidden="true" tabindex="-1"></a>Res.Df</span>
<span id="cb203-137"><a href="nonlinear-regression.html#cb203-137" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-138"><a href="nonlinear-regression.html#cb203-138" aria-hidden="true" tabindex="-1"></a>    RSS</span>
<span id="cb203-139"><a href="nonlinear-regression.html#cb203-139" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-140"><a href="nonlinear-regression.html#cb203-140" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb203-141"><a href="nonlinear-regression.html#cb203-141" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-142"><a href="nonlinear-regression.html#cb203-142" aria-hidden="true" tabindex="-1"></a>    Sum of Sq</span>
<span id="cb203-143"><a href="nonlinear-regression.html#cb203-143" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-144"><a href="nonlinear-regression.html#cb203-144" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb203-145"><a href="nonlinear-regression.html#cb203-145" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-146"><a href="nonlinear-regression.html#cb203-146" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb203-147"><a href="nonlinear-regression.html#cb203-147" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-148"><a href="nonlinear-regression.html#cb203-148" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2998</span>    <span class="dv">5022216</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb203-149"><a href="nonlinear-regression.html#cb203-149" aria-hidden="true" tabindex="-1"></a><span class="dv">2997</span>    <span class="dv">4793430</span> <span class="dv">1</span>   <span class="fl">228786.01</span>   <span class="fl">143.59</span>  <span class="fl">0.00</span></span>
<span id="cb203-150"><a href="nonlinear-regression.html#cb203-150" aria-hidden="true" tabindex="-1"></a><span class="dv">2996</span>    <span class="dv">4777674</span> <span class="dv">1</span>   <span class="fl">15755.69</span>    <span class="fl">9.89</span>    <span class="fl">0.00</span></span>
<span id="cb203-151"><a href="nonlinear-regression.html#cb203-151" aria-hidden="true" tabindex="-1"></a><span class="dv">2995</span>    <span class="dv">4771604</span> <span class="dv">1</span>   <span class="fl">6070.15</span> <span class="fl">3.81</span>    <span class="fl">0.05</span></span>
<span id="cb203-152"><a href="nonlinear-regression.html#cb203-152" aria-hidden="true" tabindex="-1"></a><span class="dv">2994</span>    <span class="dv">4770322</span> <span class="dv">1</span>   <span class="fl">1282.56</span> <span class="fl">0.80</span>    <span class="fl">0.37</span></span>
<span id="cb203-153"><a href="nonlinear-regression.html#cb203-153" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> rows</span>
<span id="cb203-154"><a href="nonlinear-regression.html#cb203-154" aria-hidden="true" tabindex="-1"></a>Рассматриваются пять моделей, в которых степени полинома от age идут по возрастанию. В крайнем правом столбце таблице приводятся p<span class="sc">-</span>значения для проверки нулевой гипотезы<span class="sc">:</span> текущая модель не даёт статистически значимого сокращения RSS по сравнению с предыдущей моделью. Можно сделать вывод, что степени <span class="dv">3</span> достаточно, дальнейшее увеличение степени не даёт значимого улучшения качества модели.</span>
<span id="cb203-155"><a href="nonlinear-regression.html#cb203-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-156"><a href="nonlinear-regression.html#cb203-156" aria-hidden="true" tabindex="-1"></a>Зависимость вероятности получать зарплату <span class="sc">&gt;</span> <span class="dv">250</span> от возраста</span>
<span id="cb203-157"><a href="nonlinear-regression.html#cb203-157" aria-hidden="true" tabindex="-1"></a>Теперь вернёмся к группе наблюдений с высоким wage. Рассмотрим зависимость вероятности того, что величина зарплаты больше <span class="dv">250</span>, от возраста.</span>
<span id="cb203-158"><a href="nonlinear-regression.html#cb203-158" aria-hidden="true" tabindex="-1"></a>Подгоняем логистическую регрессию и делаем прогнозы, для этого используем функцию для оценки обобщённой линейной модели  <span class="fu">glm</span>() и указываем тип модели binomial<span class="sc">:</span></span>
<span id="cb203-159"><a href="nonlinear-regression.html#cb203-159" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb203-160"><a href="nonlinear-regression.html#cb203-160" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb203-161"><a href="nonlinear-regression.html#cb203-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-162"><a href="nonlinear-regression.html#cb203-162" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb203-163"><a href="nonlinear-regression.html#cb203-163" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb203-164"><a href="nonlinear-regression.html#cb203-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-165"><a href="nonlinear-regression.html#cb203-165" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb203-166"><a href="nonlinear-regression.html#cb203-166" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb203-167"><a href="nonlinear-regression.html#cb203-167" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb203-168"><a href="nonlinear-regression.html#cb203-168" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb203-169"><a href="nonlinear-regression.html#cb203-169" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb203-170"><a href="nonlinear-regression.html#cb203-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-171"><a href="nonlinear-regression.html#cb203-171" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb203-172"><a href="nonlinear-regression.html#cb203-172" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb203-173"><a href="nonlinear-regression.html#cb203-173" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb203-174"><a href="nonlinear-regression.html#cb203-174" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb203-175"><a href="nonlinear-regression.html#cb203-175" aria-hidden="true" tabindex="-1"></a><span class="do">## 1           0       0.002</span></span>
<span id="cb203-176"><a href="nonlinear-regression.html#cb203-176" aria-hidden="true" tabindex="-1"></a><span class="do">## 2           0       0.003</span></span>
<span id="cb203-177"><a href="nonlinear-regression.html#cb203-177" aria-hidden="true" tabindex="-1"></a><span class="do">## 3           0       0.004</span></span>
<span id="cb203-178"><a href="nonlinear-regression.html#cb203-178" aria-hidden="true" tabindex="-1"></a><span class="do">## 4           0       0.005</span></span>
<span id="cb203-179"><a href="nonlinear-regression.html#cb203-179" aria-hidden="true" tabindex="-1"></a><span class="do">## 5           0       0.006</span></span>
<span id="cb203-180"><a href="nonlinear-regression.html#cb203-180" aria-hidden="true" tabindex="-1"></a><span class="do">## 6           0       0.007</span></span>
<span id="cb203-181"><a href="nonlinear-regression.html#cb203-181" aria-hidden="true" tabindex="-1"></a>Достраиваем график с <span class="dv">4</span> слайда презентации (рис. <span class="fl">7.1</span> книги). Рисуем правую панель.</span>
<span id="cb203-182"><a href="nonlinear-regression.html#cb203-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-183"><a href="nonlinear-regression.html#cb203-183" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb203-184"><a href="nonlinear-regression.html#cb203-184" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb203-185"><a href="nonlinear-regression.html#cb203-185" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb203-186"><a href="nonlinear-regression.html#cb203-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-187"><a href="nonlinear-regression.html#cb203-187" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb203-188"><a href="nonlinear-regression.html#cb203-188" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb203-189"><a href="nonlinear-regression.html#cb203-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-190"><a href="nonlinear-regression.html#cb203-190" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb203-191"><a href="nonlinear-regression.html#cb203-191" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb203-192"><a href="nonlinear-regression.html#cb203-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-193"><a href="nonlinear-regression.html#cb203-193" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb203-194"><a href="nonlinear-regression.html#cb203-194" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb203-195"><a href="nonlinear-regression.html#cb203-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-196"><a href="nonlinear-regression.html#cb203-196" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb203-197"><a href="nonlinear-regression.html#cb203-197" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb203-198"><a href="nonlinear-regression.html#cb203-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-199"><a href="nonlinear-regression.html#cb203-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-200"><a href="nonlinear-regression.html#cb203-200" aria-hidden="true" tabindex="-1"></a>Ступенчатые функции</span>
<span id="cb203-201"><a href="nonlinear-regression.html#cb203-201" aria-hidden="true" tabindex="-1"></a>Для начала определим несколько интервалов, на каждом из которых будем моделировать зависимость wage от age своим средним уровнем.</span>
<span id="cb203-202"><a href="nonlinear-regression.html#cb203-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-203"><a href="nonlinear-regression.html#cb203-203" aria-hidden="true" tabindex="-1"></a><span class="co"># нарезаем предиктор age на 4 равных интервала</span></span>
<span id="cb203-204"><a href="nonlinear-regression.html#cb203-204" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">cut</span>(age, <span class="dv">4</span>))</span>
<span id="cb203-205"><a href="nonlinear-regression.html#cb203-205" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb203-206"><a href="nonlinear-regression.html#cb203-206" aria-hidden="true" tabindex="-1"></a><span class="do">## (17.9,33.5]   (33.5,49]   (49,64.5] (64.5,80.1] </span></span>
<span id="cb203-207"><a href="nonlinear-regression.html#cb203-207" aria-hidden="true" tabindex="-1"></a><span class="do">##         750        1399         779          72</span></span>
<span id="cb203-208"><a href="nonlinear-regression.html#cb203-208" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем линейную модель на интервалах</span></span>
<span id="cb203-209"><a href="nonlinear-regression.html#cb203-209" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb203-210"><a href="nonlinear-regression.html#cb203-210" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb203-211"><a href="nonlinear-regression.html#cb203-211" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb203-212"><a href="nonlinear-regression.html#cb203-212" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)               94.16       1.48   63.79     0.00</span></span>
<span id="cb203-213"><a href="nonlinear-regression.html#cb203-213" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(33.5,49]      24.05       1.83   13.15     0.00</span></span>
<span id="cb203-214"><a href="nonlinear-regression.html#cb203-214" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(49,64.5]      23.66       2.07   11.44     0.00</span></span>
<span id="cb203-215"><a href="nonlinear-regression.html#cb203-215" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(64.5,80.1]     7.64       4.99    1.53     0.13</span></span>
<span id="cb203-216"><a href="nonlinear-regression.html#cb203-216" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз -- это средние по `wage` на каждом интервале</span></span>
<span id="cb203-217"><a href="nonlinear-regression.html#cb203-217" aria-hidden="true" tabindex="-1"></a>preds.cut <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb203-218"><a href="nonlinear-regression.html#cb203-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-219"><a href="nonlinear-regression.html#cb203-219" aria-hidden="true" tabindex="-1"></a><span class="co"># интервальный прогноз</span></span>
<span id="cb203-220"><a href="nonlinear-regression.html#cb203-220" aria-hidden="true" tabindex="-1"></a>se.bands.cut <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit,</span>
<span id="cb203-221"><a href="nonlinear-regression.html#cb203-221" aria-hidden="true" tabindex="-1"></a>                      <span class="at">upper.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit)</span>
<span id="cb203-222"><a href="nonlinear-regression.html#cb203-222" aria-hidden="true" tabindex="-1"></a>Воспроизведём график со слайда <span class="dv">7</span> презентации (рис. <span class="fl">7.2</span> книги).</span>
<span id="cb203-223"><a href="nonlinear-regression.html#cb203-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-224"><a href="nonlinear-regression.html#cb203-224" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb203-225"><a href="nonlinear-regression.html#cb203-225" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb203-226"><a href="nonlinear-regression.html#cb203-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-227"><a href="nonlinear-regression.html#cb203-227" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb203-228"><a href="nonlinear-regression.html#cb203-228" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.cut<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb203-229"><a href="nonlinear-regression.html#cb203-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-230"><a href="nonlinear-regression.html#cb203-230" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb203-231"><a href="nonlinear-regression.html#cb203-231" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands.cut, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb203-232"><a href="nonlinear-regression.html#cb203-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-233"><a href="nonlinear-regression.html#cb203-233" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb203-234"><a href="nonlinear-regression.html#cb203-234" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb203-235"><a href="nonlinear-regression.html#cb203-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-236"><a href="nonlinear-regression.html#cb203-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-237"><a href="nonlinear-regression.html#cb203-237" aria-hidden="true" tabindex="-1"></a>Правая часть графика, для вероятности того, что зарплата выше <span class="fl">250.</span></span>
<span id="cb203-238"><a href="nonlinear-regression.html#cb203-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-239"><a href="nonlinear-regression.html#cb203-239" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb203-240"><a href="nonlinear-regression.html#cb203-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-241"><a href="nonlinear-regression.html#cb203-241" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb203-242"><a href="nonlinear-regression.html#cb203-242" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb203-243"><a href="nonlinear-regression.html#cb203-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-244"><a href="nonlinear-regression.html#cb203-244" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb203-245"><a href="nonlinear-regression.html#cb203-245" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb203-246"><a href="nonlinear-regression.html#cb203-246" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb203-247"><a href="nonlinear-regression.html#cb203-247" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb203-248"><a href="nonlinear-regression.html#cb203-248" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb203-249"><a href="nonlinear-regression.html#cb203-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-250"><a href="nonlinear-regression.html#cb203-250" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb203-251"><a href="nonlinear-regression.html#cb203-251" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb203-252"><a href="nonlinear-regression.html#cb203-252" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb203-253"><a href="nonlinear-regression.html#cb203-253" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb203-254"><a href="nonlinear-regression.html#cb203-254" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       0.003       0.016</span></span>
<span id="cb203-255"><a href="nonlinear-regression.html#cb203-255" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       0.003       0.016</span></span>
<span id="cb203-256"><a href="nonlinear-regression.html#cb203-256" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       0.003       0.016</span></span>
<span id="cb203-257"><a href="nonlinear-regression.html#cb203-257" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       0.003       0.016</span></span>
<span id="cb203-258"><a href="nonlinear-regression.html#cb203-258" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       0.003       0.016</span></span>
<span id="cb203-259"><a href="nonlinear-regression.html#cb203-259" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       0.003       0.016</span></span>
<span id="cb203-260"><a href="nonlinear-regression.html#cb203-260" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb203-261"><a href="nonlinear-regression.html#cb203-261" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb203-262"><a href="nonlinear-regression.html#cb203-262" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb203-263"><a href="nonlinear-regression.html#cb203-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-264"><a href="nonlinear-regression.html#cb203-264" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb203-265"><a href="nonlinear-regression.html#cb203-265" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb203-266"><a href="nonlinear-regression.html#cb203-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-267"><a href="nonlinear-regression.html#cb203-267" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb203-268"><a href="nonlinear-regression.html#cb203-268" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb203-269"><a href="nonlinear-regression.html#cb203-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-270"><a href="nonlinear-regression.html#cb203-270" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb203-271"><a href="nonlinear-regression.html#cb203-271" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb203-272"><a href="nonlinear-regression.html#cb203-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-273"><a href="nonlinear-regression.html#cb203-273" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb203-274"><a href="nonlinear-regression.html#cb203-274" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb203-275"><a href="nonlinear-regression.html#cb203-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-276"><a href="nonlinear-regression.html#cb203-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-277"><a href="nonlinear-regression.html#cb203-277" aria-hidden="true" tabindex="-1"></a>Сплайны</span>
<span id="cb203-278"><a href="nonlinear-regression.html#cb203-278" aria-hidden="true" tabindex="-1"></a>Построим кубический сплайн с тремя узлами.</span>
<span id="cb203-279"><a href="nonlinear-regression.html#cb203-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-280"><a href="nonlinear-regression.html#cb203-280" aria-hidden="true" tabindex="-1"></a><span class="co"># кубический сплайн с тремя узлами</span></span>
<span id="cb203-281"><a href="nonlinear-regression.html#cb203-281" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)), <span class="at">data =</span> Wage)</span>
<span id="cb203-282"><a href="nonlinear-regression.html#cb203-282" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb203-283"><a href="nonlinear-regression.html#cb203-283" aria-hidden="true" tabindex="-1"></a>preds.spl <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb203-284"><a href="nonlinear-regression.html#cb203-284" aria-hidden="true" tabindex="-1"></a>Теперь построим натуральный по трём узлам. Три узла это <span class="dv">6</span> степеней свободы. Если функции <span class="fu">bs</span>(), которая создаёт матрицу с базисом для полиномиального сплайна, передать только степени свободы, она распределит узлы равномерно. В данном случае это квартили распределения age.</span>
<span id="cb203-285"><a href="nonlinear-regression.html#cb203-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-286"><a href="nonlinear-regression.html#cb203-286" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 узла -- 6 степеней свободы (столбцы матрицы)</span></span>
<span id="cb203-287"><a href="nonlinear-regression.html#cb203-287" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)))</span>
<span id="cb203-288"><a href="nonlinear-regression.html#cb203-288" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb203-289"><a href="nonlinear-regression.html#cb203-289" aria-hidden="true" tabindex="-1"></a><span class="co"># если не указываем узлы явно...</span></span>
<span id="cb203-290"><a href="nonlinear-regression.html#cb203-290" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>))</span>
<span id="cb203-291"><a href="nonlinear-regression.html#cb203-291" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb203-292"><a href="nonlinear-regression.html#cb203-292" aria-hidden="true" tabindex="-1"></a><span class="co">#  они привязываются к квартилям</span></span>
<span id="cb203-293"><a href="nonlinear-regression.html#cb203-293" aria-hidden="true" tabindex="-1"></a><span class="fu">attr</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>), <span class="st">&#39;knots&#39;</span>)</span>
<span id="cb203-294"><a href="nonlinear-regression.html#cb203-294" aria-hidden="true" tabindex="-1"></a><span class="do">##   25%   50%   75% </span></span>
<span id="cb203-295"><a href="nonlinear-regression.html#cb203-295" aria-hidden="true" tabindex="-1"></a><span class="do">## 33.75 42.00 51.00</span></span>
<span id="cb203-296"><a href="nonlinear-regression.html#cb203-296" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb203-297"><a href="nonlinear-regression.html#cb203-297" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(age, <span class="at">df =</span> <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb203-298"><a href="nonlinear-regression.html#cb203-298" aria-hidden="true" tabindex="-1"></a>preds.spl2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit2, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb203-299"><a href="nonlinear-regression.html#cb203-299" aria-hidden="true" tabindex="-1"></a>График сравнения кубического и натурального сплайнов.</span>
<span id="cb203-300"><a href="nonlinear-regression.html#cb203-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-301"><a href="nonlinear-regression.html#cb203-301" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="fl">8.5</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="at">xpd =</span> T)</span>
<span id="cb203-302"><a href="nonlinear-regression.html#cb203-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-303"><a href="nonlinear-regression.html#cb203-303" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb203-304"><a href="nonlinear-regression.html#cb203-304" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">col =</span> <span class="st">&#39;grey&#39;</span>)</span>
<span id="cb203-305"><a href="nonlinear-regression.html#cb203-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-306"><a href="nonlinear-regression.html#cb203-306" aria-hidden="true" tabindex="-1"></a><span class="co"># модель кубического сплайна</span></span>
<span id="cb203-307"><a href="nonlinear-regression.html#cb203-307" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb203-308"><a href="nonlinear-regression.html#cb203-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-309"><a href="nonlinear-regression.html#cb203-309" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительный интервал</span></span>
<span id="cb203-310"><a href="nonlinear-regression.html#cb203-310" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb203-311"><a href="nonlinear-regression.html#cb203-311" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb203-312"><a href="nonlinear-regression.html#cb203-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-313"><a href="nonlinear-regression.html#cb203-313" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb203-314"><a href="nonlinear-regression.html#cb203-314" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl2<span class="sc">$</span>fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb203-315"><a href="nonlinear-regression.html#cb203-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-316"><a href="nonlinear-regression.html#cb203-316" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb203-317"><a href="nonlinear-regression.html#cb203-317" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">inset =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.7</span>, <span class="dv">0</span>),</span>
<span id="cb203-318"><a href="nonlinear-regression.html#cb203-318" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;Кубический </span><span class="sc">\n</span><span class="st"> с 3 узлами&#39;</span>, <span class="st">&#39;Натуральный&#39;</span>),</span>
<span id="cb203-319"><a href="nonlinear-regression.html#cb203-319" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="fu">rep</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;red&#39;</span>))</span>
<span id="cb203-320"><a href="nonlinear-regression.html#cb203-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-321"><a href="nonlinear-regression.html#cb203-321" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb203-322"><a href="nonlinear-regression.html#cb203-322" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Сплайны&quot;</span>)</span>
<span id="cb203-323"><a href="nonlinear-regression.html#cb203-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-324"><a href="nonlinear-regression.html#cb203-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-325"><a href="nonlinear-regression.html#cb203-325" aria-hidden="true" tabindex="-1"></a>Построим график со слайда <span class="dv">20</span> (рисунок <span class="fl">7.8</span> книги).</span>
<span id="cb203-326"><a href="nonlinear-regression.html#cb203-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-327"><a href="nonlinear-regression.html#cb203-327" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">0</span>))</span>
<span id="cb203-328"><a href="nonlinear-regression.html#cb203-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-329"><a href="nonlinear-regression.html#cb203-329" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb203-330"><a href="nonlinear-regression.html#cb203-330" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb203-331"><a href="nonlinear-regression.html#cb203-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-332"><a href="nonlinear-regression.html#cb203-332" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb203-333"><a href="nonlinear-regression.html#cb203-333" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Сглаживающий сплайн&#39;</span>)</span>
<span id="cb203-334"><a href="nonlinear-regression.html#cb203-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-335"><a href="nonlinear-regression.html#cb203-335" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с 16 степенями свободы</span></span>
<span id="cb203-336"><a href="nonlinear-regression.html#cb203-336" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">df =</span> <span class="dv">16</span>)</span>
<span id="cb203-337"><a href="nonlinear-regression.html#cb203-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-338"><a href="nonlinear-regression.html#cb203-338" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с подбором лямбды с помощью перекрёстной проверки</span></span>
<span id="cb203-339"><a href="nonlinear-regression.html#cb203-339" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">cv =</span> T)</span>
<span id="cb203-340"><a href="nonlinear-regression.html#cb203-340" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in smooth.spline(age, wage, cv = T): cross-validation with non-</span></span>
<span id="cb203-341"><a href="nonlinear-regression.html#cb203-341" aria-hidden="true" tabindex="-1"></a><span class="do">## unique &#39;x&#39; values seems doubtful</span></span>
<span id="cb203-342"><a href="nonlinear-regression.html#cb203-342" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span>df</span>
<span id="cb203-343"><a href="nonlinear-regression.html#cb203-343" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 6.794596</span></span>
<span id="cb203-344"><a href="nonlinear-regression.html#cb203-344" aria-hidden="true" tabindex="-1"></a><span class="co"># рисуем модель</span></span>
<span id="cb203-345"><a href="nonlinear-regression.html#cb203-345" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb203-346"><a href="nonlinear-regression.html#cb203-346" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit2, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb203-347"><a href="nonlinear-regression.html#cb203-347" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb203-348"><a href="nonlinear-regression.html#cb203-348" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;16 df&#39;</span>, <span class="st">&#39;6.8 df&#39;</span>),</span>
<span id="cb203-349"><a href="nonlinear-regression.html#cb203-349" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb203-350"><a href="nonlinear-regression.html#cb203-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-351"><a href="nonlinear-regression.html#cb203-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-352"><a href="nonlinear-regression.html#cb203-352" aria-hidden="true" tabindex="-1"></a>Локальная регрессия</span>
<span id="cb203-353"><a href="nonlinear-regression.html#cb203-353" aria-hidden="true" tabindex="-1"></a>Строим график со слайда <span class="dv">24</span> (рис. <span class="fl">7.10</span>).</span>
<span id="cb203-354"><a href="nonlinear-regression.html#cb203-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-355"><a href="nonlinear-regression.html#cb203-355" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb203-356"><a href="nonlinear-regression.html#cb203-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-357"><a href="nonlinear-regression.html#cb203-357" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Локальная регрессия&#39;</span>)</span>
<span id="cb203-358"><a href="nonlinear-regression.html#cb203-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-359"><a href="nonlinear-regression.html#cb203-359" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.2</span></span>
<span id="cb203-360"><a href="nonlinear-regression.html#cb203-360" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.2</span>, <span class="at">data =</span> Wage)</span>
<span id="cb203-361"><a href="nonlinear-regression.html#cb203-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-362"><a href="nonlinear-regression.html#cb203-362" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.5</span></span>
<span id="cb203-363"><a href="nonlinear-regression.html#cb203-363" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.5</span>, <span class="at">data =</span> Wage)</span>
<span id="cb203-364"><a href="nonlinear-regression.html#cb203-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-365"><a href="nonlinear-regression.html#cb203-365" aria-hidden="true" tabindex="-1"></a><span class="co"># рисум модели</span></span>
<span id="cb203-366"><a href="nonlinear-regression.html#cb203-366" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb203-367"><a href="nonlinear-regression.html#cb203-367" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb203-368"><a href="nonlinear-regression.html#cb203-368" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit2, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb203-369"><a href="nonlinear-regression.html#cb203-369" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb203-370"><a href="nonlinear-regression.html#cb203-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-371"><a href="nonlinear-regression.html#cb203-371" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb203-372"><a href="nonlinear-regression.html#cb203-372" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb203-373"><a href="nonlinear-regression.html#cb203-373" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;s = 0.2&#39;</span>, <span class="st">&#39;s = 0.5&#39;</span>),</span>
<span id="cb203-374"><a href="nonlinear-regression.html#cb203-374" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb203-375"><a href="nonlinear-regression.html#cb203-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-376"><a href="nonlinear-regression.html#cb203-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-377"><a href="nonlinear-regression.html#cb203-377" aria-hidden="true" tabindex="-1"></a>Обобщённые аддитивные модели (GAM) с непрерывным откликом</span>
<span id="cb203-378"><a href="nonlinear-regression.html#cb203-378" aria-hidden="true" tabindex="-1"></a>Построим GAM на натуральных сплайнах степеней <span class="dv">4</span> (year), <span class="dv">5</span> (age) с категориальным предиктором edication.</span>
<span id="cb203-379"><a href="nonlinear-regression.html#cb203-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-380"><a href="nonlinear-regression.html#cb203-380" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на натуральных сплайнах</span></span>
<span id="cb203-381"><a href="nonlinear-regression.html#cb203-381" aria-hidden="true" tabindex="-1"></a>gam.ns <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">ns</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb203-382"><a href="nonlinear-regression.html#cb203-382" aria-hidden="true" tabindex="-1"></a>Также построим модель на сглаживающих сплайнах.</span>
<span id="cb203-383"><a href="nonlinear-regression.html#cb203-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-384"><a href="nonlinear-regression.html#cb203-384" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на сглаживающих сплайнах</span></span>
<span id="cb203-385"><a href="nonlinear-regression.html#cb203-385" aria-hidden="true" tabindex="-1"></a>gam.m3 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb203-386"><a href="nonlinear-regression.html#cb203-386" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">28</span> (рис. <span class="fl">7.12</span>).</span>
<span id="cb203-387"><a href="nonlinear-regression.html#cb203-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-388"><a href="nonlinear-regression.html#cb203-388" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb203-389"><a href="nonlinear-regression.html#cb203-389" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.m3, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb203-390"><a href="nonlinear-regression.html#cb203-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-391"><a href="nonlinear-regression.html#cb203-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-392"><a href="nonlinear-regression.html#cb203-392" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">27</span> (рис. <span class="fl">7.11</span>).</span>
<span id="cb203-393"><a href="nonlinear-regression.html#cb203-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-394"><a href="nonlinear-regression.html#cb203-394" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb203-395"><a href="nonlinear-regression.html#cb203-395" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.ns, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb203-396"><a href="nonlinear-regression.html#cb203-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-397"><a href="nonlinear-regression.html#cb203-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-398"><a href="nonlinear-regression.html#cb203-398" aria-hidden="true" tabindex="-1"></a>График функции от year похож на прямую. Сделаем ANOVA, чтобы понять, какая степень для year лучше.</span>
<span id="cb203-399"><a href="nonlinear-regression.html#cb203-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-400"><a href="nonlinear-regression.html#cb203-400" aria-hidden="true" tabindex="-1"></a>gam.m1 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)          <span class="co"># без year</span></span>
<span id="cb203-401"><a href="nonlinear-regression.html#cb203-401" aria-hidden="true" tabindex="-1"></a>gam.m2 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)   <span class="co"># year^1</span></span>
<span id="cb203-402"><a href="nonlinear-regression.html#cb203-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-403"><a href="nonlinear-regression.html#cb203-403" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(gam.m1, gam.m2, gam.m3, <span class="at">test =</span> <span class="st">&#39;F&#39;</span>)</span>
<span id="cb203-404"><a href="nonlinear-regression.html#cb203-404" aria-hidden="true" tabindex="-1"></a>Resid. Df</span>
<span id="cb203-405"><a href="nonlinear-regression.html#cb203-405" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-406"><a href="nonlinear-regression.html#cb203-406" aria-hidden="true" tabindex="-1"></a>    Resid. Dev</span>
<span id="cb203-407"><a href="nonlinear-regression.html#cb203-407" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-408"><a href="nonlinear-regression.html#cb203-408" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb203-409"><a href="nonlinear-regression.html#cb203-409" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-410"><a href="nonlinear-regression.html#cb203-410" aria-hidden="true" tabindex="-1"></a>    Deviance</span>
<span id="cb203-411"><a href="nonlinear-regression.html#cb203-411" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-412"><a href="nonlinear-regression.html#cb203-412" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb203-413"><a href="nonlinear-regression.html#cb203-413" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-414"><a href="nonlinear-regression.html#cb203-414" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb203-415"><a href="nonlinear-regression.html#cb203-415" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb203-416"><a href="nonlinear-regression.html#cb203-416" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2990</span>    <span class="dv">3711731</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb203-417"><a href="nonlinear-regression.html#cb203-417" aria-hidden="true" tabindex="-1"></a><span class="dv">2989</span>    <span class="dv">3693842</span> <span class="fl">1.000000</span>    <span class="fl">17889.243</span>   <span class="fl">14.477130</span>   <span class="fl">0.0001447167</span></span>
<span id="cb203-418"><a href="nonlinear-regression.html#cb203-418" aria-hidden="true" tabindex="-1"></a><span class="dv">2986</span>    <span class="dv">3689770</span> <span class="fl">2.999989</span>    <span class="fl">4071.134</span>    <span class="fl">1.098212</span>    <span class="fl">0.3485661430</span></span>
<span id="cb203-419"><a href="nonlinear-regression.html#cb203-419" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> rows</span>
<span id="cb203-420"><a href="nonlinear-regression.html#cb203-420" aria-hidden="true" tabindex="-1"></a>Третья модель статистически не лучше второй. Кроме того, один из параметров этой модели незначим.</span>
<span id="cb203-421"><a href="nonlinear-regression.html#cb203-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-422"><a href="nonlinear-regression.html#cb203-422" aria-hidden="true" tabindex="-1"></a><span class="co"># сводка по модели gam.m3</span></span>
<span id="cb203-423"><a href="nonlinear-regression.html#cb203-423" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gam.m3)</span>
<span id="cb203-424"><a href="nonlinear-regression.html#cb203-424" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb203-425"><a href="nonlinear-regression.html#cb203-425" aria-hidden="true" tabindex="-1"></a><span class="do">## Call: gam(formula = wage ~ s(year, 4) + s(age, 5) + education, data = Wage)</span></span>
<span id="cb203-426"><a href="nonlinear-regression.html#cb203-426" aria-hidden="true" tabindex="-1"></a><span class="do">## Deviance Residuals:</span></span>
<span id="cb203-427"><a href="nonlinear-regression.html#cb203-427" aria-hidden="true" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb203-428"><a href="nonlinear-regression.html#cb203-428" aria-hidden="true" tabindex="-1"></a><span class="do">## -119.43  -19.70   -3.33   14.17  213.48 </span></span>
<span id="cb203-429"><a href="nonlinear-regression.html#cb203-429" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb203-430"><a href="nonlinear-regression.html#cb203-430" aria-hidden="true" tabindex="-1"></a><span class="do">## (Dispersion Parameter for gaussian family taken to be 1235.69)</span></span>
<span id="cb203-431"><a href="nonlinear-regression.html#cb203-431" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb203-432"><a href="nonlinear-regression.html#cb203-432" aria-hidden="true" tabindex="-1"></a><span class="do">##     Null Deviance: 5222086 on 2999 degrees of freedom</span></span>
<span id="cb203-433"><a href="nonlinear-regression.html#cb203-433" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual Deviance: 3689770 on 2986 degrees of freedom</span></span>
<span id="cb203-434"><a href="nonlinear-regression.html#cb203-434" aria-hidden="true" tabindex="-1"></a><span class="do">## AIC: 29887.75 </span></span>
<span id="cb203-435"><a href="nonlinear-regression.html#cb203-435" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb203-436"><a href="nonlinear-regression.html#cb203-436" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Local Scoring Iterations: 2 </span></span>
<span id="cb203-437"><a href="nonlinear-regression.html#cb203-437" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb203-438"><a href="nonlinear-regression.html#cb203-438" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Parametric Effects</span></span>
<span id="cb203-439"><a href="nonlinear-regression.html#cb203-439" aria-hidden="true" tabindex="-1"></a><span class="do">##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    </span></span>
<span id="cb203-440"><a href="nonlinear-regression.html#cb203-440" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)    1   27162   27162  21.981 2.877e-06 ***</span></span>
<span id="cb203-441"><a href="nonlinear-regression.html#cb203-441" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)     1  195338  195338 158.081 &lt; 2.2e-16 ***</span></span>
<span id="cb203-442"><a href="nonlinear-regression.html#cb203-442" aria-hidden="true" tabindex="-1"></a><span class="do">## education     4 1069726  267432 216.423 &lt; 2.2e-16 ***</span></span>
<span id="cb203-443"><a href="nonlinear-regression.html#cb203-443" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals  2986 3689770    1236                      </span></span>
<span id="cb203-444"><a href="nonlinear-regression.html#cb203-444" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb203-445"><a href="nonlinear-regression.html#cb203-445" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb203-446"><a href="nonlinear-regression.html#cb203-446" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb203-447"><a href="nonlinear-regression.html#cb203-447" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Nonparametric Effects</span></span>
<span id="cb203-448"><a href="nonlinear-regression.html#cb203-448" aria-hidden="true" tabindex="-1"></a><span class="do">##             Npar Df Npar F  Pr(F)    </span></span>
<span id="cb203-449"><a href="nonlinear-regression.html#cb203-449" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)                          </span></span>
<span id="cb203-450"><a href="nonlinear-regression.html#cb203-450" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)        3  1.086 0.3537    </span></span>
<span id="cb203-451"><a href="nonlinear-regression.html#cb203-451" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)         4 32.380 &lt;2e-16 ***</span></span>
<span id="cb203-452"><a href="nonlinear-regression.html#cb203-452" aria-hidden="true" tabindex="-1"></a><span class="do">## education                            </span></span>
<span id="cb203-453"><a href="nonlinear-regression.html#cb203-453" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb203-454"><a href="nonlinear-regression.html#cb203-454" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb203-455"><a href="nonlinear-regression.html#cb203-455" aria-hidden="true" tabindex="-1"></a>Работаем с моделью gam.m2.</span>
<span id="cb203-456"><a href="nonlinear-regression.html#cb203-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-457"><a href="nonlinear-regression.html#cb203-457" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по обучающей выборке</span></span>
<span id="cb203-458"><a href="nonlinear-regression.html#cb203-458" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(gam.m2, <span class="at">newdata =</span> Wage)</span>
<span id="cb203-459"><a href="nonlinear-regression.html#cb203-459" aria-hidden="true" tabindex="-1"></a>Также можно использовать в GAM локальные регрессии.</span>
<span id="cb203-460"><a href="nonlinear-regression.html#cb203-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-461"><a href="nonlinear-regression.html#cb203-461" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на локальных регрессиях</span></span>
<span id="cb203-462"><a href="nonlinear-regression.html#cb203-462" aria-hidden="true" tabindex="-1"></a>gam.lo <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="at">df =</span> <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">lo</span>(age, <span class="at">span =</span> <span class="fl">0.7</span>) <span class="sc">+</span> education, </span>
<span id="cb203-463"><a href="nonlinear-regression.html#cb203-463" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> Wage)</span>
<span id="cb203-464"><a href="nonlinear-regression.html#cb203-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-465"><a href="nonlinear-regression.html#cb203-465" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb203-466"><a href="nonlinear-regression.html#cb203-466" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.gam</span>(gam.lo, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb203-467"><a href="nonlinear-regression.html#cb203-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-468"><a href="nonlinear-regression.html#cb203-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-469"><a href="nonlinear-regression.html#cb203-469" aria-hidden="true" tabindex="-1"></a><span class="co"># модель со взаимодействием регрессоров year и age</span></span>
<span id="cb203-470"><a href="nonlinear-regression.html#cb203-470" aria-hidden="true" tabindex="-1"></a>gam.lo.i <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">lo</span>(year, age, <span class="at">span =</span> <span class="fl">0.5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb203-471"><a href="nonlinear-regression.html#cb203-471" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb203-472"><a href="nonlinear-regression.html#cb203-472" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb203-473"><a href="nonlinear-regression.html#cb203-473" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb203-474"><a href="nonlinear-regression.html#cb203-474" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb203-475"><a href="nonlinear-regression.html#cb203-475" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb203-476"><a href="nonlinear-regression.html#cb203-476" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb203-477"><a href="nonlinear-regression.html#cb203-477" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb203-478"><a href="nonlinear-regression.html#cb203-478" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb203-479"><a href="nonlinear-regression.html#cb203-479" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lo.i)</span>
<span id="cb203-480"><a href="nonlinear-regression.html#cb203-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-481"><a href="nonlinear-regression.html#cb203-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-482"><a href="nonlinear-regression.html#cb203-482" aria-hidden="true" tabindex="-1"></a>Логистическая GAM</span>
<span id="cb203-483"><a href="nonlinear-regression.html#cb203-483" aria-hidden="true" tabindex="-1"></a>Построим логистическую GAM для всероятности того, что wage превышает <span class="fl">250.</span></span>
<span id="cb203-484"><a href="nonlinear-regression.html#cb203-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-485"><a href="nonlinear-regression.html#cb203-485" aria-hidden="true" tabindex="-1"></a>gam.lr <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education, </span>
<span id="cb203-486"><a href="nonlinear-regression.html#cb203-486" aria-hidden="true" tabindex="-1"></a>              <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage)</span>
<span id="cb203-487"><a href="nonlinear-regression.html#cb203-487" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb203-488"><a href="nonlinear-regression.html#cb203-488" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb203-489"><a href="nonlinear-regression.html#cb203-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-490"><a href="nonlinear-regression.html#cb203-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-491"><a href="nonlinear-regression.html#cb203-491" aria-hidden="true" tabindex="-1"></a><span class="co"># уровни образования по группам разного достатка</span></span>
<span id="cb203-492"><a href="nonlinear-regression.html#cb203-492" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(education, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>))</span>
<span id="cb203-493"><a href="nonlinear-regression.html#cb203-493" aria-hidden="true" tabindex="-1"></a><span class="do">##                     </span></span>
<span id="cb203-494"><a href="nonlinear-regression.html#cb203-494" aria-hidden="true" tabindex="-1"></a><span class="do">## education            FALSE TRUE</span></span>
<span id="cb203-495"><a href="nonlinear-regression.html#cb203-495" aria-hidden="true" tabindex="-1"></a><span class="do">##   1. &lt; HS Grad         268    0</span></span>
<span id="cb203-496"><a href="nonlinear-regression.html#cb203-496" aria-hidden="true" tabindex="-1"></a><span class="do">##   2. HS Grad           966    5</span></span>
<span id="cb203-497"><a href="nonlinear-regression.html#cb203-497" aria-hidden="true" tabindex="-1"></a><span class="do">##   3. Some College      643    7</span></span>
<span id="cb203-498"><a href="nonlinear-regression.html#cb203-498" aria-hidden="true" tabindex="-1"></a><span class="do">##   4. College Grad      663   22</span></span>
<span id="cb203-499"><a href="nonlinear-regression.html#cb203-499" aria-hidden="true" tabindex="-1"></a><span class="do">##   5. Advanced Degree   381   45</span></span>
<span id="cb203-500"><a href="nonlinear-regression.html#cb203-500" aria-hidden="true" tabindex="-1"></a>В категории с самым низким уровнем образования нет wage <span class="sc">&gt;</span> <span class="dv">250</span>, поэтому убираем её.</span>
<span id="cb203-501"><a href="nonlinear-regression.html#cb203-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-502"><a href="nonlinear-regression.html#cb203-502" aria-hidden="true" tabindex="-1"></a>gam.lr.s <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education,</span>
<span id="cb203-503"><a href="nonlinear-regression.html#cb203-503" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage, </span>
<span id="cb203-504"><a href="nonlinear-regression.html#cb203-504" aria-hidden="true" tabindex="-1"></a>                <span class="at">subset =</span> (education <span class="sc">!=</span> <span class="st">&quot;1. &lt; HS Grad&quot;</span>))</span>
<span id="cb203-505"><a href="nonlinear-regression.html#cb203-505" aria-hidden="true" tabindex="-1"></a><span class="co"># график</span></span>
<span id="cb203-506"><a href="nonlinear-regression.html#cb203-506" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb203-507"><a href="nonlinear-regression.html#cb203-507" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr.s, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb203-508"><a href="nonlinear-regression.html#cb203-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-509"><a href="nonlinear-regression.html#cb203-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-510"><a href="nonlinear-regression.html#cb203-510" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(Wage)</span></code></pre></div>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="nonlinear-regression.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonlinear modeling</span></span>
<span id="cb204-2"><a href="nonlinear-regression.html#cb204-2" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb204-3"><a href="nonlinear-regression.html#cb204-3" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">8</span></span>
<span id="cb204-4"><a href="nonlinear-regression.html#cb204-4" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb204-5"><a href="nonlinear-regression.html#cb204-5" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb204-6"><a href="nonlinear-regression.html#cb204-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb204-7"><a href="nonlinear-regression.html#cb204-7" aria-hidden="true" tabindex="-1"></a>    строить регрессионные деревья;</span>
<span id="cb204-8"><a href="nonlinear-regression.html#cb204-8" aria-hidden="true" tabindex="-1"></a>строить деревья классификации;</span>
<span id="cb204-9"><a href="nonlinear-regression.html#cb204-9" aria-hidden="true" tabindex="-1"></a>делать обрезку дерева;</span>
<span id="cb204-10"><a href="nonlinear-regression.html#cb204-10" aria-hidden="true" tabindex="-1"></a>использовать бэггинг, бустинг, случайный лес для улучшения качества прогнозирования.</span>
<span id="cb204-11"><a href="nonlinear-regression.html#cb204-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> деревья решений.</span>
<span id="cb204-12"><a href="nonlinear-regression.html#cb204-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Sales {ISLR}, Boston {ISLR}</span>
<span id="cb204-13"><a href="nonlinear-regression.html#cb204-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-14"><a href="nonlinear-regression.html#cb204-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">8.</span></span>
<span id="cb204-15"><a href="nonlinear-regression.html#cb204-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-16"><a href="nonlinear-regression.html#cb204-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;tree&#39;</span>)              <span class="co"># деревья</span></span>
<span id="cb204-17"><a href="nonlinear-regression.html#cb204-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;tree&#39; was built under R version 3.4.4</span></span>
<span id="cb204-18"><a href="nonlinear-regression.html#cb204-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># наборы данных</span></span>
<span id="cb204-19"><a href="nonlinear-regression.html#cb204-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;MASS&#39;</span>)</span>
<span id="cb204-20"><a href="nonlinear-regression.html#cb204-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;randomForest&#39;</span>)      <span class="co"># случайный лес</span></span>
<span id="cb204-21"><a href="nonlinear-regression.html#cb204-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;randomForest&#39; was built under R version 3.4.4</span></span>
<span id="cb204-22"><a href="nonlinear-regression.html#cb204-22" aria-hidden="true" tabindex="-1"></a><span class="do">## randomForest 4.6-14</span></span>
<span id="cb204-23"><a href="nonlinear-regression.html#cb204-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Type rfNews() to see new features/changes/bug fixes.</span></span>
<span id="cb204-24"><a href="nonlinear-regression.html#cb204-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gbm&#39;</span>)</span>
<span id="cb204-25"><a href="nonlinear-regression.html#cb204-25" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gbm&#39; was built under R version 3.4.4</span></span>
<span id="cb204-26"><a href="nonlinear-regression.html#cb204-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: survival</span></span>
<span id="cb204-27"><a href="nonlinear-regression.html#cb204-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: lattice</span></span>
<span id="cb204-28"><a href="nonlinear-regression.html#cb204-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: splines</span></span>
<span id="cb204-29"><a href="nonlinear-regression.html#cb204-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: parallel</span></span>
<span id="cb204-30"><a href="nonlinear-regression.html#cb204-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gbm 2.1.3</span></span>
<span id="cb204-31"><a href="nonlinear-regression.html#cb204-31" aria-hidden="true" tabindex="-1"></a>Деревья решений</span>
<span id="cb204-32"><a href="nonlinear-regression.html#cb204-32" aria-hidden="true" tabindex="-1"></a>Загрузим таблицу с данными по продажам детских кресел и добавим к ней переменную High – “высокие продажи” со значениями<span class="sc">:</span></span>
<span id="cb204-33"><a href="nonlinear-regression.html#cb204-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb204-34"><a href="nonlinear-regression.html#cb204-34" aria-hidden="true" tabindex="-1"></a>    Yes если продажи больше <span class="dv">8</span> (тыс. шт.);</span>
<span id="cb204-35"><a href="nonlinear-regression.html#cb204-35" aria-hidden="true" tabindex="-1"></a>No в противном случае.</span>
<span id="cb204-36"><a href="nonlinear-regression.html#cb204-36" aria-hidden="true" tabindex="-1"></a>?Carseats</span>
<span id="cb204-37"><a href="nonlinear-regression.html#cb204-37" aria-hidden="true" tabindex="-1"></a><span class="do">## starting httpd help server ... done</span></span>
<span id="cb204-38"><a href="nonlinear-regression.html#cb204-38" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Carseats)</span>
<span id="cb204-39"><a href="nonlinear-regression.html#cb204-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-40"><a href="nonlinear-regression.html#cb204-40" aria-hidden="true" tabindex="-1"></a><span class="co"># новая переменная</span></span>
<span id="cb204-41"><a href="nonlinear-regression.html#cb204-41" aria-hidden="true" tabindex="-1"></a>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Sales <span class="sc">&lt;=</span> <span class="dv">8</span>, <span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb204-42"><a href="nonlinear-regression.html#cb204-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-43"><a href="nonlinear-regression.html#cb204-43" aria-hidden="true" tabindex="-1"></a><span class="co"># присоединяем к таблице данных</span></span>
<span id="cb204-44"><a href="nonlinear-regression.html#cb204-44" aria-hidden="true" tabindex="-1"></a>Carseats <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Carseats, High)</span>
<span id="cb204-45"><a href="nonlinear-regression.html#cb204-45" aria-hidden="true" tabindex="-1"></a>Строим дерево для категориального отклика High, отбросив непрерывный отклик Sales.</span>
<span id="cb204-46"><a href="nonlinear-regression.html#cb204-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-47"><a href="nonlinear-regression.html#cb204-47" aria-hidden="true" tabindex="-1"></a><span class="co"># модель бинарного  дерева</span></span>
<span id="cb204-48"><a href="nonlinear-regression.html#cb204-48" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats)</span>
<span id="cb204-49"><a href="nonlinear-regression.html#cb204-49" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.carseats)</span>
<span id="cb204-50"><a href="nonlinear-regression.html#cb204-50" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-51"><a href="nonlinear-regression.html#cb204-51" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree:</span></span>
<span id="cb204-52"><a href="nonlinear-regression.html#cb204-52" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = High ~ . - Sales, data = Carseats)</span></span>
<span id="cb204-53"><a href="nonlinear-regression.html#cb204-53" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb204-54"><a href="nonlinear-regression.html#cb204-54" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;ShelveLoc&quot;   &quot;Price&quot;       &quot;Income&quot;      &quot;CompPrice&quot;   &quot;Population&quot; </span></span>
<span id="cb204-55"><a href="nonlinear-regression.html#cb204-55" aria-hidden="true" tabindex="-1"></a><span class="do">## [6] &quot;Advertising&quot; &quot;Age&quot;         &quot;US&quot;         </span></span>
<span id="cb204-56"><a href="nonlinear-regression.html#cb204-56" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  27 </span></span>
<span id="cb204-57"><a href="nonlinear-regression.html#cb204-57" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  0.4575 = 170.7 / 373 </span></span>
<span id="cb204-58"><a href="nonlinear-regression.html#cb204-58" aria-hidden="true" tabindex="-1"></a><span class="do">## Misclassification error rate: 0.09 = 36 / 400</span></span>
<span id="cb204-59"><a href="nonlinear-regression.html#cb204-59" aria-hidden="true" tabindex="-1"></a><span class="co"># график результата</span></span>
<span id="cb204-60"><a href="nonlinear-regression.html#cb204-60" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.carseats)            <span class="co"># ветви</span></span>
<span id="cb204-61"><a href="nonlinear-regression.html#cb204-61" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.carseats, <span class="at">pretty=</span><span class="dv">0</span>)  <span class="co"># подписи</span></span>
<span id="cb204-62"><a href="nonlinear-regression.html#cb204-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-63"><a href="nonlinear-regression.html#cb204-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-64"><a href="nonlinear-regression.html#cb204-64" aria-hidden="true" tabindex="-1"></a>tree.carseats                  <span class="co"># посмотреть всё дерево в консоли</span></span>
<span id="cb204-65"><a href="nonlinear-regression.html#cb204-65" aria-hidden="true" tabindex="-1"></a><span class="do">## node), split, n, deviance, yval, (yprob)</span></span>
<span id="cb204-66"><a href="nonlinear-regression.html#cb204-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       * denotes terminal node</span></span>
<span id="cb204-67"><a href="nonlinear-regression.html#cb204-67" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-68"><a href="nonlinear-regression.html#cb204-68" aria-hidden="true" tabindex="-1"></a><span class="do">##   1) root 400 541.500 No ( 0.59000 0.41000 )  </span></span>
<span id="cb204-69"><a href="nonlinear-regression.html#cb204-69" aria-hidden="true" tabindex="-1"></a><span class="do">##     2) ShelveLoc: Bad,Medium 315 390.600 No ( 0.68889 0.31111 )  </span></span>
<span id="cb204-70"><a href="nonlinear-regression.html#cb204-70" aria-hidden="true" tabindex="-1"></a><span class="do">##       4) Price &lt; 92.5 46  56.530 Yes ( 0.30435 0.69565 )  </span></span>
<span id="cb204-71"><a href="nonlinear-regression.html#cb204-71" aria-hidden="true" tabindex="-1"></a><span class="do">##         8) Income &lt; 57 10  12.220 No ( 0.70000 0.30000 )  </span></span>
<span id="cb204-72"><a href="nonlinear-regression.html#cb204-72" aria-hidden="true" tabindex="-1"></a><span class="do">##          16) CompPrice &lt; 110.5 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb204-73"><a href="nonlinear-regression.html#cb204-73" aria-hidden="true" tabindex="-1"></a><span class="do">##          17) CompPrice &gt; 110.5 5   6.730 Yes ( 0.40000 0.60000 ) *</span></span>
<span id="cb204-74"><a href="nonlinear-regression.html#cb204-74" aria-hidden="true" tabindex="-1"></a><span class="do">##         9) Income &gt; 57 36  35.470 Yes ( 0.19444 0.80556 )  </span></span>
<span id="cb204-75"><a href="nonlinear-regression.html#cb204-75" aria-hidden="true" tabindex="-1"></a><span class="do">##          18) Population &lt; 207.5 16  21.170 Yes ( 0.37500 0.62500 ) *</span></span>
<span id="cb204-76"><a href="nonlinear-regression.html#cb204-76" aria-hidden="true" tabindex="-1"></a><span class="do">##          19) Population &gt; 207.5 20   7.941 Yes ( 0.05000 0.95000 ) *</span></span>
<span id="cb204-77"><a href="nonlinear-regression.html#cb204-77" aria-hidden="true" tabindex="-1"></a><span class="do">##       5) Price &gt; 92.5 269 299.800 No ( 0.75465 0.24535 )  </span></span>
<span id="cb204-78"><a href="nonlinear-regression.html#cb204-78" aria-hidden="true" tabindex="-1"></a><span class="do">##        10) Advertising &lt; 13.5 224 213.200 No ( 0.81696 0.18304 )  </span></span>
<span id="cb204-79"><a href="nonlinear-regression.html#cb204-79" aria-hidden="true" tabindex="-1"></a><span class="do">##          20) CompPrice &lt; 124.5 96  44.890 No ( 0.93750 0.06250 )  </span></span>
<span id="cb204-80"><a href="nonlinear-regression.html#cb204-80" aria-hidden="true" tabindex="-1"></a><span class="do">##            40) Price &lt; 106.5 38  33.150 No ( 0.84211 0.15789 )  </span></span>
<span id="cb204-81"><a href="nonlinear-regression.html#cb204-81" aria-hidden="true" tabindex="-1"></a><span class="do">##              80) Population &lt; 177 12  16.300 No ( 0.58333 0.41667 )  </span></span>
<span id="cb204-82"><a href="nonlinear-regression.html#cb204-82" aria-hidden="true" tabindex="-1"></a><span class="do">##               160) Income &lt; 60.5 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb204-83"><a href="nonlinear-regression.html#cb204-83" aria-hidden="true" tabindex="-1"></a><span class="do">##               161) Income &gt; 60.5 6   5.407 Yes ( 0.16667 0.83333 ) *</span></span>
<span id="cb204-84"><a href="nonlinear-regression.html#cb204-84" aria-hidden="true" tabindex="-1"></a><span class="do">##              81) Population &gt; 177 26   8.477 No ( 0.96154 0.03846 ) *</span></span>
<span id="cb204-85"><a href="nonlinear-regression.html#cb204-85" aria-hidden="true" tabindex="-1"></a><span class="do">##            41) Price &gt; 106.5 58   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb204-86"><a href="nonlinear-regression.html#cb204-86" aria-hidden="true" tabindex="-1"></a><span class="do">##          21) CompPrice &gt; 124.5 128 150.200 No ( 0.72656 0.27344 )  </span></span>
<span id="cb204-87"><a href="nonlinear-regression.html#cb204-87" aria-hidden="true" tabindex="-1"></a><span class="do">##            42) Price &lt; 122.5 51  70.680 Yes ( 0.49020 0.50980 )  </span></span>
<span id="cb204-88"><a href="nonlinear-regression.html#cb204-88" aria-hidden="true" tabindex="-1"></a><span class="do">##              84) ShelveLoc: Bad 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb204-89"><a href="nonlinear-regression.html#cb204-89" aria-hidden="true" tabindex="-1"></a><span class="do">##              85) ShelveLoc: Medium 40  52.930 Yes ( 0.37500 0.62500 )  </span></span>
<span id="cb204-90"><a href="nonlinear-regression.html#cb204-90" aria-hidden="true" tabindex="-1"></a><span class="do">##               170) Price &lt; 109.5 16   7.481 Yes ( 0.06250 0.93750 ) *</span></span>
<span id="cb204-91"><a href="nonlinear-regression.html#cb204-91" aria-hidden="true" tabindex="-1"></a><span class="do">##               171) Price &gt; 109.5 24  32.600 No ( 0.58333 0.41667 )  </span></span>
<span id="cb204-92"><a href="nonlinear-regression.html#cb204-92" aria-hidden="true" tabindex="-1"></a><span class="do">##                 342) Age &lt; 49.5 13  16.050 Yes ( 0.30769 0.69231 ) *</span></span>
<span id="cb204-93"><a href="nonlinear-regression.html#cb204-93" aria-hidden="true" tabindex="-1"></a><span class="do">##                 343) Age &gt; 49.5 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb204-94"><a href="nonlinear-regression.html#cb204-94" aria-hidden="true" tabindex="-1"></a><span class="do">##            43) Price &gt; 122.5 77  55.540 No ( 0.88312 0.11688 )  </span></span>
<span id="cb204-95"><a href="nonlinear-regression.html#cb204-95" aria-hidden="true" tabindex="-1"></a><span class="do">##              86) CompPrice &lt; 147.5 58  17.400 No ( 0.96552 0.03448 ) *</span></span>
<span id="cb204-96"><a href="nonlinear-regression.html#cb204-96" aria-hidden="true" tabindex="-1"></a><span class="do">##              87) CompPrice &gt; 147.5 19  25.010 No ( 0.63158 0.36842 )  </span></span>
<span id="cb204-97"><a href="nonlinear-regression.html#cb204-97" aria-hidden="true" tabindex="-1"></a><span class="do">##               174) Price &lt; 147 12  16.300 Yes ( 0.41667 0.58333 )  </span></span>
<span id="cb204-98"><a href="nonlinear-regression.html#cb204-98" aria-hidden="true" tabindex="-1"></a><span class="do">##                 348) CompPrice &lt; 152.5 7   5.742 Yes ( 0.14286 0.85714 ) *</span></span>
<span id="cb204-99"><a href="nonlinear-regression.html#cb204-99" aria-hidden="true" tabindex="-1"></a><span class="do">##                 349) CompPrice &gt; 152.5 5   5.004 No ( 0.80000 0.20000 ) *</span></span>
<span id="cb204-100"><a href="nonlinear-regression.html#cb204-100" aria-hidden="true" tabindex="-1"></a><span class="do">##               175) Price &gt; 147 7   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb204-101"><a href="nonlinear-regression.html#cb204-101" aria-hidden="true" tabindex="-1"></a><span class="do">##        11) Advertising &gt; 13.5 45  61.830 Yes ( 0.44444 0.55556 )  </span></span>
<span id="cb204-102"><a href="nonlinear-regression.html#cb204-102" aria-hidden="true" tabindex="-1"></a><span class="do">##          22) Age &lt; 54.5 25  25.020 Yes ( 0.20000 0.80000 )  </span></span>
<span id="cb204-103"><a href="nonlinear-regression.html#cb204-103" aria-hidden="true" tabindex="-1"></a><span class="do">##            44) CompPrice &lt; 130.5 14  18.250 Yes ( 0.35714 0.64286 )  </span></span>
<span id="cb204-104"><a href="nonlinear-regression.html#cb204-104" aria-hidden="true" tabindex="-1"></a><span class="do">##              88) Income &lt; 100 9  12.370 No ( 0.55556 0.44444 ) *</span></span>
<span id="cb204-105"><a href="nonlinear-regression.html#cb204-105" aria-hidden="true" tabindex="-1"></a><span class="do">##              89) Income &gt; 100 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb204-106"><a href="nonlinear-regression.html#cb204-106" aria-hidden="true" tabindex="-1"></a><span class="do">##            45) CompPrice &gt; 130.5 11   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb204-107"><a href="nonlinear-regression.html#cb204-107" aria-hidden="true" tabindex="-1"></a><span class="do">##          23) Age &gt; 54.5 20  22.490 No ( 0.75000 0.25000 )  </span></span>
<span id="cb204-108"><a href="nonlinear-regression.html#cb204-108" aria-hidden="true" tabindex="-1"></a><span class="do">##            46) CompPrice &lt; 122.5 10   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb204-109"><a href="nonlinear-regression.html#cb204-109" aria-hidden="true" tabindex="-1"></a><span class="do">##            47) CompPrice &gt; 122.5 10  13.860 No ( 0.50000 0.50000 )  </span></span>
<span id="cb204-110"><a href="nonlinear-regression.html#cb204-110" aria-hidden="true" tabindex="-1"></a><span class="do">##              94) Price &lt; 125 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb204-111"><a href="nonlinear-regression.html#cb204-111" aria-hidden="true" tabindex="-1"></a><span class="do">##              95) Price &gt; 125 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb204-112"><a href="nonlinear-regression.html#cb204-112" aria-hidden="true" tabindex="-1"></a><span class="do">##     3) ShelveLoc: Good 85  90.330 Yes ( 0.22353 0.77647 )  </span></span>
<span id="cb204-113"><a href="nonlinear-regression.html#cb204-113" aria-hidden="true" tabindex="-1"></a><span class="do">##       6) Price &lt; 135 68  49.260 Yes ( 0.11765 0.88235 )  </span></span>
<span id="cb204-114"><a href="nonlinear-regression.html#cb204-114" aria-hidden="true" tabindex="-1"></a><span class="do">##        12) US: No 17  22.070 Yes ( 0.35294 0.64706 )  </span></span>
<span id="cb204-115"><a href="nonlinear-regression.html#cb204-115" aria-hidden="true" tabindex="-1"></a><span class="do">##          24) Price &lt; 109 8   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb204-116"><a href="nonlinear-regression.html#cb204-116" aria-hidden="true" tabindex="-1"></a><span class="do">##          25) Price &gt; 109 9  11.460 No ( 0.66667 0.33333 ) *</span></span>
<span id="cb204-117"><a href="nonlinear-regression.html#cb204-117" aria-hidden="true" tabindex="-1"></a><span class="do">##        13) US: Yes 51  16.880 Yes ( 0.03922 0.96078 ) *</span></span>
<span id="cb204-118"><a href="nonlinear-regression.html#cb204-118" aria-hidden="true" tabindex="-1"></a><span class="do">##       7) Price &gt; 135 17  22.070 No ( 0.64706 0.35294 )  </span></span>
<span id="cb204-119"><a href="nonlinear-regression.html#cb204-119" aria-hidden="true" tabindex="-1"></a><span class="do">##        14) Income &lt; 46 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb204-120"><a href="nonlinear-regression.html#cb204-120" aria-hidden="true" tabindex="-1"></a><span class="do">##        15) Income &gt; 46 11  15.160 Yes ( 0.45455 0.54545 ) *</span></span>
<span id="cb204-121"><a href="nonlinear-regression.html#cb204-121" aria-hidden="true" tabindex="-1"></a>Теперь построим дерево на обучающей выборке и оценим ошибку на тестовой.</span>
<span id="cb204-122"><a href="nonlinear-regression.html#cb204-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-123"><a href="nonlinear-regression.html#cb204-123" aria-hidden="true" tabindex="-1"></a><span class="co"># ядро генератора случайных чисел</span></span>
<span id="cb204-124"><a href="nonlinear-regression.html#cb204-124" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb204-125"><a href="nonlinear-regression.html#cb204-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-126"><a href="nonlinear-regression.html#cb204-126" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb204-127"><a href="nonlinear-regression.html#cb204-127" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Carseats), <span class="dv">200</span>)</span>
<span id="cb204-128"><a href="nonlinear-regression.html#cb204-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-129"><a href="nonlinear-regression.html#cb204-129" aria-hidden="true" tabindex="-1"></a><span class="co"># тестовая выборка</span></span>
<span id="cb204-130"><a href="nonlinear-regression.html#cb204-130" aria-hidden="true" tabindex="-1"></a>Carseats.test <span class="ot">&lt;-</span> Carseats[<span class="sc">-</span>train,]</span>
<span id="cb204-131"><a href="nonlinear-regression.html#cb204-131" aria-hidden="true" tabindex="-1"></a>High.test <span class="ot">&lt;-</span> High[<span class="sc">-</span>train]</span>
<span id="cb204-132"><a href="nonlinear-regression.html#cb204-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-133"><a href="nonlinear-regression.html#cb204-133" aria-hidden="true" tabindex="-1"></a><span class="co"># строим дерево на обучающей выборке</span></span>
<span id="cb204-134"><a href="nonlinear-regression.html#cb204-134" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats, <span class="at">subset =</span> train)</span>
<span id="cb204-135"><a href="nonlinear-regression.html#cb204-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-136"><a href="nonlinear-regression.html#cb204-136" aria-hidden="true" tabindex="-1"></a><span class="co"># делаем прогноз</span></span>
<span id="cb204-137"><a href="nonlinear-regression.html#cb204-137" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb204-138"><a href="nonlinear-regression.html#cb204-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-139"><a href="nonlinear-regression.html#cb204-139" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb204-140"><a href="nonlinear-regression.html#cb204-140" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb204-141"><a href="nonlinear-regression.html#cb204-141" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb204-142"><a href="nonlinear-regression.html#cb204-142" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb204-143"><a href="nonlinear-regression.html#cb204-143" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb204-144"><a href="nonlinear-regression.html#cb204-144" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  27</span></span>
<span id="cb204-145"><a href="nonlinear-regression.html#cb204-145" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  57</span></span>
<span id="cb204-146"><a href="nonlinear-regression.html#cb204-146" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb204-147"><a href="nonlinear-regression.html#cb204-147" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb204-148"><a href="nonlinear-regression.html#cb204-148" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb204-149"><a href="nonlinear-regression.html#cb204-149" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.715</span></span>
<span id="cb204-150"><a href="nonlinear-regression.html#cb204-150" aria-hidden="true" tabindex="-1"></a>Обобщённая характеристика точности<span class="sc">:</span> доля верных прогнозов<span class="sc">:</span> <span class="dv">0</span>.<span class="fl">72.</span></span>
<span id="cb204-151"><a href="nonlinear-regression.html#cb204-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-152"><a href="nonlinear-regression.html#cb204-152" aria-hidden="true" tabindex="-1"></a>Теперь обрезаем дерево, используя в качестве критерия частоту ошибок классификации. Функция <span class="fu">cv.tree</span>() проводит кросс<span class="sc">-</span>валидацию для выбора лучшего дерева, аргумент prune.misclass означает, что мы минимизируем ошибку классификации.</span>
<span id="cb204-153"><a href="nonlinear-regression.html#cb204-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-154"><a href="nonlinear-regression.html#cb204-154" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb204-155"><a href="nonlinear-regression.html#cb204-155" aria-hidden="true" tabindex="-1"></a>cv.carseats <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.carseats, <span class="at">FUN =</span> prune.misclass)</span>
<span id="cb204-156"><a href="nonlinear-regression.html#cb204-156" aria-hidden="true" tabindex="-1"></a><span class="co"># имена элементов полученного объекта</span></span>
<span id="cb204-157"><a href="nonlinear-regression.html#cb204-157" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(cv.carseats)</span>
<span id="cb204-158"><a href="nonlinear-regression.html#cb204-158" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;size&quot;   &quot;dev&quot;    &quot;k&quot;      &quot;method&quot;</span></span>
<span id="cb204-159"><a href="nonlinear-regression.html#cb204-159" aria-hidden="true" tabindex="-1"></a><span class="co"># сам объект</span></span>
<span id="cb204-160"><a href="nonlinear-regression.html#cb204-160" aria-hidden="true" tabindex="-1"></a>cv.carseats</span>
<span id="cb204-161"><a href="nonlinear-regression.html#cb204-161" aria-hidden="true" tabindex="-1"></a><span class="do">## $size</span></span>
<span id="cb204-162"><a href="nonlinear-regression.html#cb204-162" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 19 17 14 13  9  7  3  2  1</span></span>
<span id="cb204-163"><a href="nonlinear-regression.html#cb204-163" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-164"><a href="nonlinear-regression.html#cb204-164" aria-hidden="true" tabindex="-1"></a><span class="do">## $dev</span></span>
<span id="cb204-165"><a href="nonlinear-regression.html#cb204-165" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 55 55 53 52 50 56 69 65 80</span></span>
<span id="cb204-166"><a href="nonlinear-regression.html#cb204-166" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-167"><a href="nonlinear-regression.html#cb204-167" aria-hidden="true" tabindex="-1"></a><span class="do">## $k</span></span>
<span id="cb204-168"><a href="nonlinear-regression.html#cb204-168" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]       -Inf  0.0000000  0.6666667  1.0000000  1.7500000  2.0000000</span></span>
<span id="cb204-169"><a href="nonlinear-regression.html#cb204-169" aria-hidden="true" tabindex="-1"></a><span class="do">## [7]  4.2500000  5.0000000 23.0000000</span></span>
<span id="cb204-170"><a href="nonlinear-regression.html#cb204-170" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-171"><a href="nonlinear-regression.html#cb204-171" aria-hidden="true" tabindex="-1"></a><span class="do">## $method</span></span>
<span id="cb204-172"><a href="nonlinear-regression.html#cb204-172" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;misclass&quot;</span></span>
<span id="cb204-173"><a href="nonlinear-regression.html#cb204-173" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-174"><a href="nonlinear-regression.html#cb204-174" aria-hidden="true" tabindex="-1"></a><span class="do">## attr(,&quot;class&quot;)</span></span>
<span id="cb204-175"><a href="nonlinear-regression.html#cb204-175" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;prune&quot;         &quot;tree.sequence&quot;</span></span>
<span id="cb204-176"><a href="nonlinear-regression.html#cb204-176" aria-hidden="true" tabindex="-1"></a><span class="co"># графики изменения параметров метода по ходу обрезки дерева ###################</span></span>
<span id="cb204-177"><a href="nonlinear-regression.html#cb204-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-178"><a href="nonlinear-regression.html#cb204-178" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. ошибка с кросс-валидацией в зависимости от числа узлов</span></span>
<span id="cb204-179"><a href="nonlinear-regression.html#cb204-179" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb204-180"><a href="nonlinear-regression.html#cb204-180" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>size, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb204-181"><a href="nonlinear-regression.html#cb204-181" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb204-182"><a href="nonlinear-regression.html#cb204-182" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Число узлов (size)&#39;</span>)</span>
<span id="cb204-183"><a href="nonlinear-regression.html#cb204-183" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb204-184"><a href="nonlinear-regression.html#cb204-184" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.carseats<span class="sc">$</span>size[cv.carseats<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.carseats<span class="sc">$</span>dev)]</span>
<span id="cb204-185"><a href="nonlinear-regression.html#cb204-185" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb204-186"><a href="nonlinear-regression.html#cb204-186" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb204-187"><a href="nonlinear-regression.html#cb204-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-188"><a href="nonlinear-regression.html#cb204-188" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. ошибка с кросс-валидацией в зависимости от штрафа на сложность</span></span>
<span id="cb204-189"><a href="nonlinear-regression.html#cb204-189" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>k, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb204-190"><a href="nonlinear-regression.html#cb204-190" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb204-191"><a href="nonlinear-regression.html#cb204-191" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Штраф за сложность (k)&#39;</span>)</span>
<span id="cb204-192"><a href="nonlinear-regression.html#cb204-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-193"><a href="nonlinear-regression.html#cb204-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-194"><a href="nonlinear-regression.html#cb204-194" aria-hidden="true" tabindex="-1"></a>Как видно на графике слева, минимум частоты ошибок достигается при числе узлов <span class="fl">9.</span> Оценим точность дерева с <span class="dv">9</span> узлами.</span>
<span id="cb204-195"><a href="nonlinear-regression.html#cb204-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-196"><a href="nonlinear-regression.html#cb204-196" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 9 узлами</span></span>
<span id="cb204-197"><a href="nonlinear-regression.html#cb204-197" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">9</span>)</span>
<span id="cb204-198"><a href="nonlinear-regression.html#cb204-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-199"><a href="nonlinear-regression.html#cb204-199" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb204-200"><a href="nonlinear-regression.html#cb204-200" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb204-201"><a href="nonlinear-regression.html#cb204-201" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb204-202"><a href="nonlinear-regression.html#cb204-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-203"><a href="nonlinear-regression.html#cb204-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-204"><a href="nonlinear-regression.html#cb204-204" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb204-205"><a href="nonlinear-regression.html#cb204-205" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb204-206"><a href="nonlinear-regression.html#cb204-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-207"><a href="nonlinear-regression.html#cb204-207" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb204-208"><a href="nonlinear-regression.html#cb204-208" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb204-209"><a href="nonlinear-regression.html#cb204-209" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb204-210"><a href="nonlinear-regression.html#cb204-210" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb204-211"><a href="nonlinear-regression.html#cb204-211" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb204-212"><a href="nonlinear-regression.html#cb204-212" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  94  24</span></span>
<span id="cb204-213"><a href="nonlinear-regression.html#cb204-213" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 22  60</span></span>
<span id="cb204-214"><a href="nonlinear-regression.html#cb204-214" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb204-215"><a href="nonlinear-regression.html#cb204-215" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb204-216"><a href="nonlinear-regression.html#cb204-216" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb204-217"><a href="nonlinear-regression.html#cb204-217" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.77</span></span>
<span id="cb204-218"><a href="nonlinear-regression.html#cb204-218" aria-hidden="true" tabindex="-1"></a>Точность этой модели чуть выше точности исходного дерева и составляет <span class="dv">0</span>.<span class="fl">77.</span> Увеличив количество узлов, получим более глубокое дерево, но менее точное.</span>
<span id="cb204-219"><a href="nonlinear-regression.html#cb204-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-220"><a href="nonlinear-regression.html#cb204-220" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 13 узлами</span></span>
<span id="cb204-221"><a href="nonlinear-regression.html#cb204-221" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">15</span>)</span>
<span id="cb204-222"><a href="nonlinear-regression.html#cb204-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-223"><a href="nonlinear-regression.html#cb204-223" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb204-224"><a href="nonlinear-regression.html#cb204-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb204-225"><a href="nonlinear-regression.html#cb204-225" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb204-226"><a href="nonlinear-regression.html#cb204-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-227"><a href="nonlinear-regression.html#cb204-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-228"><a href="nonlinear-regression.html#cb204-228" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb204-229"><a href="nonlinear-regression.html#cb204-229" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb204-230"><a href="nonlinear-regression.html#cb204-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-231"><a href="nonlinear-regression.html#cb204-231" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb204-232"><a href="nonlinear-regression.html#cb204-232" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb204-233"><a href="nonlinear-regression.html#cb204-233" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb204-234"><a href="nonlinear-regression.html#cb204-234" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb204-235"><a href="nonlinear-regression.html#cb204-235" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb204-236"><a href="nonlinear-regression.html#cb204-236" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  22</span></span>
<span id="cb204-237"><a href="nonlinear-regression.html#cb204-237" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  62</span></span>
<span id="cb204-238"><a href="nonlinear-regression.html#cb204-238" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb204-239"><a href="nonlinear-regression.html#cb204-239" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb204-240"><a href="nonlinear-regression.html#cb204-240" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb204-241"><a href="nonlinear-regression.html#cb204-241" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.74</span></span>
<span id="cb204-242"><a href="nonlinear-regression.html#cb204-242" aria-hidden="true" tabindex="-1"></a><span class="co"># сбрасываем графические параметры</span></span>
<span id="cb204-243"><a href="nonlinear-regression.html#cb204-243" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb204-244"><a href="nonlinear-regression.html#cb204-244" aria-hidden="true" tabindex="-1"></a>Регрессионные деревья</span>
<span id="cb204-245"><a href="nonlinear-regression.html#cb204-245" aria-hidden="true" tabindex="-1"></a>Воспользуемся набором данных Boston.</span>
<span id="cb204-246"><a href="nonlinear-regression.html#cb204-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-247"><a href="nonlinear-regression.html#cb204-247" aria-hidden="true" tabindex="-1"></a>?Boston</span>
<span id="cb204-248"><a href="nonlinear-regression.html#cb204-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-249"><a href="nonlinear-regression.html#cb204-249" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb204-250"><a href="nonlinear-regression.html#cb204-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb204-251"><a href="nonlinear-regression.html#cb204-251" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Boston), <span class="fu">nrow</span>(Boston)<span class="sc">/</span><span class="dv">2</span>) <span class="co"># обучающая выборка -- 50%</span></span>
<span id="cb204-252"><a href="nonlinear-regression.html#cb204-252" aria-hidden="true" tabindex="-1"></a>Построим дерево регрессии для зависимой переменной medv<span class="sc">:</span> медианная стоимости домов, в которых живут собственники (тыс. долл.).</span>
<span id="cb204-253"><a href="nonlinear-regression.html#cb204-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-254"><a href="nonlinear-regression.html#cb204-254" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb204-255"><a href="nonlinear-regression.html#cb204-255" aria-hidden="true" tabindex="-1"></a>tree.boston <span class="ot">&lt;-</span> <span class="fu">tree</span>(medv <span class="sc">~</span> ., Boston, <span class="at">subset =</span> train)</span>
<span id="cb204-256"><a href="nonlinear-regression.html#cb204-256" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.boston)</span>
<span id="cb204-257"><a href="nonlinear-regression.html#cb204-257" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-258"><a href="nonlinear-regression.html#cb204-258" aria-hidden="true" tabindex="-1"></a><span class="do">## Regression tree:</span></span>
<span id="cb204-259"><a href="nonlinear-regression.html#cb204-259" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = medv ~ ., data = Boston, subset = train)</span></span>
<span id="cb204-260"><a href="nonlinear-regression.html#cb204-260" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb204-261"><a href="nonlinear-regression.html#cb204-261" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;lstat&quot; &quot;rm&quot;    &quot;dis&quot;  </span></span>
<span id="cb204-262"><a href="nonlinear-regression.html#cb204-262" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  8 </span></span>
<span id="cb204-263"><a href="nonlinear-regression.html#cb204-263" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  12.65 = 3099 / 245 </span></span>
<span id="cb204-264"><a href="nonlinear-regression.html#cb204-264" aria-hidden="true" tabindex="-1"></a><span class="do">## Distribution of residuals:</span></span>
<span id="cb204-265"><a href="nonlinear-regression.html#cb204-265" aria-hidden="true" tabindex="-1"></a><span class="do">##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. </span></span>
<span id="cb204-266"><a href="nonlinear-regression.html#cb204-266" aria-hidden="true" tabindex="-1"></a><span class="do">## -14.10000  -2.04200  -0.05357   0.00000   1.96000  12.60000</span></span>
<span id="cb204-267"><a href="nonlinear-regression.html#cb204-267" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb204-268"><a href="nonlinear-regression.html#cb204-268" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.boston)</span>
<span id="cb204-269"><a href="nonlinear-regression.html#cb204-269" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb204-270"><a href="nonlinear-regression.html#cb204-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-271"><a href="nonlinear-regression.html#cb204-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-272"><a href="nonlinear-regression.html#cb204-272" aria-hidden="true" tabindex="-1"></a>Снова сделаем обрезку дерева в целях улучшения качества прогноза.</span>
<span id="cb204-273"><a href="nonlinear-regression.html#cb204-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-274"><a href="nonlinear-regression.html#cb204-274" aria-hidden="true" tabindex="-1"></a>cv.boston <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.boston)</span>
<span id="cb204-275"><a href="nonlinear-regression.html#cb204-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-276"><a href="nonlinear-regression.html#cb204-276" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb204-277"><a href="nonlinear-regression.html#cb204-277" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.boston<span class="sc">$</span>size, cv.boston<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&#39;b&#39;</span>)</span>
<span id="cb204-278"><a href="nonlinear-regression.html#cb204-278" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.boston<span class="sc">$</span>size[cv.boston<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.boston<span class="sc">$</span>dev)]</span>
<span id="cb204-279"><a href="nonlinear-regression.html#cb204-279" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb204-280"><a href="nonlinear-regression.html#cb204-280" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb204-281"><a href="nonlinear-regression.html#cb204-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-282"><a href="nonlinear-regression.html#cb204-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-283"><a href="nonlinear-regression.html#cb204-283" aria-hidden="true" tabindex="-1"></a>В данном случаем минимум ошибки соответствует самому сложному дереву, с <span class="dv">8</span> узлами. Покажем, как при желании можно обрезать дерево до <span class="dv">7</span> узлов (ошибка ненамного выше, чем минимальная).</span>
<span id="cb204-284"><a href="nonlinear-regression.html#cb204-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-285"><a href="nonlinear-regression.html#cb204-285" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 7 узлами</span></span>
<span id="cb204-286"><a href="nonlinear-regression.html#cb204-286" aria-hidden="true" tabindex="-1"></a>prune.boston <span class="ot">=</span> <span class="fu">prune.tree</span>(tree.boston, <span class="at">best =</span> <span class="dv">7</span>)</span>
<span id="cb204-287"><a href="nonlinear-regression.html#cb204-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-288"><a href="nonlinear-regression.html#cb204-288" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb204-289"><a href="nonlinear-regression.html#cb204-289" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.boston)</span>
<span id="cb204-290"><a href="nonlinear-regression.html#cb204-290" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb204-291"><a href="nonlinear-regression.html#cb204-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-292"><a href="nonlinear-regression.html#cb204-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-293"><a href="nonlinear-regression.html#cb204-293" aria-hidden="true" tabindex="-1"></a>Прогноз сделаем по необрезанному дереву, т.к. там ошибка, оцененная по методу перекрёстной проверки, минимальна.</span>
<span id="cb204-294"><a href="nonlinear-regression.html#cb204-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-295"><a href="nonlinear-regression.html#cb204-295" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по лучшей модели (8 узлов)</span></span>
<span id="cb204-296"><a href="nonlinear-regression.html#cb204-296" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb204-297"><a href="nonlinear-regression.html#cb204-297" aria-hidden="true" tabindex="-1"></a>boston.test <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>train, <span class="st">&quot;medv&quot;</span>]</span>
<span id="cb204-298"><a href="nonlinear-regression.html#cb204-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-299"><a href="nonlinear-regression.html#cb204-299" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb204-300"><a href="nonlinear-regression.html#cb204-300" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat, boston.test)</span>
<span id="cb204-301"><a href="nonlinear-regression.html#cb204-301" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb204-302"><a href="nonlinear-regression.html#cb204-302" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb204-303"><a href="nonlinear-regression.html#cb204-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-304"><a href="nonlinear-regression.html#cb204-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-305"><a href="nonlinear-regression.html#cb204-305" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb204-306"><a href="nonlinear-regression.html#cb204-306" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb204-307"><a href="nonlinear-regression.html#cb204-307" aria-hidden="true" tabindex="-1"></a>MSE на тестовой выборке равна <span class="fl">25.05</span> (тыс.долл.).</span>
<span id="cb204-308"><a href="nonlinear-regression.html#cb204-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-309"><a href="nonlinear-regression.html#cb204-309" aria-hidden="true" tabindex="-1"></a>Бэггинг и метод случайного леса</span>
<span id="cb204-310"><a href="nonlinear-regression.html#cb204-310" aria-hidden="true" tabindex="-1"></a>Рассмотрим более сложные методы улучшения качества дерева. Бэггинг – частный случай случайного леса с m<span class="ot">=</span>p, поэтому и то, и другое можно построить функцией <span class="fu">randomForest</span>().</span>
<span id="cb204-311"><a href="nonlinear-regression.html#cb204-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-312"><a href="nonlinear-regression.html#cb204-312" aria-hidden="true" tabindex="-1"></a>Для начала используем бэггинг, причём возьмём все <span class="dv">13</span> предикторов на каждом шаге (аргумент mtry).</span>
<span id="cb204-313"><a href="nonlinear-regression.html#cb204-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-314"><a href="nonlinear-regression.html#cb204-314" aria-hidden="true" tabindex="-1"></a><span class="co"># бэггинг с 13 предикторами</span></span>
<span id="cb204-315"><a href="nonlinear-regression.html#cb204-315" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb204-316"><a href="nonlinear-regression.html#cb204-316" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train, </span>
<span id="cb204-317"><a href="nonlinear-regression.html#cb204-317" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb204-318"><a href="nonlinear-regression.html#cb204-318" aria-hidden="true" tabindex="-1"></a>bag.boston</span>
<span id="cb204-319"><a href="nonlinear-regression.html#cb204-319" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-320"><a href="nonlinear-regression.html#cb204-320" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb204-321"><a href="nonlinear-regression.html#cb204-321" aria-hidden="true" tabindex="-1"></a><span class="do">##  randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE,      subset = train) </span></span>
<span id="cb204-322"><a href="nonlinear-regression.html#cb204-322" aria-hidden="true" tabindex="-1"></a><span class="do">##                Type of random forest: regression</span></span>
<span id="cb204-323"><a href="nonlinear-regression.html#cb204-323" aria-hidden="true" tabindex="-1"></a><span class="do">##                      Number of trees: 500</span></span>
<span id="cb204-324"><a href="nonlinear-regression.html#cb204-324" aria-hidden="true" tabindex="-1"></a><span class="do">## No. of variables tried at each split: 13</span></span>
<span id="cb204-325"><a href="nonlinear-regression.html#cb204-325" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb204-326"><a href="nonlinear-regression.html#cb204-326" aria-hidden="true" tabindex="-1"></a><span class="do">##           Mean of squared residuals: 11.15723</span></span>
<span id="cb204-327"><a href="nonlinear-regression.html#cb204-327" aria-hidden="true" tabindex="-1"></a><span class="do">##                     % Var explained: 86.49</span></span>
<span id="cb204-328"><a href="nonlinear-regression.html#cb204-328" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb204-329"><a href="nonlinear-regression.html#cb204-329" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">=</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb204-330"><a href="nonlinear-regression.html#cb204-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-331"><a href="nonlinear-regression.html#cb204-331" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb204-332"><a href="nonlinear-regression.html#cb204-332" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat.bag, boston.test)</span>
<span id="cb204-333"><a href="nonlinear-regression.html#cb204-333" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb204-334"><a href="nonlinear-regression.html#cb204-334" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb204-335"><a href="nonlinear-regression.html#cb204-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-336"><a href="nonlinear-regression.html#cb204-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-337"><a href="nonlinear-regression.html#cb204-337" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb204-338"><a href="nonlinear-regression.html#cb204-338" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb204-339"><a href="nonlinear-regression.html#cb204-339" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb204-340"><a href="nonlinear-regression.html#cb204-340" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.50808</span></span>
<span id="cb204-341"><a href="nonlinear-regression.html#cb204-341" aria-hidden="true" tabindex="-1"></a>Ошибка на тестовой выборке равна <span class="dv">13</span>.<span class="fl">51.</span></span>
<span id="cb204-342"><a href="nonlinear-regression.html#cb204-342" aria-hidden="true" tabindex="-1"></a>Можно изменить число деревьев с помощью аргумента ntree.</span>
<span id="cb204-343"><a href="nonlinear-regression.html#cb204-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-344"><a href="nonlinear-regression.html#cb204-344" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb204-345"><a href="nonlinear-regression.html#cb204-345" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">ntree =</span> <span class="dv">25</span>)</span>
<span id="cb204-346"><a href="nonlinear-regression.html#cb204-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-347"><a href="nonlinear-regression.html#cb204-347" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb204-348"><a href="nonlinear-regression.html#cb204-348" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">&lt;-</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb204-349"><a href="nonlinear-regression.html#cb204-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-350"><a href="nonlinear-regression.html#cb204-350" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb204-351"><a href="nonlinear-regression.html#cb204-351" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb204-352"><a href="nonlinear-regression.html#cb204-352" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb204-353"><a href="nonlinear-regression.html#cb204-353" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.94835</span></span>
<span id="cb204-354"><a href="nonlinear-regression.html#cb204-354" aria-hidden="true" tabindex="-1"></a>Но, как видно, это только ухудшает прогноз.</span>
<span id="cb204-355"><a href="nonlinear-regression.html#cb204-355" aria-hidden="true" tabindex="-1"></a>Теперь попробуем вырастить случайный лес. Берём <span class="dv">6</span> предикторов на каждом шаге.</span>
<span id="cb204-356"><a href="nonlinear-regression.html#cb204-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-357"><a href="nonlinear-regression.html#cb204-357" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb204-358"><a href="nonlinear-regression.html#cb204-358" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb204-359"><a href="nonlinear-regression.html#cb204-359" aria-hidden="true" tabindex="-1"></a>rf.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb204-360"><a href="nonlinear-regression.html#cb204-360" aria-hidden="true" tabindex="-1"></a>                          <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb204-361"><a href="nonlinear-regression.html#cb204-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-362"><a href="nonlinear-regression.html#cb204-362" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb204-363"><a href="nonlinear-regression.html#cb204-363" aria-hidden="true" tabindex="-1"></a>yhat.rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb204-364"><a href="nonlinear-regression.html#cb204-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-365"><a href="nonlinear-regression.html#cb204-365" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb204-366"><a href="nonlinear-regression.html#cb204-366" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.rf <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb204-367"><a href="nonlinear-regression.html#cb204-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-368"><a href="nonlinear-regression.html#cb204-368" aria-hidden="true" tabindex="-1"></a><span class="co"># важность предикторов</span></span>
<span id="cb204-369"><a href="nonlinear-regression.html#cb204-369" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf.boston)  <span class="co"># оценки </span></span>
<span id="cb204-370"><a href="nonlinear-regression.html#cb204-370" aria-hidden="true" tabindex="-1"></a><span class="do">##           %IncMSE IncNodePurity</span></span>
<span id="cb204-371"><a href="nonlinear-regression.html#cb204-371" aria-hidden="true" tabindex="-1"></a><span class="do">## crim    12.132320     986.50338</span></span>
<span id="cb204-372"><a href="nonlinear-regression.html#cb204-372" aria-hidden="true" tabindex="-1"></a><span class="do">## zn       1.955579      57.96945</span></span>
<span id="cb204-373"><a href="nonlinear-regression.html#cb204-373" aria-hidden="true" tabindex="-1"></a><span class="do">## indus    9.069302     882.78261</span></span>
<span id="cb204-374"><a href="nonlinear-regression.html#cb204-374" aria-hidden="true" tabindex="-1"></a><span class="do">## chas     2.210835      45.22941</span></span>
<span id="cb204-375"><a href="nonlinear-regression.html#cb204-375" aria-hidden="true" tabindex="-1"></a><span class="do">## nox     11.104823    1044.33776</span></span>
<span id="cb204-376"><a href="nonlinear-regression.html#cb204-376" aria-hidden="true" tabindex="-1"></a><span class="do">## rm      31.784033    6359.31971</span></span>
<span id="cb204-377"><a href="nonlinear-regression.html#cb204-377" aria-hidden="true" tabindex="-1"></a><span class="do">## age     10.962684     516.82969</span></span>
<span id="cb204-378"><a href="nonlinear-regression.html#cb204-378" aria-hidden="true" tabindex="-1"></a><span class="do">## dis     15.015236    1224.11605</span></span>
<span id="cb204-379"><a href="nonlinear-regression.html#cb204-379" aria-hidden="true" tabindex="-1"></a><span class="do">## rad      4.118011      95.94586</span></span>
<span id="cb204-380"><a href="nonlinear-regression.html#cb204-380" aria-hidden="true" tabindex="-1"></a><span class="do">## tax      8.587932     502.96719</span></span>
<span id="cb204-381"><a href="nonlinear-regression.html#cb204-381" aria-hidden="true" tabindex="-1"></a><span class="do">## ptratio 12.503896     830.77523</span></span>
<span id="cb204-382"><a href="nonlinear-regression.html#cb204-382" aria-hidden="true" tabindex="-1"></a><span class="do">## black    6.702609     341.30361</span></span>
<span id="cb204-383"><a href="nonlinear-regression.html#cb204-383" aria-hidden="true" tabindex="-1"></a><span class="do">## lstat   30.695224    7505.73936</span></span>
<span id="cb204-384"><a href="nonlinear-regression.html#cb204-384" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.boston)  <span class="co"># графики</span></span>
<span id="cb204-385"><a href="nonlinear-regression.html#cb204-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-386"><a href="nonlinear-regression.html#cb204-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-387"><a href="nonlinear-regression.html#cb204-387" aria-hidden="true" tabindex="-1"></a>Ошибка по модели случайного леса равна <span class="fl">11.66</span>, что ниже, чем для бэггинга.</span>
<span id="cb204-388"><a href="nonlinear-regression.html#cb204-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-389"><a href="nonlinear-regression.html#cb204-389" aria-hidden="true" tabindex="-1"></a>Бустинг</span>
<span id="cb204-390"><a href="nonlinear-regression.html#cb204-390" aria-hidden="true" tabindex="-1"></a>Построим <span class="dv">5000</span> регрессионных деревьев с глубиной <span class="fl">4.</span></span>
<span id="cb204-391"><a href="nonlinear-regression.html#cb204-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-392"><a href="nonlinear-regression.html#cb204-392" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb204-393"><a href="nonlinear-regression.html#cb204-393" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb204-394"><a href="nonlinear-regression.html#cb204-394" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>)</span>
<span id="cb204-395"><a href="nonlinear-regression.html#cb204-395" aria-hidden="true" tabindex="-1"></a><span class="co"># график и таблица относительной важности переменных</span></span>
<span id="cb204-396"><a href="nonlinear-regression.html#cb204-396" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boost.boston)</span>
<span id="cb204-397"><a href="nonlinear-regression.html#cb204-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-398"><a href="nonlinear-regression.html#cb204-398" aria-hidden="true" tabindex="-1"></a><span class="co"># графики частной зависимости для двух наиболее важных предикторов</span></span>
<span id="cb204-399"><a href="nonlinear-regression.html#cb204-399" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb204-400"><a href="nonlinear-regression.html#cb204-400" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;rm&quot;</span>)</span>
<span id="cb204-401"><a href="nonlinear-regression.html#cb204-401" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb204-402"><a href="nonlinear-regression.html#cb204-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-403"><a href="nonlinear-regression.html#cb204-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-404"><a href="nonlinear-regression.html#cb204-404" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb204-405"><a href="nonlinear-regression.html#cb204-405" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb204-406"><a href="nonlinear-regression.html#cb204-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-407"><a href="nonlinear-regression.html#cb204-407" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb204-408"><a href="nonlinear-regression.html#cb204-408" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb204-409"><a href="nonlinear-regression.html#cb204-409" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb204-410"><a href="nonlinear-regression.html#cb204-410" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.84434</span></span>
<span id="cb204-411"><a href="nonlinear-regression.html#cb204-411" aria-hidden="true" tabindex="-1"></a>Настройку бустинга можно делать с помощью гиперпараметра λ (аргумент shrinkage). Установим его равным <span class="dv">0</span>.<span class="fl">2.</span></span>
<span id="cb204-412"><a href="nonlinear-regression.html#cb204-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-413"><a href="nonlinear-regression.html#cb204-413" aria-hidden="true" tabindex="-1"></a><span class="co"># меняем значение гиперпараметра (lambda) на 0.2 -- аргумент shrinkage</span></span>
<span id="cb204-414"><a href="nonlinear-regression.html#cb204-414" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb204-415"><a href="nonlinear-regression.html#cb204-415" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>, </span>
<span id="cb204-416"><a href="nonlinear-regression.html#cb204-416" aria-hidden="true" tabindex="-1"></a>                    <span class="at">shrinkage =</span> <span class="fl">0.2</span>, <span class="at">verbose =</span> F)</span>
<span id="cb204-417"><a href="nonlinear-regression.html#cb204-417" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb204-418"><a href="nonlinear-regression.html#cb204-418" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb204-419"><a href="nonlinear-regression.html#cb204-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-420"><a href="nonlinear-regression.html#cb204-420" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE а тестовой</span></span>
<span id="cb204-421"><a href="nonlinear-regression.html#cb204-421" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb204-422"><a href="nonlinear-regression.html#cb204-422" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb204-423"><a href="nonlinear-regression.html#cb204-423" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.51109</span></span>
<span id="cb204-424"><a href="nonlinear-regression.html#cb204-424" aria-hidden="true" tabindex="-1"></a>Таким образом, изменив гиперпараметр, мы ещё немного снизили ошибку прогноза.</span></code></pre></div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression-complex-cases.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/29_nonlinear_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
