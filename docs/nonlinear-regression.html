<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 28 Nonlinear regression | R statistics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 28 Nonlinear regression | R statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 28 Nonlinear regression | R statistics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Mark Goldberg" />


<meta name="date" content="2021-05-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-regression-complex-cases.html"/>
<link rel="next" href="multiple-linear-regression.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html"><i class="fa fa-check"></i><b>2</b> Statistics R functions reference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#get-data"><i class="fa fa-check"></i><b>2.1</b> Get data</a></li>
<li class="chapter" data-level="2.2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#data-inspection"><i class="fa fa-check"></i><b>2.2</b> Data inspection</a></li>
<li class="chapter" data-level="2.3" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#plots"><i class="fa fa-check"></i><b>2.3</b> Plots</a></li>
<li class="chapter" data-level="2.4" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#analysis-of-the-distribution"><i class="fa fa-check"></i><b>2.4</b> Analysis of the distribution</a></li>
<li class="chapter" data-level="2.5" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#distributions"><i class="fa fa-check"></i><b>2.5</b> Distributions</a></li>
<li class="chapter" data-level="2.6" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#t-test"><i class="fa fa-check"></i><b>2.6</b> t-Test</a></li>
<li class="chapter" data-level="2.7" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#anova"><i class="fa fa-check"></i><b>2.7</b> ANOVA</a></li>
<li class="chapter" data-level="2.8" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#machine-learning-functions-reference"><i class="fa fa-check"></i><b>2.8</b> Machine Learning Functions Reference</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#linear-regression"><i class="fa fa-check"></i><b>2.8.1</b> Linear Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="combinatorics.html"><a href="combinatorics.html"><i class="fa fa-check"></i><b>3</b> Combinatorics</a></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a></li>
<li class="chapter" data-level="5" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>5</b> Basic Statistics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="basic-statistics.html"><a href="basic-statistics.html#definitions"><i class="fa fa-check"></i><b>5.1</b> Definitions</a></li>
<li class="chapter" data-level="5.2" data-path="basic-statistics.html"><a href="basic-statistics.html#probability-1"><i class="fa fa-check"></i><b>5.2</b> Probability</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistical-distributions.html"><a href="statistical-distributions.html"><i class="fa fa-check"></i><b>6</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistical-distributions.html"><a href="statistical-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>6.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="6.2" data-path="statistical-distributions.html"><a href="statistical-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>6.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="6.3" data-path="statistical-distributions.html"><a href="statistical-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>6.3</b> Binomial Distribution</a></li>
<li class="chapter" data-level="6.4" data-path="statistical-distributions.html"><a href="statistical-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>6.4</b> Beta distribution</a></li>
<li class="chapter" data-level="6.5" data-path="statistical-distributions.html"><a href="statistical-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>6.5</b> Geometric Distribution</a></li>
<li class="chapter" data-level="6.6" data-path="statistical-distributions.html"><a href="statistical-distributions.html#uniform-distributions"><i class="fa fa-check"></i><b>6.6</b> Uniform Distributions</a></li>
<li class="chapter" data-level="6.7" data-path="statistical-distributions.html"><a href="statistical-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>6.7</b> Poisson Distribution</a></li>
<li class="chapter" data-level="6.8" data-path="statistical-distributions.html"><a href="statistical-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>6.8</b> Exponential Distribution</a></li>
<li class="chapter" data-level="6.9" data-path="statistical-distributions.html"><a href="statistical-distributions.html#chi-squared-distribution"><i class="fa fa-check"></i><b>6.9</b> Chi-squared Distribution</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html"><i class="fa fa-check"></i><b>7</b> Primary data analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#analysis-of-sample-distribution"><i class="fa fa-check"></i><b>7.1</b> Analysis of sample distribution</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#histogram"><i class="fa fa-check"></i><b>7.1.1</b> Histogram</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#handling-missing-data"><i class="fa fa-check"></i><b>7.2</b> Handling missing data</a></li>
<li class="chapter" data-level="7.3" data-path="primary-data-analysis.html"><a href="primary-data-analysis.html#dealing-with-outliers"><i class="fa fa-check"></i><b>7.3</b> Dealing with outliers</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-normalization.html"><a href="data-normalization.html"><i class="fa fa-check"></i><b>8</b> Data normalization</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-normalization.html"><a href="data-normalization.html#normality-test"><i class="fa fa-check"></i><b>8.1</b> Normality test</a></li>
<li class="chapter" data-level="8.2" data-path="data-normalization.html"><a href="data-normalization.html#finding-confidence-intervals"><i class="fa fa-check"></i><b>8.2</b> Finding Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="primary-data-analysis-case-studies.html"><a href="primary-data-analysis-case-studies.html"><i class="fa fa-check"></i><b>9</b> Primary data analysis - Case studies</a></li>
<li class="chapter" data-level="10" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="10.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-theory"><i class="fa fa-check"></i><b>10.1</b> Hypothesis testing theory</a></li>
<li class="chapter" data-level="10.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-practice"><i class="fa fa-check"></i><b>10.2</b> Hypothesis test (Practice)</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="t-procedures.html"><a href="t-procedures.html"><i class="fa fa-check"></i><b>11</b> t-Procedures</a>
<ul>
<li class="chapter" data-level="11.1" data-path="t-procedures.html"><a href="t-procedures.html#t-test-and-normal-distribution"><i class="fa fa-check"></i><b>11.1</b> t-test and normal distribution</a></li>
<li class="chapter" data-level="11.2" data-path="t-procedures.html"><a href="t-procedures.html#one-sample-t-test"><i class="fa fa-check"></i><b>11.2</b> One-sample t-test</a></li>
<li class="chapter" data-level="11.3" data-path="t-procedures.html"><a href="t-procedures.html#practical-example-t-test-in-r"><i class="fa fa-check"></i><b>11.3</b> Practical example: t-test in R</a></li>
<li class="chapter" data-level="11.4" data-path="t-procedures.html"><a href="t-procedures.html#two-samples-t-test"><i class="fa fa-check"></i><b>11.4</b> Two samples t-test</a></li>
<li class="chapter" data-level="11.5" data-path="t-procedures.html"><a href="t-procedures.html#compare-students-t-and-normal-distributions"><i class="fa fa-check"></i><b>11.5</b> Compare Student’s t and normal distributions</a></li>
<li class="chapter" data-level="11.6" data-path="t-procedures.html"><a href="t-procedures.html#non-parametric-tests"><i class="fa fa-check"></i><b>11.6</b> Non-parametric tests</a></li>
<li class="chapter" data-level="11.7" data-path="t-procedures.html"><a href="t-procedures.html#mann-whitney-u-rank-sum-test"><i class="fa fa-check"></i><b>11.7</b> Mann-Whitney U Rank Sum Test</a></li>
<li class="chapter" data-level="11.8" data-path="t-procedures.html"><a href="t-procedures.html#wilcoxon-test"><i class="fa fa-check"></i><b>11.8</b> Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html"><i class="fa fa-check"></i><b>12</b> Tests for categorical variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html#chi-squared-tests"><i class="fa fa-check"></i><b>12.1</b> Chi-squared tests</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>13</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="13.1" data-path="multiple-testing.html"><a href="multiple-testing.html#the-bonferroni-correction"><i class="fa fa-check"></i><b>13.1</b> The Bonferroni correction</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="sources.html"><a href="sources.html"><i class="fa fa-check"></i><b>14</b> Sources</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sources.html"><a href="sources.html#t-test-1"><i class="fa fa-check"></i><b>14.1</b> t-test</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="sources.html"><a href="sources.html#two-tailed-test"><i class="fa fa-check"></i><b>14.1.1</b> Two-tailed test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="wilcoxon-signed-rank-test.html"><a href="wilcoxon-signed-rank-test.html"><i class="fa fa-check"></i><b>15</b> Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="16" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>16</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="16.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>16.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="16.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#sources-1"><i class="fa fa-check"></i><b>16.2</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="t-test-anova-difference.html"><a href="t-test-anova-difference.html"><i class="fa fa-check"></i><b>17</b> t-test ANOVA difference</a></li>
<li class="chapter" data-level="18" data-path="chi-squared-test.html"><a href="chi-squared-test.html"><i class="fa fa-check"></i><b>18</b> Chi-squared test</a>
<ul>
<li class="chapter" data-level="18.1" data-path="chi-squared-test.html"><a href="chi-squared-test.html#multinomial-goodness-of-fit"><i class="fa fa-check"></i><b>18.1</b> Multinomial Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html"><i class="fa fa-check"></i><b>19</b> Non-parametric Methods</a>
<ul>
<li class="chapter" data-level="19.1" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#sign-test"><i class="fa fa-check"></i><b>19.1</b> Sign Test</a></li>
<li class="chapter" data-level="19.2" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#wilcoxon-signed-rank-test-1"><i class="fa fa-check"></i><b>19.2</b> Wilcoxon Signed-Rank Test</a></li>
<li class="chapter" data-level="19.3" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#mann-whitney-wilcoxon-test"><i class="fa fa-check"></i><b>19.3</b> Mann-Whitney-Wilcoxon Test</a></li>
<li class="chapter" data-level="19.4" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>19.4</b> Kruskal-Wallis Test</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>20</b> Correlation</a></li>
<li class="chapter" data-level="21" data-path="methods-and-algorithms-of-machine-learning.html"><a href="methods-and-algorithms-of-machine-learning.html"><i class="fa fa-check"></i><b>21</b> Methods and algorithms of machine learning</a></li>
<li class="chapter" data-level="22" data-path="split-data-into-train-and-test-subsets.html"><a href="split-data-into-train-and-test-subsets.html"><i class="fa fa-check"></i><b>22</b> Split data into train and test subsets</a></li>
<li class="chapter" data-level="23" data-path="estimate-model-accuracy.html"><a href="estimate-model-accuracy.html"><i class="fa fa-check"></i><b>23</b> Estimate model accuracy</a>
<ul>
<li class="chapter" data-level="23.1" data-path="estimate-model-accuracy.html"><a href="estimate-model-accuracy.html#continuous-variables"><i class="fa fa-check"></i><b>23.1</b> Continuous variables</a></li>
<li class="chapter" data-level="23.2" data-path="estimate-model-accuracy.html"><a href="estimate-model-accuracy.html#discret-variables"><i class="fa fa-check"></i><b>23.2</b> Discret variables</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="model-evaluation.html"><a href="model-evaluation.html"><i class="fa fa-check"></i><b>24</b> Model evaluation</a></li>
<li class="chapter" data-level="25" data-path="cross-validation-and-bootstrep.html"><a href="cross-validation-and-bootstrep.html"><i class="fa fa-check"></i><b>25</b> Cross-validation and Bootstrep</a></li>
<li class="chapter" data-level="26" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>26</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="26.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression---theory"><i class="fa fa-check"></i><b>26.1</b> Linear regression - theory</a></li>
<li class="chapter" data-level="26.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-random-data-set-for-the-linear-model"><i class="fa fa-check"></i><b>26.2</b> Generate random data set for the linear model</a></li>
<li class="chapter" data-level="26.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-example"><i class="fa fa-check"></i><b>26.3</b> Practical example</a></li>
<li class="chapter" data-level="26.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#mean-squared-error-mse"><i class="fa fa-check"></i><b>26.4</b> Mean squared error (MSE)</a></li>
<li class="chapter" data-level="26.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-model-in-r"><i class="fa fa-check"></i><b>26.5</b> Linear model in R</a></li>
<li class="chapter" data-level="26.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression-model-for-multiple-parameters"><i class="fa fa-check"></i><b>26.6</b> Linear regression model for multiple parameters</a></li>
<li class="chapter" data-level="26.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#choosing-explanatory-variables-for-the-model"><i class="fa fa-check"></i><b>26.7</b> Choosing explanatory variables for the model</a></li>
<li class="chapter" data-level="26.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#assessment-of-model-performance-for-categorical-data."><i class="fa fa-check"></i><b>26.8</b> Assessment of model performance for categorical data.</a></li>
<li class="chapter" data-level="26.9" data-path="linear-regression-1.html"><a href="linear-regression-1.html#confidence-intervals-for-linear-model"><i class="fa fa-check"></i><b>26.9</b> Confidence intervals for linear model</a></li>
<li class="chapter" data-level="26.10" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression"><i class="fa fa-check"></i><b>26.10</b> Practical examples for linear model regression</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html"><i class="fa fa-check"></i><b>27</b> Linear regression complex cases</a>
<ul>
<li class="chapter" data-level="27.1" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#cars"><i class="fa fa-check"></i><b>27.1</b> Cars</a></li>
<li class="chapter" data-level="27.2" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#linear-regression-modeling-compair-with-knn"><i class="fa fa-check"></i><b>27.2</b> Linear regression modeling, compair with kNN</a></li>
<li class="chapter" data-level="27.3" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#more-complex-example"><i class="fa fa-check"></i><b>27.3</b> More complex example</a></li>
<li class="chapter" data-level="27.4" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part"><i class="fa fa-check"></i><b>27.4</b> NEXT part</a></li>
<li class="chapter" data-level="27.5" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part-1"><i class="fa fa-check"></i><b>27.5</b> NEXT Part</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="nonlinear-regression.html"><a href="nonlinear-regression.html"><i class="fa fa-check"></i><b>28</b> Nonlinear regression</a></li>
<li class="chapter" data-level="29" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>29</b> Multiple linear regression</a></li>
<li class="chapter" data-level="30" data-path="spline-model.html"><a href="spline-model.html"><i class="fa fa-check"></i><b>30</b> Spline model</a>
<ul>
<li class="chapter" data-level="30.1" data-path="spline-model.html"><a href="spline-model.html#splines"><i class="fa fa-check"></i><b>30.1</b> Splines</a></li>
<li class="chapter" data-level="30.2" data-path="spline-model.html"><a href="spline-model.html#area-under-the-curve-using-spline-method"><i class="fa fa-check"></i><b>30.2</b> Area under the curve using spline method</a></li>
<li class="chapter" data-level="30.3" data-path="spline-model.html"><a href="spline-model.html#set-data-using-given-function-and-predict-curve-using-spline-method"><i class="fa fa-check"></i><b>30.3</b> Set data using given function and predict curve using spline method</a></li>
<li class="chapter" data-level="30.4" data-path="spline-model.html"><a href="spline-model.html#generate-dataset-from-a-given-function"><i class="fa fa-check"></i><b>30.4</b> Generate dataset from a given function</a></li>
<li class="chapter" data-level="30.5" data-path="spline-model.html"><a href="spline-model.html#split-data-for-train-and-test"><i class="fa fa-check"></i><b>30.5</b> Split data for train and test</a></li>
<li class="chapter" data-level="30.6" data-path="spline-model.html"><a href="spline-model.html#diagram-of-the-given-function-and-generated-datasets"><i class="fa fa-check"></i><b>30.6</b> Diagram of the given function and generated datasets</a></li>
<li class="chapter" data-level="30.7" data-path="spline-model.html"><a href="spline-model.html#build-a-model-using-splines"><i class="fa fa-check"></i><b>30.7</b> Build a model using splines</a></li>
<li class="chapter" data-level="30.8" data-path="spline-model.html"><a href="spline-model.html#diagram-of-mse-for-train-and-test-data"><i class="fa fa-check"></i><b>30.8</b> Diagram of MSE for train and test data</a></li>
<li class="chapter" data-level="30.9" data-path="spline-model.html"><a href="spline-model.html#build-optimal-model-and-plot-for-the-model"><i class="fa fa-check"></i><b>30.9</b> Build optimal model and plot for the model</a></li>
<li class="chapter" data-level="30.10" data-path="spline-model.html"><a href="spline-model.html#bibliograpy"><i class="fa fa-check"></i><b>30.10</b> Bibliograpy</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>31</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="31.1" data-path="logistic-regression.html"><a href="logistic-regression.html#confusion-matrix"><i class="fa fa-check"></i><b>31.1</b> Confusion matrix</a></li>
<li class="chapter" data-level="31.2" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-2"><i class="fa fa-check"></i><b>31.2</b> Next part</a></li>
<li class="chapter" data-level="31.3" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-3"><i class="fa fa-check"></i><b>31.3</b> NExt part</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="models-for-binary-data.html"><a href="models-for-binary-data.html"><i class="fa fa-check"></i><b>32</b> Models for binary Data</a></li>
<li class="chapter" data-level="33" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>33</b> Support Vector Machine</a></li>
<li class="chapter" data-level="34" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>34</b> Clustering</a>
<ul>
<li class="chapter" data-level="34.1" data-path="clustering.html"><a href="clustering.html#finding-distances-using-factoextra"><i class="fa fa-check"></i><b>34.1</b> Finding distances using factoextra</a></li>
<li class="chapter" data-level="34.2" data-path="clustering.html"><a href="clustering.html#example-of-choosing-clustering-model"><i class="fa fa-check"></i><b>34.2</b> Example of choosing clustering model</a></li>
<li class="chapter" data-level="34.3" data-path="clustering.html"><a href="clustering.html#k-means-clustering"><i class="fa fa-check"></i><b>34.3</b> K-means clustering</a></li>
<li class="chapter" data-level="34.4" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>34.4</b> k-Means</a></li>
<li class="chapter" data-level="34.5" data-path="clustering.html"><a href="clustering.html#hierarchical-clustering"><i class="fa fa-check"></i><b>34.5</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="34.6" data-path="clustering.html"><a href="clustering.html#knn"><i class="fa fa-check"></i><b>34.6</b> KNN</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>35</b> Regularization</a></li>
<li class="chapter" data-level="36" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>36</b> Factor analysis</a></li>
<li class="chapter" data-level="37" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>37</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="38" data-path="principal-component-analysis-1.html"><a href="principal-component-analysis-1.html"><i class="fa fa-check"></i><b>38</b> Principal component analysis</a>
<ul>
<li class="chapter" data-level="38.1" data-path="principal-component-analysis-1.html"><a href="principal-component-analysis-1.html#basic-statistics-1"><i class="fa fa-check"></i><b>38.1</b> Basic statistics</a></li>
<li class="chapter" data-level="38.2" data-path="principal-component-analysis-1.html"><a href="principal-component-analysis-1.html#basic-linear-algebra-matrices"><i class="fa fa-check"></i><b>38.2</b> Basic linear algebra (matrices)</a>
<ul>
<li class="chapter" data-level="38.2.1" data-path="principal-component-analysis-1.html"><a href="principal-component-analysis-1.html#t-sne---stochastic-neighbor-embedding"><i class="fa fa-check"></i><b>38.2.1</b> t-SNE - Stochastic Neighbor Embedding</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="39" data-path="learning-vector-quantization.html"><a href="learning-vector-quantization.html"><i class="fa fa-check"></i><b>39</b> Learning Vector Quantization</a></li>
<li class="chapter" data-level="40" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>40</b> Tree-based models</a>
<ul>
<li class="chapter" data-level="40.1" data-path="tree-based-models.html"><a href="tree-based-models.html#classification-tree-example"><i class="fa fa-check"></i><b>40.1</b> Classification Tree example</a></li>
<li class="chapter" data-level="40.2" data-path="tree-based-models.html"><a href="tree-based-models.html#regression-tree-example"><i class="fa fa-check"></i><b>40.2</b> Regression Tree example</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>41</b> Random forest</a></li>
<li class="chapter" data-level="42" data-path="gradient-boosted-trees.html"><a href="gradient-boosted-trees.html"><i class="fa fa-check"></i><b>42</b> Gradient boosted trees</a></li>
<li class="chapter" data-level="43" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>43</b> Markov Chain Monte Carlo (MCMC)</a></li>
<li class="chapter" data-level="44" data-path="simple-markov-process.html"><a href="simple-markov-process.html"><i class="fa fa-check"></i><b>44</b> Simple Markov process</a>
<ul>
<li class="chapter" data-level="44.0.1" data-path="simple-markov-process.html"><a href="simple-markov-process.html#sources-2"><i class="fa fa-check"></i><b>44.0.1</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="bayesian-inference.html"><a href="bayesian-inference.html"><i class="fa fa-check"></i><b>45</b> Bayesian inference</a>
<ul>
<li class="chapter" data-level="45.1" data-path="bayesian-inference.html"><a href="bayesian-inference.html#simple-model-with-one-binary-parameter"><i class="fa fa-check"></i><b>45.1</b> Simple model with one binary parameter</a></li>
<li class="chapter" data-level="45.2" data-path="bayesian-inference.html"><a href="bayesian-inference.html#grid-approximation"><i class="fa fa-check"></i><b>45.2</b> Grid approximation</a></li>
<li class="chapter" data-level="45.3" data-path="bayesian-inference.html"><a href="bayesian-inference.html#grid-approximation-1"><i class="fa fa-check"></i><b>45.3</b> Grid approximation</a></li>
<li class="chapter" data-level="45.4" data-path="bayesian-inference.html"><a href="bayesian-inference.html#model-of-birth-weights-using-normal-distribution"><i class="fa fa-check"></i><b>45.4</b> Model of birth weights using normal distribution</a></li>
<li class="chapter" data-level="45.5" data-path="bayesian-inference.html"><a href="bayesian-inference.html#a-bayesian-model-of-zombie-iq"><i class="fa fa-check"></i><b>45.5</b> A Bayesian model of Zombie IQ</a></li>
<li class="chapter" data-level="45.6" data-path="bayesian-inference.html"><a href="bayesian-inference.html#the-best-models"><i class="fa fa-check"></i><b>45.6</b> The BEST models</a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="naive-bayes-classifiers.html"><a href="naive-bayes-classifiers.html"><i class="fa fa-check"></i><b>46</b> Naive Bayes classifiers</a></li>
<li class="chapter" data-level="47" data-path="modeling-with-r-caret.html"><a href="modeling-with-r-caret.html"><i class="fa fa-check"></i><b>47</b> Modeling with R caret</a></li>
<li class="chapter" data-level="48" data-path="modeling-with-r-tensorflow.html"><a href="modeling-with-r-tensorflow.html"><i class="fa fa-check"></i><b>48</b> Modeling with R Tensorflow</a></li>
<li class="chapter" data-level="49" data-path="perceptron.html"><a href="perceptron.html"><i class="fa fa-check"></i><b>49</b> Perceptron</a></li>
<li class="chapter" data-level="50" data-path="deeplearning-r-h2o.html"><a href="deeplearning-r-h2o.html"><i class="fa fa-check"></i><b>50</b> Deeplearning R H2O</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonlinear-regression" class="section level1" number="28">
<h1><span class="header-section-number">Chapter 28</span> Nonlinear regression</h1>
<p>Nonlinear regression is a form of regression analysis in which observational data are modeled by a function which is a nonlinear combination of the model parameters and <strong>depends on one or more independent variables</strong>.<br />
Some nonlinear data sets can be transformed to a linear model.<br />
Sone can not be transformed. For such modeling methods of Numerical analysis should be applied such as Newton’s method, Gauss-Newton method and Levenberg–Marquardt method.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="nonlinear-regression.html#cb200-1" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb200-2"><a href="nonlinear-regression.html#cb200-2" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">7</span></span>
<span id="cb200-3"><a href="nonlinear-regression.html#cb200-3" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb200-4"><a href="nonlinear-regression.html#cb200-4" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb200-5"><a href="nonlinear-regression.html#cb200-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb200-6"><a href="nonlinear-regression.html#cb200-6" aria-hidden="true" tabindex="-1"></a>    оценивать полиномиальную регрессию;</span>
<span id="cb200-7"><a href="nonlinear-regression.html#cb200-7" aria-hidden="true" tabindex="-1"></a>аппроксимировать нелинейные модели ступенчатыми функциями;</span>
<span id="cb200-8"><a href="nonlinear-regression.html#cb200-8" aria-hidden="true" tabindex="-1"></a>строить сплайны;</span>
<span id="cb200-9"><a href="nonlinear-regression.html#cb200-9" aria-hidden="true" tabindex="-1"></a>работать с локальной регрессией;</span>
<span id="cb200-10"><a href="nonlinear-regression.html#cb200-10" aria-hidden="true" tabindex="-1"></a>строить обобщённые линейные модели (GAM).</span>
<span id="cb200-11"><a href="nonlinear-regression.html#cb200-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> полиномиальная регрессия, полиномиальная логистическая регрессия, ступенчатая модель, обобщённая линейная модель.</span>
<span id="cb200-12"><a href="nonlinear-regression.html#cb200-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Wage {ISLR}</span>
<span id="cb200-13"><a href="nonlinear-regression.html#cb200-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-14"><a href="nonlinear-regression.html#cb200-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">7.</span></span>
<span id="cb200-15"><a href="nonlinear-regression.html#cb200-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-16"><a href="nonlinear-regression.html#cb200-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># набор данных Auto</span></span>
<span id="cb200-17"><a href="nonlinear-regression.html#cb200-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;splines&#39;</span>)           <span class="co"># сплайны</span></span>
<span id="cb200-18"><a href="nonlinear-regression.html#cb200-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gam&#39;</span>)               <span class="co"># обобщённые аддитивные модели</span></span>
<span id="cb200-19"><a href="nonlinear-regression.html#cb200-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gam&#39; was built under R version 3.3.3</span></span>
<span id="cb200-20"><a href="nonlinear-regression.html#cb200-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: foreach</span></span>
<span id="cb200-21"><a href="nonlinear-regression.html#cb200-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;foreach&#39; was built under R version 3.3.3</span></span>
<span id="cb200-22"><a href="nonlinear-regression.html#cb200-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gam 1.14</span></span>
<span id="cb200-23"><a href="nonlinear-regression.html#cb200-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;akima&#39;</span>)             <span class="co"># график двумерной плоскости</span></span>
<span id="cb200-24"><a href="nonlinear-regression.html#cb200-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;akima&#39; was built under R version 3.3.3</span></span>
<span id="cb200-25"><a href="nonlinear-regression.html#cb200-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ggplot2&#39;</span>)           <span class="co"># красивые графики</span></span>
<span id="cb200-26"><a href="nonlinear-regression.html#cb200-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;ggplot2&#39; was built under R version 3.3.3</span></span>
<span id="cb200-27"><a href="nonlinear-regression.html#cb200-27" aria-hidden="true" tabindex="-1"></a>my.seed <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb200-28"><a href="nonlinear-regression.html#cb200-28" aria-hidden="true" tabindex="-1"></a>Работаем с набором данных по зарплатам <span class="dv">3000</span> работников<span class="sc">-</span>мужчин среднеатлантического региона Wage. Присоединяем его к пространству имён функцией <span class="fu">attach</span>(), и дальше обращаемся напрямую к столбцам таблицы.</span>
<span id="cb200-29"><a href="nonlinear-regression.html#cb200-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-30"><a href="nonlinear-regression.html#cb200-30" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Wage)</span>
<span id="cb200-31"><a href="nonlinear-regression.html#cb200-31" aria-hidden="true" tabindex="-1"></a>Работаем со столбцами<span class="sc">:</span></span>
<span id="cb200-32"><a href="nonlinear-regression.html#cb200-32" aria-hidden="true" tabindex="-1"></a>    <span class="er">*</span> wage – заработная плата работника до уплаты налогов;</span>
<span id="cb200-33"><a href="nonlinear-regression.html#cb200-33" aria-hidden="true" tabindex="-1"></a><span class="sc">*</span> age – возраст работника в годах.</span>
<span id="cb200-34"><a href="nonlinear-regression.html#cb200-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-35"><a href="nonlinear-regression.html#cb200-35" aria-hidden="true" tabindex="-1"></a>Полиномиальная регрессия</span>
<span id="cb200-36"><a href="nonlinear-regression.html#cb200-36" aria-hidden="true" tabindex="-1"></a>Зависимость зарплаты от возраста</span>
<span id="cb200-37"><a href="nonlinear-regression.html#cb200-37" aria-hidden="true" tabindex="-1"></a>Судя по графику ниже, ззаимосвязь заработной платы и возраста нелинейна. Наблюдается также группа наблюдений с высоким значением wage, граница проходит примерно на уровне <span class="fl">250.</span></span>
<span id="cb200-38"><a href="nonlinear-regression.html#cb200-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-39"><a href="nonlinear-regression.html#cb200-39" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> Wage, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> wage))</span>
<span id="cb200-40"><a href="nonlinear-regression.html#cb200-40" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> gp <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">0</span>, <span class="at">intercept =</span> <span class="dv">250</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb200-41"><a href="nonlinear-regression.html#cb200-41" aria-hidden="true" tabindex="-1"></a>gp</span>
<span id="cb200-42"><a href="nonlinear-regression.html#cb200-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-43"><a href="nonlinear-regression.html#cb200-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-44"><a href="nonlinear-regression.html#cb200-44" aria-hidden="true" tabindex="-1"></a>Подгоняем полином четвёртой степени для зависимости заработной платы от возраста.</span>
<span id="cb200-45"><a href="nonlinear-regression.html#cb200-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-46"><a href="nonlinear-regression.html#cb200-46" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb200-47"><a href="nonlinear-regression.html#cb200-47" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb200-48"><a href="nonlinear-regression.html#cb200-48" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb200-49"><a href="nonlinear-regression.html#cb200-49" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)     111.70       0.73  153.28     0.00</span></span>
<span id="cb200-50"><a href="nonlinear-regression.html#cb200-50" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)1   447.07      39.91   11.20     0.00</span></span>
<span id="cb200-51"><a href="nonlinear-regression.html#cb200-51" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)2  -478.32      39.91  -11.98     0.00</span></span>
<span id="cb200-52"><a href="nonlinear-regression.html#cb200-52" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)3   125.52      39.91    3.14     0.00</span></span>
<span id="cb200-53"><a href="nonlinear-regression.html#cb200-53" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)4   -77.91      39.91   -1.95     0.05</span></span>
<span id="cb200-54"><a href="nonlinear-regression.html#cb200-54" aria-hidden="true" tabindex="-1"></a>Функция <span class="fu">poly</span>(age, <span class="dv">4</span>) создаёт таблицу с базисом ортогональных полиномов<span class="sc">:</span> линейные комбинации значений переменной age в степенях от <span class="dv">1</span> до <span class="fl">4.</span></span>
<span id="cb200-55"><a href="nonlinear-regression.html#cb200-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-56"><a href="nonlinear-regression.html#cb200-56" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>)), <span class="dv">3</span>)</span>
<span id="cb200-57"><a href="nonlinear-regression.html#cb200-57" aria-hidden="true" tabindex="-1"></a><span class="do">##           1      2      3      4</span></span>
<span id="cb200-58"><a href="nonlinear-regression.html#cb200-58" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] -0.039  0.056 -0.072  0.087</span></span>
<span id="cb200-59"><a href="nonlinear-regression.html#cb200-59" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] -0.029  0.026 -0.015 -0.003</span></span>
<span id="cb200-60"><a href="nonlinear-regression.html#cb200-60" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,]  0.004 -0.015  0.000  0.014</span></span>
<span id="cb200-61"><a href="nonlinear-regression.html#cb200-61" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,]  0.001 -0.015  0.005  0.013</span></span>
<span id="cb200-62"><a href="nonlinear-regression.html#cb200-62" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,]  0.012 -0.010 -0.011  0.010</span></span>
<span id="cb200-63"><a href="nonlinear-regression.html#cb200-63" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,]  0.018 -0.002 -0.017 -0.001</span></span>
<span id="cb200-64"><a href="nonlinear-regression.html#cb200-64" aria-hidden="true" tabindex="-1"></a><span class="co"># можно получить сами значения age в заданных степенях</span></span>
<span id="cb200-65"><a href="nonlinear-regression.html#cb200-65" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T)), <span class="dv">3</span>)</span>
<span id="cb200-66"><a href="nonlinear-regression.html#cb200-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       1    2      3       4</span></span>
<span id="cb200-67"><a href="nonlinear-regression.html#cb200-67" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] 18  324   5832  104976</span></span>
<span id="cb200-68"><a href="nonlinear-regression.html#cb200-68" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] 24  576  13824  331776</span></span>
<span id="cb200-69"><a href="nonlinear-regression.html#cb200-69" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,] 45 2025  91125 4100625</span></span>
<span id="cb200-70"><a href="nonlinear-regression.html#cb200-70" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,] 43 1849  79507 3418801</span></span>
<span id="cb200-71"><a href="nonlinear-regression.html#cb200-71" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,] 50 2500 125000 6250000</span></span>
<span id="cb200-72"><a href="nonlinear-regression.html#cb200-72" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,] 54 2916 157464 8503056</span></span>
<span id="cb200-73"><a href="nonlinear-regression.html#cb200-73" aria-hidden="true" tabindex="-1"></a><span class="co"># на прогноз не повлияет, но оценки параметров изменяются</span></span>
<span id="cb200-74"><a href="nonlinear-regression.html#cb200-74" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T), <span class="at">data =</span> Wage)</span>
<span id="cb200-75"><a href="nonlinear-regression.html#cb200-75" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit<span class="fl">.2</span>)), <span class="dv">2</span>)</span>
<span id="cb200-76"><a href="nonlinear-regression.html#cb200-76" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb200-77"><a href="nonlinear-regression.html#cb200-77" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)             -184.15      60.04   -3.07     0.00</span></span>
<span id="cb200-78"><a href="nonlinear-regression.html#cb200-78" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)1    21.25       5.89    3.61     0.00</span></span>
<span id="cb200-79"><a href="nonlinear-regression.html#cb200-79" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)2    -0.56       0.21   -2.74     0.01</span></span>
<span id="cb200-80"><a href="nonlinear-regression.html#cb200-80" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)3     0.01       0.00    2.22     0.03</span></span>
<span id="cb200-81"><a href="nonlinear-regression.html#cb200-81" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)4     0.00       0.00   -1.95     0.05</span></span>
<span id="cb200-82"><a href="nonlinear-regression.html#cb200-82" aria-hidden="true" tabindex="-1"></a><span class="co"># границы изменения переменной age</span></span>
<span id="cb200-83"><a href="nonlinear-regression.html#cb200-83" aria-hidden="true" tabindex="-1"></a>agelims <span class="ot">&lt;-</span> <span class="fu">range</span>(age)</span>
<span id="cb200-84"><a href="nonlinear-regression.html#cb200-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-85"><a href="nonlinear-regression.html#cb200-85" aria-hidden="true" tabindex="-1"></a><span class="co"># значения age, для которых делаем прогноз (от min до max с шагом 1)</span></span>
<span id="cb200-86"><a href="nonlinear-regression.html#cb200-86" aria-hidden="true" tabindex="-1"></a>age.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> agelims[<span class="dv">1</span>], <span class="at">to =</span> agelims[<span class="dv">2</span>])</span>
<span id="cb200-87"><a href="nonlinear-regression.html#cb200-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-88"><a href="nonlinear-regression.html#cb200-88" aria-hidden="true" tabindex="-1"></a><span class="co"># рассчитать прогнозы и их стандартные ошибки</span></span>
<span id="cb200-89"><a href="nonlinear-regression.html#cb200-89" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb200-90"><a href="nonlinear-regression.html#cb200-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-91"><a href="nonlinear-regression.html#cb200-91" aria-hidden="true" tabindex="-1"></a><span class="co"># границы доверительного интервала для заработной платы</span></span>
<span id="cb200-92"><a href="nonlinear-regression.html#cb200-92" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb200-93"><a href="nonlinear-regression.html#cb200-93" aria-hidden="true" tabindex="-1"></a>                  <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb200-94"><a href="nonlinear-regression.html#cb200-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-95"><a href="nonlinear-regression.html#cb200-95" aria-hidden="true" tabindex="-1"></a><span class="co"># смотрим результат</span></span>
<span id="cb200-96"><a href="nonlinear-regression.html#cb200-96" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">2</span>)</span>
<span id="cb200-97"><a href="nonlinear-regression.html#cb200-97" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb200-98"><a href="nonlinear-regression.html#cb200-98" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       41.33       62.53</span></span>
<span id="cb200-99"><a href="nonlinear-regression.html#cb200-99" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       49.76       67.24</span></span>
<span id="cb200-100"><a href="nonlinear-regression.html#cb200-100" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       57.39       71.76</span></span>
<span id="cb200-101"><a href="nonlinear-regression.html#cb200-101" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       64.27       76.09</span></span>
<span id="cb200-102"><a href="nonlinear-regression.html#cb200-102" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       70.44       80.27</span></span>
<span id="cb200-103"><a href="nonlinear-regression.html#cb200-103" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       75.94       84.28</span></span>
<span id="cb200-104"><a href="nonlinear-regression.html#cb200-104" aria-hidden="true" tabindex="-1"></a>Рисуем левую панель графика со слайда <span class="dv">4</span> презентации (рис. <span class="fl">7.1</span> книги). Функция <span class="fu">matlines</span>() рисует грфик столбцов одной матрицы против столбцов другой.</span>
<span id="cb200-105"><a href="nonlinear-regression.html#cb200-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-106"><a href="nonlinear-regression.html#cb200-106" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb200-107"><a href="nonlinear-regression.html#cb200-107" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb200-108"><a href="nonlinear-regression.html#cb200-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-109"><a href="nonlinear-regression.html#cb200-109" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb200-110"><a href="nonlinear-regression.html#cb200-110" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb200-111"><a href="nonlinear-regression.html#cb200-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-112"><a href="nonlinear-regression.html#cb200-112" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb200-113"><a href="nonlinear-regression.html#cb200-113" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb200-114"><a href="nonlinear-regression.html#cb200-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-115"><a href="nonlinear-regression.html#cb200-115" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb200-116"><a href="nonlinear-regression.html#cb200-116" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb200-117"><a href="nonlinear-regression.html#cb200-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-118"><a href="nonlinear-regression.html#cb200-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-119"><a href="nonlinear-regression.html#cb200-119" aria-hidden="true" tabindex="-1"></a>Убедимся, что прогнозы по моделям с различными вызовами <span class="fu">poly</span>() совпадают.</span>
<span id="cb200-120"><a href="nonlinear-regression.html#cb200-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-121"><a href="nonlinear-regression.html#cb200-121" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы по второму вызову модели</span></span>
<span id="cb200-122"><a href="nonlinear-regression.html#cb200-122" aria-hidden="true" tabindex="-1"></a>preds2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit<span class="fl">.2</span>, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb200-123"><a href="nonlinear-regression.html#cb200-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-124"><a href="nonlinear-regression.html#cb200-124" aria-hidden="true" tabindex="-1"></a><span class="co"># максимальное расхождение между прогнозами по двум вариантам вызова модели</span></span>
<span id="cb200-125"><a href="nonlinear-regression.html#cb200-125" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(preds<span class="sc">$</span>fit <span class="sc">-</span> preds2<span class="sc">$</span>fit))</span>
<span id="cb200-126"><a href="nonlinear-regression.html#cb200-126" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 7.389644e-13</span></span>
<span id="cb200-127"><a href="nonlinear-regression.html#cb200-127" aria-hidden="true" tabindex="-1"></a>Теперь подбираем степень полинома, сравнивая модели со степенями от <span class="dv">1</span> до <span class="dv">5</span> с помощью дисперсионного анализа (ANOVA).</span>
<span id="cb200-128"><a href="nonlinear-regression.html#cb200-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-129"><a href="nonlinear-regression.html#cb200-129" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> age, <span class="at">data =</span> Wage)</span>
<span id="cb200-130"><a href="nonlinear-regression.html#cb200-130" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">2</span>), <span class="at">data =</span> Wage)</span>
<span id="cb200-131"><a href="nonlinear-regression.html#cb200-131" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">3</span>), <span class="at">data =</span> Wage)</span>
<span id="cb200-132"><a href="nonlinear-regression.html#cb200-132" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb200-133"><a href="nonlinear-regression.html#cb200-133" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">5</span>), <span class="at">data =</span> Wage)</span>
<span id="cb200-134"><a href="nonlinear-regression.html#cb200-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-135"><a href="nonlinear-regression.html#cb200-135" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">anova</span>(fit<span class="fl">.1</span>, fit<span class="fl">.2</span>, fit<span class="fl">.3</span>, fit<span class="fl">.4</span>, fit<span class="fl">.5</span>), <span class="dv">2</span>)</span>
<span id="cb200-136"><a href="nonlinear-regression.html#cb200-136" aria-hidden="true" tabindex="-1"></a>Res.Df</span>
<span id="cb200-137"><a href="nonlinear-regression.html#cb200-137" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-138"><a href="nonlinear-regression.html#cb200-138" aria-hidden="true" tabindex="-1"></a>    RSS</span>
<span id="cb200-139"><a href="nonlinear-regression.html#cb200-139" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-140"><a href="nonlinear-regression.html#cb200-140" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb200-141"><a href="nonlinear-regression.html#cb200-141" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-142"><a href="nonlinear-regression.html#cb200-142" aria-hidden="true" tabindex="-1"></a>    Sum of Sq</span>
<span id="cb200-143"><a href="nonlinear-regression.html#cb200-143" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-144"><a href="nonlinear-regression.html#cb200-144" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb200-145"><a href="nonlinear-regression.html#cb200-145" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-146"><a href="nonlinear-regression.html#cb200-146" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb200-147"><a href="nonlinear-regression.html#cb200-147" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-148"><a href="nonlinear-regression.html#cb200-148" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2998</span>    <span class="dv">5022216</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb200-149"><a href="nonlinear-regression.html#cb200-149" aria-hidden="true" tabindex="-1"></a><span class="dv">2997</span>    <span class="dv">4793430</span> <span class="dv">1</span>   <span class="fl">228786.01</span>   <span class="fl">143.59</span>  <span class="fl">0.00</span></span>
<span id="cb200-150"><a href="nonlinear-regression.html#cb200-150" aria-hidden="true" tabindex="-1"></a><span class="dv">2996</span>    <span class="dv">4777674</span> <span class="dv">1</span>   <span class="fl">15755.69</span>    <span class="fl">9.89</span>    <span class="fl">0.00</span></span>
<span id="cb200-151"><a href="nonlinear-regression.html#cb200-151" aria-hidden="true" tabindex="-1"></a><span class="dv">2995</span>    <span class="dv">4771604</span> <span class="dv">1</span>   <span class="fl">6070.15</span> <span class="fl">3.81</span>    <span class="fl">0.05</span></span>
<span id="cb200-152"><a href="nonlinear-regression.html#cb200-152" aria-hidden="true" tabindex="-1"></a><span class="dv">2994</span>    <span class="dv">4770322</span> <span class="dv">1</span>   <span class="fl">1282.56</span> <span class="fl">0.80</span>    <span class="fl">0.37</span></span>
<span id="cb200-153"><a href="nonlinear-regression.html#cb200-153" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> rows</span>
<span id="cb200-154"><a href="nonlinear-regression.html#cb200-154" aria-hidden="true" tabindex="-1"></a>Рассматриваются пять моделей, в которых степени полинома от age идут по возрастанию. В крайнем правом столбце таблице приводятся p<span class="sc">-</span>значения для проверки нулевой гипотезы<span class="sc">:</span> текущая модель не даёт статистически значимого сокращения RSS по сравнению с предыдущей моделью. Можно сделать вывод, что степени <span class="dv">3</span> достаточно, дальнейшее увеличение степени не даёт значимого улучшения качества модели.</span>
<span id="cb200-155"><a href="nonlinear-regression.html#cb200-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-156"><a href="nonlinear-regression.html#cb200-156" aria-hidden="true" tabindex="-1"></a>Зависимость вероятности получать зарплату <span class="sc">&gt;</span> <span class="dv">250</span> от возраста</span>
<span id="cb200-157"><a href="nonlinear-regression.html#cb200-157" aria-hidden="true" tabindex="-1"></a>Теперь вернёмся к группе наблюдений с высоким wage. Рассмотрим зависимость вероятности того, что величина зарплаты больше <span class="dv">250</span>, от возраста.</span>
<span id="cb200-158"><a href="nonlinear-regression.html#cb200-158" aria-hidden="true" tabindex="-1"></a>Подгоняем логистическую регрессию и делаем прогнозы, для этого используем функцию для оценки обобщённой линейной модели  <span class="fu">glm</span>() и указываем тип модели binomial<span class="sc">:</span></span>
<span id="cb200-159"><a href="nonlinear-regression.html#cb200-159" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb200-160"><a href="nonlinear-regression.html#cb200-160" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb200-161"><a href="nonlinear-regression.html#cb200-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-162"><a href="nonlinear-regression.html#cb200-162" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb200-163"><a href="nonlinear-regression.html#cb200-163" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb200-164"><a href="nonlinear-regression.html#cb200-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-165"><a href="nonlinear-regression.html#cb200-165" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb200-166"><a href="nonlinear-regression.html#cb200-166" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb200-167"><a href="nonlinear-regression.html#cb200-167" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb200-168"><a href="nonlinear-regression.html#cb200-168" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb200-169"><a href="nonlinear-regression.html#cb200-169" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb200-170"><a href="nonlinear-regression.html#cb200-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-171"><a href="nonlinear-regression.html#cb200-171" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb200-172"><a href="nonlinear-regression.html#cb200-172" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb200-173"><a href="nonlinear-regression.html#cb200-173" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb200-174"><a href="nonlinear-regression.html#cb200-174" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb200-175"><a href="nonlinear-regression.html#cb200-175" aria-hidden="true" tabindex="-1"></a><span class="do">## 1           0       0.002</span></span>
<span id="cb200-176"><a href="nonlinear-regression.html#cb200-176" aria-hidden="true" tabindex="-1"></a><span class="do">## 2           0       0.003</span></span>
<span id="cb200-177"><a href="nonlinear-regression.html#cb200-177" aria-hidden="true" tabindex="-1"></a><span class="do">## 3           0       0.004</span></span>
<span id="cb200-178"><a href="nonlinear-regression.html#cb200-178" aria-hidden="true" tabindex="-1"></a><span class="do">## 4           0       0.005</span></span>
<span id="cb200-179"><a href="nonlinear-regression.html#cb200-179" aria-hidden="true" tabindex="-1"></a><span class="do">## 5           0       0.006</span></span>
<span id="cb200-180"><a href="nonlinear-regression.html#cb200-180" aria-hidden="true" tabindex="-1"></a><span class="do">## 6           0       0.007</span></span>
<span id="cb200-181"><a href="nonlinear-regression.html#cb200-181" aria-hidden="true" tabindex="-1"></a>Достраиваем график с <span class="dv">4</span> слайда презентации (рис. <span class="fl">7.1</span> книги). Рисуем правую панель.</span>
<span id="cb200-182"><a href="nonlinear-regression.html#cb200-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-183"><a href="nonlinear-regression.html#cb200-183" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb200-184"><a href="nonlinear-regression.html#cb200-184" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb200-185"><a href="nonlinear-regression.html#cb200-185" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb200-186"><a href="nonlinear-regression.html#cb200-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-187"><a href="nonlinear-regression.html#cb200-187" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb200-188"><a href="nonlinear-regression.html#cb200-188" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb200-189"><a href="nonlinear-regression.html#cb200-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-190"><a href="nonlinear-regression.html#cb200-190" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb200-191"><a href="nonlinear-regression.html#cb200-191" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb200-192"><a href="nonlinear-regression.html#cb200-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-193"><a href="nonlinear-regression.html#cb200-193" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb200-194"><a href="nonlinear-regression.html#cb200-194" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb200-195"><a href="nonlinear-regression.html#cb200-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-196"><a href="nonlinear-regression.html#cb200-196" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb200-197"><a href="nonlinear-regression.html#cb200-197" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb200-198"><a href="nonlinear-regression.html#cb200-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-199"><a href="nonlinear-regression.html#cb200-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-200"><a href="nonlinear-regression.html#cb200-200" aria-hidden="true" tabindex="-1"></a>Ступенчатые функции</span>
<span id="cb200-201"><a href="nonlinear-regression.html#cb200-201" aria-hidden="true" tabindex="-1"></a>Для начала определим несколько интервалов, на каждом из которых будем моделировать зависимость wage от age своим средним уровнем.</span>
<span id="cb200-202"><a href="nonlinear-regression.html#cb200-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-203"><a href="nonlinear-regression.html#cb200-203" aria-hidden="true" tabindex="-1"></a><span class="co"># нарезаем предиктор age на 4 равных интервала</span></span>
<span id="cb200-204"><a href="nonlinear-regression.html#cb200-204" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">cut</span>(age, <span class="dv">4</span>))</span>
<span id="cb200-205"><a href="nonlinear-regression.html#cb200-205" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb200-206"><a href="nonlinear-regression.html#cb200-206" aria-hidden="true" tabindex="-1"></a><span class="do">## (17.9,33.5]   (33.5,49]   (49,64.5] (64.5,80.1] </span></span>
<span id="cb200-207"><a href="nonlinear-regression.html#cb200-207" aria-hidden="true" tabindex="-1"></a><span class="do">##         750        1399         779          72</span></span>
<span id="cb200-208"><a href="nonlinear-regression.html#cb200-208" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем линейную модель на интервалах</span></span>
<span id="cb200-209"><a href="nonlinear-regression.html#cb200-209" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb200-210"><a href="nonlinear-regression.html#cb200-210" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb200-211"><a href="nonlinear-regression.html#cb200-211" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb200-212"><a href="nonlinear-regression.html#cb200-212" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)               94.16       1.48   63.79     0.00</span></span>
<span id="cb200-213"><a href="nonlinear-regression.html#cb200-213" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(33.5,49]      24.05       1.83   13.15     0.00</span></span>
<span id="cb200-214"><a href="nonlinear-regression.html#cb200-214" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(49,64.5]      23.66       2.07   11.44     0.00</span></span>
<span id="cb200-215"><a href="nonlinear-regression.html#cb200-215" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(64.5,80.1]     7.64       4.99    1.53     0.13</span></span>
<span id="cb200-216"><a href="nonlinear-regression.html#cb200-216" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз -- это средние по `wage` на каждом интервале</span></span>
<span id="cb200-217"><a href="nonlinear-regression.html#cb200-217" aria-hidden="true" tabindex="-1"></a>preds.cut <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb200-218"><a href="nonlinear-regression.html#cb200-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-219"><a href="nonlinear-regression.html#cb200-219" aria-hidden="true" tabindex="-1"></a><span class="co"># интервальный прогноз</span></span>
<span id="cb200-220"><a href="nonlinear-regression.html#cb200-220" aria-hidden="true" tabindex="-1"></a>se.bands.cut <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit,</span>
<span id="cb200-221"><a href="nonlinear-regression.html#cb200-221" aria-hidden="true" tabindex="-1"></a>                      <span class="at">upper.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit)</span>
<span id="cb200-222"><a href="nonlinear-regression.html#cb200-222" aria-hidden="true" tabindex="-1"></a>Воспроизведём график со слайда <span class="dv">7</span> презентации (рис. <span class="fl">7.2</span> книги).</span>
<span id="cb200-223"><a href="nonlinear-regression.html#cb200-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-224"><a href="nonlinear-regression.html#cb200-224" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb200-225"><a href="nonlinear-regression.html#cb200-225" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb200-226"><a href="nonlinear-regression.html#cb200-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-227"><a href="nonlinear-regression.html#cb200-227" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb200-228"><a href="nonlinear-regression.html#cb200-228" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.cut<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb200-229"><a href="nonlinear-regression.html#cb200-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-230"><a href="nonlinear-regression.html#cb200-230" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb200-231"><a href="nonlinear-regression.html#cb200-231" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands.cut, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb200-232"><a href="nonlinear-regression.html#cb200-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-233"><a href="nonlinear-regression.html#cb200-233" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb200-234"><a href="nonlinear-regression.html#cb200-234" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb200-235"><a href="nonlinear-regression.html#cb200-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-236"><a href="nonlinear-regression.html#cb200-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-237"><a href="nonlinear-regression.html#cb200-237" aria-hidden="true" tabindex="-1"></a>Правая часть графика, для вероятности того, что зарплата выше <span class="fl">250.</span></span>
<span id="cb200-238"><a href="nonlinear-regression.html#cb200-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-239"><a href="nonlinear-regression.html#cb200-239" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb200-240"><a href="nonlinear-regression.html#cb200-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-241"><a href="nonlinear-regression.html#cb200-241" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb200-242"><a href="nonlinear-regression.html#cb200-242" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb200-243"><a href="nonlinear-regression.html#cb200-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-244"><a href="nonlinear-regression.html#cb200-244" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb200-245"><a href="nonlinear-regression.html#cb200-245" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb200-246"><a href="nonlinear-regression.html#cb200-246" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb200-247"><a href="nonlinear-regression.html#cb200-247" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb200-248"><a href="nonlinear-regression.html#cb200-248" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb200-249"><a href="nonlinear-regression.html#cb200-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-250"><a href="nonlinear-regression.html#cb200-250" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb200-251"><a href="nonlinear-regression.html#cb200-251" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb200-252"><a href="nonlinear-regression.html#cb200-252" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb200-253"><a href="nonlinear-regression.html#cb200-253" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb200-254"><a href="nonlinear-regression.html#cb200-254" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       0.003       0.016</span></span>
<span id="cb200-255"><a href="nonlinear-regression.html#cb200-255" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       0.003       0.016</span></span>
<span id="cb200-256"><a href="nonlinear-regression.html#cb200-256" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       0.003       0.016</span></span>
<span id="cb200-257"><a href="nonlinear-regression.html#cb200-257" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       0.003       0.016</span></span>
<span id="cb200-258"><a href="nonlinear-regression.html#cb200-258" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       0.003       0.016</span></span>
<span id="cb200-259"><a href="nonlinear-regression.html#cb200-259" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       0.003       0.016</span></span>
<span id="cb200-260"><a href="nonlinear-regression.html#cb200-260" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb200-261"><a href="nonlinear-regression.html#cb200-261" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb200-262"><a href="nonlinear-regression.html#cb200-262" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb200-263"><a href="nonlinear-regression.html#cb200-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-264"><a href="nonlinear-regression.html#cb200-264" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb200-265"><a href="nonlinear-regression.html#cb200-265" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb200-266"><a href="nonlinear-regression.html#cb200-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-267"><a href="nonlinear-regression.html#cb200-267" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb200-268"><a href="nonlinear-regression.html#cb200-268" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb200-269"><a href="nonlinear-regression.html#cb200-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-270"><a href="nonlinear-regression.html#cb200-270" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb200-271"><a href="nonlinear-regression.html#cb200-271" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb200-272"><a href="nonlinear-regression.html#cb200-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-273"><a href="nonlinear-regression.html#cb200-273" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb200-274"><a href="nonlinear-regression.html#cb200-274" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb200-275"><a href="nonlinear-regression.html#cb200-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-276"><a href="nonlinear-regression.html#cb200-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-277"><a href="nonlinear-regression.html#cb200-277" aria-hidden="true" tabindex="-1"></a>Сплайны</span>
<span id="cb200-278"><a href="nonlinear-regression.html#cb200-278" aria-hidden="true" tabindex="-1"></a>Построим кубический сплайн с тремя узлами.</span>
<span id="cb200-279"><a href="nonlinear-regression.html#cb200-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-280"><a href="nonlinear-regression.html#cb200-280" aria-hidden="true" tabindex="-1"></a><span class="co"># кубический сплайн с тремя узлами</span></span>
<span id="cb200-281"><a href="nonlinear-regression.html#cb200-281" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)), <span class="at">data =</span> Wage)</span>
<span id="cb200-282"><a href="nonlinear-regression.html#cb200-282" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb200-283"><a href="nonlinear-regression.html#cb200-283" aria-hidden="true" tabindex="-1"></a>preds.spl <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb200-284"><a href="nonlinear-regression.html#cb200-284" aria-hidden="true" tabindex="-1"></a>Теперь построим натуральный по трём узлам. Три узла это <span class="dv">6</span> степеней свободы. Если функции <span class="fu">bs</span>(), которая создаёт матрицу с базисом для полиномиального сплайна, передать только степени свободы, она распределит узлы равномерно. В данном случае это квартили распределения age.</span>
<span id="cb200-285"><a href="nonlinear-regression.html#cb200-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-286"><a href="nonlinear-regression.html#cb200-286" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 узла -- 6 степеней свободы (столбцы матрицы)</span></span>
<span id="cb200-287"><a href="nonlinear-regression.html#cb200-287" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)))</span>
<span id="cb200-288"><a href="nonlinear-regression.html#cb200-288" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb200-289"><a href="nonlinear-regression.html#cb200-289" aria-hidden="true" tabindex="-1"></a><span class="co"># если не указываем узлы явно...</span></span>
<span id="cb200-290"><a href="nonlinear-regression.html#cb200-290" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>))</span>
<span id="cb200-291"><a href="nonlinear-regression.html#cb200-291" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb200-292"><a href="nonlinear-regression.html#cb200-292" aria-hidden="true" tabindex="-1"></a><span class="co">#  они привязываются к квартилям</span></span>
<span id="cb200-293"><a href="nonlinear-regression.html#cb200-293" aria-hidden="true" tabindex="-1"></a><span class="fu">attr</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>), <span class="st">&#39;knots&#39;</span>)</span>
<span id="cb200-294"><a href="nonlinear-regression.html#cb200-294" aria-hidden="true" tabindex="-1"></a><span class="do">##   25%   50%   75% </span></span>
<span id="cb200-295"><a href="nonlinear-regression.html#cb200-295" aria-hidden="true" tabindex="-1"></a><span class="do">## 33.75 42.00 51.00</span></span>
<span id="cb200-296"><a href="nonlinear-regression.html#cb200-296" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb200-297"><a href="nonlinear-regression.html#cb200-297" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(age, <span class="at">df =</span> <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb200-298"><a href="nonlinear-regression.html#cb200-298" aria-hidden="true" tabindex="-1"></a>preds.spl2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit2, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb200-299"><a href="nonlinear-regression.html#cb200-299" aria-hidden="true" tabindex="-1"></a>График сравнения кубического и натурального сплайнов.</span>
<span id="cb200-300"><a href="nonlinear-regression.html#cb200-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-301"><a href="nonlinear-regression.html#cb200-301" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="fl">8.5</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="at">xpd =</span> T)</span>
<span id="cb200-302"><a href="nonlinear-regression.html#cb200-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-303"><a href="nonlinear-regression.html#cb200-303" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb200-304"><a href="nonlinear-regression.html#cb200-304" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">col =</span> <span class="st">&#39;grey&#39;</span>)</span>
<span id="cb200-305"><a href="nonlinear-regression.html#cb200-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-306"><a href="nonlinear-regression.html#cb200-306" aria-hidden="true" tabindex="-1"></a><span class="co"># модель кубического сплайна</span></span>
<span id="cb200-307"><a href="nonlinear-regression.html#cb200-307" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb200-308"><a href="nonlinear-regression.html#cb200-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-309"><a href="nonlinear-regression.html#cb200-309" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительный интервал</span></span>
<span id="cb200-310"><a href="nonlinear-regression.html#cb200-310" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb200-311"><a href="nonlinear-regression.html#cb200-311" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb200-312"><a href="nonlinear-regression.html#cb200-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-313"><a href="nonlinear-regression.html#cb200-313" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb200-314"><a href="nonlinear-regression.html#cb200-314" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl2<span class="sc">$</span>fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb200-315"><a href="nonlinear-regression.html#cb200-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-316"><a href="nonlinear-regression.html#cb200-316" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb200-317"><a href="nonlinear-regression.html#cb200-317" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">inset =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.7</span>, <span class="dv">0</span>),</span>
<span id="cb200-318"><a href="nonlinear-regression.html#cb200-318" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;Кубический </span><span class="sc">\n</span><span class="st"> с 3 узлами&#39;</span>, <span class="st">&#39;Натуральный&#39;</span>),</span>
<span id="cb200-319"><a href="nonlinear-regression.html#cb200-319" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="fu">rep</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;red&#39;</span>))</span>
<span id="cb200-320"><a href="nonlinear-regression.html#cb200-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-321"><a href="nonlinear-regression.html#cb200-321" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb200-322"><a href="nonlinear-regression.html#cb200-322" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Сплайны&quot;</span>)</span>
<span id="cb200-323"><a href="nonlinear-regression.html#cb200-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-324"><a href="nonlinear-regression.html#cb200-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-325"><a href="nonlinear-regression.html#cb200-325" aria-hidden="true" tabindex="-1"></a>Построим график со слайда <span class="dv">20</span> (рисунок <span class="fl">7.8</span> книги).</span>
<span id="cb200-326"><a href="nonlinear-regression.html#cb200-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-327"><a href="nonlinear-regression.html#cb200-327" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">0</span>))</span>
<span id="cb200-328"><a href="nonlinear-regression.html#cb200-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-329"><a href="nonlinear-regression.html#cb200-329" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb200-330"><a href="nonlinear-regression.html#cb200-330" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb200-331"><a href="nonlinear-regression.html#cb200-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-332"><a href="nonlinear-regression.html#cb200-332" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb200-333"><a href="nonlinear-regression.html#cb200-333" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Сглаживающий сплайн&#39;</span>)</span>
<span id="cb200-334"><a href="nonlinear-regression.html#cb200-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-335"><a href="nonlinear-regression.html#cb200-335" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с 16 степенями свободы</span></span>
<span id="cb200-336"><a href="nonlinear-regression.html#cb200-336" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">df =</span> <span class="dv">16</span>)</span>
<span id="cb200-337"><a href="nonlinear-regression.html#cb200-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-338"><a href="nonlinear-regression.html#cb200-338" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с подбором лямбды с помощью перекрёстной проверки</span></span>
<span id="cb200-339"><a href="nonlinear-regression.html#cb200-339" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">cv =</span> T)</span>
<span id="cb200-340"><a href="nonlinear-regression.html#cb200-340" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in smooth.spline(age, wage, cv = T): cross-validation with non-</span></span>
<span id="cb200-341"><a href="nonlinear-regression.html#cb200-341" aria-hidden="true" tabindex="-1"></a><span class="do">## unique &#39;x&#39; values seems doubtful</span></span>
<span id="cb200-342"><a href="nonlinear-regression.html#cb200-342" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span>df</span>
<span id="cb200-343"><a href="nonlinear-regression.html#cb200-343" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 6.794596</span></span>
<span id="cb200-344"><a href="nonlinear-regression.html#cb200-344" aria-hidden="true" tabindex="-1"></a><span class="co"># рисуем модель</span></span>
<span id="cb200-345"><a href="nonlinear-regression.html#cb200-345" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb200-346"><a href="nonlinear-regression.html#cb200-346" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit2, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb200-347"><a href="nonlinear-regression.html#cb200-347" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb200-348"><a href="nonlinear-regression.html#cb200-348" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;16 df&#39;</span>, <span class="st">&#39;6.8 df&#39;</span>),</span>
<span id="cb200-349"><a href="nonlinear-regression.html#cb200-349" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb200-350"><a href="nonlinear-regression.html#cb200-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-351"><a href="nonlinear-regression.html#cb200-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-352"><a href="nonlinear-regression.html#cb200-352" aria-hidden="true" tabindex="-1"></a>Локальная регрессия</span>
<span id="cb200-353"><a href="nonlinear-regression.html#cb200-353" aria-hidden="true" tabindex="-1"></a>Строим график со слайда <span class="dv">24</span> (рис. <span class="fl">7.10</span>).</span>
<span id="cb200-354"><a href="nonlinear-regression.html#cb200-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-355"><a href="nonlinear-regression.html#cb200-355" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb200-356"><a href="nonlinear-regression.html#cb200-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-357"><a href="nonlinear-regression.html#cb200-357" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Локальная регрессия&#39;</span>)</span>
<span id="cb200-358"><a href="nonlinear-regression.html#cb200-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-359"><a href="nonlinear-regression.html#cb200-359" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.2</span></span>
<span id="cb200-360"><a href="nonlinear-regression.html#cb200-360" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.2</span>, <span class="at">data =</span> Wage)</span>
<span id="cb200-361"><a href="nonlinear-regression.html#cb200-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-362"><a href="nonlinear-regression.html#cb200-362" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.5</span></span>
<span id="cb200-363"><a href="nonlinear-regression.html#cb200-363" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.5</span>, <span class="at">data =</span> Wage)</span>
<span id="cb200-364"><a href="nonlinear-regression.html#cb200-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-365"><a href="nonlinear-regression.html#cb200-365" aria-hidden="true" tabindex="-1"></a><span class="co"># рисум модели</span></span>
<span id="cb200-366"><a href="nonlinear-regression.html#cb200-366" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb200-367"><a href="nonlinear-regression.html#cb200-367" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb200-368"><a href="nonlinear-regression.html#cb200-368" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit2, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb200-369"><a href="nonlinear-regression.html#cb200-369" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb200-370"><a href="nonlinear-regression.html#cb200-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-371"><a href="nonlinear-regression.html#cb200-371" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb200-372"><a href="nonlinear-regression.html#cb200-372" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb200-373"><a href="nonlinear-regression.html#cb200-373" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;s = 0.2&#39;</span>, <span class="st">&#39;s = 0.5&#39;</span>),</span>
<span id="cb200-374"><a href="nonlinear-regression.html#cb200-374" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb200-375"><a href="nonlinear-regression.html#cb200-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-376"><a href="nonlinear-regression.html#cb200-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-377"><a href="nonlinear-regression.html#cb200-377" aria-hidden="true" tabindex="-1"></a>Обобщённые аддитивные модели (GAM) с непрерывным откликом</span>
<span id="cb200-378"><a href="nonlinear-regression.html#cb200-378" aria-hidden="true" tabindex="-1"></a>Построим GAM на натуральных сплайнах степеней <span class="dv">4</span> (year), <span class="dv">5</span> (age) с категориальным предиктором edication.</span>
<span id="cb200-379"><a href="nonlinear-regression.html#cb200-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-380"><a href="nonlinear-regression.html#cb200-380" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на натуральных сплайнах</span></span>
<span id="cb200-381"><a href="nonlinear-regression.html#cb200-381" aria-hidden="true" tabindex="-1"></a>gam.ns <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">ns</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb200-382"><a href="nonlinear-regression.html#cb200-382" aria-hidden="true" tabindex="-1"></a>Также построим модель на сглаживающих сплайнах.</span>
<span id="cb200-383"><a href="nonlinear-regression.html#cb200-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-384"><a href="nonlinear-regression.html#cb200-384" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на сглаживающих сплайнах</span></span>
<span id="cb200-385"><a href="nonlinear-regression.html#cb200-385" aria-hidden="true" tabindex="-1"></a>gam.m3 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb200-386"><a href="nonlinear-regression.html#cb200-386" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">28</span> (рис. <span class="fl">7.12</span>).</span>
<span id="cb200-387"><a href="nonlinear-regression.html#cb200-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-388"><a href="nonlinear-regression.html#cb200-388" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb200-389"><a href="nonlinear-regression.html#cb200-389" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.m3, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb200-390"><a href="nonlinear-regression.html#cb200-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-391"><a href="nonlinear-regression.html#cb200-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-392"><a href="nonlinear-regression.html#cb200-392" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">27</span> (рис. <span class="fl">7.11</span>).</span>
<span id="cb200-393"><a href="nonlinear-regression.html#cb200-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-394"><a href="nonlinear-regression.html#cb200-394" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb200-395"><a href="nonlinear-regression.html#cb200-395" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.ns, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb200-396"><a href="nonlinear-regression.html#cb200-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-397"><a href="nonlinear-regression.html#cb200-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-398"><a href="nonlinear-regression.html#cb200-398" aria-hidden="true" tabindex="-1"></a>График функции от year похож на прямую. Сделаем ANOVA, чтобы понять, какая степень для year лучше.</span>
<span id="cb200-399"><a href="nonlinear-regression.html#cb200-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-400"><a href="nonlinear-regression.html#cb200-400" aria-hidden="true" tabindex="-1"></a>gam.m1 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)          <span class="co"># без year</span></span>
<span id="cb200-401"><a href="nonlinear-regression.html#cb200-401" aria-hidden="true" tabindex="-1"></a>gam.m2 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)   <span class="co"># year^1</span></span>
<span id="cb200-402"><a href="nonlinear-regression.html#cb200-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-403"><a href="nonlinear-regression.html#cb200-403" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(gam.m1, gam.m2, gam.m3, <span class="at">test =</span> <span class="st">&#39;F&#39;</span>)</span>
<span id="cb200-404"><a href="nonlinear-regression.html#cb200-404" aria-hidden="true" tabindex="-1"></a>Resid. Df</span>
<span id="cb200-405"><a href="nonlinear-regression.html#cb200-405" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-406"><a href="nonlinear-regression.html#cb200-406" aria-hidden="true" tabindex="-1"></a>    Resid. Dev</span>
<span id="cb200-407"><a href="nonlinear-regression.html#cb200-407" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-408"><a href="nonlinear-regression.html#cb200-408" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb200-409"><a href="nonlinear-regression.html#cb200-409" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-410"><a href="nonlinear-regression.html#cb200-410" aria-hidden="true" tabindex="-1"></a>    Deviance</span>
<span id="cb200-411"><a href="nonlinear-regression.html#cb200-411" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-412"><a href="nonlinear-regression.html#cb200-412" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb200-413"><a href="nonlinear-regression.html#cb200-413" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-414"><a href="nonlinear-regression.html#cb200-414" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb200-415"><a href="nonlinear-regression.html#cb200-415" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb200-416"><a href="nonlinear-regression.html#cb200-416" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2990</span>    <span class="dv">3711731</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb200-417"><a href="nonlinear-regression.html#cb200-417" aria-hidden="true" tabindex="-1"></a><span class="dv">2989</span>    <span class="dv">3693842</span> <span class="fl">1.000000</span>    <span class="fl">17889.243</span>   <span class="fl">14.477130</span>   <span class="fl">0.0001447167</span></span>
<span id="cb200-418"><a href="nonlinear-regression.html#cb200-418" aria-hidden="true" tabindex="-1"></a><span class="dv">2986</span>    <span class="dv">3689770</span> <span class="fl">2.999989</span>    <span class="fl">4071.134</span>    <span class="fl">1.098212</span>    <span class="fl">0.3485661430</span></span>
<span id="cb200-419"><a href="nonlinear-regression.html#cb200-419" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> rows</span>
<span id="cb200-420"><a href="nonlinear-regression.html#cb200-420" aria-hidden="true" tabindex="-1"></a>Третья модель статистически не лучше второй. Кроме того, один из параметров этой модели незначим.</span>
<span id="cb200-421"><a href="nonlinear-regression.html#cb200-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-422"><a href="nonlinear-regression.html#cb200-422" aria-hidden="true" tabindex="-1"></a><span class="co"># сводка по модели gam.m3</span></span>
<span id="cb200-423"><a href="nonlinear-regression.html#cb200-423" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gam.m3)</span>
<span id="cb200-424"><a href="nonlinear-regression.html#cb200-424" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb200-425"><a href="nonlinear-regression.html#cb200-425" aria-hidden="true" tabindex="-1"></a><span class="do">## Call: gam(formula = wage ~ s(year, 4) + s(age, 5) + education, data = Wage)</span></span>
<span id="cb200-426"><a href="nonlinear-regression.html#cb200-426" aria-hidden="true" tabindex="-1"></a><span class="do">## Deviance Residuals:</span></span>
<span id="cb200-427"><a href="nonlinear-regression.html#cb200-427" aria-hidden="true" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb200-428"><a href="nonlinear-regression.html#cb200-428" aria-hidden="true" tabindex="-1"></a><span class="do">## -119.43  -19.70   -3.33   14.17  213.48 </span></span>
<span id="cb200-429"><a href="nonlinear-regression.html#cb200-429" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb200-430"><a href="nonlinear-regression.html#cb200-430" aria-hidden="true" tabindex="-1"></a><span class="do">## (Dispersion Parameter for gaussian family taken to be 1235.69)</span></span>
<span id="cb200-431"><a href="nonlinear-regression.html#cb200-431" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb200-432"><a href="nonlinear-regression.html#cb200-432" aria-hidden="true" tabindex="-1"></a><span class="do">##     Null Deviance: 5222086 on 2999 degrees of freedom</span></span>
<span id="cb200-433"><a href="nonlinear-regression.html#cb200-433" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual Deviance: 3689770 on 2986 degrees of freedom</span></span>
<span id="cb200-434"><a href="nonlinear-regression.html#cb200-434" aria-hidden="true" tabindex="-1"></a><span class="do">## AIC: 29887.75 </span></span>
<span id="cb200-435"><a href="nonlinear-regression.html#cb200-435" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb200-436"><a href="nonlinear-regression.html#cb200-436" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Local Scoring Iterations: 2 </span></span>
<span id="cb200-437"><a href="nonlinear-regression.html#cb200-437" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb200-438"><a href="nonlinear-regression.html#cb200-438" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Parametric Effects</span></span>
<span id="cb200-439"><a href="nonlinear-regression.html#cb200-439" aria-hidden="true" tabindex="-1"></a><span class="do">##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    </span></span>
<span id="cb200-440"><a href="nonlinear-regression.html#cb200-440" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)    1   27162   27162  21.981 2.877e-06 ***</span></span>
<span id="cb200-441"><a href="nonlinear-regression.html#cb200-441" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)     1  195338  195338 158.081 &lt; 2.2e-16 ***</span></span>
<span id="cb200-442"><a href="nonlinear-regression.html#cb200-442" aria-hidden="true" tabindex="-1"></a><span class="do">## education     4 1069726  267432 216.423 &lt; 2.2e-16 ***</span></span>
<span id="cb200-443"><a href="nonlinear-regression.html#cb200-443" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals  2986 3689770    1236                      </span></span>
<span id="cb200-444"><a href="nonlinear-regression.html#cb200-444" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb200-445"><a href="nonlinear-regression.html#cb200-445" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb200-446"><a href="nonlinear-regression.html#cb200-446" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb200-447"><a href="nonlinear-regression.html#cb200-447" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Nonparametric Effects</span></span>
<span id="cb200-448"><a href="nonlinear-regression.html#cb200-448" aria-hidden="true" tabindex="-1"></a><span class="do">##             Npar Df Npar F  Pr(F)    </span></span>
<span id="cb200-449"><a href="nonlinear-regression.html#cb200-449" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)                          </span></span>
<span id="cb200-450"><a href="nonlinear-regression.html#cb200-450" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)        3  1.086 0.3537    </span></span>
<span id="cb200-451"><a href="nonlinear-regression.html#cb200-451" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)         4 32.380 &lt;2e-16 ***</span></span>
<span id="cb200-452"><a href="nonlinear-regression.html#cb200-452" aria-hidden="true" tabindex="-1"></a><span class="do">## education                            </span></span>
<span id="cb200-453"><a href="nonlinear-regression.html#cb200-453" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb200-454"><a href="nonlinear-regression.html#cb200-454" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb200-455"><a href="nonlinear-regression.html#cb200-455" aria-hidden="true" tabindex="-1"></a>Работаем с моделью gam.m2.</span>
<span id="cb200-456"><a href="nonlinear-regression.html#cb200-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-457"><a href="nonlinear-regression.html#cb200-457" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по обучающей выборке</span></span>
<span id="cb200-458"><a href="nonlinear-regression.html#cb200-458" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(gam.m2, <span class="at">newdata =</span> Wage)</span>
<span id="cb200-459"><a href="nonlinear-regression.html#cb200-459" aria-hidden="true" tabindex="-1"></a>Также можно использовать в GAM локальные регрессии.</span>
<span id="cb200-460"><a href="nonlinear-regression.html#cb200-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-461"><a href="nonlinear-regression.html#cb200-461" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на локальных регрессиях</span></span>
<span id="cb200-462"><a href="nonlinear-regression.html#cb200-462" aria-hidden="true" tabindex="-1"></a>gam.lo <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="at">df =</span> <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">lo</span>(age, <span class="at">span =</span> <span class="fl">0.7</span>) <span class="sc">+</span> education, </span>
<span id="cb200-463"><a href="nonlinear-regression.html#cb200-463" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> Wage)</span>
<span id="cb200-464"><a href="nonlinear-regression.html#cb200-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-465"><a href="nonlinear-regression.html#cb200-465" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb200-466"><a href="nonlinear-regression.html#cb200-466" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.gam</span>(gam.lo, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb200-467"><a href="nonlinear-regression.html#cb200-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-468"><a href="nonlinear-regression.html#cb200-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-469"><a href="nonlinear-regression.html#cb200-469" aria-hidden="true" tabindex="-1"></a><span class="co"># модель со взаимодействием регрессоров year и age</span></span>
<span id="cb200-470"><a href="nonlinear-regression.html#cb200-470" aria-hidden="true" tabindex="-1"></a>gam.lo.i <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">lo</span>(year, age, <span class="at">span =</span> <span class="fl">0.5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb200-471"><a href="nonlinear-regression.html#cb200-471" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb200-472"><a href="nonlinear-regression.html#cb200-472" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb200-473"><a href="nonlinear-regression.html#cb200-473" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb200-474"><a href="nonlinear-regression.html#cb200-474" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb200-475"><a href="nonlinear-regression.html#cb200-475" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb200-476"><a href="nonlinear-regression.html#cb200-476" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb200-477"><a href="nonlinear-regression.html#cb200-477" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb200-478"><a href="nonlinear-regression.html#cb200-478" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb200-479"><a href="nonlinear-regression.html#cb200-479" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lo.i)</span>
<span id="cb200-480"><a href="nonlinear-regression.html#cb200-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-481"><a href="nonlinear-regression.html#cb200-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-482"><a href="nonlinear-regression.html#cb200-482" aria-hidden="true" tabindex="-1"></a>Логистическая GAM</span>
<span id="cb200-483"><a href="nonlinear-regression.html#cb200-483" aria-hidden="true" tabindex="-1"></a>Построим логистическую GAM для всероятности того, что wage превышает <span class="fl">250.</span></span>
<span id="cb200-484"><a href="nonlinear-regression.html#cb200-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-485"><a href="nonlinear-regression.html#cb200-485" aria-hidden="true" tabindex="-1"></a>gam.lr <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education, </span>
<span id="cb200-486"><a href="nonlinear-regression.html#cb200-486" aria-hidden="true" tabindex="-1"></a>              <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage)</span>
<span id="cb200-487"><a href="nonlinear-regression.html#cb200-487" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb200-488"><a href="nonlinear-regression.html#cb200-488" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb200-489"><a href="nonlinear-regression.html#cb200-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-490"><a href="nonlinear-regression.html#cb200-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-491"><a href="nonlinear-regression.html#cb200-491" aria-hidden="true" tabindex="-1"></a><span class="co"># уровни образования по группам разного достатка</span></span>
<span id="cb200-492"><a href="nonlinear-regression.html#cb200-492" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(education, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>))</span>
<span id="cb200-493"><a href="nonlinear-regression.html#cb200-493" aria-hidden="true" tabindex="-1"></a><span class="do">##                     </span></span>
<span id="cb200-494"><a href="nonlinear-regression.html#cb200-494" aria-hidden="true" tabindex="-1"></a><span class="do">## education            FALSE TRUE</span></span>
<span id="cb200-495"><a href="nonlinear-regression.html#cb200-495" aria-hidden="true" tabindex="-1"></a><span class="do">##   1. &lt; HS Grad         268    0</span></span>
<span id="cb200-496"><a href="nonlinear-regression.html#cb200-496" aria-hidden="true" tabindex="-1"></a><span class="do">##   2. HS Grad           966    5</span></span>
<span id="cb200-497"><a href="nonlinear-regression.html#cb200-497" aria-hidden="true" tabindex="-1"></a><span class="do">##   3. Some College      643    7</span></span>
<span id="cb200-498"><a href="nonlinear-regression.html#cb200-498" aria-hidden="true" tabindex="-1"></a><span class="do">##   4. College Grad      663   22</span></span>
<span id="cb200-499"><a href="nonlinear-regression.html#cb200-499" aria-hidden="true" tabindex="-1"></a><span class="do">##   5. Advanced Degree   381   45</span></span>
<span id="cb200-500"><a href="nonlinear-regression.html#cb200-500" aria-hidden="true" tabindex="-1"></a>В категории с самым низким уровнем образования нет wage <span class="sc">&gt;</span> <span class="dv">250</span>, поэтому убираем её.</span>
<span id="cb200-501"><a href="nonlinear-regression.html#cb200-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-502"><a href="nonlinear-regression.html#cb200-502" aria-hidden="true" tabindex="-1"></a>gam.lr.s <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education,</span>
<span id="cb200-503"><a href="nonlinear-regression.html#cb200-503" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage, </span>
<span id="cb200-504"><a href="nonlinear-regression.html#cb200-504" aria-hidden="true" tabindex="-1"></a>                <span class="at">subset =</span> (education <span class="sc">!=</span> <span class="st">&quot;1. &lt; HS Grad&quot;</span>))</span>
<span id="cb200-505"><a href="nonlinear-regression.html#cb200-505" aria-hidden="true" tabindex="-1"></a><span class="co"># график</span></span>
<span id="cb200-506"><a href="nonlinear-regression.html#cb200-506" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb200-507"><a href="nonlinear-regression.html#cb200-507" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr.s, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb200-508"><a href="nonlinear-regression.html#cb200-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-509"><a href="nonlinear-regression.html#cb200-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb200-510"><a href="nonlinear-regression.html#cb200-510" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(Wage)</span></code></pre></div>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="nonlinear-regression.html#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonlinear modeling</span></span>
<span id="cb201-2"><a href="nonlinear-regression.html#cb201-2" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb201-3"><a href="nonlinear-regression.html#cb201-3" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">8</span></span>
<span id="cb201-4"><a href="nonlinear-regression.html#cb201-4" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb201-5"><a href="nonlinear-regression.html#cb201-5" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb201-6"><a href="nonlinear-regression.html#cb201-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb201-7"><a href="nonlinear-regression.html#cb201-7" aria-hidden="true" tabindex="-1"></a>    строить регрессионные деревья;</span>
<span id="cb201-8"><a href="nonlinear-regression.html#cb201-8" aria-hidden="true" tabindex="-1"></a>строить деревья классификации;</span>
<span id="cb201-9"><a href="nonlinear-regression.html#cb201-9" aria-hidden="true" tabindex="-1"></a>делать обрезку дерева;</span>
<span id="cb201-10"><a href="nonlinear-regression.html#cb201-10" aria-hidden="true" tabindex="-1"></a>использовать бэггинг, бустинг, случайный лес для улучшения качества прогнозирования.</span>
<span id="cb201-11"><a href="nonlinear-regression.html#cb201-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> деревья решений.</span>
<span id="cb201-12"><a href="nonlinear-regression.html#cb201-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Sales {ISLR}, Boston {ISLR}</span>
<span id="cb201-13"><a href="nonlinear-regression.html#cb201-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-14"><a href="nonlinear-regression.html#cb201-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">8.</span></span>
<span id="cb201-15"><a href="nonlinear-regression.html#cb201-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-16"><a href="nonlinear-regression.html#cb201-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;tree&#39;</span>)              <span class="co"># деревья</span></span>
<span id="cb201-17"><a href="nonlinear-regression.html#cb201-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;tree&#39; was built under R version 3.4.4</span></span>
<span id="cb201-18"><a href="nonlinear-regression.html#cb201-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># наборы данных</span></span>
<span id="cb201-19"><a href="nonlinear-regression.html#cb201-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;MASS&#39;</span>)</span>
<span id="cb201-20"><a href="nonlinear-regression.html#cb201-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;randomForest&#39;</span>)      <span class="co"># случайный лес</span></span>
<span id="cb201-21"><a href="nonlinear-regression.html#cb201-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;randomForest&#39; was built under R version 3.4.4</span></span>
<span id="cb201-22"><a href="nonlinear-regression.html#cb201-22" aria-hidden="true" tabindex="-1"></a><span class="do">## randomForest 4.6-14</span></span>
<span id="cb201-23"><a href="nonlinear-regression.html#cb201-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Type rfNews() to see new features/changes/bug fixes.</span></span>
<span id="cb201-24"><a href="nonlinear-regression.html#cb201-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gbm&#39;</span>)</span>
<span id="cb201-25"><a href="nonlinear-regression.html#cb201-25" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gbm&#39; was built under R version 3.4.4</span></span>
<span id="cb201-26"><a href="nonlinear-regression.html#cb201-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: survival</span></span>
<span id="cb201-27"><a href="nonlinear-regression.html#cb201-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: lattice</span></span>
<span id="cb201-28"><a href="nonlinear-regression.html#cb201-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: splines</span></span>
<span id="cb201-29"><a href="nonlinear-regression.html#cb201-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: parallel</span></span>
<span id="cb201-30"><a href="nonlinear-regression.html#cb201-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gbm 2.1.3</span></span>
<span id="cb201-31"><a href="nonlinear-regression.html#cb201-31" aria-hidden="true" tabindex="-1"></a>Деревья решений</span>
<span id="cb201-32"><a href="nonlinear-regression.html#cb201-32" aria-hidden="true" tabindex="-1"></a>Загрузим таблицу с данными по продажам детских кресел и добавим к ней переменную High – “высокие продажи” со значениями<span class="sc">:</span></span>
<span id="cb201-33"><a href="nonlinear-regression.html#cb201-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb201-34"><a href="nonlinear-regression.html#cb201-34" aria-hidden="true" tabindex="-1"></a>    Yes если продажи больше <span class="dv">8</span> (тыс. шт.);</span>
<span id="cb201-35"><a href="nonlinear-regression.html#cb201-35" aria-hidden="true" tabindex="-1"></a>No в противном случае.</span>
<span id="cb201-36"><a href="nonlinear-regression.html#cb201-36" aria-hidden="true" tabindex="-1"></a>?Carseats</span>
<span id="cb201-37"><a href="nonlinear-regression.html#cb201-37" aria-hidden="true" tabindex="-1"></a><span class="do">## starting httpd help server ... done</span></span>
<span id="cb201-38"><a href="nonlinear-regression.html#cb201-38" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Carseats)</span>
<span id="cb201-39"><a href="nonlinear-regression.html#cb201-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-40"><a href="nonlinear-regression.html#cb201-40" aria-hidden="true" tabindex="-1"></a><span class="co"># новая переменная</span></span>
<span id="cb201-41"><a href="nonlinear-regression.html#cb201-41" aria-hidden="true" tabindex="-1"></a>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Sales <span class="sc">&lt;=</span> <span class="dv">8</span>, <span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb201-42"><a href="nonlinear-regression.html#cb201-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-43"><a href="nonlinear-regression.html#cb201-43" aria-hidden="true" tabindex="-1"></a><span class="co"># присоединяем к таблице данных</span></span>
<span id="cb201-44"><a href="nonlinear-regression.html#cb201-44" aria-hidden="true" tabindex="-1"></a>Carseats <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Carseats, High)</span>
<span id="cb201-45"><a href="nonlinear-regression.html#cb201-45" aria-hidden="true" tabindex="-1"></a>Строим дерево для категориального отклика High, отбросив непрерывный отклик Sales.</span>
<span id="cb201-46"><a href="nonlinear-regression.html#cb201-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-47"><a href="nonlinear-regression.html#cb201-47" aria-hidden="true" tabindex="-1"></a><span class="co"># модель бинарного  дерева</span></span>
<span id="cb201-48"><a href="nonlinear-regression.html#cb201-48" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats)</span>
<span id="cb201-49"><a href="nonlinear-regression.html#cb201-49" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.carseats)</span>
<span id="cb201-50"><a href="nonlinear-regression.html#cb201-50" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-51"><a href="nonlinear-regression.html#cb201-51" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree:</span></span>
<span id="cb201-52"><a href="nonlinear-regression.html#cb201-52" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = High ~ . - Sales, data = Carseats)</span></span>
<span id="cb201-53"><a href="nonlinear-regression.html#cb201-53" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb201-54"><a href="nonlinear-regression.html#cb201-54" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;ShelveLoc&quot;   &quot;Price&quot;       &quot;Income&quot;      &quot;CompPrice&quot;   &quot;Population&quot; </span></span>
<span id="cb201-55"><a href="nonlinear-regression.html#cb201-55" aria-hidden="true" tabindex="-1"></a><span class="do">## [6] &quot;Advertising&quot; &quot;Age&quot;         &quot;US&quot;         </span></span>
<span id="cb201-56"><a href="nonlinear-regression.html#cb201-56" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  27 </span></span>
<span id="cb201-57"><a href="nonlinear-regression.html#cb201-57" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  0.4575 = 170.7 / 373 </span></span>
<span id="cb201-58"><a href="nonlinear-regression.html#cb201-58" aria-hidden="true" tabindex="-1"></a><span class="do">## Misclassification error rate: 0.09 = 36 / 400</span></span>
<span id="cb201-59"><a href="nonlinear-regression.html#cb201-59" aria-hidden="true" tabindex="-1"></a><span class="co"># график результата</span></span>
<span id="cb201-60"><a href="nonlinear-regression.html#cb201-60" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.carseats)            <span class="co"># ветви</span></span>
<span id="cb201-61"><a href="nonlinear-regression.html#cb201-61" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.carseats, <span class="at">pretty=</span><span class="dv">0</span>)  <span class="co"># подписи</span></span>
<span id="cb201-62"><a href="nonlinear-regression.html#cb201-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-63"><a href="nonlinear-regression.html#cb201-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-64"><a href="nonlinear-regression.html#cb201-64" aria-hidden="true" tabindex="-1"></a>tree.carseats                  <span class="co"># посмотреть всё дерево в консоли</span></span>
<span id="cb201-65"><a href="nonlinear-regression.html#cb201-65" aria-hidden="true" tabindex="-1"></a><span class="do">## node), split, n, deviance, yval, (yprob)</span></span>
<span id="cb201-66"><a href="nonlinear-regression.html#cb201-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       * denotes terminal node</span></span>
<span id="cb201-67"><a href="nonlinear-regression.html#cb201-67" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-68"><a href="nonlinear-regression.html#cb201-68" aria-hidden="true" tabindex="-1"></a><span class="do">##   1) root 400 541.500 No ( 0.59000 0.41000 )  </span></span>
<span id="cb201-69"><a href="nonlinear-regression.html#cb201-69" aria-hidden="true" tabindex="-1"></a><span class="do">##     2) ShelveLoc: Bad,Medium 315 390.600 No ( 0.68889 0.31111 )  </span></span>
<span id="cb201-70"><a href="nonlinear-regression.html#cb201-70" aria-hidden="true" tabindex="-1"></a><span class="do">##       4) Price &lt; 92.5 46  56.530 Yes ( 0.30435 0.69565 )  </span></span>
<span id="cb201-71"><a href="nonlinear-regression.html#cb201-71" aria-hidden="true" tabindex="-1"></a><span class="do">##         8) Income &lt; 57 10  12.220 No ( 0.70000 0.30000 )  </span></span>
<span id="cb201-72"><a href="nonlinear-regression.html#cb201-72" aria-hidden="true" tabindex="-1"></a><span class="do">##          16) CompPrice &lt; 110.5 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb201-73"><a href="nonlinear-regression.html#cb201-73" aria-hidden="true" tabindex="-1"></a><span class="do">##          17) CompPrice &gt; 110.5 5   6.730 Yes ( 0.40000 0.60000 ) *</span></span>
<span id="cb201-74"><a href="nonlinear-regression.html#cb201-74" aria-hidden="true" tabindex="-1"></a><span class="do">##         9) Income &gt; 57 36  35.470 Yes ( 0.19444 0.80556 )  </span></span>
<span id="cb201-75"><a href="nonlinear-regression.html#cb201-75" aria-hidden="true" tabindex="-1"></a><span class="do">##          18) Population &lt; 207.5 16  21.170 Yes ( 0.37500 0.62500 ) *</span></span>
<span id="cb201-76"><a href="nonlinear-regression.html#cb201-76" aria-hidden="true" tabindex="-1"></a><span class="do">##          19) Population &gt; 207.5 20   7.941 Yes ( 0.05000 0.95000 ) *</span></span>
<span id="cb201-77"><a href="nonlinear-regression.html#cb201-77" aria-hidden="true" tabindex="-1"></a><span class="do">##       5) Price &gt; 92.5 269 299.800 No ( 0.75465 0.24535 )  </span></span>
<span id="cb201-78"><a href="nonlinear-regression.html#cb201-78" aria-hidden="true" tabindex="-1"></a><span class="do">##        10) Advertising &lt; 13.5 224 213.200 No ( 0.81696 0.18304 )  </span></span>
<span id="cb201-79"><a href="nonlinear-regression.html#cb201-79" aria-hidden="true" tabindex="-1"></a><span class="do">##          20) CompPrice &lt; 124.5 96  44.890 No ( 0.93750 0.06250 )  </span></span>
<span id="cb201-80"><a href="nonlinear-regression.html#cb201-80" aria-hidden="true" tabindex="-1"></a><span class="do">##            40) Price &lt; 106.5 38  33.150 No ( 0.84211 0.15789 )  </span></span>
<span id="cb201-81"><a href="nonlinear-regression.html#cb201-81" aria-hidden="true" tabindex="-1"></a><span class="do">##              80) Population &lt; 177 12  16.300 No ( 0.58333 0.41667 )  </span></span>
<span id="cb201-82"><a href="nonlinear-regression.html#cb201-82" aria-hidden="true" tabindex="-1"></a><span class="do">##               160) Income &lt; 60.5 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb201-83"><a href="nonlinear-regression.html#cb201-83" aria-hidden="true" tabindex="-1"></a><span class="do">##               161) Income &gt; 60.5 6   5.407 Yes ( 0.16667 0.83333 ) *</span></span>
<span id="cb201-84"><a href="nonlinear-regression.html#cb201-84" aria-hidden="true" tabindex="-1"></a><span class="do">##              81) Population &gt; 177 26   8.477 No ( 0.96154 0.03846 ) *</span></span>
<span id="cb201-85"><a href="nonlinear-regression.html#cb201-85" aria-hidden="true" tabindex="-1"></a><span class="do">##            41) Price &gt; 106.5 58   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb201-86"><a href="nonlinear-regression.html#cb201-86" aria-hidden="true" tabindex="-1"></a><span class="do">##          21) CompPrice &gt; 124.5 128 150.200 No ( 0.72656 0.27344 )  </span></span>
<span id="cb201-87"><a href="nonlinear-regression.html#cb201-87" aria-hidden="true" tabindex="-1"></a><span class="do">##            42) Price &lt; 122.5 51  70.680 Yes ( 0.49020 0.50980 )  </span></span>
<span id="cb201-88"><a href="nonlinear-regression.html#cb201-88" aria-hidden="true" tabindex="-1"></a><span class="do">##              84) ShelveLoc: Bad 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb201-89"><a href="nonlinear-regression.html#cb201-89" aria-hidden="true" tabindex="-1"></a><span class="do">##              85) ShelveLoc: Medium 40  52.930 Yes ( 0.37500 0.62500 )  </span></span>
<span id="cb201-90"><a href="nonlinear-regression.html#cb201-90" aria-hidden="true" tabindex="-1"></a><span class="do">##               170) Price &lt; 109.5 16   7.481 Yes ( 0.06250 0.93750 ) *</span></span>
<span id="cb201-91"><a href="nonlinear-regression.html#cb201-91" aria-hidden="true" tabindex="-1"></a><span class="do">##               171) Price &gt; 109.5 24  32.600 No ( 0.58333 0.41667 )  </span></span>
<span id="cb201-92"><a href="nonlinear-regression.html#cb201-92" aria-hidden="true" tabindex="-1"></a><span class="do">##                 342) Age &lt; 49.5 13  16.050 Yes ( 0.30769 0.69231 ) *</span></span>
<span id="cb201-93"><a href="nonlinear-regression.html#cb201-93" aria-hidden="true" tabindex="-1"></a><span class="do">##                 343) Age &gt; 49.5 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb201-94"><a href="nonlinear-regression.html#cb201-94" aria-hidden="true" tabindex="-1"></a><span class="do">##            43) Price &gt; 122.5 77  55.540 No ( 0.88312 0.11688 )  </span></span>
<span id="cb201-95"><a href="nonlinear-regression.html#cb201-95" aria-hidden="true" tabindex="-1"></a><span class="do">##              86) CompPrice &lt; 147.5 58  17.400 No ( 0.96552 0.03448 ) *</span></span>
<span id="cb201-96"><a href="nonlinear-regression.html#cb201-96" aria-hidden="true" tabindex="-1"></a><span class="do">##              87) CompPrice &gt; 147.5 19  25.010 No ( 0.63158 0.36842 )  </span></span>
<span id="cb201-97"><a href="nonlinear-regression.html#cb201-97" aria-hidden="true" tabindex="-1"></a><span class="do">##               174) Price &lt; 147 12  16.300 Yes ( 0.41667 0.58333 )  </span></span>
<span id="cb201-98"><a href="nonlinear-regression.html#cb201-98" aria-hidden="true" tabindex="-1"></a><span class="do">##                 348) CompPrice &lt; 152.5 7   5.742 Yes ( 0.14286 0.85714 ) *</span></span>
<span id="cb201-99"><a href="nonlinear-regression.html#cb201-99" aria-hidden="true" tabindex="-1"></a><span class="do">##                 349) CompPrice &gt; 152.5 5   5.004 No ( 0.80000 0.20000 ) *</span></span>
<span id="cb201-100"><a href="nonlinear-regression.html#cb201-100" aria-hidden="true" tabindex="-1"></a><span class="do">##               175) Price &gt; 147 7   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb201-101"><a href="nonlinear-regression.html#cb201-101" aria-hidden="true" tabindex="-1"></a><span class="do">##        11) Advertising &gt; 13.5 45  61.830 Yes ( 0.44444 0.55556 )  </span></span>
<span id="cb201-102"><a href="nonlinear-regression.html#cb201-102" aria-hidden="true" tabindex="-1"></a><span class="do">##          22) Age &lt; 54.5 25  25.020 Yes ( 0.20000 0.80000 )  </span></span>
<span id="cb201-103"><a href="nonlinear-regression.html#cb201-103" aria-hidden="true" tabindex="-1"></a><span class="do">##            44) CompPrice &lt; 130.5 14  18.250 Yes ( 0.35714 0.64286 )  </span></span>
<span id="cb201-104"><a href="nonlinear-regression.html#cb201-104" aria-hidden="true" tabindex="-1"></a><span class="do">##              88) Income &lt; 100 9  12.370 No ( 0.55556 0.44444 ) *</span></span>
<span id="cb201-105"><a href="nonlinear-regression.html#cb201-105" aria-hidden="true" tabindex="-1"></a><span class="do">##              89) Income &gt; 100 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb201-106"><a href="nonlinear-regression.html#cb201-106" aria-hidden="true" tabindex="-1"></a><span class="do">##            45) CompPrice &gt; 130.5 11   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb201-107"><a href="nonlinear-regression.html#cb201-107" aria-hidden="true" tabindex="-1"></a><span class="do">##          23) Age &gt; 54.5 20  22.490 No ( 0.75000 0.25000 )  </span></span>
<span id="cb201-108"><a href="nonlinear-regression.html#cb201-108" aria-hidden="true" tabindex="-1"></a><span class="do">##            46) CompPrice &lt; 122.5 10   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb201-109"><a href="nonlinear-regression.html#cb201-109" aria-hidden="true" tabindex="-1"></a><span class="do">##            47) CompPrice &gt; 122.5 10  13.860 No ( 0.50000 0.50000 )  </span></span>
<span id="cb201-110"><a href="nonlinear-regression.html#cb201-110" aria-hidden="true" tabindex="-1"></a><span class="do">##              94) Price &lt; 125 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb201-111"><a href="nonlinear-regression.html#cb201-111" aria-hidden="true" tabindex="-1"></a><span class="do">##              95) Price &gt; 125 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb201-112"><a href="nonlinear-regression.html#cb201-112" aria-hidden="true" tabindex="-1"></a><span class="do">##     3) ShelveLoc: Good 85  90.330 Yes ( 0.22353 0.77647 )  </span></span>
<span id="cb201-113"><a href="nonlinear-regression.html#cb201-113" aria-hidden="true" tabindex="-1"></a><span class="do">##       6) Price &lt; 135 68  49.260 Yes ( 0.11765 0.88235 )  </span></span>
<span id="cb201-114"><a href="nonlinear-regression.html#cb201-114" aria-hidden="true" tabindex="-1"></a><span class="do">##        12) US: No 17  22.070 Yes ( 0.35294 0.64706 )  </span></span>
<span id="cb201-115"><a href="nonlinear-regression.html#cb201-115" aria-hidden="true" tabindex="-1"></a><span class="do">##          24) Price &lt; 109 8   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb201-116"><a href="nonlinear-regression.html#cb201-116" aria-hidden="true" tabindex="-1"></a><span class="do">##          25) Price &gt; 109 9  11.460 No ( 0.66667 0.33333 ) *</span></span>
<span id="cb201-117"><a href="nonlinear-regression.html#cb201-117" aria-hidden="true" tabindex="-1"></a><span class="do">##        13) US: Yes 51  16.880 Yes ( 0.03922 0.96078 ) *</span></span>
<span id="cb201-118"><a href="nonlinear-regression.html#cb201-118" aria-hidden="true" tabindex="-1"></a><span class="do">##       7) Price &gt; 135 17  22.070 No ( 0.64706 0.35294 )  </span></span>
<span id="cb201-119"><a href="nonlinear-regression.html#cb201-119" aria-hidden="true" tabindex="-1"></a><span class="do">##        14) Income &lt; 46 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb201-120"><a href="nonlinear-regression.html#cb201-120" aria-hidden="true" tabindex="-1"></a><span class="do">##        15) Income &gt; 46 11  15.160 Yes ( 0.45455 0.54545 ) *</span></span>
<span id="cb201-121"><a href="nonlinear-regression.html#cb201-121" aria-hidden="true" tabindex="-1"></a>Теперь построим дерево на обучающей выборке и оценим ошибку на тестовой.</span>
<span id="cb201-122"><a href="nonlinear-regression.html#cb201-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-123"><a href="nonlinear-regression.html#cb201-123" aria-hidden="true" tabindex="-1"></a><span class="co"># ядро генератора случайных чисел</span></span>
<span id="cb201-124"><a href="nonlinear-regression.html#cb201-124" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb201-125"><a href="nonlinear-regression.html#cb201-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-126"><a href="nonlinear-regression.html#cb201-126" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb201-127"><a href="nonlinear-regression.html#cb201-127" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Carseats), <span class="dv">200</span>)</span>
<span id="cb201-128"><a href="nonlinear-regression.html#cb201-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-129"><a href="nonlinear-regression.html#cb201-129" aria-hidden="true" tabindex="-1"></a><span class="co"># тестовая выборка</span></span>
<span id="cb201-130"><a href="nonlinear-regression.html#cb201-130" aria-hidden="true" tabindex="-1"></a>Carseats.test <span class="ot">&lt;-</span> Carseats[<span class="sc">-</span>train,]</span>
<span id="cb201-131"><a href="nonlinear-regression.html#cb201-131" aria-hidden="true" tabindex="-1"></a>High.test <span class="ot">&lt;-</span> High[<span class="sc">-</span>train]</span>
<span id="cb201-132"><a href="nonlinear-regression.html#cb201-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-133"><a href="nonlinear-regression.html#cb201-133" aria-hidden="true" tabindex="-1"></a><span class="co"># строим дерево на обучающей выборке</span></span>
<span id="cb201-134"><a href="nonlinear-regression.html#cb201-134" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats, <span class="at">subset =</span> train)</span>
<span id="cb201-135"><a href="nonlinear-regression.html#cb201-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-136"><a href="nonlinear-regression.html#cb201-136" aria-hidden="true" tabindex="-1"></a><span class="co"># делаем прогноз</span></span>
<span id="cb201-137"><a href="nonlinear-regression.html#cb201-137" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb201-138"><a href="nonlinear-regression.html#cb201-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-139"><a href="nonlinear-regression.html#cb201-139" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb201-140"><a href="nonlinear-regression.html#cb201-140" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb201-141"><a href="nonlinear-regression.html#cb201-141" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb201-142"><a href="nonlinear-regression.html#cb201-142" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb201-143"><a href="nonlinear-regression.html#cb201-143" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb201-144"><a href="nonlinear-regression.html#cb201-144" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  27</span></span>
<span id="cb201-145"><a href="nonlinear-regression.html#cb201-145" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  57</span></span>
<span id="cb201-146"><a href="nonlinear-regression.html#cb201-146" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb201-147"><a href="nonlinear-regression.html#cb201-147" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb201-148"><a href="nonlinear-regression.html#cb201-148" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb201-149"><a href="nonlinear-regression.html#cb201-149" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.715</span></span>
<span id="cb201-150"><a href="nonlinear-regression.html#cb201-150" aria-hidden="true" tabindex="-1"></a>Обобщённая характеристика точности<span class="sc">:</span> доля верных прогнозов<span class="sc">:</span> <span class="dv">0</span>.<span class="fl">72.</span></span>
<span id="cb201-151"><a href="nonlinear-regression.html#cb201-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-152"><a href="nonlinear-regression.html#cb201-152" aria-hidden="true" tabindex="-1"></a>Теперь обрезаем дерево, используя в качестве критерия частоту ошибок классификации. Функция <span class="fu">cv.tree</span>() проводит кросс<span class="sc">-</span>валидацию для выбора лучшего дерева, аргумент prune.misclass означает, что мы минимизируем ошибку классификации.</span>
<span id="cb201-153"><a href="nonlinear-regression.html#cb201-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-154"><a href="nonlinear-regression.html#cb201-154" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb201-155"><a href="nonlinear-regression.html#cb201-155" aria-hidden="true" tabindex="-1"></a>cv.carseats <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.carseats, <span class="at">FUN =</span> prune.misclass)</span>
<span id="cb201-156"><a href="nonlinear-regression.html#cb201-156" aria-hidden="true" tabindex="-1"></a><span class="co"># имена элементов полученного объекта</span></span>
<span id="cb201-157"><a href="nonlinear-regression.html#cb201-157" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(cv.carseats)</span>
<span id="cb201-158"><a href="nonlinear-regression.html#cb201-158" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;size&quot;   &quot;dev&quot;    &quot;k&quot;      &quot;method&quot;</span></span>
<span id="cb201-159"><a href="nonlinear-regression.html#cb201-159" aria-hidden="true" tabindex="-1"></a><span class="co"># сам объект</span></span>
<span id="cb201-160"><a href="nonlinear-regression.html#cb201-160" aria-hidden="true" tabindex="-1"></a>cv.carseats</span>
<span id="cb201-161"><a href="nonlinear-regression.html#cb201-161" aria-hidden="true" tabindex="-1"></a><span class="do">## $size</span></span>
<span id="cb201-162"><a href="nonlinear-regression.html#cb201-162" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 19 17 14 13  9  7  3  2  1</span></span>
<span id="cb201-163"><a href="nonlinear-regression.html#cb201-163" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-164"><a href="nonlinear-regression.html#cb201-164" aria-hidden="true" tabindex="-1"></a><span class="do">## $dev</span></span>
<span id="cb201-165"><a href="nonlinear-regression.html#cb201-165" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 55 55 53 52 50 56 69 65 80</span></span>
<span id="cb201-166"><a href="nonlinear-regression.html#cb201-166" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-167"><a href="nonlinear-regression.html#cb201-167" aria-hidden="true" tabindex="-1"></a><span class="do">## $k</span></span>
<span id="cb201-168"><a href="nonlinear-regression.html#cb201-168" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]       -Inf  0.0000000  0.6666667  1.0000000  1.7500000  2.0000000</span></span>
<span id="cb201-169"><a href="nonlinear-regression.html#cb201-169" aria-hidden="true" tabindex="-1"></a><span class="do">## [7]  4.2500000  5.0000000 23.0000000</span></span>
<span id="cb201-170"><a href="nonlinear-regression.html#cb201-170" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-171"><a href="nonlinear-regression.html#cb201-171" aria-hidden="true" tabindex="-1"></a><span class="do">## $method</span></span>
<span id="cb201-172"><a href="nonlinear-regression.html#cb201-172" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;misclass&quot;</span></span>
<span id="cb201-173"><a href="nonlinear-regression.html#cb201-173" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-174"><a href="nonlinear-regression.html#cb201-174" aria-hidden="true" tabindex="-1"></a><span class="do">## attr(,&quot;class&quot;)</span></span>
<span id="cb201-175"><a href="nonlinear-regression.html#cb201-175" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;prune&quot;         &quot;tree.sequence&quot;</span></span>
<span id="cb201-176"><a href="nonlinear-regression.html#cb201-176" aria-hidden="true" tabindex="-1"></a><span class="co"># графики изменения параметров метода по ходу обрезки дерева ###################</span></span>
<span id="cb201-177"><a href="nonlinear-regression.html#cb201-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-178"><a href="nonlinear-regression.html#cb201-178" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. ошибка с кросс-валидацией в зависимости от числа узлов</span></span>
<span id="cb201-179"><a href="nonlinear-regression.html#cb201-179" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb201-180"><a href="nonlinear-regression.html#cb201-180" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>size, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb201-181"><a href="nonlinear-regression.html#cb201-181" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb201-182"><a href="nonlinear-regression.html#cb201-182" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Число узлов (size)&#39;</span>)</span>
<span id="cb201-183"><a href="nonlinear-regression.html#cb201-183" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb201-184"><a href="nonlinear-regression.html#cb201-184" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.carseats<span class="sc">$</span>size[cv.carseats<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.carseats<span class="sc">$</span>dev)]</span>
<span id="cb201-185"><a href="nonlinear-regression.html#cb201-185" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb201-186"><a href="nonlinear-regression.html#cb201-186" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb201-187"><a href="nonlinear-regression.html#cb201-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-188"><a href="nonlinear-regression.html#cb201-188" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. ошибка с кросс-валидацией в зависимости от штрафа на сложность</span></span>
<span id="cb201-189"><a href="nonlinear-regression.html#cb201-189" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>k, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb201-190"><a href="nonlinear-regression.html#cb201-190" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb201-191"><a href="nonlinear-regression.html#cb201-191" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Штраф за сложность (k)&#39;</span>)</span>
<span id="cb201-192"><a href="nonlinear-regression.html#cb201-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-193"><a href="nonlinear-regression.html#cb201-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-194"><a href="nonlinear-regression.html#cb201-194" aria-hidden="true" tabindex="-1"></a>Как видно на графике слева, минимум частоты ошибок достигается при числе узлов <span class="fl">9.</span> Оценим точность дерева с <span class="dv">9</span> узлами.</span>
<span id="cb201-195"><a href="nonlinear-regression.html#cb201-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-196"><a href="nonlinear-regression.html#cb201-196" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 9 узлами</span></span>
<span id="cb201-197"><a href="nonlinear-regression.html#cb201-197" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">9</span>)</span>
<span id="cb201-198"><a href="nonlinear-regression.html#cb201-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-199"><a href="nonlinear-regression.html#cb201-199" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb201-200"><a href="nonlinear-regression.html#cb201-200" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb201-201"><a href="nonlinear-regression.html#cb201-201" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb201-202"><a href="nonlinear-regression.html#cb201-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-203"><a href="nonlinear-regression.html#cb201-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-204"><a href="nonlinear-regression.html#cb201-204" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb201-205"><a href="nonlinear-regression.html#cb201-205" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb201-206"><a href="nonlinear-regression.html#cb201-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-207"><a href="nonlinear-regression.html#cb201-207" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb201-208"><a href="nonlinear-regression.html#cb201-208" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb201-209"><a href="nonlinear-regression.html#cb201-209" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb201-210"><a href="nonlinear-regression.html#cb201-210" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb201-211"><a href="nonlinear-regression.html#cb201-211" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb201-212"><a href="nonlinear-regression.html#cb201-212" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  94  24</span></span>
<span id="cb201-213"><a href="nonlinear-regression.html#cb201-213" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 22  60</span></span>
<span id="cb201-214"><a href="nonlinear-regression.html#cb201-214" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb201-215"><a href="nonlinear-regression.html#cb201-215" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb201-216"><a href="nonlinear-regression.html#cb201-216" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb201-217"><a href="nonlinear-regression.html#cb201-217" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.77</span></span>
<span id="cb201-218"><a href="nonlinear-regression.html#cb201-218" aria-hidden="true" tabindex="-1"></a>Точность этой модели чуть выше точности исходного дерева и составляет <span class="dv">0</span>.<span class="fl">77.</span> Увеличив количество узлов, получим более глубокое дерево, но менее точное.</span>
<span id="cb201-219"><a href="nonlinear-regression.html#cb201-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-220"><a href="nonlinear-regression.html#cb201-220" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 13 узлами</span></span>
<span id="cb201-221"><a href="nonlinear-regression.html#cb201-221" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">15</span>)</span>
<span id="cb201-222"><a href="nonlinear-regression.html#cb201-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-223"><a href="nonlinear-regression.html#cb201-223" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb201-224"><a href="nonlinear-regression.html#cb201-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb201-225"><a href="nonlinear-regression.html#cb201-225" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb201-226"><a href="nonlinear-regression.html#cb201-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-227"><a href="nonlinear-regression.html#cb201-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-228"><a href="nonlinear-regression.html#cb201-228" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb201-229"><a href="nonlinear-regression.html#cb201-229" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb201-230"><a href="nonlinear-regression.html#cb201-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-231"><a href="nonlinear-regression.html#cb201-231" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb201-232"><a href="nonlinear-regression.html#cb201-232" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb201-233"><a href="nonlinear-regression.html#cb201-233" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb201-234"><a href="nonlinear-regression.html#cb201-234" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb201-235"><a href="nonlinear-regression.html#cb201-235" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb201-236"><a href="nonlinear-regression.html#cb201-236" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  22</span></span>
<span id="cb201-237"><a href="nonlinear-regression.html#cb201-237" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  62</span></span>
<span id="cb201-238"><a href="nonlinear-regression.html#cb201-238" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb201-239"><a href="nonlinear-regression.html#cb201-239" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb201-240"><a href="nonlinear-regression.html#cb201-240" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb201-241"><a href="nonlinear-regression.html#cb201-241" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.74</span></span>
<span id="cb201-242"><a href="nonlinear-regression.html#cb201-242" aria-hidden="true" tabindex="-1"></a><span class="co"># сбрасываем графические параметры</span></span>
<span id="cb201-243"><a href="nonlinear-regression.html#cb201-243" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb201-244"><a href="nonlinear-regression.html#cb201-244" aria-hidden="true" tabindex="-1"></a>Регрессионные деревья</span>
<span id="cb201-245"><a href="nonlinear-regression.html#cb201-245" aria-hidden="true" tabindex="-1"></a>Воспользуемся набором данных Boston.</span>
<span id="cb201-246"><a href="nonlinear-regression.html#cb201-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-247"><a href="nonlinear-regression.html#cb201-247" aria-hidden="true" tabindex="-1"></a>?Boston</span>
<span id="cb201-248"><a href="nonlinear-regression.html#cb201-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-249"><a href="nonlinear-regression.html#cb201-249" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb201-250"><a href="nonlinear-regression.html#cb201-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb201-251"><a href="nonlinear-regression.html#cb201-251" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Boston), <span class="fu">nrow</span>(Boston)<span class="sc">/</span><span class="dv">2</span>) <span class="co"># обучающая выборка -- 50%</span></span>
<span id="cb201-252"><a href="nonlinear-regression.html#cb201-252" aria-hidden="true" tabindex="-1"></a>Построим дерево регрессии для зависимой переменной medv<span class="sc">:</span> медианная стоимости домов, в которых живут собственники (тыс. долл.).</span>
<span id="cb201-253"><a href="nonlinear-regression.html#cb201-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-254"><a href="nonlinear-regression.html#cb201-254" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb201-255"><a href="nonlinear-regression.html#cb201-255" aria-hidden="true" tabindex="-1"></a>tree.boston <span class="ot">&lt;-</span> <span class="fu">tree</span>(medv <span class="sc">~</span> ., Boston, <span class="at">subset =</span> train)</span>
<span id="cb201-256"><a href="nonlinear-regression.html#cb201-256" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.boston)</span>
<span id="cb201-257"><a href="nonlinear-regression.html#cb201-257" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-258"><a href="nonlinear-regression.html#cb201-258" aria-hidden="true" tabindex="-1"></a><span class="do">## Regression tree:</span></span>
<span id="cb201-259"><a href="nonlinear-regression.html#cb201-259" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = medv ~ ., data = Boston, subset = train)</span></span>
<span id="cb201-260"><a href="nonlinear-regression.html#cb201-260" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb201-261"><a href="nonlinear-regression.html#cb201-261" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;lstat&quot; &quot;rm&quot;    &quot;dis&quot;  </span></span>
<span id="cb201-262"><a href="nonlinear-regression.html#cb201-262" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  8 </span></span>
<span id="cb201-263"><a href="nonlinear-regression.html#cb201-263" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  12.65 = 3099 / 245 </span></span>
<span id="cb201-264"><a href="nonlinear-regression.html#cb201-264" aria-hidden="true" tabindex="-1"></a><span class="do">## Distribution of residuals:</span></span>
<span id="cb201-265"><a href="nonlinear-regression.html#cb201-265" aria-hidden="true" tabindex="-1"></a><span class="do">##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. </span></span>
<span id="cb201-266"><a href="nonlinear-regression.html#cb201-266" aria-hidden="true" tabindex="-1"></a><span class="do">## -14.10000  -2.04200  -0.05357   0.00000   1.96000  12.60000</span></span>
<span id="cb201-267"><a href="nonlinear-regression.html#cb201-267" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb201-268"><a href="nonlinear-regression.html#cb201-268" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.boston)</span>
<span id="cb201-269"><a href="nonlinear-regression.html#cb201-269" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb201-270"><a href="nonlinear-regression.html#cb201-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-271"><a href="nonlinear-regression.html#cb201-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-272"><a href="nonlinear-regression.html#cb201-272" aria-hidden="true" tabindex="-1"></a>Снова сделаем обрезку дерева в целях улучшения качества прогноза.</span>
<span id="cb201-273"><a href="nonlinear-regression.html#cb201-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-274"><a href="nonlinear-regression.html#cb201-274" aria-hidden="true" tabindex="-1"></a>cv.boston <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.boston)</span>
<span id="cb201-275"><a href="nonlinear-regression.html#cb201-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-276"><a href="nonlinear-regression.html#cb201-276" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb201-277"><a href="nonlinear-regression.html#cb201-277" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.boston<span class="sc">$</span>size, cv.boston<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&#39;b&#39;</span>)</span>
<span id="cb201-278"><a href="nonlinear-regression.html#cb201-278" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.boston<span class="sc">$</span>size[cv.boston<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.boston<span class="sc">$</span>dev)]</span>
<span id="cb201-279"><a href="nonlinear-regression.html#cb201-279" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb201-280"><a href="nonlinear-regression.html#cb201-280" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb201-281"><a href="nonlinear-regression.html#cb201-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-282"><a href="nonlinear-regression.html#cb201-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-283"><a href="nonlinear-regression.html#cb201-283" aria-hidden="true" tabindex="-1"></a>В данном случаем минимум ошибки соответствует самому сложному дереву, с <span class="dv">8</span> узлами. Покажем, как при желании можно обрезать дерево до <span class="dv">7</span> узлов (ошибка ненамного выше, чем минимальная).</span>
<span id="cb201-284"><a href="nonlinear-regression.html#cb201-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-285"><a href="nonlinear-regression.html#cb201-285" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 7 узлами</span></span>
<span id="cb201-286"><a href="nonlinear-regression.html#cb201-286" aria-hidden="true" tabindex="-1"></a>prune.boston <span class="ot">=</span> <span class="fu">prune.tree</span>(tree.boston, <span class="at">best =</span> <span class="dv">7</span>)</span>
<span id="cb201-287"><a href="nonlinear-regression.html#cb201-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-288"><a href="nonlinear-regression.html#cb201-288" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb201-289"><a href="nonlinear-regression.html#cb201-289" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.boston)</span>
<span id="cb201-290"><a href="nonlinear-regression.html#cb201-290" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb201-291"><a href="nonlinear-regression.html#cb201-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-292"><a href="nonlinear-regression.html#cb201-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-293"><a href="nonlinear-regression.html#cb201-293" aria-hidden="true" tabindex="-1"></a>Прогноз сделаем по необрезанному дереву, т.к. там ошибка, оцененная по методу перекрёстной проверки, минимальна.</span>
<span id="cb201-294"><a href="nonlinear-regression.html#cb201-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-295"><a href="nonlinear-regression.html#cb201-295" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по лучшей модели (8 узлов)</span></span>
<span id="cb201-296"><a href="nonlinear-regression.html#cb201-296" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb201-297"><a href="nonlinear-regression.html#cb201-297" aria-hidden="true" tabindex="-1"></a>boston.test <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>train, <span class="st">&quot;medv&quot;</span>]</span>
<span id="cb201-298"><a href="nonlinear-regression.html#cb201-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-299"><a href="nonlinear-regression.html#cb201-299" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb201-300"><a href="nonlinear-regression.html#cb201-300" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat, boston.test)</span>
<span id="cb201-301"><a href="nonlinear-regression.html#cb201-301" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb201-302"><a href="nonlinear-regression.html#cb201-302" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb201-303"><a href="nonlinear-regression.html#cb201-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-304"><a href="nonlinear-regression.html#cb201-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-305"><a href="nonlinear-regression.html#cb201-305" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb201-306"><a href="nonlinear-regression.html#cb201-306" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb201-307"><a href="nonlinear-regression.html#cb201-307" aria-hidden="true" tabindex="-1"></a>MSE на тестовой выборке равна <span class="fl">25.05</span> (тыс.долл.).</span>
<span id="cb201-308"><a href="nonlinear-regression.html#cb201-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-309"><a href="nonlinear-regression.html#cb201-309" aria-hidden="true" tabindex="-1"></a>Бэггинг и метод случайного леса</span>
<span id="cb201-310"><a href="nonlinear-regression.html#cb201-310" aria-hidden="true" tabindex="-1"></a>Рассмотрим более сложные методы улучшения качества дерева. Бэггинг – частный случай случайного леса с m<span class="ot">=</span>p, поэтому и то, и другое можно построить функцией <span class="fu">randomForest</span>().</span>
<span id="cb201-311"><a href="nonlinear-regression.html#cb201-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-312"><a href="nonlinear-regression.html#cb201-312" aria-hidden="true" tabindex="-1"></a>Для начала используем бэггинг, причём возьмём все <span class="dv">13</span> предикторов на каждом шаге (аргумент mtry).</span>
<span id="cb201-313"><a href="nonlinear-regression.html#cb201-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-314"><a href="nonlinear-regression.html#cb201-314" aria-hidden="true" tabindex="-1"></a><span class="co"># бэггинг с 13 предикторами</span></span>
<span id="cb201-315"><a href="nonlinear-regression.html#cb201-315" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb201-316"><a href="nonlinear-regression.html#cb201-316" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train, </span>
<span id="cb201-317"><a href="nonlinear-regression.html#cb201-317" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb201-318"><a href="nonlinear-regression.html#cb201-318" aria-hidden="true" tabindex="-1"></a>bag.boston</span>
<span id="cb201-319"><a href="nonlinear-regression.html#cb201-319" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-320"><a href="nonlinear-regression.html#cb201-320" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb201-321"><a href="nonlinear-regression.html#cb201-321" aria-hidden="true" tabindex="-1"></a><span class="do">##  randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE,      subset = train) </span></span>
<span id="cb201-322"><a href="nonlinear-regression.html#cb201-322" aria-hidden="true" tabindex="-1"></a><span class="do">##                Type of random forest: regression</span></span>
<span id="cb201-323"><a href="nonlinear-regression.html#cb201-323" aria-hidden="true" tabindex="-1"></a><span class="do">##                      Number of trees: 500</span></span>
<span id="cb201-324"><a href="nonlinear-regression.html#cb201-324" aria-hidden="true" tabindex="-1"></a><span class="do">## No. of variables tried at each split: 13</span></span>
<span id="cb201-325"><a href="nonlinear-regression.html#cb201-325" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb201-326"><a href="nonlinear-regression.html#cb201-326" aria-hidden="true" tabindex="-1"></a><span class="do">##           Mean of squared residuals: 11.15723</span></span>
<span id="cb201-327"><a href="nonlinear-regression.html#cb201-327" aria-hidden="true" tabindex="-1"></a><span class="do">##                     % Var explained: 86.49</span></span>
<span id="cb201-328"><a href="nonlinear-regression.html#cb201-328" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb201-329"><a href="nonlinear-regression.html#cb201-329" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">=</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb201-330"><a href="nonlinear-regression.html#cb201-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-331"><a href="nonlinear-regression.html#cb201-331" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb201-332"><a href="nonlinear-regression.html#cb201-332" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat.bag, boston.test)</span>
<span id="cb201-333"><a href="nonlinear-regression.html#cb201-333" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb201-334"><a href="nonlinear-regression.html#cb201-334" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb201-335"><a href="nonlinear-regression.html#cb201-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-336"><a href="nonlinear-regression.html#cb201-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-337"><a href="nonlinear-regression.html#cb201-337" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb201-338"><a href="nonlinear-regression.html#cb201-338" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb201-339"><a href="nonlinear-regression.html#cb201-339" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb201-340"><a href="nonlinear-regression.html#cb201-340" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.50808</span></span>
<span id="cb201-341"><a href="nonlinear-regression.html#cb201-341" aria-hidden="true" tabindex="-1"></a>Ошибка на тестовой выборке равна <span class="dv">13</span>.<span class="fl">51.</span></span>
<span id="cb201-342"><a href="nonlinear-regression.html#cb201-342" aria-hidden="true" tabindex="-1"></a>Можно изменить число деревьев с помощью аргумента ntree.</span>
<span id="cb201-343"><a href="nonlinear-regression.html#cb201-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-344"><a href="nonlinear-regression.html#cb201-344" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb201-345"><a href="nonlinear-regression.html#cb201-345" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">ntree =</span> <span class="dv">25</span>)</span>
<span id="cb201-346"><a href="nonlinear-regression.html#cb201-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-347"><a href="nonlinear-regression.html#cb201-347" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb201-348"><a href="nonlinear-regression.html#cb201-348" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">&lt;-</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb201-349"><a href="nonlinear-regression.html#cb201-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-350"><a href="nonlinear-regression.html#cb201-350" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb201-351"><a href="nonlinear-regression.html#cb201-351" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb201-352"><a href="nonlinear-regression.html#cb201-352" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb201-353"><a href="nonlinear-regression.html#cb201-353" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.94835</span></span>
<span id="cb201-354"><a href="nonlinear-regression.html#cb201-354" aria-hidden="true" tabindex="-1"></a>Но, как видно, это только ухудшает прогноз.</span>
<span id="cb201-355"><a href="nonlinear-regression.html#cb201-355" aria-hidden="true" tabindex="-1"></a>Теперь попробуем вырастить случайный лес. Берём <span class="dv">6</span> предикторов на каждом шаге.</span>
<span id="cb201-356"><a href="nonlinear-regression.html#cb201-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-357"><a href="nonlinear-regression.html#cb201-357" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb201-358"><a href="nonlinear-regression.html#cb201-358" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb201-359"><a href="nonlinear-regression.html#cb201-359" aria-hidden="true" tabindex="-1"></a>rf.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb201-360"><a href="nonlinear-regression.html#cb201-360" aria-hidden="true" tabindex="-1"></a>                          <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb201-361"><a href="nonlinear-regression.html#cb201-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-362"><a href="nonlinear-regression.html#cb201-362" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb201-363"><a href="nonlinear-regression.html#cb201-363" aria-hidden="true" tabindex="-1"></a>yhat.rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb201-364"><a href="nonlinear-regression.html#cb201-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-365"><a href="nonlinear-regression.html#cb201-365" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb201-366"><a href="nonlinear-regression.html#cb201-366" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.rf <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb201-367"><a href="nonlinear-regression.html#cb201-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-368"><a href="nonlinear-regression.html#cb201-368" aria-hidden="true" tabindex="-1"></a><span class="co"># важность предикторов</span></span>
<span id="cb201-369"><a href="nonlinear-regression.html#cb201-369" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf.boston)  <span class="co"># оценки </span></span>
<span id="cb201-370"><a href="nonlinear-regression.html#cb201-370" aria-hidden="true" tabindex="-1"></a><span class="do">##           %IncMSE IncNodePurity</span></span>
<span id="cb201-371"><a href="nonlinear-regression.html#cb201-371" aria-hidden="true" tabindex="-1"></a><span class="do">## crim    12.132320     986.50338</span></span>
<span id="cb201-372"><a href="nonlinear-regression.html#cb201-372" aria-hidden="true" tabindex="-1"></a><span class="do">## zn       1.955579      57.96945</span></span>
<span id="cb201-373"><a href="nonlinear-regression.html#cb201-373" aria-hidden="true" tabindex="-1"></a><span class="do">## indus    9.069302     882.78261</span></span>
<span id="cb201-374"><a href="nonlinear-regression.html#cb201-374" aria-hidden="true" tabindex="-1"></a><span class="do">## chas     2.210835      45.22941</span></span>
<span id="cb201-375"><a href="nonlinear-regression.html#cb201-375" aria-hidden="true" tabindex="-1"></a><span class="do">## nox     11.104823    1044.33776</span></span>
<span id="cb201-376"><a href="nonlinear-regression.html#cb201-376" aria-hidden="true" tabindex="-1"></a><span class="do">## rm      31.784033    6359.31971</span></span>
<span id="cb201-377"><a href="nonlinear-regression.html#cb201-377" aria-hidden="true" tabindex="-1"></a><span class="do">## age     10.962684     516.82969</span></span>
<span id="cb201-378"><a href="nonlinear-regression.html#cb201-378" aria-hidden="true" tabindex="-1"></a><span class="do">## dis     15.015236    1224.11605</span></span>
<span id="cb201-379"><a href="nonlinear-regression.html#cb201-379" aria-hidden="true" tabindex="-1"></a><span class="do">## rad      4.118011      95.94586</span></span>
<span id="cb201-380"><a href="nonlinear-regression.html#cb201-380" aria-hidden="true" tabindex="-1"></a><span class="do">## tax      8.587932     502.96719</span></span>
<span id="cb201-381"><a href="nonlinear-regression.html#cb201-381" aria-hidden="true" tabindex="-1"></a><span class="do">## ptratio 12.503896     830.77523</span></span>
<span id="cb201-382"><a href="nonlinear-regression.html#cb201-382" aria-hidden="true" tabindex="-1"></a><span class="do">## black    6.702609     341.30361</span></span>
<span id="cb201-383"><a href="nonlinear-regression.html#cb201-383" aria-hidden="true" tabindex="-1"></a><span class="do">## lstat   30.695224    7505.73936</span></span>
<span id="cb201-384"><a href="nonlinear-regression.html#cb201-384" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.boston)  <span class="co"># графики</span></span>
<span id="cb201-385"><a href="nonlinear-regression.html#cb201-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-386"><a href="nonlinear-regression.html#cb201-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-387"><a href="nonlinear-regression.html#cb201-387" aria-hidden="true" tabindex="-1"></a>Ошибка по модели случайного леса равна <span class="fl">11.66</span>, что ниже, чем для бэггинга.</span>
<span id="cb201-388"><a href="nonlinear-regression.html#cb201-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-389"><a href="nonlinear-regression.html#cb201-389" aria-hidden="true" tabindex="-1"></a>Бустинг</span>
<span id="cb201-390"><a href="nonlinear-regression.html#cb201-390" aria-hidden="true" tabindex="-1"></a>Построим <span class="dv">5000</span> регрессионных деревьев с глубиной <span class="fl">4.</span></span>
<span id="cb201-391"><a href="nonlinear-regression.html#cb201-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-392"><a href="nonlinear-regression.html#cb201-392" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb201-393"><a href="nonlinear-regression.html#cb201-393" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb201-394"><a href="nonlinear-regression.html#cb201-394" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>)</span>
<span id="cb201-395"><a href="nonlinear-regression.html#cb201-395" aria-hidden="true" tabindex="-1"></a><span class="co"># график и таблица относительной важности переменных</span></span>
<span id="cb201-396"><a href="nonlinear-regression.html#cb201-396" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boost.boston)</span>
<span id="cb201-397"><a href="nonlinear-regression.html#cb201-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-398"><a href="nonlinear-regression.html#cb201-398" aria-hidden="true" tabindex="-1"></a><span class="co"># графики частной зависимости для двух наиболее важных предикторов</span></span>
<span id="cb201-399"><a href="nonlinear-regression.html#cb201-399" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb201-400"><a href="nonlinear-regression.html#cb201-400" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;rm&quot;</span>)</span>
<span id="cb201-401"><a href="nonlinear-regression.html#cb201-401" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb201-402"><a href="nonlinear-regression.html#cb201-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-403"><a href="nonlinear-regression.html#cb201-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-404"><a href="nonlinear-regression.html#cb201-404" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb201-405"><a href="nonlinear-regression.html#cb201-405" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb201-406"><a href="nonlinear-regression.html#cb201-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-407"><a href="nonlinear-regression.html#cb201-407" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb201-408"><a href="nonlinear-regression.html#cb201-408" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb201-409"><a href="nonlinear-regression.html#cb201-409" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb201-410"><a href="nonlinear-regression.html#cb201-410" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.84434</span></span>
<span id="cb201-411"><a href="nonlinear-regression.html#cb201-411" aria-hidden="true" tabindex="-1"></a>Настройку бустинга можно делать с помощью гиперпараметра λ (аргумент shrinkage). Установим его равным <span class="dv">0</span>.<span class="fl">2.</span></span>
<span id="cb201-412"><a href="nonlinear-regression.html#cb201-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-413"><a href="nonlinear-regression.html#cb201-413" aria-hidden="true" tabindex="-1"></a><span class="co"># меняем значение гиперпараметра (lambda) на 0.2 -- аргумент shrinkage</span></span>
<span id="cb201-414"><a href="nonlinear-regression.html#cb201-414" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb201-415"><a href="nonlinear-regression.html#cb201-415" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>, </span>
<span id="cb201-416"><a href="nonlinear-regression.html#cb201-416" aria-hidden="true" tabindex="-1"></a>                    <span class="at">shrinkage =</span> <span class="fl">0.2</span>, <span class="at">verbose =</span> F)</span>
<span id="cb201-417"><a href="nonlinear-regression.html#cb201-417" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb201-418"><a href="nonlinear-regression.html#cb201-418" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb201-419"><a href="nonlinear-regression.html#cb201-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb201-420"><a href="nonlinear-regression.html#cb201-420" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE а тестовой</span></span>
<span id="cb201-421"><a href="nonlinear-regression.html#cb201-421" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb201-422"><a href="nonlinear-regression.html#cb201-422" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb201-423"><a href="nonlinear-regression.html#cb201-423" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.51109</span></span>
<span id="cb201-424"><a href="nonlinear-regression.html#cb201-424" aria-hidden="true" tabindex="-1"></a>Таким образом, изменив гиперпараметр, мы ещё немного снизили ошибку прогноза.</span></code></pre></div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression-complex-cases.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/35_nonlinear_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
