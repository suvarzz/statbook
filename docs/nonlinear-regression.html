<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 24 Nonlinear regression | R statistics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 24 Nonlinear regression | R statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 24 Nonlinear regression | R statistics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Mark Goldberg" />


<meta name="date" content="2021-04-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-regression-complex-cases.html"/>
<link rel="next" href="multiple-linear-regression.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html"><i class="fa fa-check"></i><b>2</b> Statistics R functions reference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#get-data"><i class="fa fa-check"></i><b>2.1</b> Get data</a></li>
<li class="chapter" data-level="2.2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#data-inspection"><i class="fa fa-check"></i><b>2.2</b> Data inspection</a></li>
<li class="chapter" data-level="2.3" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#plots"><i class="fa fa-check"></i><b>2.3</b> Plots</a></li>
<li class="chapter" data-level="2.4" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#analysis-of-the-distribution"><i class="fa fa-check"></i><b>2.4</b> Analysis of the distribution</a></li>
<li class="chapter" data-level="2.5" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#distributions"><i class="fa fa-check"></i><b>2.5</b> Distributions</a></li>
<li class="chapter" data-level="2.6" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#t-test"><i class="fa fa-check"></i><b>2.6</b> t-Test</a></li>
<li class="chapter" data-level="2.7" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#anova"><i class="fa fa-check"></i><b>2.7</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>3</b> Basic Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="basic-statistics.html"><a href="basic-statistics.html#definitions"><i class="fa fa-check"></i><b>3.1</b> Definitions</a></li>
<li class="chapter" data-level="3.2" data-path="basic-statistics.html"><a href="basic-statistics.html#analysis-of-sample-distribution"><i class="fa fa-check"></i><b>3.2</b> Analysis of sample distribution</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="basic-statistics.html"><a href="basic-statistics.html#histogram"><i class="fa fa-check"></i><b>3.2.1</b> Histogram</a></li>
<li class="chapter" data-level="3.2.2" data-path="basic-statistics.html"><a href="basic-statistics.html#outliers"><i class="fa fa-check"></i><b>3.2.2</b> Outliers</a></li>
<li class="chapter" data-level="3.2.3" data-path="basic-statistics.html"><a href="basic-statistics.html#normality"><i class="fa fa-check"></i><b>3.2.3</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="basic-statistics.html"><a href="basic-statistics.html#confidence-interval"><i class="fa fa-check"></i><b>3.3</b> Confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-normalization.html"><a href="data-normalization.html"><i class="fa fa-check"></i><b>4</b> Data normalization</a></li>
<li class="chapter" data-level="5" data-path="primary-analysis.html"><a href="primary-analysis.html"><i class="fa fa-check"></i><b>5</b> Primary analysis</a></li>
<li class="chapter" data-level="6" data-path="statistical-distributions.html"><a href="statistical-distributions.html"><i class="fa fa-check"></i><b>6</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistical-distributions.html"><a href="statistical-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>6.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="6.2" data-path="statistical-distributions.html"><a href="statistical-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>6.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="6.3" data-path="statistical-distributions.html"><a href="statistical-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>6.3</b> Binomial Distribution</a></li>
<li class="chapter" data-level="6.4" data-path="statistical-distributions.html"><a href="statistical-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>6.4</b> Geometric Distribution</a></li>
<li class="chapter" data-level="6.5" data-path="statistical-distributions.html"><a href="statistical-distributions.html#uniform-distributions"><i class="fa fa-check"></i><b>6.5</b> Uniform Distributions</a></li>
<li class="chapter" data-level="6.6" data-path="statistical-distributions.html"><a href="statistical-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>6.6</b> Poisson Distribution</a></li>
<li class="chapter" data-level="6.7" data-path="statistical-distributions.html"><a href="statistical-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>6.7</b> Exponential Distribution</a></li>
<li class="chapter" data-level="6.8" data-path="statistical-distributions.html"><a href="statistical-distributions.html#chi-squared-distribution"><i class="fa fa-check"></i><b>6.8</b> Chi-squared Distribution</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>7</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-theory"><i class="fa fa-check"></i><b>7.1</b> Hypothesis testing theory</a></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-practice"><i class="fa fa-check"></i><b>7.2</b> Hypothesis test (Practice)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="t-procedures.html"><a href="t-procedures.html"><i class="fa fa-check"></i><b>8</b> t-Procedures</a>
<ul>
<li class="chapter" data-level="8.1" data-path="t-procedures.html"><a href="t-procedures.html#t-test-and-normal-distribution"><i class="fa fa-check"></i><b>8.1</b> t-test and normal distribution</a></li>
<li class="chapter" data-level="8.2" data-path="t-procedures.html"><a href="t-procedures.html#one-sample-t-test"><i class="fa fa-check"></i><b>8.2</b> One-sample t-test</a></li>
<li class="chapter" data-level="8.3" data-path="t-procedures.html"><a href="t-procedures.html#practical-example-t-test-in-r"><i class="fa fa-check"></i><b>8.3</b> Practical example: t-test in R</a></li>
<li class="chapter" data-level="8.4" data-path="t-procedures.html"><a href="t-procedures.html#two-samples-t-test"><i class="fa fa-check"></i><b>8.4</b> Two samples t-test</a></li>
<li class="chapter" data-level="8.5" data-path="t-procedures.html"><a href="t-procedures.html#compare-students-t-and-normal-distributions"><i class="fa fa-check"></i><b>8.5</b> Compare Student’s t and normal distributions</a></li>
<li class="chapter" data-level="8.6" data-path="t-procedures.html"><a href="t-procedures.html#non-parametric-tests"><i class="fa fa-check"></i><b>8.6</b> Non-parametric tests</a></li>
<li class="chapter" data-level="8.7" data-path="t-procedures.html"><a href="t-procedures.html#mann-whitney-u-rank-sum-test"><i class="fa fa-check"></i><b>8.7</b> Mann-Whitney U Rank Sum Test</a></li>
<li class="chapter" data-level="8.8" data-path="t-procedures.html"><a href="t-procedures.html#wilcoxon-test"><i class="fa fa-check"></i><b>8.8</b> Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html"><i class="fa fa-check"></i><b>9</b> Tests for categorical variables</a>
<ul>
<li class="chapter" data-level="9.1" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html#chi-squared-tests"><i class="fa fa-check"></i><b>9.1</b> Chi-squared tests</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>10</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="10.1" data-path="multiple-testing.html"><a href="multiple-testing.html#the-bonferroni-correction"><i class="fa fa-check"></i><b>10.1</b> The Bonferroni correction</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="sources.html"><a href="sources.html"><i class="fa fa-check"></i><b>11</b> Sources</a>
<ul>
<li class="chapter" data-level="11.1" data-path="sources.html"><a href="sources.html#t-test-1"><i class="fa fa-check"></i><b>11.1</b> t-test</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="sources.html"><a href="sources.html#two-tailed-test"><i class="fa fa-check"></i><b>11.1.1</b> Two-tailed test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>12</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="12.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>12.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="12.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#sources-1"><i class="fa fa-check"></i><b>12.2</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="t-test-anova-difference.html"><a href="t-test-anova-difference.html"><i class="fa fa-check"></i><b>13</b> t-test ANOVA difference</a></li>
<li class="chapter" data-level="14" data-path="chi-squared-test.html"><a href="chi-squared-test.html"><i class="fa fa-check"></i><b>14</b> Chi-squared test</a>
<ul>
<li class="chapter" data-level="14.1" data-path="chi-squared-test.html"><a href="chi-squared-test.html#multinomial-goodness-of-fit"><i class="fa fa-check"></i><b>14.1</b> Multinomial Goodness of Fit</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html"><i class="fa fa-check"></i><b>15</b> Non-parametric Methods</a>
<ul>
<li class="chapter" data-level="15.1" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#sign-test"><i class="fa fa-check"></i><b>15.1</b> Sign Test</a></li>
<li class="chapter" data-level="15.2" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>15.2</b> Wilcoxon Signed-Rank Test</a></li>
<li class="chapter" data-level="15.3" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#mann-whitney-wilcoxon-test"><i class="fa fa-check"></i><b>15.3</b> Mann-Whitney-Wilcoxon Test</a></li>
<li class="chapter" data-level="15.4" data-path="non-parametric-methods.html"><a href="non-parametric-methods.html#kruskal-wallis-test"><i class="fa fa-check"></i><b>15.4</b> Kruskal-Wallis Test</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="wilcoxon-signed-rank-test-1.html"><a href="wilcoxon-signed-rank-test-1.html"><i class="fa fa-check"></i><b>16</b> Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="17" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>17</b> Support Vector Machine</a></li>
<li class="chapter" data-level="18" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>18</b> Correlation</a></li>
<li class="chapter" data-level="19" data-path="methods-and-algorithms-of-machine-learning.html"><a href="methods-and-algorithms-of-machine-learning.html"><i class="fa fa-check"></i><b>19</b> Methods and algorithms of machine learning</a></li>
<li class="chapter" data-level="20" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html"><i class="fa fa-check"></i><b>20</b> Machine Learning Functions Reference</a>
<ul>
<li class="chapter" data-level="20.1" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html#linear-regression"><i class="fa fa-check"></i><b>20.1</b> Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="split-data-into-train-and-test-subsets.html"><a href="split-data-into-train-and-test-subsets.html"><i class="fa fa-check"></i><b>21</b> Split data into train and test subsets</a></li>
<li class="chapter" data-level="22" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>22</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="22.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression---theory"><i class="fa fa-check"></i><b>22.1</b> Linear regression - theory</a></li>
<li class="chapter" data-level="22.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-random-data-set-for-the-linear-model"><i class="fa fa-check"></i><b>22.2</b> Generate random data set for the linear model</a></li>
<li class="chapter" data-level="22.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-example"><i class="fa fa-check"></i><b>22.3</b> Practical example</a></li>
<li class="chapter" data-level="22.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#mean-squared-error-mse"><i class="fa fa-check"></i><b>22.4</b> Mean squared error (MSE)</a></li>
<li class="chapter" data-level="22.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-model-in-r"><i class="fa fa-check"></i><b>22.5</b> Linear model in R</a></li>
<li class="chapter" data-level="22.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression-model-for-multiple-parameters"><i class="fa fa-check"></i><b>22.6</b> Linear regression model for multiple parameters</a></li>
<li class="chapter" data-level="22.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#choosing-explanatory-variables-for-the-model"><i class="fa fa-check"></i><b>22.7</b> Choosing explanatory variables for the model</a></li>
<li class="chapter" data-level="22.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#assessment-of-model-performance-for-categorical-data."><i class="fa fa-check"></i><b>22.8</b> Assessment of model performance for categorical data.</a></li>
<li class="chapter" data-level="22.9" data-path="linear-regression-1.html"><a href="linear-regression-1.html#confidence-intervals-for-linear-model"><i class="fa fa-check"></i><b>22.9</b> Confidence intervals for linear model</a></li>
<li class="chapter" data-level="22.10" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression"><i class="fa fa-check"></i><b>22.10</b> Practical examples for linear model regression</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html"><i class="fa fa-check"></i><b>23</b> Linear regression complex cases</a>
<ul>
<li class="chapter" data-level="23.1" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#cars"><i class="fa fa-check"></i><b>23.1</b> Cars</a></li>
<li class="chapter" data-level="23.2" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#linear-regression-modeling-compair-with-knn"><i class="fa fa-check"></i><b>23.2</b> Linear regression modeling, compair with kNN</a></li>
<li class="chapter" data-level="23.3" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#more-complex-example"><i class="fa fa-check"></i><b>23.3</b> More complex example</a></li>
<li class="chapter" data-level="23.4" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part"><i class="fa fa-check"></i><b>23.4</b> NEXT part</a></li>
<li class="chapter" data-level="23.5" data-path="linear-regression-complex-cases.html"><a href="linear-regression-complex-cases.html#next-part-1"><i class="fa fa-check"></i><b>23.5</b> NEXT Part</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="nonlinear-regression.html"><a href="nonlinear-regression.html"><i class="fa fa-check"></i><b>24</b> Nonlinear regression</a></li>
<li class="chapter" data-level="25" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>25</b> Multiple linear regression</a></li>
<li class="chapter" data-level="26" data-path="spline-model.html"><a href="spline-model.html"><i class="fa fa-check"></i><b>26</b> Spline model</a>
<ul>
<li class="chapter" data-level="26.1" data-path="spline-model.html"><a href="spline-model.html#generate-dataset-from-a-given-function"><i class="fa fa-check"></i><b>26.1</b> Generate dataset from a given function</a></li>
<li class="chapter" data-level="26.2" data-path="spline-model.html"><a href="spline-model.html#split-data-for-train-and-test"><i class="fa fa-check"></i><b>26.2</b> Split data for train and test</a></li>
<li class="chapter" data-level="26.3" data-path="spline-model.html"><a href="spline-model.html#diagram-of-the-given-function-and-generated-datasets"><i class="fa fa-check"></i><b>26.3</b> Diagram of the given function and generated datasets</a></li>
<li class="chapter" data-level="26.4" data-path="spline-model.html"><a href="spline-model.html#build-a-model-using-splines"><i class="fa fa-check"></i><b>26.4</b> Build a model using splines</a></li>
<li class="chapter" data-level="26.5" data-path="spline-model.html"><a href="spline-model.html#diagram-of-mse-for-train-and-test-data"><i class="fa fa-check"></i><b>26.5</b> Diagram of MSE for train and test data</a></li>
<li class="chapter" data-level="26.6" data-path="spline-model.html"><a href="spline-model.html#build-optimal-model-and-plot-for-the-model"><i class="fa fa-check"></i><b>26.6</b> Build optimal model and plot for the model</a></li>
<li class="chapter" data-level="26.7" data-path="spline-model.html"><a href="spline-model.html#bibliograpy"><i class="fa fa-check"></i><b>26.7</b> Bibliograpy</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>27</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="27.1" data-path="logistic-regression.html"><a href="logistic-regression.html#confusion-matrix"><i class="fa fa-check"></i><b>27.1</b> Confusion matrix</a></li>
<li class="chapter" data-level="27.2" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-2"><i class="fa fa-check"></i><b>27.2</b> Next part</a></li>
<li class="chapter" data-level="27.3" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-3"><i class="fa fa-check"></i><b>27.3</b> NExt part</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>28</b> Clustering</a>
<ul>
<li class="chapter" data-level="28.1" data-path="clustering.html"><a href="clustering.html#next-part-4"><i class="fa fa-check"></i><b>28.1</b> Next part</a></li>
<li class="chapter" data-level="28.2" data-path="clustering.html"><a href="clustering.html#example"><i class="fa fa-check"></i><b>28.2</b> Example</a></li>
<li class="chapter" data-level="28.3" data-path="clustering.html"><a href="clustering.html#next-part-5"><i class="fa fa-check"></i><b>28.3</b> NEXT PART</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="learning-vector-quantization.html"><a href="learning-vector-quantization.html"><i class="fa fa-check"></i><b>29</b> Learning Vector Quantization</a></li>
<li class="chapter" data-level="30" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>30</b> Bayesian Statistics</a></li>
<li class="chapter" data-level="31" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>31</b> Naive Bayes</a></li>
<li class="chapter" data-level="32" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>32</b> Markov Chain Monte Carlo (MCMC)</a></li>
<li class="chapter" data-level="33" data-path="simple-markov-process.html"><a href="simple-markov-process.html"><i class="fa fa-check"></i><b>33</b> Simple Markov process</a>
<ul>
<li class="chapter" data-level="33.0.1" data-path="simple-markov-process.html"><a href="simple-markov-process.html#sources-2"><i class="fa fa-check"></i><b>33.0.1</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="tree-based-models.html"><a href="tree-based-models.html"><i class="fa fa-check"></i><b>34</b> Tree-based models</a>
<ul>
<li class="chapter" data-level="34.1" data-path="tree-based-models.html"><a href="tree-based-models.html#classification-tree-example"><i class="fa fa-check"></i><b>34.1</b> Classification Tree example</a></li>
<li class="chapter" data-level="34.2" data-path="tree-based-models.html"><a href="tree-based-models.html#regression-tree-example"><i class="fa fa-check"></i><b>34.2</b> Regression Tree example</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonlinear-regression" class="section level1" number="24">
<h1><span class="header-section-number">Chapter 24</span> Nonlinear regression</h1>
<p>Nonlinear regression is a form of regression analysis in which observational data are modeled by a function which is a nonlinear combination of the model parameters and <strong>depends on one or more independent variables</strong>.<br />
Some nonlinear data sets can be transformed to a linear model.<br />
Sone can not be transformed. For such modeling methods of Numerical analysis should be applied such as Newton’s method, Gauss-Newton method and Levenberg–Marquardt method.</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="nonlinear-regression.html#cb166-1" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb166-2"><a href="nonlinear-regression.html#cb166-2" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">7</span></span>
<span id="cb166-3"><a href="nonlinear-regression.html#cb166-3" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb166-4"><a href="nonlinear-regression.html#cb166-4" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb166-5"><a href="nonlinear-regression.html#cb166-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb166-6"><a href="nonlinear-regression.html#cb166-6" aria-hidden="true" tabindex="-1"></a>    оценивать полиномиальную регрессию;</span>
<span id="cb166-7"><a href="nonlinear-regression.html#cb166-7" aria-hidden="true" tabindex="-1"></a>аппроксимировать нелинейные модели ступенчатыми функциями;</span>
<span id="cb166-8"><a href="nonlinear-regression.html#cb166-8" aria-hidden="true" tabindex="-1"></a>строить сплайны;</span>
<span id="cb166-9"><a href="nonlinear-regression.html#cb166-9" aria-hidden="true" tabindex="-1"></a>работать с локальной регрессией;</span>
<span id="cb166-10"><a href="nonlinear-regression.html#cb166-10" aria-hidden="true" tabindex="-1"></a>строить обобщённые линейные модели (GAM).</span>
<span id="cb166-11"><a href="nonlinear-regression.html#cb166-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> полиномиальная регрессия, полиномиальная логистическая регрессия, ступенчатая модель, обобщённая линейная модель.</span>
<span id="cb166-12"><a href="nonlinear-regression.html#cb166-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Wage {ISLR}</span>
<span id="cb166-13"><a href="nonlinear-regression.html#cb166-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-14"><a href="nonlinear-regression.html#cb166-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">7.</span></span>
<span id="cb166-15"><a href="nonlinear-regression.html#cb166-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-16"><a href="nonlinear-regression.html#cb166-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># набор данных Auto</span></span>
<span id="cb166-17"><a href="nonlinear-regression.html#cb166-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;splines&#39;</span>)           <span class="co"># сплайны</span></span>
<span id="cb166-18"><a href="nonlinear-regression.html#cb166-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gam&#39;</span>)               <span class="co"># обобщённые аддитивные модели</span></span>
<span id="cb166-19"><a href="nonlinear-regression.html#cb166-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gam&#39; was built under R version 3.3.3</span></span>
<span id="cb166-20"><a href="nonlinear-regression.html#cb166-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: foreach</span></span>
<span id="cb166-21"><a href="nonlinear-regression.html#cb166-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;foreach&#39; was built under R version 3.3.3</span></span>
<span id="cb166-22"><a href="nonlinear-regression.html#cb166-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gam 1.14</span></span>
<span id="cb166-23"><a href="nonlinear-regression.html#cb166-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;akima&#39;</span>)             <span class="co"># график двумерной плоскости</span></span>
<span id="cb166-24"><a href="nonlinear-regression.html#cb166-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;akima&#39; was built under R version 3.3.3</span></span>
<span id="cb166-25"><a href="nonlinear-regression.html#cb166-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ggplot2&#39;</span>)           <span class="co"># красивые графики</span></span>
<span id="cb166-26"><a href="nonlinear-regression.html#cb166-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;ggplot2&#39; was built under R version 3.3.3</span></span>
<span id="cb166-27"><a href="nonlinear-regression.html#cb166-27" aria-hidden="true" tabindex="-1"></a>my.seed <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb166-28"><a href="nonlinear-regression.html#cb166-28" aria-hidden="true" tabindex="-1"></a>Работаем с набором данных по зарплатам <span class="dv">3000</span> работников<span class="sc">-</span>мужчин среднеатлантического региона Wage. Присоединяем его к пространству имён функцией <span class="fu">attach</span>(), и дальше обращаемся напрямую к столбцам таблицы.</span>
<span id="cb166-29"><a href="nonlinear-regression.html#cb166-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-30"><a href="nonlinear-regression.html#cb166-30" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Wage)</span>
<span id="cb166-31"><a href="nonlinear-regression.html#cb166-31" aria-hidden="true" tabindex="-1"></a>Работаем со столбцами<span class="sc">:</span></span>
<span id="cb166-32"><a href="nonlinear-regression.html#cb166-32" aria-hidden="true" tabindex="-1"></a>    <span class="er">*</span> wage – заработная плата работника до уплаты налогов;</span>
<span id="cb166-33"><a href="nonlinear-regression.html#cb166-33" aria-hidden="true" tabindex="-1"></a><span class="sc">*</span> age – возраст работника в годах.</span>
<span id="cb166-34"><a href="nonlinear-regression.html#cb166-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-35"><a href="nonlinear-regression.html#cb166-35" aria-hidden="true" tabindex="-1"></a>Полиномиальная регрессия</span>
<span id="cb166-36"><a href="nonlinear-regression.html#cb166-36" aria-hidden="true" tabindex="-1"></a>Зависимость зарплаты от возраста</span>
<span id="cb166-37"><a href="nonlinear-regression.html#cb166-37" aria-hidden="true" tabindex="-1"></a>Судя по графику ниже, ззаимосвязь заработной платы и возраста нелинейна. Наблюдается также группа наблюдений с высоким значением wage, граница проходит примерно на уровне <span class="fl">250.</span></span>
<span id="cb166-38"><a href="nonlinear-regression.html#cb166-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-39"><a href="nonlinear-regression.html#cb166-39" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> Wage, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> wage))</span>
<span id="cb166-40"><a href="nonlinear-regression.html#cb166-40" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> gp <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">0</span>, <span class="at">intercept =</span> <span class="dv">250</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb166-41"><a href="nonlinear-regression.html#cb166-41" aria-hidden="true" tabindex="-1"></a>gp</span>
<span id="cb166-42"><a href="nonlinear-regression.html#cb166-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-43"><a href="nonlinear-regression.html#cb166-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-44"><a href="nonlinear-regression.html#cb166-44" aria-hidden="true" tabindex="-1"></a>Подгоняем полином четвёртой степени для зависимости заработной платы от возраста.</span>
<span id="cb166-45"><a href="nonlinear-regression.html#cb166-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-46"><a href="nonlinear-regression.html#cb166-46" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb166-47"><a href="nonlinear-regression.html#cb166-47" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb166-48"><a href="nonlinear-regression.html#cb166-48" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb166-49"><a href="nonlinear-regression.html#cb166-49" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)     111.70       0.73  153.28     0.00</span></span>
<span id="cb166-50"><a href="nonlinear-regression.html#cb166-50" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)1   447.07      39.91   11.20     0.00</span></span>
<span id="cb166-51"><a href="nonlinear-regression.html#cb166-51" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)2  -478.32      39.91  -11.98     0.00</span></span>
<span id="cb166-52"><a href="nonlinear-regression.html#cb166-52" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)3   125.52      39.91    3.14     0.00</span></span>
<span id="cb166-53"><a href="nonlinear-regression.html#cb166-53" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)4   -77.91      39.91   -1.95     0.05</span></span>
<span id="cb166-54"><a href="nonlinear-regression.html#cb166-54" aria-hidden="true" tabindex="-1"></a>Функция <span class="fu">poly</span>(age, <span class="dv">4</span>) создаёт таблицу с базисом ортогональных полиномов<span class="sc">:</span> линейные комбинации значений переменной age в степенях от <span class="dv">1</span> до <span class="fl">4.</span></span>
<span id="cb166-55"><a href="nonlinear-regression.html#cb166-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-56"><a href="nonlinear-regression.html#cb166-56" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>)), <span class="dv">3</span>)</span>
<span id="cb166-57"><a href="nonlinear-regression.html#cb166-57" aria-hidden="true" tabindex="-1"></a><span class="do">##           1      2      3      4</span></span>
<span id="cb166-58"><a href="nonlinear-regression.html#cb166-58" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] -0.039  0.056 -0.072  0.087</span></span>
<span id="cb166-59"><a href="nonlinear-regression.html#cb166-59" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] -0.029  0.026 -0.015 -0.003</span></span>
<span id="cb166-60"><a href="nonlinear-regression.html#cb166-60" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,]  0.004 -0.015  0.000  0.014</span></span>
<span id="cb166-61"><a href="nonlinear-regression.html#cb166-61" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,]  0.001 -0.015  0.005  0.013</span></span>
<span id="cb166-62"><a href="nonlinear-regression.html#cb166-62" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,]  0.012 -0.010 -0.011  0.010</span></span>
<span id="cb166-63"><a href="nonlinear-regression.html#cb166-63" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,]  0.018 -0.002 -0.017 -0.001</span></span>
<span id="cb166-64"><a href="nonlinear-regression.html#cb166-64" aria-hidden="true" tabindex="-1"></a><span class="co"># можно получить сами значения age в заданных степенях</span></span>
<span id="cb166-65"><a href="nonlinear-regression.html#cb166-65" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T)), <span class="dv">3</span>)</span>
<span id="cb166-66"><a href="nonlinear-regression.html#cb166-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       1    2      3       4</span></span>
<span id="cb166-67"><a href="nonlinear-regression.html#cb166-67" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] 18  324   5832  104976</span></span>
<span id="cb166-68"><a href="nonlinear-regression.html#cb166-68" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] 24  576  13824  331776</span></span>
<span id="cb166-69"><a href="nonlinear-regression.html#cb166-69" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,] 45 2025  91125 4100625</span></span>
<span id="cb166-70"><a href="nonlinear-regression.html#cb166-70" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,] 43 1849  79507 3418801</span></span>
<span id="cb166-71"><a href="nonlinear-regression.html#cb166-71" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,] 50 2500 125000 6250000</span></span>
<span id="cb166-72"><a href="nonlinear-regression.html#cb166-72" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,] 54 2916 157464 8503056</span></span>
<span id="cb166-73"><a href="nonlinear-regression.html#cb166-73" aria-hidden="true" tabindex="-1"></a><span class="co"># на прогноз не повлияет, но оценки параметров изменяются</span></span>
<span id="cb166-74"><a href="nonlinear-regression.html#cb166-74" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T), <span class="at">data =</span> Wage)</span>
<span id="cb166-75"><a href="nonlinear-regression.html#cb166-75" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit<span class="fl">.2</span>)), <span class="dv">2</span>)</span>
<span id="cb166-76"><a href="nonlinear-regression.html#cb166-76" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb166-77"><a href="nonlinear-regression.html#cb166-77" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)             -184.15      60.04   -3.07     0.00</span></span>
<span id="cb166-78"><a href="nonlinear-regression.html#cb166-78" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)1    21.25       5.89    3.61     0.00</span></span>
<span id="cb166-79"><a href="nonlinear-regression.html#cb166-79" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)2    -0.56       0.21   -2.74     0.01</span></span>
<span id="cb166-80"><a href="nonlinear-regression.html#cb166-80" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)3     0.01       0.00    2.22     0.03</span></span>
<span id="cb166-81"><a href="nonlinear-regression.html#cb166-81" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)4     0.00       0.00   -1.95     0.05</span></span>
<span id="cb166-82"><a href="nonlinear-regression.html#cb166-82" aria-hidden="true" tabindex="-1"></a><span class="co"># границы изменения переменной age</span></span>
<span id="cb166-83"><a href="nonlinear-regression.html#cb166-83" aria-hidden="true" tabindex="-1"></a>agelims <span class="ot">&lt;-</span> <span class="fu">range</span>(age)</span>
<span id="cb166-84"><a href="nonlinear-regression.html#cb166-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-85"><a href="nonlinear-regression.html#cb166-85" aria-hidden="true" tabindex="-1"></a><span class="co"># значения age, для которых делаем прогноз (от min до max с шагом 1)</span></span>
<span id="cb166-86"><a href="nonlinear-regression.html#cb166-86" aria-hidden="true" tabindex="-1"></a>age.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> agelims[<span class="dv">1</span>], <span class="at">to =</span> agelims[<span class="dv">2</span>])</span>
<span id="cb166-87"><a href="nonlinear-regression.html#cb166-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-88"><a href="nonlinear-regression.html#cb166-88" aria-hidden="true" tabindex="-1"></a><span class="co"># рассчитать прогнозы и их стандартные ошибки</span></span>
<span id="cb166-89"><a href="nonlinear-regression.html#cb166-89" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb166-90"><a href="nonlinear-regression.html#cb166-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-91"><a href="nonlinear-regression.html#cb166-91" aria-hidden="true" tabindex="-1"></a><span class="co"># границы доверительного интервала для заработной платы</span></span>
<span id="cb166-92"><a href="nonlinear-regression.html#cb166-92" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb166-93"><a href="nonlinear-regression.html#cb166-93" aria-hidden="true" tabindex="-1"></a>                  <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb166-94"><a href="nonlinear-regression.html#cb166-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-95"><a href="nonlinear-regression.html#cb166-95" aria-hidden="true" tabindex="-1"></a><span class="co"># смотрим результат</span></span>
<span id="cb166-96"><a href="nonlinear-regression.html#cb166-96" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">2</span>)</span>
<span id="cb166-97"><a href="nonlinear-regression.html#cb166-97" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb166-98"><a href="nonlinear-regression.html#cb166-98" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       41.33       62.53</span></span>
<span id="cb166-99"><a href="nonlinear-regression.html#cb166-99" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       49.76       67.24</span></span>
<span id="cb166-100"><a href="nonlinear-regression.html#cb166-100" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       57.39       71.76</span></span>
<span id="cb166-101"><a href="nonlinear-regression.html#cb166-101" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       64.27       76.09</span></span>
<span id="cb166-102"><a href="nonlinear-regression.html#cb166-102" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       70.44       80.27</span></span>
<span id="cb166-103"><a href="nonlinear-regression.html#cb166-103" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       75.94       84.28</span></span>
<span id="cb166-104"><a href="nonlinear-regression.html#cb166-104" aria-hidden="true" tabindex="-1"></a>Рисуем левую панель графика со слайда <span class="dv">4</span> презентации (рис. <span class="fl">7.1</span> книги). Функция <span class="fu">matlines</span>() рисует грфик столбцов одной матрицы против столбцов другой.</span>
<span id="cb166-105"><a href="nonlinear-regression.html#cb166-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-106"><a href="nonlinear-regression.html#cb166-106" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb166-107"><a href="nonlinear-regression.html#cb166-107" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb166-108"><a href="nonlinear-regression.html#cb166-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-109"><a href="nonlinear-regression.html#cb166-109" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb166-110"><a href="nonlinear-regression.html#cb166-110" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb166-111"><a href="nonlinear-regression.html#cb166-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-112"><a href="nonlinear-regression.html#cb166-112" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb166-113"><a href="nonlinear-regression.html#cb166-113" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb166-114"><a href="nonlinear-regression.html#cb166-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-115"><a href="nonlinear-regression.html#cb166-115" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb166-116"><a href="nonlinear-regression.html#cb166-116" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb166-117"><a href="nonlinear-regression.html#cb166-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-118"><a href="nonlinear-regression.html#cb166-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-119"><a href="nonlinear-regression.html#cb166-119" aria-hidden="true" tabindex="-1"></a>Убедимся, что прогнозы по моделям с различными вызовами <span class="fu">poly</span>() совпадают.</span>
<span id="cb166-120"><a href="nonlinear-regression.html#cb166-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-121"><a href="nonlinear-regression.html#cb166-121" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы по второму вызову модели</span></span>
<span id="cb166-122"><a href="nonlinear-regression.html#cb166-122" aria-hidden="true" tabindex="-1"></a>preds2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit<span class="fl">.2</span>, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb166-123"><a href="nonlinear-regression.html#cb166-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-124"><a href="nonlinear-regression.html#cb166-124" aria-hidden="true" tabindex="-1"></a><span class="co"># максимальное расхождение между прогнозами по двум вариантам вызова модели</span></span>
<span id="cb166-125"><a href="nonlinear-regression.html#cb166-125" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(preds<span class="sc">$</span>fit <span class="sc">-</span> preds2<span class="sc">$</span>fit))</span>
<span id="cb166-126"><a href="nonlinear-regression.html#cb166-126" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 7.389644e-13</span></span>
<span id="cb166-127"><a href="nonlinear-regression.html#cb166-127" aria-hidden="true" tabindex="-1"></a>Теперь подбираем степень полинома, сравнивая модели со степенями от <span class="dv">1</span> до <span class="dv">5</span> с помощью дисперсионного анализа (ANOVA).</span>
<span id="cb166-128"><a href="nonlinear-regression.html#cb166-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-129"><a href="nonlinear-regression.html#cb166-129" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> age, <span class="at">data =</span> Wage)</span>
<span id="cb166-130"><a href="nonlinear-regression.html#cb166-130" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">2</span>), <span class="at">data =</span> Wage)</span>
<span id="cb166-131"><a href="nonlinear-regression.html#cb166-131" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">3</span>), <span class="at">data =</span> Wage)</span>
<span id="cb166-132"><a href="nonlinear-regression.html#cb166-132" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb166-133"><a href="nonlinear-regression.html#cb166-133" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">5</span>), <span class="at">data =</span> Wage)</span>
<span id="cb166-134"><a href="nonlinear-regression.html#cb166-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-135"><a href="nonlinear-regression.html#cb166-135" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">anova</span>(fit<span class="fl">.1</span>, fit<span class="fl">.2</span>, fit<span class="fl">.3</span>, fit<span class="fl">.4</span>, fit<span class="fl">.5</span>), <span class="dv">2</span>)</span>
<span id="cb166-136"><a href="nonlinear-regression.html#cb166-136" aria-hidden="true" tabindex="-1"></a>Res.Df</span>
<span id="cb166-137"><a href="nonlinear-regression.html#cb166-137" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-138"><a href="nonlinear-regression.html#cb166-138" aria-hidden="true" tabindex="-1"></a>    RSS</span>
<span id="cb166-139"><a href="nonlinear-regression.html#cb166-139" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-140"><a href="nonlinear-regression.html#cb166-140" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb166-141"><a href="nonlinear-regression.html#cb166-141" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-142"><a href="nonlinear-regression.html#cb166-142" aria-hidden="true" tabindex="-1"></a>    Sum of Sq</span>
<span id="cb166-143"><a href="nonlinear-regression.html#cb166-143" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-144"><a href="nonlinear-regression.html#cb166-144" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb166-145"><a href="nonlinear-regression.html#cb166-145" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-146"><a href="nonlinear-regression.html#cb166-146" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb166-147"><a href="nonlinear-regression.html#cb166-147" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-148"><a href="nonlinear-regression.html#cb166-148" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2998</span>    <span class="dv">5022216</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb166-149"><a href="nonlinear-regression.html#cb166-149" aria-hidden="true" tabindex="-1"></a><span class="dv">2997</span>    <span class="dv">4793430</span> <span class="dv">1</span>   <span class="fl">228786.01</span>   <span class="fl">143.59</span>  <span class="fl">0.00</span></span>
<span id="cb166-150"><a href="nonlinear-regression.html#cb166-150" aria-hidden="true" tabindex="-1"></a><span class="dv">2996</span>    <span class="dv">4777674</span> <span class="dv">1</span>   <span class="fl">15755.69</span>    <span class="fl">9.89</span>    <span class="fl">0.00</span></span>
<span id="cb166-151"><a href="nonlinear-regression.html#cb166-151" aria-hidden="true" tabindex="-1"></a><span class="dv">2995</span>    <span class="dv">4771604</span> <span class="dv">1</span>   <span class="fl">6070.15</span> <span class="fl">3.81</span>    <span class="fl">0.05</span></span>
<span id="cb166-152"><a href="nonlinear-regression.html#cb166-152" aria-hidden="true" tabindex="-1"></a><span class="dv">2994</span>    <span class="dv">4770322</span> <span class="dv">1</span>   <span class="fl">1282.56</span> <span class="fl">0.80</span>    <span class="fl">0.37</span></span>
<span id="cb166-153"><a href="nonlinear-regression.html#cb166-153" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> rows</span>
<span id="cb166-154"><a href="nonlinear-regression.html#cb166-154" aria-hidden="true" tabindex="-1"></a>Рассматриваются пять моделей, в которых степени полинома от age идут по возрастанию. В крайнем правом столбце таблице приводятся p<span class="sc">-</span>значения для проверки нулевой гипотезы<span class="sc">:</span> текущая модель не даёт статистически значимого сокращения RSS по сравнению с предыдущей моделью. Можно сделать вывод, что степени <span class="dv">3</span> достаточно, дальнейшее увеличение степени не даёт значимого улучшения качества модели.</span>
<span id="cb166-155"><a href="nonlinear-regression.html#cb166-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-156"><a href="nonlinear-regression.html#cb166-156" aria-hidden="true" tabindex="-1"></a>Зависимость вероятности получать зарплату <span class="sc">&gt;</span> <span class="dv">250</span> от возраста</span>
<span id="cb166-157"><a href="nonlinear-regression.html#cb166-157" aria-hidden="true" tabindex="-1"></a>Теперь вернёмся к группе наблюдений с высоким wage. Рассмотрим зависимость вероятности того, что величина зарплаты больше <span class="dv">250</span>, от возраста.</span>
<span id="cb166-158"><a href="nonlinear-regression.html#cb166-158" aria-hidden="true" tabindex="-1"></a>Подгоняем логистическую регрессию и делаем прогнозы, для этого используем функцию для оценки обобщённой линейной модели  <span class="fu">glm</span>() и указываем тип модели binomial<span class="sc">:</span></span>
<span id="cb166-159"><a href="nonlinear-regression.html#cb166-159" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb166-160"><a href="nonlinear-regression.html#cb166-160" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb166-161"><a href="nonlinear-regression.html#cb166-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-162"><a href="nonlinear-regression.html#cb166-162" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb166-163"><a href="nonlinear-regression.html#cb166-163" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb166-164"><a href="nonlinear-regression.html#cb166-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-165"><a href="nonlinear-regression.html#cb166-165" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb166-166"><a href="nonlinear-regression.html#cb166-166" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb166-167"><a href="nonlinear-regression.html#cb166-167" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb166-168"><a href="nonlinear-regression.html#cb166-168" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb166-169"><a href="nonlinear-regression.html#cb166-169" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb166-170"><a href="nonlinear-regression.html#cb166-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-171"><a href="nonlinear-regression.html#cb166-171" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb166-172"><a href="nonlinear-regression.html#cb166-172" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb166-173"><a href="nonlinear-regression.html#cb166-173" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb166-174"><a href="nonlinear-regression.html#cb166-174" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb166-175"><a href="nonlinear-regression.html#cb166-175" aria-hidden="true" tabindex="-1"></a><span class="do">## 1           0       0.002</span></span>
<span id="cb166-176"><a href="nonlinear-regression.html#cb166-176" aria-hidden="true" tabindex="-1"></a><span class="do">## 2           0       0.003</span></span>
<span id="cb166-177"><a href="nonlinear-regression.html#cb166-177" aria-hidden="true" tabindex="-1"></a><span class="do">## 3           0       0.004</span></span>
<span id="cb166-178"><a href="nonlinear-regression.html#cb166-178" aria-hidden="true" tabindex="-1"></a><span class="do">## 4           0       0.005</span></span>
<span id="cb166-179"><a href="nonlinear-regression.html#cb166-179" aria-hidden="true" tabindex="-1"></a><span class="do">## 5           0       0.006</span></span>
<span id="cb166-180"><a href="nonlinear-regression.html#cb166-180" aria-hidden="true" tabindex="-1"></a><span class="do">## 6           0       0.007</span></span>
<span id="cb166-181"><a href="nonlinear-regression.html#cb166-181" aria-hidden="true" tabindex="-1"></a>Достраиваем график с <span class="dv">4</span> слайда презентации (рис. <span class="fl">7.1</span> книги). Рисуем правую панель.</span>
<span id="cb166-182"><a href="nonlinear-regression.html#cb166-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-183"><a href="nonlinear-regression.html#cb166-183" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb166-184"><a href="nonlinear-regression.html#cb166-184" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb166-185"><a href="nonlinear-regression.html#cb166-185" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb166-186"><a href="nonlinear-regression.html#cb166-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-187"><a href="nonlinear-regression.html#cb166-187" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb166-188"><a href="nonlinear-regression.html#cb166-188" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb166-189"><a href="nonlinear-regression.html#cb166-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-190"><a href="nonlinear-regression.html#cb166-190" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb166-191"><a href="nonlinear-regression.html#cb166-191" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb166-192"><a href="nonlinear-regression.html#cb166-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-193"><a href="nonlinear-regression.html#cb166-193" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb166-194"><a href="nonlinear-regression.html#cb166-194" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb166-195"><a href="nonlinear-regression.html#cb166-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-196"><a href="nonlinear-regression.html#cb166-196" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb166-197"><a href="nonlinear-regression.html#cb166-197" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb166-198"><a href="nonlinear-regression.html#cb166-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-199"><a href="nonlinear-regression.html#cb166-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-200"><a href="nonlinear-regression.html#cb166-200" aria-hidden="true" tabindex="-1"></a>Ступенчатые функции</span>
<span id="cb166-201"><a href="nonlinear-regression.html#cb166-201" aria-hidden="true" tabindex="-1"></a>Для начала определим несколько интервалов, на каждом из которых будем моделировать зависимость wage от age своим средним уровнем.</span>
<span id="cb166-202"><a href="nonlinear-regression.html#cb166-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-203"><a href="nonlinear-regression.html#cb166-203" aria-hidden="true" tabindex="-1"></a><span class="co"># нарезаем предиктор age на 4 равных интервала</span></span>
<span id="cb166-204"><a href="nonlinear-regression.html#cb166-204" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">cut</span>(age, <span class="dv">4</span>))</span>
<span id="cb166-205"><a href="nonlinear-regression.html#cb166-205" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb166-206"><a href="nonlinear-regression.html#cb166-206" aria-hidden="true" tabindex="-1"></a><span class="do">## (17.9,33.5]   (33.5,49]   (49,64.5] (64.5,80.1] </span></span>
<span id="cb166-207"><a href="nonlinear-regression.html#cb166-207" aria-hidden="true" tabindex="-1"></a><span class="do">##         750        1399         779          72</span></span>
<span id="cb166-208"><a href="nonlinear-regression.html#cb166-208" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем линейную модель на интервалах</span></span>
<span id="cb166-209"><a href="nonlinear-regression.html#cb166-209" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb166-210"><a href="nonlinear-regression.html#cb166-210" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb166-211"><a href="nonlinear-regression.html#cb166-211" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb166-212"><a href="nonlinear-regression.html#cb166-212" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)               94.16       1.48   63.79     0.00</span></span>
<span id="cb166-213"><a href="nonlinear-regression.html#cb166-213" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(33.5,49]      24.05       1.83   13.15     0.00</span></span>
<span id="cb166-214"><a href="nonlinear-regression.html#cb166-214" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(49,64.5]      23.66       2.07   11.44     0.00</span></span>
<span id="cb166-215"><a href="nonlinear-regression.html#cb166-215" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(64.5,80.1]     7.64       4.99    1.53     0.13</span></span>
<span id="cb166-216"><a href="nonlinear-regression.html#cb166-216" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз -- это средние по `wage` на каждом интервале</span></span>
<span id="cb166-217"><a href="nonlinear-regression.html#cb166-217" aria-hidden="true" tabindex="-1"></a>preds.cut <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb166-218"><a href="nonlinear-regression.html#cb166-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-219"><a href="nonlinear-regression.html#cb166-219" aria-hidden="true" tabindex="-1"></a><span class="co"># интервальный прогноз</span></span>
<span id="cb166-220"><a href="nonlinear-regression.html#cb166-220" aria-hidden="true" tabindex="-1"></a>se.bands.cut <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit,</span>
<span id="cb166-221"><a href="nonlinear-regression.html#cb166-221" aria-hidden="true" tabindex="-1"></a>                      <span class="at">upper.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit)</span>
<span id="cb166-222"><a href="nonlinear-regression.html#cb166-222" aria-hidden="true" tabindex="-1"></a>Воспроизведём график со слайда <span class="dv">7</span> презентации (рис. <span class="fl">7.2</span> книги).</span>
<span id="cb166-223"><a href="nonlinear-regression.html#cb166-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-224"><a href="nonlinear-regression.html#cb166-224" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb166-225"><a href="nonlinear-regression.html#cb166-225" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb166-226"><a href="nonlinear-regression.html#cb166-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-227"><a href="nonlinear-regression.html#cb166-227" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb166-228"><a href="nonlinear-regression.html#cb166-228" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.cut<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb166-229"><a href="nonlinear-regression.html#cb166-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-230"><a href="nonlinear-regression.html#cb166-230" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb166-231"><a href="nonlinear-regression.html#cb166-231" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands.cut, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb166-232"><a href="nonlinear-regression.html#cb166-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-233"><a href="nonlinear-regression.html#cb166-233" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb166-234"><a href="nonlinear-regression.html#cb166-234" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb166-235"><a href="nonlinear-regression.html#cb166-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-236"><a href="nonlinear-regression.html#cb166-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-237"><a href="nonlinear-regression.html#cb166-237" aria-hidden="true" tabindex="-1"></a>Правая часть графика, для вероятности того, что зарплата выше <span class="fl">250.</span></span>
<span id="cb166-238"><a href="nonlinear-regression.html#cb166-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-239"><a href="nonlinear-regression.html#cb166-239" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb166-240"><a href="nonlinear-regression.html#cb166-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-241"><a href="nonlinear-regression.html#cb166-241" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb166-242"><a href="nonlinear-regression.html#cb166-242" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb166-243"><a href="nonlinear-regression.html#cb166-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-244"><a href="nonlinear-regression.html#cb166-244" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb166-245"><a href="nonlinear-regression.html#cb166-245" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb166-246"><a href="nonlinear-regression.html#cb166-246" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb166-247"><a href="nonlinear-regression.html#cb166-247" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb166-248"><a href="nonlinear-regression.html#cb166-248" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb166-249"><a href="nonlinear-regression.html#cb166-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-250"><a href="nonlinear-regression.html#cb166-250" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb166-251"><a href="nonlinear-regression.html#cb166-251" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb166-252"><a href="nonlinear-regression.html#cb166-252" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb166-253"><a href="nonlinear-regression.html#cb166-253" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb166-254"><a href="nonlinear-regression.html#cb166-254" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       0.003       0.016</span></span>
<span id="cb166-255"><a href="nonlinear-regression.html#cb166-255" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       0.003       0.016</span></span>
<span id="cb166-256"><a href="nonlinear-regression.html#cb166-256" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       0.003       0.016</span></span>
<span id="cb166-257"><a href="nonlinear-regression.html#cb166-257" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       0.003       0.016</span></span>
<span id="cb166-258"><a href="nonlinear-regression.html#cb166-258" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       0.003       0.016</span></span>
<span id="cb166-259"><a href="nonlinear-regression.html#cb166-259" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       0.003       0.016</span></span>
<span id="cb166-260"><a href="nonlinear-regression.html#cb166-260" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb166-261"><a href="nonlinear-regression.html#cb166-261" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb166-262"><a href="nonlinear-regression.html#cb166-262" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb166-263"><a href="nonlinear-regression.html#cb166-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-264"><a href="nonlinear-regression.html#cb166-264" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb166-265"><a href="nonlinear-regression.html#cb166-265" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb166-266"><a href="nonlinear-regression.html#cb166-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-267"><a href="nonlinear-regression.html#cb166-267" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb166-268"><a href="nonlinear-regression.html#cb166-268" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb166-269"><a href="nonlinear-regression.html#cb166-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-270"><a href="nonlinear-regression.html#cb166-270" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb166-271"><a href="nonlinear-regression.html#cb166-271" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb166-272"><a href="nonlinear-regression.html#cb166-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-273"><a href="nonlinear-regression.html#cb166-273" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb166-274"><a href="nonlinear-regression.html#cb166-274" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb166-275"><a href="nonlinear-regression.html#cb166-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-276"><a href="nonlinear-regression.html#cb166-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-277"><a href="nonlinear-regression.html#cb166-277" aria-hidden="true" tabindex="-1"></a>Сплайны</span>
<span id="cb166-278"><a href="nonlinear-regression.html#cb166-278" aria-hidden="true" tabindex="-1"></a>Построим кубический сплайн с тремя узлами.</span>
<span id="cb166-279"><a href="nonlinear-regression.html#cb166-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-280"><a href="nonlinear-regression.html#cb166-280" aria-hidden="true" tabindex="-1"></a><span class="co"># кубический сплайн с тремя узлами</span></span>
<span id="cb166-281"><a href="nonlinear-regression.html#cb166-281" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)), <span class="at">data =</span> Wage)</span>
<span id="cb166-282"><a href="nonlinear-regression.html#cb166-282" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb166-283"><a href="nonlinear-regression.html#cb166-283" aria-hidden="true" tabindex="-1"></a>preds.spl <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb166-284"><a href="nonlinear-regression.html#cb166-284" aria-hidden="true" tabindex="-1"></a>Теперь построим натуральный по трём узлам. Три узла это <span class="dv">6</span> степеней свободы. Если функции <span class="fu">bs</span>(), которая создаёт матрицу с базисом для полиномиального сплайна, передать только степени свободы, она распределит узлы равномерно. В данном случае это квартили распределения age.</span>
<span id="cb166-285"><a href="nonlinear-regression.html#cb166-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-286"><a href="nonlinear-regression.html#cb166-286" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 узла -- 6 степеней свободы (столбцы матрицы)</span></span>
<span id="cb166-287"><a href="nonlinear-regression.html#cb166-287" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)))</span>
<span id="cb166-288"><a href="nonlinear-regression.html#cb166-288" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb166-289"><a href="nonlinear-regression.html#cb166-289" aria-hidden="true" tabindex="-1"></a><span class="co"># если не указываем узлы явно...</span></span>
<span id="cb166-290"><a href="nonlinear-regression.html#cb166-290" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>))</span>
<span id="cb166-291"><a href="nonlinear-regression.html#cb166-291" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb166-292"><a href="nonlinear-regression.html#cb166-292" aria-hidden="true" tabindex="-1"></a><span class="co">#  они привязываются к квартилям</span></span>
<span id="cb166-293"><a href="nonlinear-regression.html#cb166-293" aria-hidden="true" tabindex="-1"></a><span class="fu">attr</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>), <span class="st">&#39;knots&#39;</span>)</span>
<span id="cb166-294"><a href="nonlinear-regression.html#cb166-294" aria-hidden="true" tabindex="-1"></a><span class="do">##   25%   50%   75% </span></span>
<span id="cb166-295"><a href="nonlinear-regression.html#cb166-295" aria-hidden="true" tabindex="-1"></a><span class="do">## 33.75 42.00 51.00</span></span>
<span id="cb166-296"><a href="nonlinear-regression.html#cb166-296" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb166-297"><a href="nonlinear-regression.html#cb166-297" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(age, <span class="at">df =</span> <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb166-298"><a href="nonlinear-regression.html#cb166-298" aria-hidden="true" tabindex="-1"></a>preds.spl2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit2, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb166-299"><a href="nonlinear-regression.html#cb166-299" aria-hidden="true" tabindex="-1"></a>График сравнения кубического и натурального сплайнов.</span>
<span id="cb166-300"><a href="nonlinear-regression.html#cb166-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-301"><a href="nonlinear-regression.html#cb166-301" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="fl">8.5</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="at">xpd =</span> T)</span>
<span id="cb166-302"><a href="nonlinear-regression.html#cb166-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-303"><a href="nonlinear-regression.html#cb166-303" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb166-304"><a href="nonlinear-regression.html#cb166-304" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">col =</span> <span class="st">&#39;grey&#39;</span>)</span>
<span id="cb166-305"><a href="nonlinear-regression.html#cb166-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-306"><a href="nonlinear-regression.html#cb166-306" aria-hidden="true" tabindex="-1"></a><span class="co"># модель кубического сплайна</span></span>
<span id="cb166-307"><a href="nonlinear-regression.html#cb166-307" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb166-308"><a href="nonlinear-regression.html#cb166-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-309"><a href="nonlinear-regression.html#cb166-309" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительный интервал</span></span>
<span id="cb166-310"><a href="nonlinear-regression.html#cb166-310" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb166-311"><a href="nonlinear-regression.html#cb166-311" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb166-312"><a href="nonlinear-regression.html#cb166-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-313"><a href="nonlinear-regression.html#cb166-313" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb166-314"><a href="nonlinear-regression.html#cb166-314" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl2<span class="sc">$</span>fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb166-315"><a href="nonlinear-regression.html#cb166-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-316"><a href="nonlinear-regression.html#cb166-316" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb166-317"><a href="nonlinear-regression.html#cb166-317" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">inset =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.7</span>, <span class="dv">0</span>),</span>
<span id="cb166-318"><a href="nonlinear-regression.html#cb166-318" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;Кубический </span><span class="sc">\n</span><span class="st"> с 3 узлами&#39;</span>, <span class="st">&#39;Натуральный&#39;</span>),</span>
<span id="cb166-319"><a href="nonlinear-regression.html#cb166-319" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="fu">rep</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;red&#39;</span>))</span>
<span id="cb166-320"><a href="nonlinear-regression.html#cb166-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-321"><a href="nonlinear-regression.html#cb166-321" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb166-322"><a href="nonlinear-regression.html#cb166-322" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Сплайны&quot;</span>)</span>
<span id="cb166-323"><a href="nonlinear-regression.html#cb166-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-324"><a href="nonlinear-regression.html#cb166-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-325"><a href="nonlinear-regression.html#cb166-325" aria-hidden="true" tabindex="-1"></a>Построим график со слайда <span class="dv">20</span> (рисунок <span class="fl">7.8</span> книги).</span>
<span id="cb166-326"><a href="nonlinear-regression.html#cb166-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-327"><a href="nonlinear-regression.html#cb166-327" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">0</span>))</span>
<span id="cb166-328"><a href="nonlinear-regression.html#cb166-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-329"><a href="nonlinear-regression.html#cb166-329" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb166-330"><a href="nonlinear-regression.html#cb166-330" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb166-331"><a href="nonlinear-regression.html#cb166-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-332"><a href="nonlinear-regression.html#cb166-332" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb166-333"><a href="nonlinear-regression.html#cb166-333" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Сглаживающий сплайн&#39;</span>)</span>
<span id="cb166-334"><a href="nonlinear-regression.html#cb166-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-335"><a href="nonlinear-regression.html#cb166-335" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с 16 степенями свободы</span></span>
<span id="cb166-336"><a href="nonlinear-regression.html#cb166-336" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">df =</span> <span class="dv">16</span>)</span>
<span id="cb166-337"><a href="nonlinear-regression.html#cb166-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-338"><a href="nonlinear-regression.html#cb166-338" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с подбором лямбды с помощью перекрёстной проверки</span></span>
<span id="cb166-339"><a href="nonlinear-regression.html#cb166-339" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">cv =</span> T)</span>
<span id="cb166-340"><a href="nonlinear-regression.html#cb166-340" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in smooth.spline(age, wage, cv = T): cross-validation with non-</span></span>
<span id="cb166-341"><a href="nonlinear-regression.html#cb166-341" aria-hidden="true" tabindex="-1"></a><span class="do">## unique &#39;x&#39; values seems doubtful</span></span>
<span id="cb166-342"><a href="nonlinear-regression.html#cb166-342" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span>df</span>
<span id="cb166-343"><a href="nonlinear-regression.html#cb166-343" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 6.794596</span></span>
<span id="cb166-344"><a href="nonlinear-regression.html#cb166-344" aria-hidden="true" tabindex="-1"></a><span class="co"># рисуем модель</span></span>
<span id="cb166-345"><a href="nonlinear-regression.html#cb166-345" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb166-346"><a href="nonlinear-regression.html#cb166-346" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit2, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb166-347"><a href="nonlinear-regression.html#cb166-347" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb166-348"><a href="nonlinear-regression.html#cb166-348" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;16 df&#39;</span>, <span class="st">&#39;6.8 df&#39;</span>),</span>
<span id="cb166-349"><a href="nonlinear-regression.html#cb166-349" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb166-350"><a href="nonlinear-regression.html#cb166-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-351"><a href="nonlinear-regression.html#cb166-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-352"><a href="nonlinear-regression.html#cb166-352" aria-hidden="true" tabindex="-1"></a>Локальная регрессия</span>
<span id="cb166-353"><a href="nonlinear-regression.html#cb166-353" aria-hidden="true" tabindex="-1"></a>Строим график со слайда <span class="dv">24</span> (рис. <span class="fl">7.10</span>).</span>
<span id="cb166-354"><a href="nonlinear-regression.html#cb166-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-355"><a href="nonlinear-regression.html#cb166-355" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb166-356"><a href="nonlinear-regression.html#cb166-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-357"><a href="nonlinear-regression.html#cb166-357" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Локальная регрессия&#39;</span>)</span>
<span id="cb166-358"><a href="nonlinear-regression.html#cb166-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-359"><a href="nonlinear-regression.html#cb166-359" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.2</span></span>
<span id="cb166-360"><a href="nonlinear-regression.html#cb166-360" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.2</span>, <span class="at">data =</span> Wage)</span>
<span id="cb166-361"><a href="nonlinear-regression.html#cb166-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-362"><a href="nonlinear-regression.html#cb166-362" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.5</span></span>
<span id="cb166-363"><a href="nonlinear-regression.html#cb166-363" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.5</span>, <span class="at">data =</span> Wage)</span>
<span id="cb166-364"><a href="nonlinear-regression.html#cb166-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-365"><a href="nonlinear-regression.html#cb166-365" aria-hidden="true" tabindex="-1"></a><span class="co"># рисум модели</span></span>
<span id="cb166-366"><a href="nonlinear-regression.html#cb166-366" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb166-367"><a href="nonlinear-regression.html#cb166-367" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb166-368"><a href="nonlinear-regression.html#cb166-368" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit2, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb166-369"><a href="nonlinear-regression.html#cb166-369" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb166-370"><a href="nonlinear-regression.html#cb166-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-371"><a href="nonlinear-regression.html#cb166-371" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb166-372"><a href="nonlinear-regression.html#cb166-372" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb166-373"><a href="nonlinear-regression.html#cb166-373" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;s = 0.2&#39;</span>, <span class="st">&#39;s = 0.5&#39;</span>),</span>
<span id="cb166-374"><a href="nonlinear-regression.html#cb166-374" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb166-375"><a href="nonlinear-regression.html#cb166-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-376"><a href="nonlinear-regression.html#cb166-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-377"><a href="nonlinear-regression.html#cb166-377" aria-hidden="true" tabindex="-1"></a>Обобщённые аддитивные модели (GAM) с непрерывным откликом</span>
<span id="cb166-378"><a href="nonlinear-regression.html#cb166-378" aria-hidden="true" tabindex="-1"></a>Построим GAM на натуральных сплайнах степеней <span class="dv">4</span> (year), <span class="dv">5</span> (age) с категориальным предиктором edication.</span>
<span id="cb166-379"><a href="nonlinear-regression.html#cb166-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-380"><a href="nonlinear-regression.html#cb166-380" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на натуральных сплайнах</span></span>
<span id="cb166-381"><a href="nonlinear-regression.html#cb166-381" aria-hidden="true" tabindex="-1"></a>gam.ns <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">ns</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb166-382"><a href="nonlinear-regression.html#cb166-382" aria-hidden="true" tabindex="-1"></a>Также построим модель на сглаживающих сплайнах.</span>
<span id="cb166-383"><a href="nonlinear-regression.html#cb166-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-384"><a href="nonlinear-regression.html#cb166-384" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на сглаживающих сплайнах</span></span>
<span id="cb166-385"><a href="nonlinear-regression.html#cb166-385" aria-hidden="true" tabindex="-1"></a>gam.m3 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb166-386"><a href="nonlinear-regression.html#cb166-386" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">28</span> (рис. <span class="fl">7.12</span>).</span>
<span id="cb166-387"><a href="nonlinear-regression.html#cb166-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-388"><a href="nonlinear-regression.html#cb166-388" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb166-389"><a href="nonlinear-regression.html#cb166-389" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.m3, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb166-390"><a href="nonlinear-regression.html#cb166-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-391"><a href="nonlinear-regression.html#cb166-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-392"><a href="nonlinear-regression.html#cb166-392" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">27</span> (рис. <span class="fl">7.11</span>).</span>
<span id="cb166-393"><a href="nonlinear-regression.html#cb166-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-394"><a href="nonlinear-regression.html#cb166-394" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb166-395"><a href="nonlinear-regression.html#cb166-395" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.ns, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb166-396"><a href="nonlinear-regression.html#cb166-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-397"><a href="nonlinear-regression.html#cb166-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-398"><a href="nonlinear-regression.html#cb166-398" aria-hidden="true" tabindex="-1"></a>График функции от year похож на прямую. Сделаем ANOVA, чтобы понять, какая степень для year лучше.</span>
<span id="cb166-399"><a href="nonlinear-regression.html#cb166-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-400"><a href="nonlinear-regression.html#cb166-400" aria-hidden="true" tabindex="-1"></a>gam.m1 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)          <span class="co"># без year</span></span>
<span id="cb166-401"><a href="nonlinear-regression.html#cb166-401" aria-hidden="true" tabindex="-1"></a>gam.m2 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)   <span class="co"># year^1</span></span>
<span id="cb166-402"><a href="nonlinear-regression.html#cb166-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-403"><a href="nonlinear-regression.html#cb166-403" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(gam.m1, gam.m2, gam.m3, <span class="at">test =</span> <span class="st">&#39;F&#39;</span>)</span>
<span id="cb166-404"><a href="nonlinear-regression.html#cb166-404" aria-hidden="true" tabindex="-1"></a>Resid. Df</span>
<span id="cb166-405"><a href="nonlinear-regression.html#cb166-405" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-406"><a href="nonlinear-regression.html#cb166-406" aria-hidden="true" tabindex="-1"></a>    Resid. Dev</span>
<span id="cb166-407"><a href="nonlinear-regression.html#cb166-407" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-408"><a href="nonlinear-regression.html#cb166-408" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb166-409"><a href="nonlinear-regression.html#cb166-409" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-410"><a href="nonlinear-regression.html#cb166-410" aria-hidden="true" tabindex="-1"></a>    Deviance</span>
<span id="cb166-411"><a href="nonlinear-regression.html#cb166-411" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-412"><a href="nonlinear-regression.html#cb166-412" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb166-413"><a href="nonlinear-regression.html#cb166-413" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-414"><a href="nonlinear-regression.html#cb166-414" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb166-415"><a href="nonlinear-regression.html#cb166-415" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb166-416"><a href="nonlinear-regression.html#cb166-416" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2990</span>    <span class="dv">3711731</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb166-417"><a href="nonlinear-regression.html#cb166-417" aria-hidden="true" tabindex="-1"></a><span class="dv">2989</span>    <span class="dv">3693842</span> <span class="fl">1.000000</span>    <span class="fl">17889.243</span>   <span class="fl">14.477130</span>   <span class="fl">0.0001447167</span></span>
<span id="cb166-418"><a href="nonlinear-regression.html#cb166-418" aria-hidden="true" tabindex="-1"></a><span class="dv">2986</span>    <span class="dv">3689770</span> <span class="fl">2.999989</span>    <span class="fl">4071.134</span>    <span class="fl">1.098212</span>    <span class="fl">0.3485661430</span></span>
<span id="cb166-419"><a href="nonlinear-regression.html#cb166-419" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> rows</span>
<span id="cb166-420"><a href="nonlinear-regression.html#cb166-420" aria-hidden="true" tabindex="-1"></a>Третья модель статистически не лучше второй. Кроме того, один из параметров этой модели незначим.</span>
<span id="cb166-421"><a href="nonlinear-regression.html#cb166-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-422"><a href="nonlinear-regression.html#cb166-422" aria-hidden="true" tabindex="-1"></a><span class="co"># сводка по модели gam.m3</span></span>
<span id="cb166-423"><a href="nonlinear-regression.html#cb166-423" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gam.m3)</span>
<span id="cb166-424"><a href="nonlinear-regression.html#cb166-424" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb166-425"><a href="nonlinear-regression.html#cb166-425" aria-hidden="true" tabindex="-1"></a><span class="do">## Call: gam(formula = wage ~ s(year, 4) + s(age, 5) + education, data = Wage)</span></span>
<span id="cb166-426"><a href="nonlinear-regression.html#cb166-426" aria-hidden="true" tabindex="-1"></a><span class="do">## Deviance Residuals:</span></span>
<span id="cb166-427"><a href="nonlinear-regression.html#cb166-427" aria-hidden="true" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb166-428"><a href="nonlinear-regression.html#cb166-428" aria-hidden="true" tabindex="-1"></a><span class="do">## -119.43  -19.70   -3.33   14.17  213.48 </span></span>
<span id="cb166-429"><a href="nonlinear-regression.html#cb166-429" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb166-430"><a href="nonlinear-regression.html#cb166-430" aria-hidden="true" tabindex="-1"></a><span class="do">## (Dispersion Parameter for gaussian family taken to be 1235.69)</span></span>
<span id="cb166-431"><a href="nonlinear-regression.html#cb166-431" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb166-432"><a href="nonlinear-regression.html#cb166-432" aria-hidden="true" tabindex="-1"></a><span class="do">##     Null Deviance: 5222086 on 2999 degrees of freedom</span></span>
<span id="cb166-433"><a href="nonlinear-regression.html#cb166-433" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual Deviance: 3689770 on 2986 degrees of freedom</span></span>
<span id="cb166-434"><a href="nonlinear-regression.html#cb166-434" aria-hidden="true" tabindex="-1"></a><span class="do">## AIC: 29887.75 </span></span>
<span id="cb166-435"><a href="nonlinear-regression.html#cb166-435" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb166-436"><a href="nonlinear-regression.html#cb166-436" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Local Scoring Iterations: 2 </span></span>
<span id="cb166-437"><a href="nonlinear-regression.html#cb166-437" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb166-438"><a href="nonlinear-regression.html#cb166-438" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Parametric Effects</span></span>
<span id="cb166-439"><a href="nonlinear-regression.html#cb166-439" aria-hidden="true" tabindex="-1"></a><span class="do">##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    </span></span>
<span id="cb166-440"><a href="nonlinear-regression.html#cb166-440" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)    1   27162   27162  21.981 2.877e-06 ***</span></span>
<span id="cb166-441"><a href="nonlinear-regression.html#cb166-441" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)     1  195338  195338 158.081 &lt; 2.2e-16 ***</span></span>
<span id="cb166-442"><a href="nonlinear-regression.html#cb166-442" aria-hidden="true" tabindex="-1"></a><span class="do">## education     4 1069726  267432 216.423 &lt; 2.2e-16 ***</span></span>
<span id="cb166-443"><a href="nonlinear-regression.html#cb166-443" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals  2986 3689770    1236                      </span></span>
<span id="cb166-444"><a href="nonlinear-regression.html#cb166-444" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb166-445"><a href="nonlinear-regression.html#cb166-445" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb166-446"><a href="nonlinear-regression.html#cb166-446" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb166-447"><a href="nonlinear-regression.html#cb166-447" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Nonparametric Effects</span></span>
<span id="cb166-448"><a href="nonlinear-regression.html#cb166-448" aria-hidden="true" tabindex="-1"></a><span class="do">##             Npar Df Npar F  Pr(F)    </span></span>
<span id="cb166-449"><a href="nonlinear-regression.html#cb166-449" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)                          </span></span>
<span id="cb166-450"><a href="nonlinear-regression.html#cb166-450" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)        3  1.086 0.3537    </span></span>
<span id="cb166-451"><a href="nonlinear-regression.html#cb166-451" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)         4 32.380 &lt;2e-16 ***</span></span>
<span id="cb166-452"><a href="nonlinear-regression.html#cb166-452" aria-hidden="true" tabindex="-1"></a><span class="do">## education                            </span></span>
<span id="cb166-453"><a href="nonlinear-regression.html#cb166-453" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb166-454"><a href="nonlinear-regression.html#cb166-454" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb166-455"><a href="nonlinear-regression.html#cb166-455" aria-hidden="true" tabindex="-1"></a>Работаем с моделью gam.m2.</span>
<span id="cb166-456"><a href="nonlinear-regression.html#cb166-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-457"><a href="nonlinear-regression.html#cb166-457" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по обучающей выборке</span></span>
<span id="cb166-458"><a href="nonlinear-regression.html#cb166-458" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(gam.m2, <span class="at">newdata =</span> Wage)</span>
<span id="cb166-459"><a href="nonlinear-regression.html#cb166-459" aria-hidden="true" tabindex="-1"></a>Также можно использовать в GAM локальные регрессии.</span>
<span id="cb166-460"><a href="nonlinear-regression.html#cb166-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-461"><a href="nonlinear-regression.html#cb166-461" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на локальных регрессиях</span></span>
<span id="cb166-462"><a href="nonlinear-regression.html#cb166-462" aria-hidden="true" tabindex="-1"></a>gam.lo <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="at">df =</span> <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">lo</span>(age, <span class="at">span =</span> <span class="fl">0.7</span>) <span class="sc">+</span> education, </span>
<span id="cb166-463"><a href="nonlinear-regression.html#cb166-463" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> Wage)</span>
<span id="cb166-464"><a href="nonlinear-regression.html#cb166-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-465"><a href="nonlinear-regression.html#cb166-465" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb166-466"><a href="nonlinear-regression.html#cb166-466" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.gam</span>(gam.lo, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb166-467"><a href="nonlinear-regression.html#cb166-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-468"><a href="nonlinear-regression.html#cb166-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-469"><a href="nonlinear-regression.html#cb166-469" aria-hidden="true" tabindex="-1"></a><span class="co"># модель со взаимодействием регрессоров year и age</span></span>
<span id="cb166-470"><a href="nonlinear-regression.html#cb166-470" aria-hidden="true" tabindex="-1"></a>gam.lo.i <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">lo</span>(year, age, <span class="at">span =</span> <span class="fl">0.5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb166-471"><a href="nonlinear-regression.html#cb166-471" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb166-472"><a href="nonlinear-regression.html#cb166-472" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb166-473"><a href="nonlinear-regression.html#cb166-473" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb166-474"><a href="nonlinear-regression.html#cb166-474" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb166-475"><a href="nonlinear-regression.html#cb166-475" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb166-476"><a href="nonlinear-regression.html#cb166-476" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb166-477"><a href="nonlinear-regression.html#cb166-477" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb166-478"><a href="nonlinear-regression.html#cb166-478" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb166-479"><a href="nonlinear-regression.html#cb166-479" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lo.i)</span>
<span id="cb166-480"><a href="nonlinear-regression.html#cb166-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-481"><a href="nonlinear-regression.html#cb166-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-482"><a href="nonlinear-regression.html#cb166-482" aria-hidden="true" tabindex="-1"></a>Логистическая GAM</span>
<span id="cb166-483"><a href="nonlinear-regression.html#cb166-483" aria-hidden="true" tabindex="-1"></a>Построим логистическую GAM для всероятности того, что wage превышает <span class="fl">250.</span></span>
<span id="cb166-484"><a href="nonlinear-regression.html#cb166-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-485"><a href="nonlinear-regression.html#cb166-485" aria-hidden="true" tabindex="-1"></a>gam.lr <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education, </span>
<span id="cb166-486"><a href="nonlinear-regression.html#cb166-486" aria-hidden="true" tabindex="-1"></a>              <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage)</span>
<span id="cb166-487"><a href="nonlinear-regression.html#cb166-487" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb166-488"><a href="nonlinear-regression.html#cb166-488" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb166-489"><a href="nonlinear-regression.html#cb166-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-490"><a href="nonlinear-regression.html#cb166-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-491"><a href="nonlinear-regression.html#cb166-491" aria-hidden="true" tabindex="-1"></a><span class="co"># уровни образования по группам разного достатка</span></span>
<span id="cb166-492"><a href="nonlinear-regression.html#cb166-492" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(education, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>))</span>
<span id="cb166-493"><a href="nonlinear-regression.html#cb166-493" aria-hidden="true" tabindex="-1"></a><span class="do">##                     </span></span>
<span id="cb166-494"><a href="nonlinear-regression.html#cb166-494" aria-hidden="true" tabindex="-1"></a><span class="do">## education            FALSE TRUE</span></span>
<span id="cb166-495"><a href="nonlinear-regression.html#cb166-495" aria-hidden="true" tabindex="-1"></a><span class="do">##   1. &lt; HS Grad         268    0</span></span>
<span id="cb166-496"><a href="nonlinear-regression.html#cb166-496" aria-hidden="true" tabindex="-1"></a><span class="do">##   2. HS Grad           966    5</span></span>
<span id="cb166-497"><a href="nonlinear-regression.html#cb166-497" aria-hidden="true" tabindex="-1"></a><span class="do">##   3. Some College      643    7</span></span>
<span id="cb166-498"><a href="nonlinear-regression.html#cb166-498" aria-hidden="true" tabindex="-1"></a><span class="do">##   4. College Grad      663   22</span></span>
<span id="cb166-499"><a href="nonlinear-regression.html#cb166-499" aria-hidden="true" tabindex="-1"></a><span class="do">##   5. Advanced Degree   381   45</span></span>
<span id="cb166-500"><a href="nonlinear-regression.html#cb166-500" aria-hidden="true" tabindex="-1"></a>В категории с самым низким уровнем образования нет wage <span class="sc">&gt;</span> <span class="dv">250</span>, поэтому убираем её.</span>
<span id="cb166-501"><a href="nonlinear-regression.html#cb166-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-502"><a href="nonlinear-regression.html#cb166-502" aria-hidden="true" tabindex="-1"></a>gam.lr.s <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education,</span>
<span id="cb166-503"><a href="nonlinear-regression.html#cb166-503" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage, </span>
<span id="cb166-504"><a href="nonlinear-regression.html#cb166-504" aria-hidden="true" tabindex="-1"></a>                <span class="at">subset =</span> (education <span class="sc">!=</span> <span class="st">&quot;1. &lt; HS Grad&quot;</span>))</span>
<span id="cb166-505"><a href="nonlinear-regression.html#cb166-505" aria-hidden="true" tabindex="-1"></a><span class="co"># график</span></span>
<span id="cb166-506"><a href="nonlinear-regression.html#cb166-506" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb166-507"><a href="nonlinear-regression.html#cb166-507" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr.s, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb166-508"><a href="nonlinear-regression.html#cb166-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-509"><a href="nonlinear-regression.html#cb166-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-510"><a href="nonlinear-regression.html#cb166-510" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(Wage)</span></code></pre></div>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="nonlinear-regression.html#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonlinear modeling</span></span>
<span id="cb167-2"><a href="nonlinear-regression.html#cb167-2" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb167-3"><a href="nonlinear-regression.html#cb167-3" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">8</span></span>
<span id="cb167-4"><a href="nonlinear-regression.html#cb167-4" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb167-5"><a href="nonlinear-regression.html#cb167-5" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb167-6"><a href="nonlinear-regression.html#cb167-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb167-7"><a href="nonlinear-regression.html#cb167-7" aria-hidden="true" tabindex="-1"></a>    строить регрессионные деревья;</span>
<span id="cb167-8"><a href="nonlinear-regression.html#cb167-8" aria-hidden="true" tabindex="-1"></a>строить деревья классификации;</span>
<span id="cb167-9"><a href="nonlinear-regression.html#cb167-9" aria-hidden="true" tabindex="-1"></a>делать обрезку дерева;</span>
<span id="cb167-10"><a href="nonlinear-regression.html#cb167-10" aria-hidden="true" tabindex="-1"></a>использовать бэггинг, бустинг, случайный лес для улучшения качества прогнозирования.</span>
<span id="cb167-11"><a href="nonlinear-regression.html#cb167-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> деревья решений.</span>
<span id="cb167-12"><a href="nonlinear-regression.html#cb167-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Sales {ISLR}, Boston {ISLR}</span>
<span id="cb167-13"><a href="nonlinear-regression.html#cb167-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-14"><a href="nonlinear-regression.html#cb167-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">8.</span></span>
<span id="cb167-15"><a href="nonlinear-regression.html#cb167-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-16"><a href="nonlinear-regression.html#cb167-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;tree&#39;</span>)              <span class="co"># деревья</span></span>
<span id="cb167-17"><a href="nonlinear-regression.html#cb167-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;tree&#39; was built under R version 3.4.4</span></span>
<span id="cb167-18"><a href="nonlinear-regression.html#cb167-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># наборы данных</span></span>
<span id="cb167-19"><a href="nonlinear-regression.html#cb167-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;MASS&#39;</span>)</span>
<span id="cb167-20"><a href="nonlinear-regression.html#cb167-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;randomForest&#39;</span>)      <span class="co"># случайный лес</span></span>
<span id="cb167-21"><a href="nonlinear-regression.html#cb167-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;randomForest&#39; was built under R version 3.4.4</span></span>
<span id="cb167-22"><a href="nonlinear-regression.html#cb167-22" aria-hidden="true" tabindex="-1"></a><span class="do">## randomForest 4.6-14</span></span>
<span id="cb167-23"><a href="nonlinear-regression.html#cb167-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Type rfNews() to see new features/changes/bug fixes.</span></span>
<span id="cb167-24"><a href="nonlinear-regression.html#cb167-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gbm&#39;</span>)</span>
<span id="cb167-25"><a href="nonlinear-regression.html#cb167-25" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gbm&#39; was built under R version 3.4.4</span></span>
<span id="cb167-26"><a href="nonlinear-regression.html#cb167-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: survival</span></span>
<span id="cb167-27"><a href="nonlinear-regression.html#cb167-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: lattice</span></span>
<span id="cb167-28"><a href="nonlinear-regression.html#cb167-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: splines</span></span>
<span id="cb167-29"><a href="nonlinear-regression.html#cb167-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: parallel</span></span>
<span id="cb167-30"><a href="nonlinear-regression.html#cb167-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gbm 2.1.3</span></span>
<span id="cb167-31"><a href="nonlinear-regression.html#cb167-31" aria-hidden="true" tabindex="-1"></a>Деревья решений</span>
<span id="cb167-32"><a href="nonlinear-regression.html#cb167-32" aria-hidden="true" tabindex="-1"></a>Загрузим таблицу с данными по продажам детских кресел и добавим к ней переменную High – “высокие продажи” со значениями<span class="sc">:</span></span>
<span id="cb167-33"><a href="nonlinear-regression.html#cb167-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb167-34"><a href="nonlinear-regression.html#cb167-34" aria-hidden="true" tabindex="-1"></a>    Yes если продажи больше <span class="dv">8</span> (тыс. шт.);</span>
<span id="cb167-35"><a href="nonlinear-regression.html#cb167-35" aria-hidden="true" tabindex="-1"></a>No в противном случае.</span>
<span id="cb167-36"><a href="nonlinear-regression.html#cb167-36" aria-hidden="true" tabindex="-1"></a>?Carseats</span>
<span id="cb167-37"><a href="nonlinear-regression.html#cb167-37" aria-hidden="true" tabindex="-1"></a><span class="do">## starting httpd help server ... done</span></span>
<span id="cb167-38"><a href="nonlinear-regression.html#cb167-38" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Carseats)</span>
<span id="cb167-39"><a href="nonlinear-regression.html#cb167-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-40"><a href="nonlinear-regression.html#cb167-40" aria-hidden="true" tabindex="-1"></a><span class="co"># новая переменная</span></span>
<span id="cb167-41"><a href="nonlinear-regression.html#cb167-41" aria-hidden="true" tabindex="-1"></a>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Sales <span class="sc">&lt;=</span> <span class="dv">8</span>, <span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb167-42"><a href="nonlinear-regression.html#cb167-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-43"><a href="nonlinear-regression.html#cb167-43" aria-hidden="true" tabindex="-1"></a><span class="co"># присоединяем к таблице данных</span></span>
<span id="cb167-44"><a href="nonlinear-regression.html#cb167-44" aria-hidden="true" tabindex="-1"></a>Carseats <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Carseats, High)</span>
<span id="cb167-45"><a href="nonlinear-regression.html#cb167-45" aria-hidden="true" tabindex="-1"></a>Строим дерево для категориального отклика High, отбросив непрерывный отклик Sales.</span>
<span id="cb167-46"><a href="nonlinear-regression.html#cb167-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-47"><a href="nonlinear-regression.html#cb167-47" aria-hidden="true" tabindex="-1"></a><span class="co"># модель бинарного  дерева</span></span>
<span id="cb167-48"><a href="nonlinear-regression.html#cb167-48" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats)</span>
<span id="cb167-49"><a href="nonlinear-regression.html#cb167-49" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.carseats)</span>
<span id="cb167-50"><a href="nonlinear-regression.html#cb167-50" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-51"><a href="nonlinear-regression.html#cb167-51" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree:</span></span>
<span id="cb167-52"><a href="nonlinear-regression.html#cb167-52" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = High ~ . - Sales, data = Carseats)</span></span>
<span id="cb167-53"><a href="nonlinear-regression.html#cb167-53" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb167-54"><a href="nonlinear-regression.html#cb167-54" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;ShelveLoc&quot;   &quot;Price&quot;       &quot;Income&quot;      &quot;CompPrice&quot;   &quot;Population&quot; </span></span>
<span id="cb167-55"><a href="nonlinear-regression.html#cb167-55" aria-hidden="true" tabindex="-1"></a><span class="do">## [6] &quot;Advertising&quot; &quot;Age&quot;         &quot;US&quot;         </span></span>
<span id="cb167-56"><a href="nonlinear-regression.html#cb167-56" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  27 </span></span>
<span id="cb167-57"><a href="nonlinear-regression.html#cb167-57" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  0.4575 = 170.7 / 373 </span></span>
<span id="cb167-58"><a href="nonlinear-regression.html#cb167-58" aria-hidden="true" tabindex="-1"></a><span class="do">## Misclassification error rate: 0.09 = 36 / 400</span></span>
<span id="cb167-59"><a href="nonlinear-regression.html#cb167-59" aria-hidden="true" tabindex="-1"></a><span class="co"># график результата</span></span>
<span id="cb167-60"><a href="nonlinear-regression.html#cb167-60" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.carseats)            <span class="co"># ветви</span></span>
<span id="cb167-61"><a href="nonlinear-regression.html#cb167-61" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.carseats, <span class="at">pretty=</span><span class="dv">0</span>)  <span class="co"># подписи</span></span>
<span id="cb167-62"><a href="nonlinear-regression.html#cb167-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-63"><a href="nonlinear-regression.html#cb167-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-64"><a href="nonlinear-regression.html#cb167-64" aria-hidden="true" tabindex="-1"></a>tree.carseats                  <span class="co"># посмотреть всё дерево в консоли</span></span>
<span id="cb167-65"><a href="nonlinear-regression.html#cb167-65" aria-hidden="true" tabindex="-1"></a><span class="do">## node), split, n, deviance, yval, (yprob)</span></span>
<span id="cb167-66"><a href="nonlinear-regression.html#cb167-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       * denotes terminal node</span></span>
<span id="cb167-67"><a href="nonlinear-regression.html#cb167-67" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-68"><a href="nonlinear-regression.html#cb167-68" aria-hidden="true" tabindex="-1"></a><span class="do">##   1) root 400 541.500 No ( 0.59000 0.41000 )  </span></span>
<span id="cb167-69"><a href="nonlinear-regression.html#cb167-69" aria-hidden="true" tabindex="-1"></a><span class="do">##     2) ShelveLoc: Bad,Medium 315 390.600 No ( 0.68889 0.31111 )  </span></span>
<span id="cb167-70"><a href="nonlinear-regression.html#cb167-70" aria-hidden="true" tabindex="-1"></a><span class="do">##       4) Price &lt; 92.5 46  56.530 Yes ( 0.30435 0.69565 )  </span></span>
<span id="cb167-71"><a href="nonlinear-regression.html#cb167-71" aria-hidden="true" tabindex="-1"></a><span class="do">##         8) Income &lt; 57 10  12.220 No ( 0.70000 0.30000 )  </span></span>
<span id="cb167-72"><a href="nonlinear-regression.html#cb167-72" aria-hidden="true" tabindex="-1"></a><span class="do">##          16) CompPrice &lt; 110.5 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb167-73"><a href="nonlinear-regression.html#cb167-73" aria-hidden="true" tabindex="-1"></a><span class="do">##          17) CompPrice &gt; 110.5 5   6.730 Yes ( 0.40000 0.60000 ) *</span></span>
<span id="cb167-74"><a href="nonlinear-regression.html#cb167-74" aria-hidden="true" tabindex="-1"></a><span class="do">##         9) Income &gt; 57 36  35.470 Yes ( 0.19444 0.80556 )  </span></span>
<span id="cb167-75"><a href="nonlinear-regression.html#cb167-75" aria-hidden="true" tabindex="-1"></a><span class="do">##          18) Population &lt; 207.5 16  21.170 Yes ( 0.37500 0.62500 ) *</span></span>
<span id="cb167-76"><a href="nonlinear-regression.html#cb167-76" aria-hidden="true" tabindex="-1"></a><span class="do">##          19) Population &gt; 207.5 20   7.941 Yes ( 0.05000 0.95000 ) *</span></span>
<span id="cb167-77"><a href="nonlinear-regression.html#cb167-77" aria-hidden="true" tabindex="-1"></a><span class="do">##       5) Price &gt; 92.5 269 299.800 No ( 0.75465 0.24535 )  </span></span>
<span id="cb167-78"><a href="nonlinear-regression.html#cb167-78" aria-hidden="true" tabindex="-1"></a><span class="do">##        10) Advertising &lt; 13.5 224 213.200 No ( 0.81696 0.18304 )  </span></span>
<span id="cb167-79"><a href="nonlinear-regression.html#cb167-79" aria-hidden="true" tabindex="-1"></a><span class="do">##          20) CompPrice &lt; 124.5 96  44.890 No ( 0.93750 0.06250 )  </span></span>
<span id="cb167-80"><a href="nonlinear-regression.html#cb167-80" aria-hidden="true" tabindex="-1"></a><span class="do">##            40) Price &lt; 106.5 38  33.150 No ( 0.84211 0.15789 )  </span></span>
<span id="cb167-81"><a href="nonlinear-regression.html#cb167-81" aria-hidden="true" tabindex="-1"></a><span class="do">##              80) Population &lt; 177 12  16.300 No ( 0.58333 0.41667 )  </span></span>
<span id="cb167-82"><a href="nonlinear-regression.html#cb167-82" aria-hidden="true" tabindex="-1"></a><span class="do">##               160) Income &lt; 60.5 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb167-83"><a href="nonlinear-regression.html#cb167-83" aria-hidden="true" tabindex="-1"></a><span class="do">##               161) Income &gt; 60.5 6   5.407 Yes ( 0.16667 0.83333 ) *</span></span>
<span id="cb167-84"><a href="nonlinear-regression.html#cb167-84" aria-hidden="true" tabindex="-1"></a><span class="do">##              81) Population &gt; 177 26   8.477 No ( 0.96154 0.03846 ) *</span></span>
<span id="cb167-85"><a href="nonlinear-regression.html#cb167-85" aria-hidden="true" tabindex="-1"></a><span class="do">##            41) Price &gt; 106.5 58   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb167-86"><a href="nonlinear-regression.html#cb167-86" aria-hidden="true" tabindex="-1"></a><span class="do">##          21) CompPrice &gt; 124.5 128 150.200 No ( 0.72656 0.27344 )  </span></span>
<span id="cb167-87"><a href="nonlinear-regression.html#cb167-87" aria-hidden="true" tabindex="-1"></a><span class="do">##            42) Price &lt; 122.5 51  70.680 Yes ( 0.49020 0.50980 )  </span></span>
<span id="cb167-88"><a href="nonlinear-regression.html#cb167-88" aria-hidden="true" tabindex="-1"></a><span class="do">##              84) ShelveLoc: Bad 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb167-89"><a href="nonlinear-regression.html#cb167-89" aria-hidden="true" tabindex="-1"></a><span class="do">##              85) ShelveLoc: Medium 40  52.930 Yes ( 0.37500 0.62500 )  </span></span>
<span id="cb167-90"><a href="nonlinear-regression.html#cb167-90" aria-hidden="true" tabindex="-1"></a><span class="do">##               170) Price &lt; 109.5 16   7.481 Yes ( 0.06250 0.93750 ) *</span></span>
<span id="cb167-91"><a href="nonlinear-regression.html#cb167-91" aria-hidden="true" tabindex="-1"></a><span class="do">##               171) Price &gt; 109.5 24  32.600 No ( 0.58333 0.41667 )  </span></span>
<span id="cb167-92"><a href="nonlinear-regression.html#cb167-92" aria-hidden="true" tabindex="-1"></a><span class="do">##                 342) Age &lt; 49.5 13  16.050 Yes ( 0.30769 0.69231 ) *</span></span>
<span id="cb167-93"><a href="nonlinear-regression.html#cb167-93" aria-hidden="true" tabindex="-1"></a><span class="do">##                 343) Age &gt; 49.5 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb167-94"><a href="nonlinear-regression.html#cb167-94" aria-hidden="true" tabindex="-1"></a><span class="do">##            43) Price &gt; 122.5 77  55.540 No ( 0.88312 0.11688 )  </span></span>
<span id="cb167-95"><a href="nonlinear-regression.html#cb167-95" aria-hidden="true" tabindex="-1"></a><span class="do">##              86) CompPrice &lt; 147.5 58  17.400 No ( 0.96552 0.03448 ) *</span></span>
<span id="cb167-96"><a href="nonlinear-regression.html#cb167-96" aria-hidden="true" tabindex="-1"></a><span class="do">##              87) CompPrice &gt; 147.5 19  25.010 No ( 0.63158 0.36842 )  </span></span>
<span id="cb167-97"><a href="nonlinear-regression.html#cb167-97" aria-hidden="true" tabindex="-1"></a><span class="do">##               174) Price &lt; 147 12  16.300 Yes ( 0.41667 0.58333 )  </span></span>
<span id="cb167-98"><a href="nonlinear-regression.html#cb167-98" aria-hidden="true" tabindex="-1"></a><span class="do">##                 348) CompPrice &lt; 152.5 7   5.742 Yes ( 0.14286 0.85714 ) *</span></span>
<span id="cb167-99"><a href="nonlinear-regression.html#cb167-99" aria-hidden="true" tabindex="-1"></a><span class="do">##                 349) CompPrice &gt; 152.5 5   5.004 No ( 0.80000 0.20000 ) *</span></span>
<span id="cb167-100"><a href="nonlinear-regression.html#cb167-100" aria-hidden="true" tabindex="-1"></a><span class="do">##               175) Price &gt; 147 7   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb167-101"><a href="nonlinear-regression.html#cb167-101" aria-hidden="true" tabindex="-1"></a><span class="do">##        11) Advertising &gt; 13.5 45  61.830 Yes ( 0.44444 0.55556 )  </span></span>
<span id="cb167-102"><a href="nonlinear-regression.html#cb167-102" aria-hidden="true" tabindex="-1"></a><span class="do">##          22) Age &lt; 54.5 25  25.020 Yes ( 0.20000 0.80000 )  </span></span>
<span id="cb167-103"><a href="nonlinear-regression.html#cb167-103" aria-hidden="true" tabindex="-1"></a><span class="do">##            44) CompPrice &lt; 130.5 14  18.250 Yes ( 0.35714 0.64286 )  </span></span>
<span id="cb167-104"><a href="nonlinear-regression.html#cb167-104" aria-hidden="true" tabindex="-1"></a><span class="do">##              88) Income &lt; 100 9  12.370 No ( 0.55556 0.44444 ) *</span></span>
<span id="cb167-105"><a href="nonlinear-regression.html#cb167-105" aria-hidden="true" tabindex="-1"></a><span class="do">##              89) Income &gt; 100 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb167-106"><a href="nonlinear-regression.html#cb167-106" aria-hidden="true" tabindex="-1"></a><span class="do">##            45) CompPrice &gt; 130.5 11   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb167-107"><a href="nonlinear-regression.html#cb167-107" aria-hidden="true" tabindex="-1"></a><span class="do">##          23) Age &gt; 54.5 20  22.490 No ( 0.75000 0.25000 )  </span></span>
<span id="cb167-108"><a href="nonlinear-regression.html#cb167-108" aria-hidden="true" tabindex="-1"></a><span class="do">##            46) CompPrice &lt; 122.5 10   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb167-109"><a href="nonlinear-regression.html#cb167-109" aria-hidden="true" tabindex="-1"></a><span class="do">##            47) CompPrice &gt; 122.5 10  13.860 No ( 0.50000 0.50000 )  </span></span>
<span id="cb167-110"><a href="nonlinear-regression.html#cb167-110" aria-hidden="true" tabindex="-1"></a><span class="do">##              94) Price &lt; 125 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb167-111"><a href="nonlinear-regression.html#cb167-111" aria-hidden="true" tabindex="-1"></a><span class="do">##              95) Price &gt; 125 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb167-112"><a href="nonlinear-regression.html#cb167-112" aria-hidden="true" tabindex="-1"></a><span class="do">##     3) ShelveLoc: Good 85  90.330 Yes ( 0.22353 0.77647 )  </span></span>
<span id="cb167-113"><a href="nonlinear-regression.html#cb167-113" aria-hidden="true" tabindex="-1"></a><span class="do">##       6) Price &lt; 135 68  49.260 Yes ( 0.11765 0.88235 )  </span></span>
<span id="cb167-114"><a href="nonlinear-regression.html#cb167-114" aria-hidden="true" tabindex="-1"></a><span class="do">##        12) US: No 17  22.070 Yes ( 0.35294 0.64706 )  </span></span>
<span id="cb167-115"><a href="nonlinear-regression.html#cb167-115" aria-hidden="true" tabindex="-1"></a><span class="do">##          24) Price &lt; 109 8   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb167-116"><a href="nonlinear-regression.html#cb167-116" aria-hidden="true" tabindex="-1"></a><span class="do">##          25) Price &gt; 109 9  11.460 No ( 0.66667 0.33333 ) *</span></span>
<span id="cb167-117"><a href="nonlinear-regression.html#cb167-117" aria-hidden="true" tabindex="-1"></a><span class="do">##        13) US: Yes 51  16.880 Yes ( 0.03922 0.96078 ) *</span></span>
<span id="cb167-118"><a href="nonlinear-regression.html#cb167-118" aria-hidden="true" tabindex="-1"></a><span class="do">##       7) Price &gt; 135 17  22.070 No ( 0.64706 0.35294 )  </span></span>
<span id="cb167-119"><a href="nonlinear-regression.html#cb167-119" aria-hidden="true" tabindex="-1"></a><span class="do">##        14) Income &lt; 46 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb167-120"><a href="nonlinear-regression.html#cb167-120" aria-hidden="true" tabindex="-1"></a><span class="do">##        15) Income &gt; 46 11  15.160 Yes ( 0.45455 0.54545 ) *</span></span>
<span id="cb167-121"><a href="nonlinear-regression.html#cb167-121" aria-hidden="true" tabindex="-1"></a>Теперь построим дерево на обучающей выборке и оценим ошибку на тестовой.</span>
<span id="cb167-122"><a href="nonlinear-regression.html#cb167-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-123"><a href="nonlinear-regression.html#cb167-123" aria-hidden="true" tabindex="-1"></a><span class="co"># ядро генератора случайных чисел</span></span>
<span id="cb167-124"><a href="nonlinear-regression.html#cb167-124" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb167-125"><a href="nonlinear-regression.html#cb167-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-126"><a href="nonlinear-regression.html#cb167-126" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb167-127"><a href="nonlinear-regression.html#cb167-127" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Carseats), <span class="dv">200</span>)</span>
<span id="cb167-128"><a href="nonlinear-regression.html#cb167-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-129"><a href="nonlinear-regression.html#cb167-129" aria-hidden="true" tabindex="-1"></a><span class="co"># тестовая выборка</span></span>
<span id="cb167-130"><a href="nonlinear-regression.html#cb167-130" aria-hidden="true" tabindex="-1"></a>Carseats.test <span class="ot">&lt;-</span> Carseats[<span class="sc">-</span>train,]</span>
<span id="cb167-131"><a href="nonlinear-regression.html#cb167-131" aria-hidden="true" tabindex="-1"></a>High.test <span class="ot">&lt;-</span> High[<span class="sc">-</span>train]</span>
<span id="cb167-132"><a href="nonlinear-regression.html#cb167-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-133"><a href="nonlinear-regression.html#cb167-133" aria-hidden="true" tabindex="-1"></a><span class="co"># строим дерево на обучающей выборке</span></span>
<span id="cb167-134"><a href="nonlinear-regression.html#cb167-134" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats, <span class="at">subset =</span> train)</span>
<span id="cb167-135"><a href="nonlinear-regression.html#cb167-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-136"><a href="nonlinear-regression.html#cb167-136" aria-hidden="true" tabindex="-1"></a><span class="co"># делаем прогноз</span></span>
<span id="cb167-137"><a href="nonlinear-regression.html#cb167-137" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb167-138"><a href="nonlinear-regression.html#cb167-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-139"><a href="nonlinear-regression.html#cb167-139" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb167-140"><a href="nonlinear-regression.html#cb167-140" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb167-141"><a href="nonlinear-regression.html#cb167-141" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb167-142"><a href="nonlinear-regression.html#cb167-142" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb167-143"><a href="nonlinear-regression.html#cb167-143" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb167-144"><a href="nonlinear-regression.html#cb167-144" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  27</span></span>
<span id="cb167-145"><a href="nonlinear-regression.html#cb167-145" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  57</span></span>
<span id="cb167-146"><a href="nonlinear-regression.html#cb167-146" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb167-147"><a href="nonlinear-regression.html#cb167-147" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb167-148"><a href="nonlinear-regression.html#cb167-148" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb167-149"><a href="nonlinear-regression.html#cb167-149" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.715</span></span>
<span id="cb167-150"><a href="nonlinear-regression.html#cb167-150" aria-hidden="true" tabindex="-1"></a>Обобщённая характеристика точности<span class="sc">:</span> доля верных прогнозов<span class="sc">:</span> <span class="dv">0</span>.<span class="fl">72.</span></span>
<span id="cb167-151"><a href="nonlinear-regression.html#cb167-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-152"><a href="nonlinear-regression.html#cb167-152" aria-hidden="true" tabindex="-1"></a>Теперь обрезаем дерево, используя в качестве критерия частоту ошибок классификации. Функция <span class="fu">cv.tree</span>() проводит кросс<span class="sc">-</span>валидацию для выбора лучшего дерева, аргумент prune.misclass означает, что мы минимизируем ошибку классификации.</span>
<span id="cb167-153"><a href="nonlinear-regression.html#cb167-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-154"><a href="nonlinear-regression.html#cb167-154" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb167-155"><a href="nonlinear-regression.html#cb167-155" aria-hidden="true" tabindex="-1"></a>cv.carseats <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.carseats, <span class="at">FUN =</span> prune.misclass)</span>
<span id="cb167-156"><a href="nonlinear-regression.html#cb167-156" aria-hidden="true" tabindex="-1"></a><span class="co"># имена элементов полученного объекта</span></span>
<span id="cb167-157"><a href="nonlinear-regression.html#cb167-157" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(cv.carseats)</span>
<span id="cb167-158"><a href="nonlinear-regression.html#cb167-158" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;size&quot;   &quot;dev&quot;    &quot;k&quot;      &quot;method&quot;</span></span>
<span id="cb167-159"><a href="nonlinear-regression.html#cb167-159" aria-hidden="true" tabindex="-1"></a><span class="co"># сам объект</span></span>
<span id="cb167-160"><a href="nonlinear-regression.html#cb167-160" aria-hidden="true" tabindex="-1"></a>cv.carseats</span>
<span id="cb167-161"><a href="nonlinear-regression.html#cb167-161" aria-hidden="true" tabindex="-1"></a><span class="do">## $size</span></span>
<span id="cb167-162"><a href="nonlinear-regression.html#cb167-162" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 19 17 14 13  9  7  3  2  1</span></span>
<span id="cb167-163"><a href="nonlinear-regression.html#cb167-163" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-164"><a href="nonlinear-regression.html#cb167-164" aria-hidden="true" tabindex="-1"></a><span class="do">## $dev</span></span>
<span id="cb167-165"><a href="nonlinear-regression.html#cb167-165" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 55 55 53 52 50 56 69 65 80</span></span>
<span id="cb167-166"><a href="nonlinear-regression.html#cb167-166" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-167"><a href="nonlinear-regression.html#cb167-167" aria-hidden="true" tabindex="-1"></a><span class="do">## $k</span></span>
<span id="cb167-168"><a href="nonlinear-regression.html#cb167-168" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]       -Inf  0.0000000  0.6666667  1.0000000  1.7500000  2.0000000</span></span>
<span id="cb167-169"><a href="nonlinear-regression.html#cb167-169" aria-hidden="true" tabindex="-1"></a><span class="do">## [7]  4.2500000  5.0000000 23.0000000</span></span>
<span id="cb167-170"><a href="nonlinear-regression.html#cb167-170" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-171"><a href="nonlinear-regression.html#cb167-171" aria-hidden="true" tabindex="-1"></a><span class="do">## $method</span></span>
<span id="cb167-172"><a href="nonlinear-regression.html#cb167-172" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;misclass&quot;</span></span>
<span id="cb167-173"><a href="nonlinear-regression.html#cb167-173" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-174"><a href="nonlinear-regression.html#cb167-174" aria-hidden="true" tabindex="-1"></a><span class="do">## attr(,&quot;class&quot;)</span></span>
<span id="cb167-175"><a href="nonlinear-regression.html#cb167-175" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;prune&quot;         &quot;tree.sequence&quot;</span></span>
<span id="cb167-176"><a href="nonlinear-regression.html#cb167-176" aria-hidden="true" tabindex="-1"></a><span class="co"># графики изменения параметров метода по ходу обрезки дерева ###################</span></span>
<span id="cb167-177"><a href="nonlinear-regression.html#cb167-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-178"><a href="nonlinear-regression.html#cb167-178" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. ошибка с кросс-валидацией в зависимости от числа узлов</span></span>
<span id="cb167-179"><a href="nonlinear-regression.html#cb167-179" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb167-180"><a href="nonlinear-regression.html#cb167-180" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>size, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb167-181"><a href="nonlinear-regression.html#cb167-181" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb167-182"><a href="nonlinear-regression.html#cb167-182" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Число узлов (size)&#39;</span>)</span>
<span id="cb167-183"><a href="nonlinear-regression.html#cb167-183" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb167-184"><a href="nonlinear-regression.html#cb167-184" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.carseats<span class="sc">$</span>size[cv.carseats<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.carseats<span class="sc">$</span>dev)]</span>
<span id="cb167-185"><a href="nonlinear-regression.html#cb167-185" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb167-186"><a href="nonlinear-regression.html#cb167-186" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb167-187"><a href="nonlinear-regression.html#cb167-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-188"><a href="nonlinear-regression.html#cb167-188" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. ошибка с кросс-валидацией в зависимости от штрафа на сложность</span></span>
<span id="cb167-189"><a href="nonlinear-regression.html#cb167-189" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>k, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb167-190"><a href="nonlinear-regression.html#cb167-190" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb167-191"><a href="nonlinear-regression.html#cb167-191" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Штраф за сложность (k)&#39;</span>)</span>
<span id="cb167-192"><a href="nonlinear-regression.html#cb167-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-193"><a href="nonlinear-regression.html#cb167-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-194"><a href="nonlinear-regression.html#cb167-194" aria-hidden="true" tabindex="-1"></a>Как видно на графике слева, минимум частоты ошибок достигается при числе узлов <span class="fl">9.</span> Оценим точность дерева с <span class="dv">9</span> узлами.</span>
<span id="cb167-195"><a href="nonlinear-regression.html#cb167-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-196"><a href="nonlinear-regression.html#cb167-196" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 9 узлами</span></span>
<span id="cb167-197"><a href="nonlinear-regression.html#cb167-197" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">9</span>)</span>
<span id="cb167-198"><a href="nonlinear-regression.html#cb167-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-199"><a href="nonlinear-regression.html#cb167-199" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb167-200"><a href="nonlinear-regression.html#cb167-200" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb167-201"><a href="nonlinear-regression.html#cb167-201" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb167-202"><a href="nonlinear-regression.html#cb167-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-203"><a href="nonlinear-regression.html#cb167-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-204"><a href="nonlinear-regression.html#cb167-204" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb167-205"><a href="nonlinear-regression.html#cb167-205" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb167-206"><a href="nonlinear-regression.html#cb167-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-207"><a href="nonlinear-regression.html#cb167-207" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb167-208"><a href="nonlinear-regression.html#cb167-208" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb167-209"><a href="nonlinear-regression.html#cb167-209" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb167-210"><a href="nonlinear-regression.html#cb167-210" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb167-211"><a href="nonlinear-regression.html#cb167-211" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb167-212"><a href="nonlinear-regression.html#cb167-212" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  94  24</span></span>
<span id="cb167-213"><a href="nonlinear-regression.html#cb167-213" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 22  60</span></span>
<span id="cb167-214"><a href="nonlinear-regression.html#cb167-214" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb167-215"><a href="nonlinear-regression.html#cb167-215" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb167-216"><a href="nonlinear-regression.html#cb167-216" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb167-217"><a href="nonlinear-regression.html#cb167-217" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.77</span></span>
<span id="cb167-218"><a href="nonlinear-regression.html#cb167-218" aria-hidden="true" tabindex="-1"></a>Точность этой модели чуть выше точности исходного дерева и составляет <span class="dv">0</span>.<span class="fl">77.</span> Увеличив количество узлов, получим более глубокое дерево, но менее точное.</span>
<span id="cb167-219"><a href="nonlinear-regression.html#cb167-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-220"><a href="nonlinear-regression.html#cb167-220" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 13 узлами</span></span>
<span id="cb167-221"><a href="nonlinear-regression.html#cb167-221" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">15</span>)</span>
<span id="cb167-222"><a href="nonlinear-regression.html#cb167-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-223"><a href="nonlinear-regression.html#cb167-223" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb167-224"><a href="nonlinear-regression.html#cb167-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb167-225"><a href="nonlinear-regression.html#cb167-225" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb167-226"><a href="nonlinear-regression.html#cb167-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-227"><a href="nonlinear-regression.html#cb167-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-228"><a href="nonlinear-regression.html#cb167-228" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb167-229"><a href="nonlinear-regression.html#cb167-229" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb167-230"><a href="nonlinear-regression.html#cb167-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-231"><a href="nonlinear-regression.html#cb167-231" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb167-232"><a href="nonlinear-regression.html#cb167-232" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb167-233"><a href="nonlinear-regression.html#cb167-233" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb167-234"><a href="nonlinear-regression.html#cb167-234" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb167-235"><a href="nonlinear-regression.html#cb167-235" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb167-236"><a href="nonlinear-regression.html#cb167-236" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  22</span></span>
<span id="cb167-237"><a href="nonlinear-regression.html#cb167-237" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  62</span></span>
<span id="cb167-238"><a href="nonlinear-regression.html#cb167-238" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb167-239"><a href="nonlinear-regression.html#cb167-239" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb167-240"><a href="nonlinear-regression.html#cb167-240" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb167-241"><a href="nonlinear-regression.html#cb167-241" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.74</span></span>
<span id="cb167-242"><a href="nonlinear-regression.html#cb167-242" aria-hidden="true" tabindex="-1"></a><span class="co"># сбрасываем графические параметры</span></span>
<span id="cb167-243"><a href="nonlinear-regression.html#cb167-243" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb167-244"><a href="nonlinear-regression.html#cb167-244" aria-hidden="true" tabindex="-1"></a>Регрессионные деревья</span>
<span id="cb167-245"><a href="nonlinear-regression.html#cb167-245" aria-hidden="true" tabindex="-1"></a>Воспользуемся набором данных Boston.</span>
<span id="cb167-246"><a href="nonlinear-regression.html#cb167-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-247"><a href="nonlinear-regression.html#cb167-247" aria-hidden="true" tabindex="-1"></a>?Boston</span>
<span id="cb167-248"><a href="nonlinear-regression.html#cb167-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-249"><a href="nonlinear-regression.html#cb167-249" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb167-250"><a href="nonlinear-regression.html#cb167-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb167-251"><a href="nonlinear-regression.html#cb167-251" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Boston), <span class="fu">nrow</span>(Boston)<span class="sc">/</span><span class="dv">2</span>) <span class="co"># обучающая выборка -- 50%</span></span>
<span id="cb167-252"><a href="nonlinear-regression.html#cb167-252" aria-hidden="true" tabindex="-1"></a>Построим дерево регрессии для зависимой переменной medv<span class="sc">:</span> медианная стоимости домов, в которых живут собственники (тыс. долл.).</span>
<span id="cb167-253"><a href="nonlinear-regression.html#cb167-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-254"><a href="nonlinear-regression.html#cb167-254" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb167-255"><a href="nonlinear-regression.html#cb167-255" aria-hidden="true" tabindex="-1"></a>tree.boston <span class="ot">&lt;-</span> <span class="fu">tree</span>(medv <span class="sc">~</span> ., Boston, <span class="at">subset =</span> train)</span>
<span id="cb167-256"><a href="nonlinear-regression.html#cb167-256" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.boston)</span>
<span id="cb167-257"><a href="nonlinear-regression.html#cb167-257" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-258"><a href="nonlinear-regression.html#cb167-258" aria-hidden="true" tabindex="-1"></a><span class="do">## Regression tree:</span></span>
<span id="cb167-259"><a href="nonlinear-regression.html#cb167-259" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = medv ~ ., data = Boston, subset = train)</span></span>
<span id="cb167-260"><a href="nonlinear-regression.html#cb167-260" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb167-261"><a href="nonlinear-regression.html#cb167-261" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;lstat&quot; &quot;rm&quot;    &quot;dis&quot;  </span></span>
<span id="cb167-262"><a href="nonlinear-regression.html#cb167-262" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  8 </span></span>
<span id="cb167-263"><a href="nonlinear-regression.html#cb167-263" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  12.65 = 3099 / 245 </span></span>
<span id="cb167-264"><a href="nonlinear-regression.html#cb167-264" aria-hidden="true" tabindex="-1"></a><span class="do">## Distribution of residuals:</span></span>
<span id="cb167-265"><a href="nonlinear-regression.html#cb167-265" aria-hidden="true" tabindex="-1"></a><span class="do">##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. </span></span>
<span id="cb167-266"><a href="nonlinear-regression.html#cb167-266" aria-hidden="true" tabindex="-1"></a><span class="do">## -14.10000  -2.04200  -0.05357   0.00000   1.96000  12.60000</span></span>
<span id="cb167-267"><a href="nonlinear-regression.html#cb167-267" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb167-268"><a href="nonlinear-regression.html#cb167-268" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.boston)</span>
<span id="cb167-269"><a href="nonlinear-regression.html#cb167-269" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb167-270"><a href="nonlinear-regression.html#cb167-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-271"><a href="nonlinear-regression.html#cb167-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-272"><a href="nonlinear-regression.html#cb167-272" aria-hidden="true" tabindex="-1"></a>Снова сделаем обрезку дерева в целях улучшения качества прогноза.</span>
<span id="cb167-273"><a href="nonlinear-regression.html#cb167-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-274"><a href="nonlinear-regression.html#cb167-274" aria-hidden="true" tabindex="-1"></a>cv.boston <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.boston)</span>
<span id="cb167-275"><a href="nonlinear-regression.html#cb167-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-276"><a href="nonlinear-regression.html#cb167-276" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb167-277"><a href="nonlinear-regression.html#cb167-277" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.boston<span class="sc">$</span>size, cv.boston<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&#39;b&#39;</span>)</span>
<span id="cb167-278"><a href="nonlinear-regression.html#cb167-278" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.boston<span class="sc">$</span>size[cv.boston<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.boston<span class="sc">$</span>dev)]</span>
<span id="cb167-279"><a href="nonlinear-regression.html#cb167-279" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb167-280"><a href="nonlinear-regression.html#cb167-280" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb167-281"><a href="nonlinear-regression.html#cb167-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-282"><a href="nonlinear-regression.html#cb167-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-283"><a href="nonlinear-regression.html#cb167-283" aria-hidden="true" tabindex="-1"></a>В данном случаем минимум ошибки соответствует самому сложному дереву, с <span class="dv">8</span> узлами. Покажем, как при желании можно обрезать дерево до <span class="dv">7</span> узлов (ошибка ненамного выше, чем минимальная).</span>
<span id="cb167-284"><a href="nonlinear-regression.html#cb167-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-285"><a href="nonlinear-regression.html#cb167-285" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 7 узлами</span></span>
<span id="cb167-286"><a href="nonlinear-regression.html#cb167-286" aria-hidden="true" tabindex="-1"></a>prune.boston <span class="ot">=</span> <span class="fu">prune.tree</span>(tree.boston, <span class="at">best =</span> <span class="dv">7</span>)</span>
<span id="cb167-287"><a href="nonlinear-regression.html#cb167-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-288"><a href="nonlinear-regression.html#cb167-288" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb167-289"><a href="nonlinear-regression.html#cb167-289" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.boston)</span>
<span id="cb167-290"><a href="nonlinear-regression.html#cb167-290" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb167-291"><a href="nonlinear-regression.html#cb167-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-292"><a href="nonlinear-regression.html#cb167-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-293"><a href="nonlinear-regression.html#cb167-293" aria-hidden="true" tabindex="-1"></a>Прогноз сделаем по необрезанному дереву, т.к. там ошибка, оцененная по методу перекрёстной проверки, минимальна.</span>
<span id="cb167-294"><a href="nonlinear-regression.html#cb167-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-295"><a href="nonlinear-regression.html#cb167-295" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по лучшей модели (8 узлов)</span></span>
<span id="cb167-296"><a href="nonlinear-regression.html#cb167-296" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb167-297"><a href="nonlinear-regression.html#cb167-297" aria-hidden="true" tabindex="-1"></a>boston.test <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>train, <span class="st">&quot;medv&quot;</span>]</span>
<span id="cb167-298"><a href="nonlinear-regression.html#cb167-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-299"><a href="nonlinear-regression.html#cb167-299" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb167-300"><a href="nonlinear-regression.html#cb167-300" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat, boston.test)</span>
<span id="cb167-301"><a href="nonlinear-regression.html#cb167-301" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb167-302"><a href="nonlinear-regression.html#cb167-302" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb167-303"><a href="nonlinear-regression.html#cb167-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-304"><a href="nonlinear-regression.html#cb167-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-305"><a href="nonlinear-regression.html#cb167-305" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb167-306"><a href="nonlinear-regression.html#cb167-306" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb167-307"><a href="nonlinear-regression.html#cb167-307" aria-hidden="true" tabindex="-1"></a>MSE на тестовой выборке равна <span class="fl">25.05</span> (тыс.долл.).</span>
<span id="cb167-308"><a href="nonlinear-regression.html#cb167-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-309"><a href="nonlinear-regression.html#cb167-309" aria-hidden="true" tabindex="-1"></a>Бэггинг и метод случайного леса</span>
<span id="cb167-310"><a href="nonlinear-regression.html#cb167-310" aria-hidden="true" tabindex="-1"></a>Рассмотрим более сложные методы улучшения качества дерева. Бэггинг – частный случай случайного леса с m<span class="ot">=</span>p, поэтому и то, и другое можно построить функцией <span class="fu">randomForest</span>().</span>
<span id="cb167-311"><a href="nonlinear-regression.html#cb167-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-312"><a href="nonlinear-regression.html#cb167-312" aria-hidden="true" tabindex="-1"></a>Для начала используем бэггинг, причём возьмём все <span class="dv">13</span> предикторов на каждом шаге (аргумент mtry).</span>
<span id="cb167-313"><a href="nonlinear-regression.html#cb167-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-314"><a href="nonlinear-regression.html#cb167-314" aria-hidden="true" tabindex="-1"></a><span class="co"># бэггинг с 13 предикторами</span></span>
<span id="cb167-315"><a href="nonlinear-regression.html#cb167-315" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb167-316"><a href="nonlinear-regression.html#cb167-316" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train, </span>
<span id="cb167-317"><a href="nonlinear-regression.html#cb167-317" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb167-318"><a href="nonlinear-regression.html#cb167-318" aria-hidden="true" tabindex="-1"></a>bag.boston</span>
<span id="cb167-319"><a href="nonlinear-regression.html#cb167-319" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-320"><a href="nonlinear-regression.html#cb167-320" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb167-321"><a href="nonlinear-regression.html#cb167-321" aria-hidden="true" tabindex="-1"></a><span class="do">##  randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE,      subset = train) </span></span>
<span id="cb167-322"><a href="nonlinear-regression.html#cb167-322" aria-hidden="true" tabindex="-1"></a><span class="do">##                Type of random forest: regression</span></span>
<span id="cb167-323"><a href="nonlinear-regression.html#cb167-323" aria-hidden="true" tabindex="-1"></a><span class="do">##                      Number of trees: 500</span></span>
<span id="cb167-324"><a href="nonlinear-regression.html#cb167-324" aria-hidden="true" tabindex="-1"></a><span class="do">## No. of variables tried at each split: 13</span></span>
<span id="cb167-325"><a href="nonlinear-regression.html#cb167-325" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb167-326"><a href="nonlinear-regression.html#cb167-326" aria-hidden="true" tabindex="-1"></a><span class="do">##           Mean of squared residuals: 11.15723</span></span>
<span id="cb167-327"><a href="nonlinear-regression.html#cb167-327" aria-hidden="true" tabindex="-1"></a><span class="do">##                     % Var explained: 86.49</span></span>
<span id="cb167-328"><a href="nonlinear-regression.html#cb167-328" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb167-329"><a href="nonlinear-regression.html#cb167-329" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">=</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb167-330"><a href="nonlinear-regression.html#cb167-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-331"><a href="nonlinear-regression.html#cb167-331" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb167-332"><a href="nonlinear-regression.html#cb167-332" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat.bag, boston.test)</span>
<span id="cb167-333"><a href="nonlinear-regression.html#cb167-333" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb167-334"><a href="nonlinear-regression.html#cb167-334" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb167-335"><a href="nonlinear-regression.html#cb167-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-336"><a href="nonlinear-regression.html#cb167-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-337"><a href="nonlinear-regression.html#cb167-337" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb167-338"><a href="nonlinear-regression.html#cb167-338" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb167-339"><a href="nonlinear-regression.html#cb167-339" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb167-340"><a href="nonlinear-regression.html#cb167-340" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.50808</span></span>
<span id="cb167-341"><a href="nonlinear-regression.html#cb167-341" aria-hidden="true" tabindex="-1"></a>Ошибка на тестовой выборке равна <span class="dv">13</span>.<span class="fl">51.</span></span>
<span id="cb167-342"><a href="nonlinear-regression.html#cb167-342" aria-hidden="true" tabindex="-1"></a>Можно изменить число деревьев с помощью аргумента ntree.</span>
<span id="cb167-343"><a href="nonlinear-regression.html#cb167-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-344"><a href="nonlinear-regression.html#cb167-344" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb167-345"><a href="nonlinear-regression.html#cb167-345" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">ntree =</span> <span class="dv">25</span>)</span>
<span id="cb167-346"><a href="nonlinear-regression.html#cb167-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-347"><a href="nonlinear-regression.html#cb167-347" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb167-348"><a href="nonlinear-regression.html#cb167-348" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">&lt;-</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb167-349"><a href="nonlinear-regression.html#cb167-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-350"><a href="nonlinear-regression.html#cb167-350" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb167-351"><a href="nonlinear-regression.html#cb167-351" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb167-352"><a href="nonlinear-regression.html#cb167-352" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb167-353"><a href="nonlinear-regression.html#cb167-353" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.94835</span></span>
<span id="cb167-354"><a href="nonlinear-regression.html#cb167-354" aria-hidden="true" tabindex="-1"></a>Но, как видно, это только ухудшает прогноз.</span>
<span id="cb167-355"><a href="nonlinear-regression.html#cb167-355" aria-hidden="true" tabindex="-1"></a>Теперь попробуем вырастить случайный лес. Берём <span class="dv">6</span> предикторов на каждом шаге.</span>
<span id="cb167-356"><a href="nonlinear-regression.html#cb167-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-357"><a href="nonlinear-regression.html#cb167-357" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb167-358"><a href="nonlinear-regression.html#cb167-358" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb167-359"><a href="nonlinear-regression.html#cb167-359" aria-hidden="true" tabindex="-1"></a>rf.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb167-360"><a href="nonlinear-regression.html#cb167-360" aria-hidden="true" tabindex="-1"></a>                          <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb167-361"><a href="nonlinear-regression.html#cb167-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-362"><a href="nonlinear-regression.html#cb167-362" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb167-363"><a href="nonlinear-regression.html#cb167-363" aria-hidden="true" tabindex="-1"></a>yhat.rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb167-364"><a href="nonlinear-regression.html#cb167-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-365"><a href="nonlinear-regression.html#cb167-365" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb167-366"><a href="nonlinear-regression.html#cb167-366" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.rf <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb167-367"><a href="nonlinear-regression.html#cb167-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-368"><a href="nonlinear-regression.html#cb167-368" aria-hidden="true" tabindex="-1"></a><span class="co"># важность предикторов</span></span>
<span id="cb167-369"><a href="nonlinear-regression.html#cb167-369" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf.boston)  <span class="co"># оценки </span></span>
<span id="cb167-370"><a href="nonlinear-regression.html#cb167-370" aria-hidden="true" tabindex="-1"></a><span class="do">##           %IncMSE IncNodePurity</span></span>
<span id="cb167-371"><a href="nonlinear-regression.html#cb167-371" aria-hidden="true" tabindex="-1"></a><span class="do">## crim    12.132320     986.50338</span></span>
<span id="cb167-372"><a href="nonlinear-regression.html#cb167-372" aria-hidden="true" tabindex="-1"></a><span class="do">## zn       1.955579      57.96945</span></span>
<span id="cb167-373"><a href="nonlinear-regression.html#cb167-373" aria-hidden="true" tabindex="-1"></a><span class="do">## indus    9.069302     882.78261</span></span>
<span id="cb167-374"><a href="nonlinear-regression.html#cb167-374" aria-hidden="true" tabindex="-1"></a><span class="do">## chas     2.210835      45.22941</span></span>
<span id="cb167-375"><a href="nonlinear-regression.html#cb167-375" aria-hidden="true" tabindex="-1"></a><span class="do">## nox     11.104823    1044.33776</span></span>
<span id="cb167-376"><a href="nonlinear-regression.html#cb167-376" aria-hidden="true" tabindex="-1"></a><span class="do">## rm      31.784033    6359.31971</span></span>
<span id="cb167-377"><a href="nonlinear-regression.html#cb167-377" aria-hidden="true" tabindex="-1"></a><span class="do">## age     10.962684     516.82969</span></span>
<span id="cb167-378"><a href="nonlinear-regression.html#cb167-378" aria-hidden="true" tabindex="-1"></a><span class="do">## dis     15.015236    1224.11605</span></span>
<span id="cb167-379"><a href="nonlinear-regression.html#cb167-379" aria-hidden="true" tabindex="-1"></a><span class="do">## rad      4.118011      95.94586</span></span>
<span id="cb167-380"><a href="nonlinear-regression.html#cb167-380" aria-hidden="true" tabindex="-1"></a><span class="do">## tax      8.587932     502.96719</span></span>
<span id="cb167-381"><a href="nonlinear-regression.html#cb167-381" aria-hidden="true" tabindex="-1"></a><span class="do">## ptratio 12.503896     830.77523</span></span>
<span id="cb167-382"><a href="nonlinear-regression.html#cb167-382" aria-hidden="true" tabindex="-1"></a><span class="do">## black    6.702609     341.30361</span></span>
<span id="cb167-383"><a href="nonlinear-regression.html#cb167-383" aria-hidden="true" tabindex="-1"></a><span class="do">## lstat   30.695224    7505.73936</span></span>
<span id="cb167-384"><a href="nonlinear-regression.html#cb167-384" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.boston)  <span class="co"># графики</span></span>
<span id="cb167-385"><a href="nonlinear-regression.html#cb167-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-386"><a href="nonlinear-regression.html#cb167-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-387"><a href="nonlinear-regression.html#cb167-387" aria-hidden="true" tabindex="-1"></a>Ошибка по модели случайного леса равна <span class="fl">11.66</span>, что ниже, чем для бэггинга.</span>
<span id="cb167-388"><a href="nonlinear-regression.html#cb167-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-389"><a href="nonlinear-regression.html#cb167-389" aria-hidden="true" tabindex="-1"></a>Бустинг</span>
<span id="cb167-390"><a href="nonlinear-regression.html#cb167-390" aria-hidden="true" tabindex="-1"></a>Построим <span class="dv">5000</span> регрессионных деревьев с глубиной <span class="fl">4.</span></span>
<span id="cb167-391"><a href="nonlinear-regression.html#cb167-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-392"><a href="nonlinear-regression.html#cb167-392" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb167-393"><a href="nonlinear-regression.html#cb167-393" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb167-394"><a href="nonlinear-regression.html#cb167-394" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>)</span>
<span id="cb167-395"><a href="nonlinear-regression.html#cb167-395" aria-hidden="true" tabindex="-1"></a><span class="co"># график и таблица относительной важности переменных</span></span>
<span id="cb167-396"><a href="nonlinear-regression.html#cb167-396" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boost.boston)</span>
<span id="cb167-397"><a href="nonlinear-regression.html#cb167-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-398"><a href="nonlinear-regression.html#cb167-398" aria-hidden="true" tabindex="-1"></a><span class="co"># графики частной зависимости для двух наиболее важных предикторов</span></span>
<span id="cb167-399"><a href="nonlinear-regression.html#cb167-399" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb167-400"><a href="nonlinear-regression.html#cb167-400" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;rm&quot;</span>)</span>
<span id="cb167-401"><a href="nonlinear-regression.html#cb167-401" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb167-402"><a href="nonlinear-regression.html#cb167-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-403"><a href="nonlinear-regression.html#cb167-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-404"><a href="nonlinear-regression.html#cb167-404" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb167-405"><a href="nonlinear-regression.html#cb167-405" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb167-406"><a href="nonlinear-regression.html#cb167-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-407"><a href="nonlinear-regression.html#cb167-407" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb167-408"><a href="nonlinear-regression.html#cb167-408" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb167-409"><a href="nonlinear-regression.html#cb167-409" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb167-410"><a href="nonlinear-regression.html#cb167-410" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.84434</span></span>
<span id="cb167-411"><a href="nonlinear-regression.html#cb167-411" aria-hidden="true" tabindex="-1"></a>Настройку бустинга можно делать с помощью гиперпараметра λ (аргумент shrinkage). Установим его равным <span class="dv">0</span>.<span class="fl">2.</span></span>
<span id="cb167-412"><a href="nonlinear-regression.html#cb167-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-413"><a href="nonlinear-regression.html#cb167-413" aria-hidden="true" tabindex="-1"></a><span class="co"># меняем значение гиперпараметра (lambda) на 0.2 -- аргумент shrinkage</span></span>
<span id="cb167-414"><a href="nonlinear-regression.html#cb167-414" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb167-415"><a href="nonlinear-regression.html#cb167-415" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>, </span>
<span id="cb167-416"><a href="nonlinear-regression.html#cb167-416" aria-hidden="true" tabindex="-1"></a>                    <span class="at">shrinkage =</span> <span class="fl">0.2</span>, <span class="at">verbose =</span> F)</span>
<span id="cb167-417"><a href="nonlinear-regression.html#cb167-417" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb167-418"><a href="nonlinear-regression.html#cb167-418" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb167-419"><a href="nonlinear-regression.html#cb167-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-420"><a href="nonlinear-regression.html#cb167-420" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE а тестовой</span></span>
<span id="cb167-421"><a href="nonlinear-regression.html#cb167-421" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb167-422"><a href="nonlinear-regression.html#cb167-422" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb167-423"><a href="nonlinear-regression.html#cb167-423" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.51109</span></span>
<span id="cb167-424"><a href="nonlinear-regression.html#cb167-424" aria-hidden="true" tabindex="-1"></a>Таким образом, изменив гиперпараметр, мы ещё немного снизили ошибку прогноза.</span></code></pre></div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression-complex-cases.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/24_nonlinear_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
