<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 21 Nonlinear regression | R statistics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 21 Nonlinear regression | R statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 21 Nonlinear regression | R statistics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Mark Goldberg" />


<meta name="date" content="2021-04-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="next-part-3.html"/>
<link rel="next" href="spline-model.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html"><i class="fa fa-check"></i><b>2</b> Statistics R functions reference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#get-data"><i class="fa fa-check"></i><b>2.1</b> Get data</a></li>
<li class="chapter" data-level="2.2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#data-inspection"><i class="fa fa-check"></i><b>2.2</b> Data inspection</a></li>
<li class="chapter" data-level="2.3" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#plots"><i class="fa fa-check"></i><b>2.3</b> Plots</a></li>
<li class="chapter" data-level="2.4" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#analysis-of-the-distribution"><i class="fa fa-check"></i><b>2.4</b> Analysis of the distribution</a></li>
<li class="chapter" data-level="2.5" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#t-test"><i class="fa fa-check"></i><b>2.5</b> t-Test</a></li>
<li class="chapter" data-level="2.6" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#anova"><i class="fa fa-check"></i><b>2.6</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>3</b> Basic Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="basic-statistics.html"><a href="basic-statistics.html#definitions"><i class="fa fa-check"></i><b>3.1</b> Definitions</a></li>
<li class="chapter" data-level="3.2" data-path="basic-statistics.html"><a href="basic-statistics.html#primary-analysis"><i class="fa fa-check"></i><b>3.2</b> Primary analysis</a></li>
<li class="chapter" data-level="3.3" data-path="basic-statistics.html"><a href="basic-statistics.html#outliers"><i class="fa fa-check"></i><b>3.3</b> Outliers</a></li>
<li class="chapter" data-level="3.4" data-path="basic-statistics.html"><a href="basic-statistics.html#normality"><i class="fa fa-check"></i><b>3.4</b> Normality</a></li>
<li class="chapter" data-level="3.5" data-path="basic-statistics.html"><a href="basic-statistics.html#confidence-interval"><i class="fa fa-check"></i><b>3.5</b> Confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="primary-analysis-1.html"><a href="primary-analysis-1.html"><i class="fa fa-check"></i><b>4</b> Primary analysis</a></li>
<li class="chapter" data-level="5" data-path="statistical-distributions.html"><a href="statistical-distributions.html"><i class="fa fa-check"></i><b>5</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="statistical-distributions.html"><a href="statistical-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>5.1</b> Normal Distribution</a></li>
<li class="chapter" data-level="5.2" data-path="statistical-distributions.html"><a href="statistical-distributions.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.2</b> Bernoulli Distribution</a></li>
<li class="chapter" data-level="5.3" data-path="statistical-distributions.html"><a href="statistical-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>5.3</b> Binomial Distribution</a></li>
<li class="chapter" data-level="5.4" data-path="statistical-distributions.html"><a href="statistical-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>5.4</b> Geometric Distribution</a></li>
<li class="chapter" data-level="5.5" data-path="statistical-distributions.html"><a href="statistical-distributions.html#uniform-distributions"><i class="fa fa-check"></i><b>5.5</b> Uniform Distributions</a></li>
<li class="chapter" data-level="5.6" data-path="statistical-distributions.html"><a href="statistical-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>5.6</b> Poisson Distribution</a></li>
<li class="chapter" data-level="5.7" data-path="statistical-distributions.html"><a href="statistical-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>5.7</b> Exponential Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-theory"><i class="fa fa-check"></i><b>6.1</b> Hypothesis testing theory</a></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-practice"><i class="fa fa-check"></i><b>6.2</b> Hypothesis test (Practice)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="t-procedures.html"><a href="t-procedures.html"><i class="fa fa-check"></i><b>7</b> t-Procedures</a>
<ul>
<li class="chapter" data-level="7.1" data-path="t-procedures.html"><a href="t-procedures.html#t-test-and-normal-distribution"><i class="fa fa-check"></i><b>7.1</b> t-test and normal distribution</a></li>
<li class="chapter" data-level="7.2" data-path="t-procedures.html"><a href="t-procedures.html#one-sample-t-test"><i class="fa fa-check"></i><b>7.2</b> One-sample t-test</a></li>
<li class="chapter" data-level="7.3" data-path="t-procedures.html"><a href="t-procedures.html#practical-example-t-test-in-r"><i class="fa fa-check"></i><b>7.3</b> Practical example: t-test in R</a></li>
<li class="chapter" data-level="7.4" data-path="t-procedures.html"><a href="t-procedures.html#two-samples-t-test"><i class="fa fa-check"></i><b>7.4</b> Two samples t-test</a></li>
<li class="chapter" data-level="7.5" data-path="t-procedures.html"><a href="t-procedures.html#compare-students-t-and-normal-distributions"><i class="fa fa-check"></i><b>7.5</b> Compare Student’s t and normal distributions</a></li>
<li class="chapter" data-level="7.6" data-path="t-procedures.html"><a href="t-procedures.html#non-parametric-tests"><i class="fa fa-check"></i><b>7.6</b> Non-parametric tests</a></li>
<li class="chapter" data-level="7.7" data-path="t-procedures.html"><a href="t-procedures.html#mann-whitney-u-rank-sum-test"><i class="fa fa-check"></i><b>7.7</b> Mann-Whitney U Rank Sum Test</a></li>
<li class="chapter" data-level="7.8" data-path="t-procedures.html"><a href="t-procedures.html#wilcoxon-test"><i class="fa fa-check"></i><b>7.8</b> Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html"><i class="fa fa-check"></i><b>8</b> Tests for categorical variables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html#chi-squared-tests"><i class="fa fa-check"></i><b>8.1</b> Chi-squared tests</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>9</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="9.1" data-path="multiple-testing.html"><a href="multiple-testing.html#the-bonferroni-correction"><i class="fa fa-check"></i><b>9.1</b> The Bonferroni correction</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sources.html"><a href="sources.html"><i class="fa fa-check"></i><b>10</b> Sources</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sources.html"><a href="sources.html#t-test-1"><i class="fa fa-check"></i><b>10.1</b> t-test</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="sources.html"><a href="sources.html#two-tailed-test"><i class="fa fa-check"></i><b>10.1.1</b> Two-tailed test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>11</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>11.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="11.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#sources-1"><i class="fa fa-check"></i><b>11.2</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>12</b> Correlation</a></li>
<li class="chapter" data-level="13" data-path="t-test-anova-difference.html"><a href="t-test-anova-difference.html"><i class="fa fa-check"></i><b>13</b> t-test ANOVA difference</a></li>
<li class="chapter" data-level="14" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>14</b> Clustering</a>
<ul>
<li class="chapter" data-level="14.1" data-path="clustering.html"><a href="clustering.html#next-part"><i class="fa fa-check"></i><b>14.1</b> Next part</a></li>
<li class="chapter" data-level="14.2" data-path="clustering.html"><a href="clustering.html#example"><i class="fa fa-check"></i><b>14.2</b> Example</a></li>
<li class="chapter" data-level="14.3" data-path="clustering.html"><a href="clustering.html#next-part-1"><i class="fa fa-check"></i><b>14.3</b> NEXT PART</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>15</b> Support Vector Machine</a></li>
<li class="chapter" data-level="16" data-path="methods-and-algorithms-of-machine-learning.html"><a href="methods-and-algorithms-of-machine-learning.html"><i class="fa fa-check"></i><b>16</b> Methods and algorithms of machine learning</a></li>
<li class="chapter" data-level="17" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html"><i class="fa fa-check"></i><b>17</b> Machine Learning Functions Reference</a>
<ul>
<li class="chapter" data-level="17.1" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html#linear-regression"><i class="fa fa-check"></i><b>17.1</b> Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="split-data-into-train-and-test-subsets.html"><a href="split-data-into-train-and-test-subsets.html"><i class="fa fa-check"></i><b>18</b> Split data into train and test subsets</a></li>
<li class="chapter" data-level="19" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>19</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="19.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-random-data-set-a-linear-model"><i class="fa fa-check"></i><b>19.1</b> Generate Random Data Set a Linear Model</a></li>
<li class="chapter" data-level="19.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression---theory"><i class="fa fa-check"></i><b>19.2</b> Linear regression - theory</a></li>
<li class="chapter" data-level="19.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-example"><i class="fa fa-check"></i><b>19.3</b> Practical example</a></li>
<li class="chapter" data-level="19.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#example-of-linear-regression"><i class="fa fa-check"></i><b>19.4</b> Example of linear regression</a></li>
<li class="chapter" data-level="19.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#standard-error-of-train-data"><i class="fa fa-check"></i><b>19.5</b> Standard error of train data</a></li>
<li class="chapter" data-level="19.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression"><i class="fa fa-check"></i><b>19.6</b> Practical examples for linear model regression</a></li>
<li class="chapter" data-level="19.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression-1"><i class="fa fa-check"></i><b>19.7</b> Practical examples for linear model regression</a></li>
<li class="chapter" data-level="19.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#next-part-2"><i class="fa fa-check"></i><b>19.8</b> NEXT part</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="next-part-3.html"><a href="next-part-3.html"><i class="fa fa-check"></i><b>20</b> NEXT part</a>
<ul>
<li class="chapter" data-level="20.1" data-path="next-part-3.html"><a href="next-part-3.html#next-part-4"><i class="fa fa-check"></i><b>20.1</b> NEXT part</a></li>
<li class="chapter" data-level="20.2" data-path="next-part-3.html"><a href="next-part-3.html#next-part-5"><i class="fa fa-check"></i><b>20.2</b> NEXT Part</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="nonlinear-regression.html"><a href="nonlinear-regression.html"><i class="fa fa-check"></i><b>21</b> Nonlinear regression</a></li>
<li class="chapter" data-level="22" data-path="spline-model.html"><a href="spline-model.html"><i class="fa fa-check"></i><b>22</b> Spline model</a>
<ul>
<li class="chapter" data-level="22.1" data-path="spline-model.html"><a href="spline-model.html#generate-dataset-from-a-given-function"><i class="fa fa-check"></i><b>22.1</b> Generate dataset from a given function</a></li>
<li class="chapter" data-level="22.2" data-path="spline-model.html"><a href="spline-model.html#split-data-for-train-and-test"><i class="fa fa-check"></i><b>22.2</b> Split data for train and test</a></li>
<li class="chapter" data-level="22.3" data-path="spline-model.html"><a href="spline-model.html#diagram-of-the-given-function-and-generated-datasets"><i class="fa fa-check"></i><b>22.3</b> Diagram of the given function and generated datasets</a></li>
<li class="chapter" data-level="22.4" data-path="spline-model.html"><a href="spline-model.html#build-a-model-using-splines"><i class="fa fa-check"></i><b>22.4</b> Build a model using splines</a></li>
<li class="chapter" data-level="22.5" data-path="spline-model.html"><a href="spline-model.html#diagram-of-mse-for-train-and-test-data"><i class="fa fa-check"></i><b>22.5</b> Diagram of MSE for train and test data</a></li>
<li class="chapter" data-level="22.6" data-path="spline-model.html"><a href="spline-model.html#build-optimal-model-and-plot-for-the-model"><i class="fa fa-check"></i><b>22.6</b> Build optimal model and plot for the model</a></li>
<li class="chapter" data-level="22.7" data-path="spline-model.html"><a href="spline-model.html#bibliograpy"><i class="fa fa-check"></i><b>22.7</b> Bibliograpy</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>23</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="23.1" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-6"><i class="fa fa-check"></i><b>23.1</b> Next part</a></li>
<li class="chapter" data-level="23.2" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-7"><i class="fa fa-check"></i><b>23.2</b> NEXT Part</a></li>
<li class="chapter" data-level="23.3" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-8"><i class="fa fa-check"></i><b>23.3</b> NExt part</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>24</b> Multiple linear regression</a></li>
<li class="chapter" data-level="25" data-path="simple-markov-process.html"><a href="simple-markov-process.html"><i class="fa fa-check"></i><b>25</b> Simple Markov process</a>
<ul>
<li class="chapter" data-level="25.0.1" data-path="simple-markov-process.html"><a href="simple-markov-process.html#sources-2"><i class="fa fa-check"></i><b>25.0.1</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>26</b> Naive Bayes</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonlinear-regression" class="section level1" number="21">
<h1><span class="header-section-number">Chapter 21</span> Nonlinear regression</h1>
<p>Nonlinear regression is a form of regression analysis in which observational data are modeled by a function which is a nonlinear combination of the model parameters and <strong>depends on one or more independent variables</strong>.<br />
Some nonlinear data sets can be transformed to a linear model.<br />
Sone can not be transformed. For such modeling methods of Numerical analysis should be applied such as Newton’s method, Gauss-Newton method and Levenberg–Marquardt method.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="nonlinear-regression.html#cb106-1" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb106-2"><a href="nonlinear-regression.html#cb106-2" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">7</span></span>
<span id="cb106-3"><a href="nonlinear-regression.html#cb106-3" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb106-4"><a href="nonlinear-regression.html#cb106-4" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb106-5"><a href="nonlinear-regression.html#cb106-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-6"><a href="nonlinear-regression.html#cb106-6" aria-hidden="true" tabindex="-1"></a>    оценивать полиномиальную регрессию;</span>
<span id="cb106-7"><a href="nonlinear-regression.html#cb106-7" aria-hidden="true" tabindex="-1"></a>аппроксимировать нелинейные модели ступенчатыми функциями;</span>
<span id="cb106-8"><a href="nonlinear-regression.html#cb106-8" aria-hidden="true" tabindex="-1"></a>строить сплайны;</span>
<span id="cb106-9"><a href="nonlinear-regression.html#cb106-9" aria-hidden="true" tabindex="-1"></a>работать с локальной регрессией;</span>
<span id="cb106-10"><a href="nonlinear-regression.html#cb106-10" aria-hidden="true" tabindex="-1"></a>строить обобщённые линейные модели (GAM).</span>
<span id="cb106-11"><a href="nonlinear-regression.html#cb106-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> полиномиальная регрессия, полиномиальная логистическая регрессия, ступенчатая модель, обобщённая линейная модель.</span>
<span id="cb106-12"><a href="nonlinear-regression.html#cb106-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Wage {ISLR}</span>
<span id="cb106-13"><a href="nonlinear-regression.html#cb106-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-14"><a href="nonlinear-regression.html#cb106-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">7.</span></span>
<span id="cb106-15"><a href="nonlinear-regression.html#cb106-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-16"><a href="nonlinear-regression.html#cb106-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># набор данных Auto</span></span>
<span id="cb106-17"><a href="nonlinear-regression.html#cb106-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;splines&#39;</span>)           <span class="co"># сплайны</span></span>
<span id="cb106-18"><a href="nonlinear-regression.html#cb106-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gam&#39;</span>)               <span class="co"># обобщённые аддитивные модели</span></span>
<span id="cb106-19"><a href="nonlinear-regression.html#cb106-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gam&#39; was built under R version 3.3.3</span></span>
<span id="cb106-20"><a href="nonlinear-regression.html#cb106-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: foreach</span></span>
<span id="cb106-21"><a href="nonlinear-regression.html#cb106-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;foreach&#39; was built under R version 3.3.3</span></span>
<span id="cb106-22"><a href="nonlinear-regression.html#cb106-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gam 1.14</span></span>
<span id="cb106-23"><a href="nonlinear-regression.html#cb106-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;akima&#39;</span>)             <span class="co"># график двумерной плоскости</span></span>
<span id="cb106-24"><a href="nonlinear-regression.html#cb106-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;akima&#39; was built under R version 3.3.3</span></span>
<span id="cb106-25"><a href="nonlinear-regression.html#cb106-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ggplot2&#39;</span>)           <span class="co"># красивые графики</span></span>
<span id="cb106-26"><a href="nonlinear-regression.html#cb106-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;ggplot2&#39; was built under R version 3.3.3</span></span>
<span id="cb106-27"><a href="nonlinear-regression.html#cb106-27" aria-hidden="true" tabindex="-1"></a>my.seed <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb106-28"><a href="nonlinear-regression.html#cb106-28" aria-hidden="true" tabindex="-1"></a>Работаем с набором данных по зарплатам <span class="dv">3000</span> работников<span class="sc">-</span>мужчин среднеатлантического региона Wage. Присоединяем его к пространству имён функцией <span class="fu">attach</span>(), и дальше обращаемся напрямую к столбцам таблицы.</span>
<span id="cb106-29"><a href="nonlinear-regression.html#cb106-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-30"><a href="nonlinear-regression.html#cb106-30" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Wage)</span>
<span id="cb106-31"><a href="nonlinear-regression.html#cb106-31" aria-hidden="true" tabindex="-1"></a>Работаем со столбцами<span class="sc">:</span></span>
<span id="cb106-32"><a href="nonlinear-regression.html#cb106-32" aria-hidden="true" tabindex="-1"></a>    <span class="er">*</span> wage – заработная плата работника до уплаты налогов;</span>
<span id="cb106-33"><a href="nonlinear-regression.html#cb106-33" aria-hidden="true" tabindex="-1"></a><span class="sc">*</span> age – возраст работника в годах.</span>
<span id="cb106-34"><a href="nonlinear-regression.html#cb106-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-35"><a href="nonlinear-regression.html#cb106-35" aria-hidden="true" tabindex="-1"></a>Полиномиальная регрессия</span>
<span id="cb106-36"><a href="nonlinear-regression.html#cb106-36" aria-hidden="true" tabindex="-1"></a>Зависимость зарплаты от возраста</span>
<span id="cb106-37"><a href="nonlinear-regression.html#cb106-37" aria-hidden="true" tabindex="-1"></a>Судя по графику ниже, ззаимосвязь заработной платы и возраста нелинейна. Наблюдается также группа наблюдений с высоким значением wage, граница проходит примерно на уровне <span class="fl">250.</span></span>
<span id="cb106-38"><a href="nonlinear-regression.html#cb106-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-39"><a href="nonlinear-regression.html#cb106-39" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> Wage, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> wage))</span>
<span id="cb106-40"><a href="nonlinear-regression.html#cb106-40" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> gp <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">0</span>, <span class="at">intercept =</span> <span class="dv">250</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb106-41"><a href="nonlinear-regression.html#cb106-41" aria-hidden="true" tabindex="-1"></a>gp</span>
<span id="cb106-42"><a href="nonlinear-regression.html#cb106-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-43"><a href="nonlinear-regression.html#cb106-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-44"><a href="nonlinear-regression.html#cb106-44" aria-hidden="true" tabindex="-1"></a>Подгоняем полином четвёртой степени для зависимости заработной платы от возраста.</span>
<span id="cb106-45"><a href="nonlinear-regression.html#cb106-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-46"><a href="nonlinear-regression.html#cb106-46" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb106-47"><a href="nonlinear-regression.html#cb106-47" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb106-48"><a href="nonlinear-regression.html#cb106-48" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb106-49"><a href="nonlinear-regression.html#cb106-49" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)     111.70       0.73  153.28     0.00</span></span>
<span id="cb106-50"><a href="nonlinear-regression.html#cb106-50" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)1   447.07      39.91   11.20     0.00</span></span>
<span id="cb106-51"><a href="nonlinear-regression.html#cb106-51" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)2  -478.32      39.91  -11.98     0.00</span></span>
<span id="cb106-52"><a href="nonlinear-regression.html#cb106-52" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)3   125.52      39.91    3.14     0.00</span></span>
<span id="cb106-53"><a href="nonlinear-regression.html#cb106-53" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)4   -77.91      39.91   -1.95     0.05</span></span>
<span id="cb106-54"><a href="nonlinear-regression.html#cb106-54" aria-hidden="true" tabindex="-1"></a>Функция <span class="fu">poly</span>(age, <span class="dv">4</span>) создаёт таблицу с базисом ортогональных полиномов<span class="sc">:</span> линейные комбинации значений переменной age в степенях от <span class="dv">1</span> до <span class="fl">4.</span></span>
<span id="cb106-55"><a href="nonlinear-regression.html#cb106-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-56"><a href="nonlinear-regression.html#cb106-56" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>)), <span class="dv">3</span>)</span>
<span id="cb106-57"><a href="nonlinear-regression.html#cb106-57" aria-hidden="true" tabindex="-1"></a><span class="do">##           1      2      3      4</span></span>
<span id="cb106-58"><a href="nonlinear-regression.html#cb106-58" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] -0.039  0.056 -0.072  0.087</span></span>
<span id="cb106-59"><a href="nonlinear-regression.html#cb106-59" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] -0.029  0.026 -0.015 -0.003</span></span>
<span id="cb106-60"><a href="nonlinear-regression.html#cb106-60" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,]  0.004 -0.015  0.000  0.014</span></span>
<span id="cb106-61"><a href="nonlinear-regression.html#cb106-61" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,]  0.001 -0.015  0.005  0.013</span></span>
<span id="cb106-62"><a href="nonlinear-regression.html#cb106-62" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,]  0.012 -0.010 -0.011  0.010</span></span>
<span id="cb106-63"><a href="nonlinear-regression.html#cb106-63" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,]  0.018 -0.002 -0.017 -0.001</span></span>
<span id="cb106-64"><a href="nonlinear-regression.html#cb106-64" aria-hidden="true" tabindex="-1"></a><span class="co"># можно получить сами значения age в заданных степенях</span></span>
<span id="cb106-65"><a href="nonlinear-regression.html#cb106-65" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T)), <span class="dv">3</span>)</span>
<span id="cb106-66"><a href="nonlinear-regression.html#cb106-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       1    2      3       4</span></span>
<span id="cb106-67"><a href="nonlinear-regression.html#cb106-67" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] 18  324   5832  104976</span></span>
<span id="cb106-68"><a href="nonlinear-regression.html#cb106-68" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] 24  576  13824  331776</span></span>
<span id="cb106-69"><a href="nonlinear-regression.html#cb106-69" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,] 45 2025  91125 4100625</span></span>
<span id="cb106-70"><a href="nonlinear-regression.html#cb106-70" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,] 43 1849  79507 3418801</span></span>
<span id="cb106-71"><a href="nonlinear-regression.html#cb106-71" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,] 50 2500 125000 6250000</span></span>
<span id="cb106-72"><a href="nonlinear-regression.html#cb106-72" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,] 54 2916 157464 8503056</span></span>
<span id="cb106-73"><a href="nonlinear-regression.html#cb106-73" aria-hidden="true" tabindex="-1"></a><span class="co"># на прогноз не повлияет, но оценки параметров изменяются</span></span>
<span id="cb106-74"><a href="nonlinear-regression.html#cb106-74" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T), <span class="at">data =</span> Wage)</span>
<span id="cb106-75"><a href="nonlinear-regression.html#cb106-75" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit<span class="fl">.2</span>)), <span class="dv">2</span>)</span>
<span id="cb106-76"><a href="nonlinear-regression.html#cb106-76" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb106-77"><a href="nonlinear-regression.html#cb106-77" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)             -184.15      60.04   -3.07     0.00</span></span>
<span id="cb106-78"><a href="nonlinear-regression.html#cb106-78" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)1    21.25       5.89    3.61     0.00</span></span>
<span id="cb106-79"><a href="nonlinear-regression.html#cb106-79" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)2    -0.56       0.21   -2.74     0.01</span></span>
<span id="cb106-80"><a href="nonlinear-regression.html#cb106-80" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)3     0.01       0.00    2.22     0.03</span></span>
<span id="cb106-81"><a href="nonlinear-regression.html#cb106-81" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)4     0.00       0.00   -1.95     0.05</span></span>
<span id="cb106-82"><a href="nonlinear-regression.html#cb106-82" aria-hidden="true" tabindex="-1"></a><span class="co"># границы изменения переменной age</span></span>
<span id="cb106-83"><a href="nonlinear-regression.html#cb106-83" aria-hidden="true" tabindex="-1"></a>agelims <span class="ot">&lt;-</span> <span class="fu">range</span>(age)</span>
<span id="cb106-84"><a href="nonlinear-regression.html#cb106-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-85"><a href="nonlinear-regression.html#cb106-85" aria-hidden="true" tabindex="-1"></a><span class="co"># значения age, для которых делаем прогноз (от min до max с шагом 1)</span></span>
<span id="cb106-86"><a href="nonlinear-regression.html#cb106-86" aria-hidden="true" tabindex="-1"></a>age.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> agelims[<span class="dv">1</span>], <span class="at">to =</span> agelims[<span class="dv">2</span>])</span>
<span id="cb106-87"><a href="nonlinear-regression.html#cb106-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-88"><a href="nonlinear-regression.html#cb106-88" aria-hidden="true" tabindex="-1"></a><span class="co"># рассчитать прогнозы и их стандартные ошибки</span></span>
<span id="cb106-89"><a href="nonlinear-regression.html#cb106-89" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb106-90"><a href="nonlinear-regression.html#cb106-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-91"><a href="nonlinear-regression.html#cb106-91" aria-hidden="true" tabindex="-1"></a><span class="co"># границы доверительного интервала для заработной платы</span></span>
<span id="cb106-92"><a href="nonlinear-regression.html#cb106-92" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb106-93"><a href="nonlinear-regression.html#cb106-93" aria-hidden="true" tabindex="-1"></a>                  <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb106-94"><a href="nonlinear-regression.html#cb106-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-95"><a href="nonlinear-regression.html#cb106-95" aria-hidden="true" tabindex="-1"></a><span class="co"># смотрим результат</span></span>
<span id="cb106-96"><a href="nonlinear-regression.html#cb106-96" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">2</span>)</span>
<span id="cb106-97"><a href="nonlinear-regression.html#cb106-97" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb106-98"><a href="nonlinear-regression.html#cb106-98" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       41.33       62.53</span></span>
<span id="cb106-99"><a href="nonlinear-regression.html#cb106-99" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       49.76       67.24</span></span>
<span id="cb106-100"><a href="nonlinear-regression.html#cb106-100" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       57.39       71.76</span></span>
<span id="cb106-101"><a href="nonlinear-regression.html#cb106-101" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       64.27       76.09</span></span>
<span id="cb106-102"><a href="nonlinear-regression.html#cb106-102" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       70.44       80.27</span></span>
<span id="cb106-103"><a href="nonlinear-regression.html#cb106-103" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       75.94       84.28</span></span>
<span id="cb106-104"><a href="nonlinear-regression.html#cb106-104" aria-hidden="true" tabindex="-1"></a>Рисуем левую панель графика со слайда <span class="dv">4</span> презентации (рис. <span class="fl">7.1</span> книги). Функция <span class="fu">matlines</span>() рисует грфик столбцов одной матрицы против столбцов другой.</span>
<span id="cb106-105"><a href="nonlinear-regression.html#cb106-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-106"><a href="nonlinear-regression.html#cb106-106" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb106-107"><a href="nonlinear-regression.html#cb106-107" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb106-108"><a href="nonlinear-regression.html#cb106-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-109"><a href="nonlinear-regression.html#cb106-109" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb106-110"><a href="nonlinear-regression.html#cb106-110" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb106-111"><a href="nonlinear-regression.html#cb106-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-112"><a href="nonlinear-regression.html#cb106-112" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb106-113"><a href="nonlinear-regression.html#cb106-113" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb106-114"><a href="nonlinear-regression.html#cb106-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-115"><a href="nonlinear-regression.html#cb106-115" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb106-116"><a href="nonlinear-regression.html#cb106-116" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb106-117"><a href="nonlinear-regression.html#cb106-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-118"><a href="nonlinear-regression.html#cb106-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-119"><a href="nonlinear-regression.html#cb106-119" aria-hidden="true" tabindex="-1"></a>Убедимся, что прогнозы по моделям с различными вызовами <span class="fu">poly</span>() совпадают.</span>
<span id="cb106-120"><a href="nonlinear-regression.html#cb106-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-121"><a href="nonlinear-regression.html#cb106-121" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы по второму вызову модели</span></span>
<span id="cb106-122"><a href="nonlinear-regression.html#cb106-122" aria-hidden="true" tabindex="-1"></a>preds2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit<span class="fl">.2</span>, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb106-123"><a href="nonlinear-regression.html#cb106-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-124"><a href="nonlinear-regression.html#cb106-124" aria-hidden="true" tabindex="-1"></a><span class="co"># максимальное расхождение между прогнозами по двум вариантам вызова модели</span></span>
<span id="cb106-125"><a href="nonlinear-regression.html#cb106-125" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(preds<span class="sc">$</span>fit <span class="sc">-</span> preds2<span class="sc">$</span>fit))</span>
<span id="cb106-126"><a href="nonlinear-regression.html#cb106-126" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 7.389644e-13</span></span>
<span id="cb106-127"><a href="nonlinear-regression.html#cb106-127" aria-hidden="true" tabindex="-1"></a>Теперь подбираем степень полинома, сравнивая модели со степенями от <span class="dv">1</span> до <span class="dv">5</span> с помощью дисперсионного анализа (ANOVA).</span>
<span id="cb106-128"><a href="nonlinear-regression.html#cb106-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-129"><a href="nonlinear-regression.html#cb106-129" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> age, <span class="at">data =</span> Wage)</span>
<span id="cb106-130"><a href="nonlinear-regression.html#cb106-130" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">2</span>), <span class="at">data =</span> Wage)</span>
<span id="cb106-131"><a href="nonlinear-regression.html#cb106-131" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">3</span>), <span class="at">data =</span> Wage)</span>
<span id="cb106-132"><a href="nonlinear-regression.html#cb106-132" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb106-133"><a href="nonlinear-regression.html#cb106-133" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">5</span>), <span class="at">data =</span> Wage)</span>
<span id="cb106-134"><a href="nonlinear-regression.html#cb106-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-135"><a href="nonlinear-regression.html#cb106-135" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">anova</span>(fit<span class="fl">.1</span>, fit<span class="fl">.2</span>, fit<span class="fl">.3</span>, fit<span class="fl">.4</span>, fit<span class="fl">.5</span>), <span class="dv">2</span>)</span>
<span id="cb106-136"><a href="nonlinear-regression.html#cb106-136" aria-hidden="true" tabindex="-1"></a>Res.Df</span>
<span id="cb106-137"><a href="nonlinear-regression.html#cb106-137" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-138"><a href="nonlinear-regression.html#cb106-138" aria-hidden="true" tabindex="-1"></a>    RSS</span>
<span id="cb106-139"><a href="nonlinear-regression.html#cb106-139" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-140"><a href="nonlinear-regression.html#cb106-140" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb106-141"><a href="nonlinear-regression.html#cb106-141" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-142"><a href="nonlinear-regression.html#cb106-142" aria-hidden="true" tabindex="-1"></a>    Sum of Sq</span>
<span id="cb106-143"><a href="nonlinear-regression.html#cb106-143" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-144"><a href="nonlinear-regression.html#cb106-144" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb106-145"><a href="nonlinear-regression.html#cb106-145" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-146"><a href="nonlinear-regression.html#cb106-146" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb106-147"><a href="nonlinear-regression.html#cb106-147" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-148"><a href="nonlinear-regression.html#cb106-148" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2998</span>    <span class="dv">5022216</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb106-149"><a href="nonlinear-regression.html#cb106-149" aria-hidden="true" tabindex="-1"></a><span class="dv">2997</span>    <span class="dv">4793430</span> <span class="dv">1</span>   <span class="fl">228786.01</span>   <span class="fl">143.59</span>  <span class="fl">0.00</span></span>
<span id="cb106-150"><a href="nonlinear-regression.html#cb106-150" aria-hidden="true" tabindex="-1"></a><span class="dv">2996</span>    <span class="dv">4777674</span> <span class="dv">1</span>   <span class="fl">15755.69</span>    <span class="fl">9.89</span>    <span class="fl">0.00</span></span>
<span id="cb106-151"><a href="nonlinear-regression.html#cb106-151" aria-hidden="true" tabindex="-1"></a><span class="dv">2995</span>    <span class="dv">4771604</span> <span class="dv">1</span>   <span class="fl">6070.15</span> <span class="fl">3.81</span>    <span class="fl">0.05</span></span>
<span id="cb106-152"><a href="nonlinear-regression.html#cb106-152" aria-hidden="true" tabindex="-1"></a><span class="dv">2994</span>    <span class="dv">4770322</span> <span class="dv">1</span>   <span class="fl">1282.56</span> <span class="fl">0.80</span>    <span class="fl">0.37</span></span>
<span id="cb106-153"><a href="nonlinear-regression.html#cb106-153" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> rows</span>
<span id="cb106-154"><a href="nonlinear-regression.html#cb106-154" aria-hidden="true" tabindex="-1"></a>Рассматриваются пять моделей, в которых степени полинома от age идут по возрастанию. В крайнем правом столбце таблице приводятся p<span class="sc">-</span>значения для проверки нулевой гипотезы<span class="sc">:</span> текущая модель не даёт статистически значимого сокращения RSS по сравнению с предыдущей моделью. Можно сделать вывод, что степени <span class="dv">3</span> достаточно, дальнейшее увеличение степени не даёт значимого улучшения качества модели.</span>
<span id="cb106-155"><a href="nonlinear-regression.html#cb106-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-156"><a href="nonlinear-regression.html#cb106-156" aria-hidden="true" tabindex="-1"></a>Зависимость вероятности получать зарплату <span class="sc">&gt;</span> <span class="dv">250</span> от возраста</span>
<span id="cb106-157"><a href="nonlinear-regression.html#cb106-157" aria-hidden="true" tabindex="-1"></a>Теперь вернёмся к группе наблюдений с высоким wage. Рассмотрим зависимость вероятности того, что величина зарплаты больше <span class="dv">250</span>, от возраста.</span>
<span id="cb106-158"><a href="nonlinear-regression.html#cb106-158" aria-hidden="true" tabindex="-1"></a>Подгоняем логистическую регрессию и делаем прогнозы, для этого используем функцию для оценки обобщённой линейной модели  <span class="fu">glm</span>() и указываем тип модели binomial<span class="sc">:</span></span>
<span id="cb106-159"><a href="nonlinear-regression.html#cb106-159" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-160"><a href="nonlinear-regression.html#cb106-160" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb106-161"><a href="nonlinear-regression.html#cb106-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-162"><a href="nonlinear-regression.html#cb106-162" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb106-163"><a href="nonlinear-regression.html#cb106-163" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb106-164"><a href="nonlinear-regression.html#cb106-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-165"><a href="nonlinear-regression.html#cb106-165" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb106-166"><a href="nonlinear-regression.html#cb106-166" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb106-167"><a href="nonlinear-regression.html#cb106-167" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb106-168"><a href="nonlinear-regression.html#cb106-168" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb106-169"><a href="nonlinear-regression.html#cb106-169" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb106-170"><a href="nonlinear-regression.html#cb106-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-171"><a href="nonlinear-regression.html#cb106-171" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb106-172"><a href="nonlinear-regression.html#cb106-172" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb106-173"><a href="nonlinear-regression.html#cb106-173" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb106-174"><a href="nonlinear-regression.html#cb106-174" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb106-175"><a href="nonlinear-regression.html#cb106-175" aria-hidden="true" tabindex="-1"></a><span class="do">## 1           0       0.002</span></span>
<span id="cb106-176"><a href="nonlinear-regression.html#cb106-176" aria-hidden="true" tabindex="-1"></a><span class="do">## 2           0       0.003</span></span>
<span id="cb106-177"><a href="nonlinear-regression.html#cb106-177" aria-hidden="true" tabindex="-1"></a><span class="do">## 3           0       0.004</span></span>
<span id="cb106-178"><a href="nonlinear-regression.html#cb106-178" aria-hidden="true" tabindex="-1"></a><span class="do">## 4           0       0.005</span></span>
<span id="cb106-179"><a href="nonlinear-regression.html#cb106-179" aria-hidden="true" tabindex="-1"></a><span class="do">## 5           0       0.006</span></span>
<span id="cb106-180"><a href="nonlinear-regression.html#cb106-180" aria-hidden="true" tabindex="-1"></a><span class="do">## 6           0       0.007</span></span>
<span id="cb106-181"><a href="nonlinear-regression.html#cb106-181" aria-hidden="true" tabindex="-1"></a>Достраиваем график с <span class="dv">4</span> слайда презентации (рис. <span class="fl">7.1</span> книги). Рисуем правую панель.</span>
<span id="cb106-182"><a href="nonlinear-regression.html#cb106-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-183"><a href="nonlinear-regression.html#cb106-183" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb106-184"><a href="nonlinear-regression.html#cb106-184" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb106-185"><a href="nonlinear-regression.html#cb106-185" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb106-186"><a href="nonlinear-regression.html#cb106-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-187"><a href="nonlinear-regression.html#cb106-187" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb106-188"><a href="nonlinear-regression.html#cb106-188" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb106-189"><a href="nonlinear-regression.html#cb106-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-190"><a href="nonlinear-regression.html#cb106-190" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb106-191"><a href="nonlinear-regression.html#cb106-191" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb106-192"><a href="nonlinear-regression.html#cb106-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-193"><a href="nonlinear-regression.html#cb106-193" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb106-194"><a href="nonlinear-regression.html#cb106-194" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb106-195"><a href="nonlinear-regression.html#cb106-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-196"><a href="nonlinear-regression.html#cb106-196" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb106-197"><a href="nonlinear-regression.html#cb106-197" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb106-198"><a href="nonlinear-regression.html#cb106-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-199"><a href="nonlinear-regression.html#cb106-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-200"><a href="nonlinear-regression.html#cb106-200" aria-hidden="true" tabindex="-1"></a>Ступенчатые функции</span>
<span id="cb106-201"><a href="nonlinear-regression.html#cb106-201" aria-hidden="true" tabindex="-1"></a>Для начала определим несколько интервалов, на каждом из которых будем моделировать зависимость wage от age своим средним уровнем.</span>
<span id="cb106-202"><a href="nonlinear-regression.html#cb106-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-203"><a href="nonlinear-regression.html#cb106-203" aria-hidden="true" tabindex="-1"></a><span class="co"># нарезаем предиктор age на 4 равных интервала</span></span>
<span id="cb106-204"><a href="nonlinear-regression.html#cb106-204" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">cut</span>(age, <span class="dv">4</span>))</span>
<span id="cb106-205"><a href="nonlinear-regression.html#cb106-205" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb106-206"><a href="nonlinear-regression.html#cb106-206" aria-hidden="true" tabindex="-1"></a><span class="do">## (17.9,33.5]   (33.5,49]   (49,64.5] (64.5,80.1] </span></span>
<span id="cb106-207"><a href="nonlinear-regression.html#cb106-207" aria-hidden="true" tabindex="-1"></a><span class="do">##         750        1399         779          72</span></span>
<span id="cb106-208"><a href="nonlinear-regression.html#cb106-208" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем линейную модель на интервалах</span></span>
<span id="cb106-209"><a href="nonlinear-regression.html#cb106-209" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb106-210"><a href="nonlinear-regression.html#cb106-210" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb106-211"><a href="nonlinear-regression.html#cb106-211" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb106-212"><a href="nonlinear-regression.html#cb106-212" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)               94.16       1.48   63.79     0.00</span></span>
<span id="cb106-213"><a href="nonlinear-regression.html#cb106-213" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(33.5,49]      24.05       1.83   13.15     0.00</span></span>
<span id="cb106-214"><a href="nonlinear-regression.html#cb106-214" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(49,64.5]      23.66       2.07   11.44     0.00</span></span>
<span id="cb106-215"><a href="nonlinear-regression.html#cb106-215" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(64.5,80.1]     7.64       4.99    1.53     0.13</span></span>
<span id="cb106-216"><a href="nonlinear-regression.html#cb106-216" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз -- это средние по `wage` на каждом интервале</span></span>
<span id="cb106-217"><a href="nonlinear-regression.html#cb106-217" aria-hidden="true" tabindex="-1"></a>preds.cut <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb106-218"><a href="nonlinear-regression.html#cb106-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-219"><a href="nonlinear-regression.html#cb106-219" aria-hidden="true" tabindex="-1"></a><span class="co"># интервальный прогноз</span></span>
<span id="cb106-220"><a href="nonlinear-regression.html#cb106-220" aria-hidden="true" tabindex="-1"></a>se.bands.cut <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit,</span>
<span id="cb106-221"><a href="nonlinear-regression.html#cb106-221" aria-hidden="true" tabindex="-1"></a>                      <span class="at">upper.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit)</span>
<span id="cb106-222"><a href="nonlinear-regression.html#cb106-222" aria-hidden="true" tabindex="-1"></a>Воспроизведём график со слайда <span class="dv">7</span> презентации (рис. <span class="fl">7.2</span> книги).</span>
<span id="cb106-223"><a href="nonlinear-regression.html#cb106-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-224"><a href="nonlinear-regression.html#cb106-224" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb106-225"><a href="nonlinear-regression.html#cb106-225" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb106-226"><a href="nonlinear-regression.html#cb106-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-227"><a href="nonlinear-regression.html#cb106-227" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb106-228"><a href="nonlinear-regression.html#cb106-228" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.cut<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb106-229"><a href="nonlinear-regression.html#cb106-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-230"><a href="nonlinear-regression.html#cb106-230" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb106-231"><a href="nonlinear-regression.html#cb106-231" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands.cut, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb106-232"><a href="nonlinear-regression.html#cb106-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-233"><a href="nonlinear-regression.html#cb106-233" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb106-234"><a href="nonlinear-regression.html#cb106-234" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb106-235"><a href="nonlinear-regression.html#cb106-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-236"><a href="nonlinear-regression.html#cb106-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-237"><a href="nonlinear-regression.html#cb106-237" aria-hidden="true" tabindex="-1"></a>Правая часть графика, для вероятности того, что зарплата выше <span class="fl">250.</span></span>
<span id="cb106-238"><a href="nonlinear-regression.html#cb106-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-239"><a href="nonlinear-regression.html#cb106-239" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb106-240"><a href="nonlinear-regression.html#cb106-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-241"><a href="nonlinear-regression.html#cb106-241" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb106-242"><a href="nonlinear-regression.html#cb106-242" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb106-243"><a href="nonlinear-regression.html#cb106-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-244"><a href="nonlinear-regression.html#cb106-244" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb106-245"><a href="nonlinear-regression.html#cb106-245" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb106-246"><a href="nonlinear-regression.html#cb106-246" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb106-247"><a href="nonlinear-regression.html#cb106-247" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb106-248"><a href="nonlinear-regression.html#cb106-248" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb106-249"><a href="nonlinear-regression.html#cb106-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-250"><a href="nonlinear-regression.html#cb106-250" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb106-251"><a href="nonlinear-regression.html#cb106-251" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb106-252"><a href="nonlinear-regression.html#cb106-252" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb106-253"><a href="nonlinear-regression.html#cb106-253" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb106-254"><a href="nonlinear-regression.html#cb106-254" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       0.003       0.016</span></span>
<span id="cb106-255"><a href="nonlinear-regression.html#cb106-255" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       0.003       0.016</span></span>
<span id="cb106-256"><a href="nonlinear-regression.html#cb106-256" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       0.003       0.016</span></span>
<span id="cb106-257"><a href="nonlinear-regression.html#cb106-257" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       0.003       0.016</span></span>
<span id="cb106-258"><a href="nonlinear-regression.html#cb106-258" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       0.003       0.016</span></span>
<span id="cb106-259"><a href="nonlinear-regression.html#cb106-259" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       0.003       0.016</span></span>
<span id="cb106-260"><a href="nonlinear-regression.html#cb106-260" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb106-261"><a href="nonlinear-regression.html#cb106-261" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb106-262"><a href="nonlinear-regression.html#cb106-262" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb106-263"><a href="nonlinear-regression.html#cb106-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-264"><a href="nonlinear-regression.html#cb106-264" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb106-265"><a href="nonlinear-regression.html#cb106-265" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb106-266"><a href="nonlinear-regression.html#cb106-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-267"><a href="nonlinear-regression.html#cb106-267" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb106-268"><a href="nonlinear-regression.html#cb106-268" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb106-269"><a href="nonlinear-regression.html#cb106-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-270"><a href="nonlinear-regression.html#cb106-270" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb106-271"><a href="nonlinear-regression.html#cb106-271" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb106-272"><a href="nonlinear-regression.html#cb106-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-273"><a href="nonlinear-regression.html#cb106-273" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb106-274"><a href="nonlinear-regression.html#cb106-274" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb106-275"><a href="nonlinear-regression.html#cb106-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-276"><a href="nonlinear-regression.html#cb106-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-277"><a href="nonlinear-regression.html#cb106-277" aria-hidden="true" tabindex="-1"></a>Сплайны</span>
<span id="cb106-278"><a href="nonlinear-regression.html#cb106-278" aria-hidden="true" tabindex="-1"></a>Построим кубический сплайн с тремя узлами.</span>
<span id="cb106-279"><a href="nonlinear-regression.html#cb106-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-280"><a href="nonlinear-regression.html#cb106-280" aria-hidden="true" tabindex="-1"></a><span class="co"># кубический сплайн с тремя узлами</span></span>
<span id="cb106-281"><a href="nonlinear-regression.html#cb106-281" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)), <span class="at">data =</span> Wage)</span>
<span id="cb106-282"><a href="nonlinear-regression.html#cb106-282" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb106-283"><a href="nonlinear-regression.html#cb106-283" aria-hidden="true" tabindex="-1"></a>preds.spl <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb106-284"><a href="nonlinear-regression.html#cb106-284" aria-hidden="true" tabindex="-1"></a>Теперь построим натуральный по трём узлам. Три узла это <span class="dv">6</span> степеней свободы. Если функции <span class="fu">bs</span>(), которая создаёт матрицу с базисом для полиномиального сплайна, передать только степени свободы, она распределит узлы равномерно. В данном случае это квартили распределения age.</span>
<span id="cb106-285"><a href="nonlinear-regression.html#cb106-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-286"><a href="nonlinear-regression.html#cb106-286" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 узла -- 6 степеней свободы (столбцы матрицы)</span></span>
<span id="cb106-287"><a href="nonlinear-regression.html#cb106-287" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)))</span>
<span id="cb106-288"><a href="nonlinear-regression.html#cb106-288" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb106-289"><a href="nonlinear-regression.html#cb106-289" aria-hidden="true" tabindex="-1"></a><span class="co"># если не указываем узлы явно...</span></span>
<span id="cb106-290"><a href="nonlinear-regression.html#cb106-290" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>))</span>
<span id="cb106-291"><a href="nonlinear-regression.html#cb106-291" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb106-292"><a href="nonlinear-regression.html#cb106-292" aria-hidden="true" tabindex="-1"></a><span class="co">#  они привязываются к квартилям</span></span>
<span id="cb106-293"><a href="nonlinear-regression.html#cb106-293" aria-hidden="true" tabindex="-1"></a><span class="fu">attr</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>), <span class="st">&#39;knots&#39;</span>)</span>
<span id="cb106-294"><a href="nonlinear-regression.html#cb106-294" aria-hidden="true" tabindex="-1"></a><span class="do">##   25%   50%   75% </span></span>
<span id="cb106-295"><a href="nonlinear-regression.html#cb106-295" aria-hidden="true" tabindex="-1"></a><span class="do">## 33.75 42.00 51.00</span></span>
<span id="cb106-296"><a href="nonlinear-regression.html#cb106-296" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb106-297"><a href="nonlinear-regression.html#cb106-297" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(age, <span class="at">df =</span> <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb106-298"><a href="nonlinear-regression.html#cb106-298" aria-hidden="true" tabindex="-1"></a>preds.spl2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit2, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb106-299"><a href="nonlinear-regression.html#cb106-299" aria-hidden="true" tabindex="-1"></a>График сравнения кубического и натурального сплайнов.</span>
<span id="cb106-300"><a href="nonlinear-regression.html#cb106-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-301"><a href="nonlinear-regression.html#cb106-301" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="fl">8.5</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="at">xpd =</span> T)</span>
<span id="cb106-302"><a href="nonlinear-regression.html#cb106-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-303"><a href="nonlinear-regression.html#cb106-303" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb106-304"><a href="nonlinear-regression.html#cb106-304" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">col =</span> <span class="st">&#39;grey&#39;</span>)</span>
<span id="cb106-305"><a href="nonlinear-regression.html#cb106-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-306"><a href="nonlinear-regression.html#cb106-306" aria-hidden="true" tabindex="-1"></a><span class="co"># модель кубического сплайна</span></span>
<span id="cb106-307"><a href="nonlinear-regression.html#cb106-307" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb106-308"><a href="nonlinear-regression.html#cb106-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-309"><a href="nonlinear-regression.html#cb106-309" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительный интервал</span></span>
<span id="cb106-310"><a href="nonlinear-regression.html#cb106-310" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb106-311"><a href="nonlinear-regression.html#cb106-311" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb106-312"><a href="nonlinear-regression.html#cb106-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-313"><a href="nonlinear-regression.html#cb106-313" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb106-314"><a href="nonlinear-regression.html#cb106-314" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl2<span class="sc">$</span>fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb106-315"><a href="nonlinear-regression.html#cb106-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-316"><a href="nonlinear-regression.html#cb106-316" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb106-317"><a href="nonlinear-regression.html#cb106-317" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">inset =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.7</span>, <span class="dv">0</span>),</span>
<span id="cb106-318"><a href="nonlinear-regression.html#cb106-318" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;Кубический </span><span class="sc">\n</span><span class="st"> с 3 узлами&#39;</span>, <span class="st">&#39;Натуральный&#39;</span>),</span>
<span id="cb106-319"><a href="nonlinear-regression.html#cb106-319" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="fu">rep</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;red&#39;</span>))</span>
<span id="cb106-320"><a href="nonlinear-regression.html#cb106-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-321"><a href="nonlinear-regression.html#cb106-321" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb106-322"><a href="nonlinear-regression.html#cb106-322" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Сплайны&quot;</span>)</span>
<span id="cb106-323"><a href="nonlinear-regression.html#cb106-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-324"><a href="nonlinear-regression.html#cb106-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-325"><a href="nonlinear-regression.html#cb106-325" aria-hidden="true" tabindex="-1"></a>Построим график со слайда <span class="dv">20</span> (рисунок <span class="fl">7.8</span> книги).</span>
<span id="cb106-326"><a href="nonlinear-regression.html#cb106-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-327"><a href="nonlinear-regression.html#cb106-327" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">0</span>))</span>
<span id="cb106-328"><a href="nonlinear-regression.html#cb106-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-329"><a href="nonlinear-regression.html#cb106-329" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb106-330"><a href="nonlinear-regression.html#cb106-330" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb106-331"><a href="nonlinear-regression.html#cb106-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-332"><a href="nonlinear-regression.html#cb106-332" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb106-333"><a href="nonlinear-regression.html#cb106-333" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Сглаживающий сплайн&#39;</span>)</span>
<span id="cb106-334"><a href="nonlinear-regression.html#cb106-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-335"><a href="nonlinear-regression.html#cb106-335" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с 16 степенями свободы</span></span>
<span id="cb106-336"><a href="nonlinear-regression.html#cb106-336" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">df =</span> <span class="dv">16</span>)</span>
<span id="cb106-337"><a href="nonlinear-regression.html#cb106-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-338"><a href="nonlinear-regression.html#cb106-338" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с подбором лямбды с помощью перекрёстной проверки</span></span>
<span id="cb106-339"><a href="nonlinear-regression.html#cb106-339" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">cv =</span> T)</span>
<span id="cb106-340"><a href="nonlinear-regression.html#cb106-340" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in smooth.spline(age, wage, cv = T): cross-validation with non-</span></span>
<span id="cb106-341"><a href="nonlinear-regression.html#cb106-341" aria-hidden="true" tabindex="-1"></a><span class="do">## unique &#39;x&#39; values seems doubtful</span></span>
<span id="cb106-342"><a href="nonlinear-regression.html#cb106-342" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span>df</span>
<span id="cb106-343"><a href="nonlinear-regression.html#cb106-343" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 6.794596</span></span>
<span id="cb106-344"><a href="nonlinear-regression.html#cb106-344" aria-hidden="true" tabindex="-1"></a><span class="co"># рисуем модель</span></span>
<span id="cb106-345"><a href="nonlinear-regression.html#cb106-345" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb106-346"><a href="nonlinear-regression.html#cb106-346" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit2, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb106-347"><a href="nonlinear-regression.html#cb106-347" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb106-348"><a href="nonlinear-regression.html#cb106-348" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;16 df&#39;</span>, <span class="st">&#39;6.8 df&#39;</span>),</span>
<span id="cb106-349"><a href="nonlinear-regression.html#cb106-349" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb106-350"><a href="nonlinear-regression.html#cb106-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-351"><a href="nonlinear-regression.html#cb106-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-352"><a href="nonlinear-regression.html#cb106-352" aria-hidden="true" tabindex="-1"></a>Локальная регрессия</span>
<span id="cb106-353"><a href="nonlinear-regression.html#cb106-353" aria-hidden="true" tabindex="-1"></a>Строим график со слайда <span class="dv">24</span> (рис. <span class="fl">7.10</span>).</span>
<span id="cb106-354"><a href="nonlinear-regression.html#cb106-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-355"><a href="nonlinear-regression.html#cb106-355" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb106-356"><a href="nonlinear-regression.html#cb106-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-357"><a href="nonlinear-regression.html#cb106-357" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Локальная регрессия&#39;</span>)</span>
<span id="cb106-358"><a href="nonlinear-regression.html#cb106-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-359"><a href="nonlinear-regression.html#cb106-359" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.2</span></span>
<span id="cb106-360"><a href="nonlinear-regression.html#cb106-360" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.2</span>, <span class="at">data =</span> Wage)</span>
<span id="cb106-361"><a href="nonlinear-regression.html#cb106-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-362"><a href="nonlinear-regression.html#cb106-362" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.5</span></span>
<span id="cb106-363"><a href="nonlinear-regression.html#cb106-363" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.5</span>, <span class="at">data =</span> Wage)</span>
<span id="cb106-364"><a href="nonlinear-regression.html#cb106-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-365"><a href="nonlinear-regression.html#cb106-365" aria-hidden="true" tabindex="-1"></a><span class="co"># рисум модели</span></span>
<span id="cb106-366"><a href="nonlinear-regression.html#cb106-366" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb106-367"><a href="nonlinear-regression.html#cb106-367" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb106-368"><a href="nonlinear-regression.html#cb106-368" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit2, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb106-369"><a href="nonlinear-regression.html#cb106-369" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb106-370"><a href="nonlinear-regression.html#cb106-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-371"><a href="nonlinear-regression.html#cb106-371" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb106-372"><a href="nonlinear-regression.html#cb106-372" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb106-373"><a href="nonlinear-regression.html#cb106-373" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;s = 0.2&#39;</span>, <span class="st">&#39;s = 0.5&#39;</span>),</span>
<span id="cb106-374"><a href="nonlinear-regression.html#cb106-374" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb106-375"><a href="nonlinear-regression.html#cb106-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-376"><a href="nonlinear-regression.html#cb106-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-377"><a href="nonlinear-regression.html#cb106-377" aria-hidden="true" tabindex="-1"></a>Обобщённые аддитивные модели (GAM) с непрерывным откликом</span>
<span id="cb106-378"><a href="nonlinear-regression.html#cb106-378" aria-hidden="true" tabindex="-1"></a>Построим GAM на натуральных сплайнах степеней <span class="dv">4</span> (year), <span class="dv">5</span> (age) с категориальным предиктором edication.</span>
<span id="cb106-379"><a href="nonlinear-regression.html#cb106-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-380"><a href="nonlinear-regression.html#cb106-380" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на натуральных сплайнах</span></span>
<span id="cb106-381"><a href="nonlinear-regression.html#cb106-381" aria-hidden="true" tabindex="-1"></a>gam.ns <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">ns</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb106-382"><a href="nonlinear-regression.html#cb106-382" aria-hidden="true" tabindex="-1"></a>Также построим модель на сглаживающих сплайнах.</span>
<span id="cb106-383"><a href="nonlinear-regression.html#cb106-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-384"><a href="nonlinear-regression.html#cb106-384" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на сглаживающих сплайнах</span></span>
<span id="cb106-385"><a href="nonlinear-regression.html#cb106-385" aria-hidden="true" tabindex="-1"></a>gam.m3 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb106-386"><a href="nonlinear-regression.html#cb106-386" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">28</span> (рис. <span class="fl">7.12</span>).</span>
<span id="cb106-387"><a href="nonlinear-regression.html#cb106-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-388"><a href="nonlinear-regression.html#cb106-388" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb106-389"><a href="nonlinear-regression.html#cb106-389" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.m3, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb106-390"><a href="nonlinear-regression.html#cb106-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-391"><a href="nonlinear-regression.html#cb106-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-392"><a href="nonlinear-regression.html#cb106-392" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">27</span> (рис. <span class="fl">7.11</span>).</span>
<span id="cb106-393"><a href="nonlinear-regression.html#cb106-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-394"><a href="nonlinear-regression.html#cb106-394" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb106-395"><a href="nonlinear-regression.html#cb106-395" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.ns, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb106-396"><a href="nonlinear-regression.html#cb106-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-397"><a href="nonlinear-regression.html#cb106-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-398"><a href="nonlinear-regression.html#cb106-398" aria-hidden="true" tabindex="-1"></a>График функции от year похож на прямую. Сделаем ANOVA, чтобы понять, какая степень для year лучше.</span>
<span id="cb106-399"><a href="nonlinear-regression.html#cb106-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-400"><a href="nonlinear-regression.html#cb106-400" aria-hidden="true" tabindex="-1"></a>gam.m1 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)          <span class="co"># без year</span></span>
<span id="cb106-401"><a href="nonlinear-regression.html#cb106-401" aria-hidden="true" tabindex="-1"></a>gam.m2 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)   <span class="co"># year^1</span></span>
<span id="cb106-402"><a href="nonlinear-regression.html#cb106-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-403"><a href="nonlinear-regression.html#cb106-403" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(gam.m1, gam.m2, gam.m3, <span class="at">test =</span> <span class="st">&#39;F&#39;</span>)</span>
<span id="cb106-404"><a href="nonlinear-regression.html#cb106-404" aria-hidden="true" tabindex="-1"></a>Resid. Df</span>
<span id="cb106-405"><a href="nonlinear-regression.html#cb106-405" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-406"><a href="nonlinear-regression.html#cb106-406" aria-hidden="true" tabindex="-1"></a>    Resid. Dev</span>
<span id="cb106-407"><a href="nonlinear-regression.html#cb106-407" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-408"><a href="nonlinear-regression.html#cb106-408" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb106-409"><a href="nonlinear-regression.html#cb106-409" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-410"><a href="nonlinear-regression.html#cb106-410" aria-hidden="true" tabindex="-1"></a>    Deviance</span>
<span id="cb106-411"><a href="nonlinear-regression.html#cb106-411" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-412"><a href="nonlinear-regression.html#cb106-412" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb106-413"><a href="nonlinear-regression.html#cb106-413" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-414"><a href="nonlinear-regression.html#cb106-414" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb106-415"><a href="nonlinear-regression.html#cb106-415" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb106-416"><a href="nonlinear-regression.html#cb106-416" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2990</span>    <span class="dv">3711731</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb106-417"><a href="nonlinear-regression.html#cb106-417" aria-hidden="true" tabindex="-1"></a><span class="dv">2989</span>    <span class="dv">3693842</span> <span class="fl">1.000000</span>    <span class="fl">17889.243</span>   <span class="fl">14.477130</span>   <span class="fl">0.0001447167</span></span>
<span id="cb106-418"><a href="nonlinear-regression.html#cb106-418" aria-hidden="true" tabindex="-1"></a><span class="dv">2986</span>    <span class="dv">3689770</span> <span class="fl">2.999989</span>    <span class="fl">4071.134</span>    <span class="fl">1.098212</span>    <span class="fl">0.3485661430</span></span>
<span id="cb106-419"><a href="nonlinear-regression.html#cb106-419" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> rows</span>
<span id="cb106-420"><a href="nonlinear-regression.html#cb106-420" aria-hidden="true" tabindex="-1"></a>Третья модель статистически не лучше второй. Кроме того, один из параметров этой модели незначим.</span>
<span id="cb106-421"><a href="nonlinear-regression.html#cb106-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-422"><a href="nonlinear-regression.html#cb106-422" aria-hidden="true" tabindex="-1"></a><span class="co"># сводка по модели gam.m3</span></span>
<span id="cb106-423"><a href="nonlinear-regression.html#cb106-423" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gam.m3)</span>
<span id="cb106-424"><a href="nonlinear-regression.html#cb106-424" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb106-425"><a href="nonlinear-regression.html#cb106-425" aria-hidden="true" tabindex="-1"></a><span class="do">## Call: gam(formula = wage ~ s(year, 4) + s(age, 5) + education, data = Wage)</span></span>
<span id="cb106-426"><a href="nonlinear-regression.html#cb106-426" aria-hidden="true" tabindex="-1"></a><span class="do">## Deviance Residuals:</span></span>
<span id="cb106-427"><a href="nonlinear-regression.html#cb106-427" aria-hidden="true" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb106-428"><a href="nonlinear-regression.html#cb106-428" aria-hidden="true" tabindex="-1"></a><span class="do">## -119.43  -19.70   -3.33   14.17  213.48 </span></span>
<span id="cb106-429"><a href="nonlinear-regression.html#cb106-429" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb106-430"><a href="nonlinear-regression.html#cb106-430" aria-hidden="true" tabindex="-1"></a><span class="do">## (Dispersion Parameter for gaussian family taken to be 1235.69)</span></span>
<span id="cb106-431"><a href="nonlinear-regression.html#cb106-431" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb106-432"><a href="nonlinear-regression.html#cb106-432" aria-hidden="true" tabindex="-1"></a><span class="do">##     Null Deviance: 5222086 on 2999 degrees of freedom</span></span>
<span id="cb106-433"><a href="nonlinear-regression.html#cb106-433" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual Deviance: 3689770 on 2986 degrees of freedom</span></span>
<span id="cb106-434"><a href="nonlinear-regression.html#cb106-434" aria-hidden="true" tabindex="-1"></a><span class="do">## AIC: 29887.75 </span></span>
<span id="cb106-435"><a href="nonlinear-regression.html#cb106-435" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb106-436"><a href="nonlinear-regression.html#cb106-436" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Local Scoring Iterations: 2 </span></span>
<span id="cb106-437"><a href="nonlinear-regression.html#cb106-437" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb106-438"><a href="nonlinear-regression.html#cb106-438" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Parametric Effects</span></span>
<span id="cb106-439"><a href="nonlinear-regression.html#cb106-439" aria-hidden="true" tabindex="-1"></a><span class="do">##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    </span></span>
<span id="cb106-440"><a href="nonlinear-regression.html#cb106-440" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)    1   27162   27162  21.981 2.877e-06 ***</span></span>
<span id="cb106-441"><a href="nonlinear-regression.html#cb106-441" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)     1  195338  195338 158.081 &lt; 2.2e-16 ***</span></span>
<span id="cb106-442"><a href="nonlinear-regression.html#cb106-442" aria-hidden="true" tabindex="-1"></a><span class="do">## education     4 1069726  267432 216.423 &lt; 2.2e-16 ***</span></span>
<span id="cb106-443"><a href="nonlinear-regression.html#cb106-443" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals  2986 3689770    1236                      </span></span>
<span id="cb106-444"><a href="nonlinear-regression.html#cb106-444" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb106-445"><a href="nonlinear-regression.html#cb106-445" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb106-446"><a href="nonlinear-regression.html#cb106-446" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb106-447"><a href="nonlinear-regression.html#cb106-447" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Nonparametric Effects</span></span>
<span id="cb106-448"><a href="nonlinear-regression.html#cb106-448" aria-hidden="true" tabindex="-1"></a><span class="do">##             Npar Df Npar F  Pr(F)    </span></span>
<span id="cb106-449"><a href="nonlinear-regression.html#cb106-449" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)                          </span></span>
<span id="cb106-450"><a href="nonlinear-regression.html#cb106-450" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)        3  1.086 0.3537    </span></span>
<span id="cb106-451"><a href="nonlinear-regression.html#cb106-451" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)         4 32.380 &lt;2e-16 ***</span></span>
<span id="cb106-452"><a href="nonlinear-regression.html#cb106-452" aria-hidden="true" tabindex="-1"></a><span class="do">## education                            </span></span>
<span id="cb106-453"><a href="nonlinear-regression.html#cb106-453" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb106-454"><a href="nonlinear-regression.html#cb106-454" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb106-455"><a href="nonlinear-regression.html#cb106-455" aria-hidden="true" tabindex="-1"></a>Работаем с моделью gam.m2.</span>
<span id="cb106-456"><a href="nonlinear-regression.html#cb106-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-457"><a href="nonlinear-regression.html#cb106-457" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по обучающей выборке</span></span>
<span id="cb106-458"><a href="nonlinear-regression.html#cb106-458" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(gam.m2, <span class="at">newdata =</span> Wage)</span>
<span id="cb106-459"><a href="nonlinear-regression.html#cb106-459" aria-hidden="true" tabindex="-1"></a>Также можно использовать в GAM локальные регрессии.</span>
<span id="cb106-460"><a href="nonlinear-regression.html#cb106-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-461"><a href="nonlinear-regression.html#cb106-461" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на локальных регрессиях</span></span>
<span id="cb106-462"><a href="nonlinear-regression.html#cb106-462" aria-hidden="true" tabindex="-1"></a>gam.lo <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="at">df =</span> <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">lo</span>(age, <span class="at">span =</span> <span class="fl">0.7</span>) <span class="sc">+</span> education, </span>
<span id="cb106-463"><a href="nonlinear-regression.html#cb106-463" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> Wage)</span>
<span id="cb106-464"><a href="nonlinear-regression.html#cb106-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-465"><a href="nonlinear-regression.html#cb106-465" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb106-466"><a href="nonlinear-regression.html#cb106-466" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.gam</span>(gam.lo, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb106-467"><a href="nonlinear-regression.html#cb106-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-468"><a href="nonlinear-regression.html#cb106-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-469"><a href="nonlinear-regression.html#cb106-469" aria-hidden="true" tabindex="-1"></a><span class="co"># модель со взаимодействием регрессоров year и age</span></span>
<span id="cb106-470"><a href="nonlinear-regression.html#cb106-470" aria-hidden="true" tabindex="-1"></a>gam.lo.i <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">lo</span>(year, age, <span class="at">span =</span> <span class="fl">0.5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb106-471"><a href="nonlinear-regression.html#cb106-471" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb106-472"><a href="nonlinear-regression.html#cb106-472" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb106-473"><a href="nonlinear-regression.html#cb106-473" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb106-474"><a href="nonlinear-regression.html#cb106-474" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb106-475"><a href="nonlinear-regression.html#cb106-475" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb106-476"><a href="nonlinear-regression.html#cb106-476" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb106-477"><a href="nonlinear-regression.html#cb106-477" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb106-478"><a href="nonlinear-regression.html#cb106-478" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb106-479"><a href="nonlinear-regression.html#cb106-479" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lo.i)</span>
<span id="cb106-480"><a href="nonlinear-regression.html#cb106-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-481"><a href="nonlinear-regression.html#cb106-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-482"><a href="nonlinear-regression.html#cb106-482" aria-hidden="true" tabindex="-1"></a>Логистическая GAM</span>
<span id="cb106-483"><a href="nonlinear-regression.html#cb106-483" aria-hidden="true" tabindex="-1"></a>Построим логистическую GAM для всероятности того, что wage превышает <span class="fl">250.</span></span>
<span id="cb106-484"><a href="nonlinear-regression.html#cb106-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-485"><a href="nonlinear-regression.html#cb106-485" aria-hidden="true" tabindex="-1"></a>gam.lr <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education, </span>
<span id="cb106-486"><a href="nonlinear-regression.html#cb106-486" aria-hidden="true" tabindex="-1"></a>              <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage)</span>
<span id="cb106-487"><a href="nonlinear-regression.html#cb106-487" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb106-488"><a href="nonlinear-regression.html#cb106-488" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb106-489"><a href="nonlinear-regression.html#cb106-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-490"><a href="nonlinear-regression.html#cb106-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-491"><a href="nonlinear-regression.html#cb106-491" aria-hidden="true" tabindex="-1"></a><span class="co"># уровни образования по группам разного достатка</span></span>
<span id="cb106-492"><a href="nonlinear-regression.html#cb106-492" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(education, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>))</span>
<span id="cb106-493"><a href="nonlinear-regression.html#cb106-493" aria-hidden="true" tabindex="-1"></a><span class="do">##                     </span></span>
<span id="cb106-494"><a href="nonlinear-regression.html#cb106-494" aria-hidden="true" tabindex="-1"></a><span class="do">## education            FALSE TRUE</span></span>
<span id="cb106-495"><a href="nonlinear-regression.html#cb106-495" aria-hidden="true" tabindex="-1"></a><span class="do">##   1. &lt; HS Grad         268    0</span></span>
<span id="cb106-496"><a href="nonlinear-regression.html#cb106-496" aria-hidden="true" tabindex="-1"></a><span class="do">##   2. HS Grad           966    5</span></span>
<span id="cb106-497"><a href="nonlinear-regression.html#cb106-497" aria-hidden="true" tabindex="-1"></a><span class="do">##   3. Some College      643    7</span></span>
<span id="cb106-498"><a href="nonlinear-regression.html#cb106-498" aria-hidden="true" tabindex="-1"></a><span class="do">##   4. College Grad      663   22</span></span>
<span id="cb106-499"><a href="nonlinear-regression.html#cb106-499" aria-hidden="true" tabindex="-1"></a><span class="do">##   5. Advanced Degree   381   45</span></span>
<span id="cb106-500"><a href="nonlinear-regression.html#cb106-500" aria-hidden="true" tabindex="-1"></a>В категории с самым низким уровнем образования нет wage <span class="sc">&gt;</span> <span class="dv">250</span>, поэтому убираем её.</span>
<span id="cb106-501"><a href="nonlinear-regression.html#cb106-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-502"><a href="nonlinear-regression.html#cb106-502" aria-hidden="true" tabindex="-1"></a>gam.lr.s <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education,</span>
<span id="cb106-503"><a href="nonlinear-regression.html#cb106-503" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage, </span>
<span id="cb106-504"><a href="nonlinear-regression.html#cb106-504" aria-hidden="true" tabindex="-1"></a>                <span class="at">subset =</span> (education <span class="sc">!=</span> <span class="st">&quot;1. &lt; HS Grad&quot;</span>))</span>
<span id="cb106-505"><a href="nonlinear-regression.html#cb106-505" aria-hidden="true" tabindex="-1"></a><span class="co"># график</span></span>
<span id="cb106-506"><a href="nonlinear-regression.html#cb106-506" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb106-507"><a href="nonlinear-regression.html#cb106-507" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr.s, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb106-508"><a href="nonlinear-regression.html#cb106-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-509"><a href="nonlinear-regression.html#cb106-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-510"><a href="nonlinear-regression.html#cb106-510" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(Wage)</span></code></pre></div>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="nonlinear-regression.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonlinear modeling</span></span>
<span id="cb107-2"><a href="nonlinear-regression.html#cb107-2" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb107-3"><a href="nonlinear-regression.html#cb107-3" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">8</span></span>
<span id="cb107-4"><a href="nonlinear-regression.html#cb107-4" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb107-5"><a href="nonlinear-regression.html#cb107-5" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb107-6"><a href="nonlinear-regression.html#cb107-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb107-7"><a href="nonlinear-regression.html#cb107-7" aria-hidden="true" tabindex="-1"></a>    строить регрессионные деревья;</span>
<span id="cb107-8"><a href="nonlinear-regression.html#cb107-8" aria-hidden="true" tabindex="-1"></a>строить деревья классификации;</span>
<span id="cb107-9"><a href="nonlinear-regression.html#cb107-9" aria-hidden="true" tabindex="-1"></a>делать обрезку дерева;</span>
<span id="cb107-10"><a href="nonlinear-regression.html#cb107-10" aria-hidden="true" tabindex="-1"></a>использовать бэггинг, бустинг, случайный лес для улучшения качества прогнозирования.</span>
<span id="cb107-11"><a href="nonlinear-regression.html#cb107-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> деревья решений.</span>
<span id="cb107-12"><a href="nonlinear-regression.html#cb107-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Sales {ISLR}, Boston {ISLR}</span>
<span id="cb107-13"><a href="nonlinear-regression.html#cb107-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-14"><a href="nonlinear-regression.html#cb107-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">8.</span></span>
<span id="cb107-15"><a href="nonlinear-regression.html#cb107-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-16"><a href="nonlinear-regression.html#cb107-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;tree&#39;</span>)              <span class="co"># деревья</span></span>
<span id="cb107-17"><a href="nonlinear-regression.html#cb107-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;tree&#39; was built under R version 3.4.4</span></span>
<span id="cb107-18"><a href="nonlinear-regression.html#cb107-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># наборы данных</span></span>
<span id="cb107-19"><a href="nonlinear-regression.html#cb107-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;MASS&#39;</span>)</span>
<span id="cb107-20"><a href="nonlinear-regression.html#cb107-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;randomForest&#39;</span>)      <span class="co"># случайный лес</span></span>
<span id="cb107-21"><a href="nonlinear-regression.html#cb107-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;randomForest&#39; was built under R version 3.4.4</span></span>
<span id="cb107-22"><a href="nonlinear-regression.html#cb107-22" aria-hidden="true" tabindex="-1"></a><span class="do">## randomForest 4.6-14</span></span>
<span id="cb107-23"><a href="nonlinear-regression.html#cb107-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Type rfNews() to see new features/changes/bug fixes.</span></span>
<span id="cb107-24"><a href="nonlinear-regression.html#cb107-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gbm&#39;</span>)</span>
<span id="cb107-25"><a href="nonlinear-regression.html#cb107-25" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gbm&#39; was built under R version 3.4.4</span></span>
<span id="cb107-26"><a href="nonlinear-regression.html#cb107-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: survival</span></span>
<span id="cb107-27"><a href="nonlinear-regression.html#cb107-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: lattice</span></span>
<span id="cb107-28"><a href="nonlinear-regression.html#cb107-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: splines</span></span>
<span id="cb107-29"><a href="nonlinear-regression.html#cb107-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: parallel</span></span>
<span id="cb107-30"><a href="nonlinear-regression.html#cb107-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gbm 2.1.3</span></span>
<span id="cb107-31"><a href="nonlinear-regression.html#cb107-31" aria-hidden="true" tabindex="-1"></a>Деревья решений</span>
<span id="cb107-32"><a href="nonlinear-regression.html#cb107-32" aria-hidden="true" tabindex="-1"></a>Загрузим таблицу с данными по продажам детских кресел и добавим к ней переменную High – “высокие продажи” со значениями<span class="sc">:</span></span>
<span id="cb107-33"><a href="nonlinear-regression.html#cb107-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb107-34"><a href="nonlinear-regression.html#cb107-34" aria-hidden="true" tabindex="-1"></a>    Yes если продажи больше <span class="dv">8</span> (тыс. шт.);</span>
<span id="cb107-35"><a href="nonlinear-regression.html#cb107-35" aria-hidden="true" tabindex="-1"></a>No в противном случае.</span>
<span id="cb107-36"><a href="nonlinear-regression.html#cb107-36" aria-hidden="true" tabindex="-1"></a>?Carseats</span>
<span id="cb107-37"><a href="nonlinear-regression.html#cb107-37" aria-hidden="true" tabindex="-1"></a><span class="do">## starting httpd help server ... done</span></span>
<span id="cb107-38"><a href="nonlinear-regression.html#cb107-38" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Carseats)</span>
<span id="cb107-39"><a href="nonlinear-regression.html#cb107-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-40"><a href="nonlinear-regression.html#cb107-40" aria-hidden="true" tabindex="-1"></a><span class="co"># новая переменная</span></span>
<span id="cb107-41"><a href="nonlinear-regression.html#cb107-41" aria-hidden="true" tabindex="-1"></a>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Sales <span class="sc">&lt;=</span> <span class="dv">8</span>, <span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb107-42"><a href="nonlinear-regression.html#cb107-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-43"><a href="nonlinear-regression.html#cb107-43" aria-hidden="true" tabindex="-1"></a><span class="co"># присоединяем к таблице данных</span></span>
<span id="cb107-44"><a href="nonlinear-regression.html#cb107-44" aria-hidden="true" tabindex="-1"></a>Carseats <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Carseats, High)</span>
<span id="cb107-45"><a href="nonlinear-regression.html#cb107-45" aria-hidden="true" tabindex="-1"></a>Строим дерево для категориального отклика High, отбросив непрерывный отклик Sales.</span>
<span id="cb107-46"><a href="nonlinear-regression.html#cb107-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-47"><a href="nonlinear-regression.html#cb107-47" aria-hidden="true" tabindex="-1"></a><span class="co"># модель бинарного  дерева</span></span>
<span id="cb107-48"><a href="nonlinear-regression.html#cb107-48" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats)</span>
<span id="cb107-49"><a href="nonlinear-regression.html#cb107-49" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.carseats)</span>
<span id="cb107-50"><a href="nonlinear-regression.html#cb107-50" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-51"><a href="nonlinear-regression.html#cb107-51" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree:</span></span>
<span id="cb107-52"><a href="nonlinear-regression.html#cb107-52" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = High ~ . - Sales, data = Carseats)</span></span>
<span id="cb107-53"><a href="nonlinear-regression.html#cb107-53" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb107-54"><a href="nonlinear-regression.html#cb107-54" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;ShelveLoc&quot;   &quot;Price&quot;       &quot;Income&quot;      &quot;CompPrice&quot;   &quot;Population&quot; </span></span>
<span id="cb107-55"><a href="nonlinear-regression.html#cb107-55" aria-hidden="true" tabindex="-1"></a><span class="do">## [6] &quot;Advertising&quot; &quot;Age&quot;         &quot;US&quot;         </span></span>
<span id="cb107-56"><a href="nonlinear-regression.html#cb107-56" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  27 </span></span>
<span id="cb107-57"><a href="nonlinear-regression.html#cb107-57" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  0.4575 = 170.7 / 373 </span></span>
<span id="cb107-58"><a href="nonlinear-regression.html#cb107-58" aria-hidden="true" tabindex="-1"></a><span class="do">## Misclassification error rate: 0.09 = 36 / 400</span></span>
<span id="cb107-59"><a href="nonlinear-regression.html#cb107-59" aria-hidden="true" tabindex="-1"></a><span class="co"># график результата</span></span>
<span id="cb107-60"><a href="nonlinear-regression.html#cb107-60" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.carseats)            <span class="co"># ветви</span></span>
<span id="cb107-61"><a href="nonlinear-regression.html#cb107-61" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.carseats, <span class="at">pretty=</span><span class="dv">0</span>)  <span class="co"># подписи</span></span>
<span id="cb107-62"><a href="nonlinear-regression.html#cb107-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-63"><a href="nonlinear-regression.html#cb107-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-64"><a href="nonlinear-regression.html#cb107-64" aria-hidden="true" tabindex="-1"></a>tree.carseats                  <span class="co"># посмотреть всё дерево в консоли</span></span>
<span id="cb107-65"><a href="nonlinear-regression.html#cb107-65" aria-hidden="true" tabindex="-1"></a><span class="do">## node), split, n, deviance, yval, (yprob)</span></span>
<span id="cb107-66"><a href="nonlinear-regression.html#cb107-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       * denotes terminal node</span></span>
<span id="cb107-67"><a href="nonlinear-regression.html#cb107-67" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-68"><a href="nonlinear-regression.html#cb107-68" aria-hidden="true" tabindex="-1"></a><span class="do">##   1) root 400 541.500 No ( 0.59000 0.41000 )  </span></span>
<span id="cb107-69"><a href="nonlinear-regression.html#cb107-69" aria-hidden="true" tabindex="-1"></a><span class="do">##     2) ShelveLoc: Bad,Medium 315 390.600 No ( 0.68889 0.31111 )  </span></span>
<span id="cb107-70"><a href="nonlinear-regression.html#cb107-70" aria-hidden="true" tabindex="-1"></a><span class="do">##       4) Price &lt; 92.5 46  56.530 Yes ( 0.30435 0.69565 )  </span></span>
<span id="cb107-71"><a href="nonlinear-regression.html#cb107-71" aria-hidden="true" tabindex="-1"></a><span class="do">##         8) Income &lt; 57 10  12.220 No ( 0.70000 0.30000 )  </span></span>
<span id="cb107-72"><a href="nonlinear-regression.html#cb107-72" aria-hidden="true" tabindex="-1"></a><span class="do">##          16) CompPrice &lt; 110.5 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb107-73"><a href="nonlinear-regression.html#cb107-73" aria-hidden="true" tabindex="-1"></a><span class="do">##          17) CompPrice &gt; 110.5 5   6.730 Yes ( 0.40000 0.60000 ) *</span></span>
<span id="cb107-74"><a href="nonlinear-regression.html#cb107-74" aria-hidden="true" tabindex="-1"></a><span class="do">##         9) Income &gt; 57 36  35.470 Yes ( 0.19444 0.80556 )  </span></span>
<span id="cb107-75"><a href="nonlinear-regression.html#cb107-75" aria-hidden="true" tabindex="-1"></a><span class="do">##          18) Population &lt; 207.5 16  21.170 Yes ( 0.37500 0.62500 ) *</span></span>
<span id="cb107-76"><a href="nonlinear-regression.html#cb107-76" aria-hidden="true" tabindex="-1"></a><span class="do">##          19) Population &gt; 207.5 20   7.941 Yes ( 0.05000 0.95000 ) *</span></span>
<span id="cb107-77"><a href="nonlinear-regression.html#cb107-77" aria-hidden="true" tabindex="-1"></a><span class="do">##       5) Price &gt; 92.5 269 299.800 No ( 0.75465 0.24535 )  </span></span>
<span id="cb107-78"><a href="nonlinear-regression.html#cb107-78" aria-hidden="true" tabindex="-1"></a><span class="do">##        10) Advertising &lt; 13.5 224 213.200 No ( 0.81696 0.18304 )  </span></span>
<span id="cb107-79"><a href="nonlinear-regression.html#cb107-79" aria-hidden="true" tabindex="-1"></a><span class="do">##          20) CompPrice &lt; 124.5 96  44.890 No ( 0.93750 0.06250 )  </span></span>
<span id="cb107-80"><a href="nonlinear-regression.html#cb107-80" aria-hidden="true" tabindex="-1"></a><span class="do">##            40) Price &lt; 106.5 38  33.150 No ( 0.84211 0.15789 )  </span></span>
<span id="cb107-81"><a href="nonlinear-regression.html#cb107-81" aria-hidden="true" tabindex="-1"></a><span class="do">##              80) Population &lt; 177 12  16.300 No ( 0.58333 0.41667 )  </span></span>
<span id="cb107-82"><a href="nonlinear-regression.html#cb107-82" aria-hidden="true" tabindex="-1"></a><span class="do">##               160) Income &lt; 60.5 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb107-83"><a href="nonlinear-regression.html#cb107-83" aria-hidden="true" tabindex="-1"></a><span class="do">##               161) Income &gt; 60.5 6   5.407 Yes ( 0.16667 0.83333 ) *</span></span>
<span id="cb107-84"><a href="nonlinear-regression.html#cb107-84" aria-hidden="true" tabindex="-1"></a><span class="do">##              81) Population &gt; 177 26   8.477 No ( 0.96154 0.03846 ) *</span></span>
<span id="cb107-85"><a href="nonlinear-regression.html#cb107-85" aria-hidden="true" tabindex="-1"></a><span class="do">##            41) Price &gt; 106.5 58   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb107-86"><a href="nonlinear-regression.html#cb107-86" aria-hidden="true" tabindex="-1"></a><span class="do">##          21) CompPrice &gt; 124.5 128 150.200 No ( 0.72656 0.27344 )  </span></span>
<span id="cb107-87"><a href="nonlinear-regression.html#cb107-87" aria-hidden="true" tabindex="-1"></a><span class="do">##            42) Price &lt; 122.5 51  70.680 Yes ( 0.49020 0.50980 )  </span></span>
<span id="cb107-88"><a href="nonlinear-regression.html#cb107-88" aria-hidden="true" tabindex="-1"></a><span class="do">##              84) ShelveLoc: Bad 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb107-89"><a href="nonlinear-regression.html#cb107-89" aria-hidden="true" tabindex="-1"></a><span class="do">##              85) ShelveLoc: Medium 40  52.930 Yes ( 0.37500 0.62500 )  </span></span>
<span id="cb107-90"><a href="nonlinear-regression.html#cb107-90" aria-hidden="true" tabindex="-1"></a><span class="do">##               170) Price &lt; 109.5 16   7.481 Yes ( 0.06250 0.93750 ) *</span></span>
<span id="cb107-91"><a href="nonlinear-regression.html#cb107-91" aria-hidden="true" tabindex="-1"></a><span class="do">##               171) Price &gt; 109.5 24  32.600 No ( 0.58333 0.41667 )  </span></span>
<span id="cb107-92"><a href="nonlinear-regression.html#cb107-92" aria-hidden="true" tabindex="-1"></a><span class="do">##                 342) Age &lt; 49.5 13  16.050 Yes ( 0.30769 0.69231 ) *</span></span>
<span id="cb107-93"><a href="nonlinear-regression.html#cb107-93" aria-hidden="true" tabindex="-1"></a><span class="do">##                 343) Age &gt; 49.5 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb107-94"><a href="nonlinear-regression.html#cb107-94" aria-hidden="true" tabindex="-1"></a><span class="do">##            43) Price &gt; 122.5 77  55.540 No ( 0.88312 0.11688 )  </span></span>
<span id="cb107-95"><a href="nonlinear-regression.html#cb107-95" aria-hidden="true" tabindex="-1"></a><span class="do">##              86) CompPrice &lt; 147.5 58  17.400 No ( 0.96552 0.03448 ) *</span></span>
<span id="cb107-96"><a href="nonlinear-regression.html#cb107-96" aria-hidden="true" tabindex="-1"></a><span class="do">##              87) CompPrice &gt; 147.5 19  25.010 No ( 0.63158 0.36842 )  </span></span>
<span id="cb107-97"><a href="nonlinear-regression.html#cb107-97" aria-hidden="true" tabindex="-1"></a><span class="do">##               174) Price &lt; 147 12  16.300 Yes ( 0.41667 0.58333 )  </span></span>
<span id="cb107-98"><a href="nonlinear-regression.html#cb107-98" aria-hidden="true" tabindex="-1"></a><span class="do">##                 348) CompPrice &lt; 152.5 7   5.742 Yes ( 0.14286 0.85714 ) *</span></span>
<span id="cb107-99"><a href="nonlinear-regression.html#cb107-99" aria-hidden="true" tabindex="-1"></a><span class="do">##                 349) CompPrice &gt; 152.5 5   5.004 No ( 0.80000 0.20000 ) *</span></span>
<span id="cb107-100"><a href="nonlinear-regression.html#cb107-100" aria-hidden="true" tabindex="-1"></a><span class="do">##               175) Price &gt; 147 7   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb107-101"><a href="nonlinear-regression.html#cb107-101" aria-hidden="true" tabindex="-1"></a><span class="do">##        11) Advertising &gt; 13.5 45  61.830 Yes ( 0.44444 0.55556 )  </span></span>
<span id="cb107-102"><a href="nonlinear-regression.html#cb107-102" aria-hidden="true" tabindex="-1"></a><span class="do">##          22) Age &lt; 54.5 25  25.020 Yes ( 0.20000 0.80000 )  </span></span>
<span id="cb107-103"><a href="nonlinear-regression.html#cb107-103" aria-hidden="true" tabindex="-1"></a><span class="do">##            44) CompPrice &lt; 130.5 14  18.250 Yes ( 0.35714 0.64286 )  </span></span>
<span id="cb107-104"><a href="nonlinear-regression.html#cb107-104" aria-hidden="true" tabindex="-1"></a><span class="do">##              88) Income &lt; 100 9  12.370 No ( 0.55556 0.44444 ) *</span></span>
<span id="cb107-105"><a href="nonlinear-regression.html#cb107-105" aria-hidden="true" tabindex="-1"></a><span class="do">##              89) Income &gt; 100 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb107-106"><a href="nonlinear-regression.html#cb107-106" aria-hidden="true" tabindex="-1"></a><span class="do">##            45) CompPrice &gt; 130.5 11   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb107-107"><a href="nonlinear-regression.html#cb107-107" aria-hidden="true" tabindex="-1"></a><span class="do">##          23) Age &gt; 54.5 20  22.490 No ( 0.75000 0.25000 )  </span></span>
<span id="cb107-108"><a href="nonlinear-regression.html#cb107-108" aria-hidden="true" tabindex="-1"></a><span class="do">##            46) CompPrice &lt; 122.5 10   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb107-109"><a href="nonlinear-regression.html#cb107-109" aria-hidden="true" tabindex="-1"></a><span class="do">##            47) CompPrice &gt; 122.5 10  13.860 No ( 0.50000 0.50000 )  </span></span>
<span id="cb107-110"><a href="nonlinear-regression.html#cb107-110" aria-hidden="true" tabindex="-1"></a><span class="do">##              94) Price &lt; 125 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb107-111"><a href="nonlinear-regression.html#cb107-111" aria-hidden="true" tabindex="-1"></a><span class="do">##              95) Price &gt; 125 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb107-112"><a href="nonlinear-regression.html#cb107-112" aria-hidden="true" tabindex="-1"></a><span class="do">##     3) ShelveLoc: Good 85  90.330 Yes ( 0.22353 0.77647 )  </span></span>
<span id="cb107-113"><a href="nonlinear-regression.html#cb107-113" aria-hidden="true" tabindex="-1"></a><span class="do">##       6) Price &lt; 135 68  49.260 Yes ( 0.11765 0.88235 )  </span></span>
<span id="cb107-114"><a href="nonlinear-regression.html#cb107-114" aria-hidden="true" tabindex="-1"></a><span class="do">##        12) US: No 17  22.070 Yes ( 0.35294 0.64706 )  </span></span>
<span id="cb107-115"><a href="nonlinear-regression.html#cb107-115" aria-hidden="true" tabindex="-1"></a><span class="do">##          24) Price &lt; 109 8   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb107-116"><a href="nonlinear-regression.html#cb107-116" aria-hidden="true" tabindex="-1"></a><span class="do">##          25) Price &gt; 109 9  11.460 No ( 0.66667 0.33333 ) *</span></span>
<span id="cb107-117"><a href="nonlinear-regression.html#cb107-117" aria-hidden="true" tabindex="-1"></a><span class="do">##        13) US: Yes 51  16.880 Yes ( 0.03922 0.96078 ) *</span></span>
<span id="cb107-118"><a href="nonlinear-regression.html#cb107-118" aria-hidden="true" tabindex="-1"></a><span class="do">##       7) Price &gt; 135 17  22.070 No ( 0.64706 0.35294 )  </span></span>
<span id="cb107-119"><a href="nonlinear-regression.html#cb107-119" aria-hidden="true" tabindex="-1"></a><span class="do">##        14) Income &lt; 46 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb107-120"><a href="nonlinear-regression.html#cb107-120" aria-hidden="true" tabindex="-1"></a><span class="do">##        15) Income &gt; 46 11  15.160 Yes ( 0.45455 0.54545 ) *</span></span>
<span id="cb107-121"><a href="nonlinear-regression.html#cb107-121" aria-hidden="true" tabindex="-1"></a>Теперь построим дерево на обучающей выборке и оценим ошибку на тестовой.</span>
<span id="cb107-122"><a href="nonlinear-regression.html#cb107-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-123"><a href="nonlinear-regression.html#cb107-123" aria-hidden="true" tabindex="-1"></a><span class="co"># ядро генератора случайных чисел</span></span>
<span id="cb107-124"><a href="nonlinear-regression.html#cb107-124" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb107-125"><a href="nonlinear-regression.html#cb107-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-126"><a href="nonlinear-regression.html#cb107-126" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb107-127"><a href="nonlinear-regression.html#cb107-127" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Carseats), <span class="dv">200</span>)</span>
<span id="cb107-128"><a href="nonlinear-regression.html#cb107-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-129"><a href="nonlinear-regression.html#cb107-129" aria-hidden="true" tabindex="-1"></a><span class="co"># тестовая выборка</span></span>
<span id="cb107-130"><a href="nonlinear-regression.html#cb107-130" aria-hidden="true" tabindex="-1"></a>Carseats.test <span class="ot">&lt;-</span> Carseats[<span class="sc">-</span>train,]</span>
<span id="cb107-131"><a href="nonlinear-regression.html#cb107-131" aria-hidden="true" tabindex="-1"></a>High.test <span class="ot">&lt;-</span> High[<span class="sc">-</span>train]</span>
<span id="cb107-132"><a href="nonlinear-regression.html#cb107-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-133"><a href="nonlinear-regression.html#cb107-133" aria-hidden="true" tabindex="-1"></a><span class="co"># строим дерево на обучающей выборке</span></span>
<span id="cb107-134"><a href="nonlinear-regression.html#cb107-134" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats, <span class="at">subset =</span> train)</span>
<span id="cb107-135"><a href="nonlinear-regression.html#cb107-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-136"><a href="nonlinear-regression.html#cb107-136" aria-hidden="true" tabindex="-1"></a><span class="co"># делаем прогноз</span></span>
<span id="cb107-137"><a href="nonlinear-regression.html#cb107-137" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb107-138"><a href="nonlinear-regression.html#cb107-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-139"><a href="nonlinear-regression.html#cb107-139" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb107-140"><a href="nonlinear-regression.html#cb107-140" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb107-141"><a href="nonlinear-regression.html#cb107-141" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb107-142"><a href="nonlinear-regression.html#cb107-142" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb107-143"><a href="nonlinear-regression.html#cb107-143" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb107-144"><a href="nonlinear-regression.html#cb107-144" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  27</span></span>
<span id="cb107-145"><a href="nonlinear-regression.html#cb107-145" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  57</span></span>
<span id="cb107-146"><a href="nonlinear-regression.html#cb107-146" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb107-147"><a href="nonlinear-regression.html#cb107-147" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb107-148"><a href="nonlinear-regression.html#cb107-148" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb107-149"><a href="nonlinear-regression.html#cb107-149" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.715</span></span>
<span id="cb107-150"><a href="nonlinear-regression.html#cb107-150" aria-hidden="true" tabindex="-1"></a>Обобщённая характеристика точности<span class="sc">:</span> доля верных прогнозов<span class="sc">:</span> <span class="dv">0</span>.<span class="fl">72.</span></span>
<span id="cb107-151"><a href="nonlinear-regression.html#cb107-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-152"><a href="nonlinear-regression.html#cb107-152" aria-hidden="true" tabindex="-1"></a>Теперь обрезаем дерево, используя в качестве критерия частоту ошибок классификации. Функция <span class="fu">cv.tree</span>() проводит кросс<span class="sc">-</span>валидацию для выбора лучшего дерева, аргумент prune.misclass означает, что мы минимизируем ошибку классификации.</span>
<span id="cb107-153"><a href="nonlinear-regression.html#cb107-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-154"><a href="nonlinear-regression.html#cb107-154" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb107-155"><a href="nonlinear-regression.html#cb107-155" aria-hidden="true" tabindex="-1"></a>cv.carseats <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.carseats, <span class="at">FUN =</span> prune.misclass)</span>
<span id="cb107-156"><a href="nonlinear-regression.html#cb107-156" aria-hidden="true" tabindex="-1"></a><span class="co"># имена элементов полученного объекта</span></span>
<span id="cb107-157"><a href="nonlinear-regression.html#cb107-157" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(cv.carseats)</span>
<span id="cb107-158"><a href="nonlinear-regression.html#cb107-158" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;size&quot;   &quot;dev&quot;    &quot;k&quot;      &quot;method&quot;</span></span>
<span id="cb107-159"><a href="nonlinear-regression.html#cb107-159" aria-hidden="true" tabindex="-1"></a><span class="co"># сам объект</span></span>
<span id="cb107-160"><a href="nonlinear-regression.html#cb107-160" aria-hidden="true" tabindex="-1"></a>cv.carseats</span>
<span id="cb107-161"><a href="nonlinear-regression.html#cb107-161" aria-hidden="true" tabindex="-1"></a><span class="do">## $size</span></span>
<span id="cb107-162"><a href="nonlinear-regression.html#cb107-162" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 19 17 14 13  9  7  3  2  1</span></span>
<span id="cb107-163"><a href="nonlinear-regression.html#cb107-163" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-164"><a href="nonlinear-regression.html#cb107-164" aria-hidden="true" tabindex="-1"></a><span class="do">## $dev</span></span>
<span id="cb107-165"><a href="nonlinear-regression.html#cb107-165" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 55 55 53 52 50 56 69 65 80</span></span>
<span id="cb107-166"><a href="nonlinear-regression.html#cb107-166" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-167"><a href="nonlinear-regression.html#cb107-167" aria-hidden="true" tabindex="-1"></a><span class="do">## $k</span></span>
<span id="cb107-168"><a href="nonlinear-regression.html#cb107-168" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]       -Inf  0.0000000  0.6666667  1.0000000  1.7500000  2.0000000</span></span>
<span id="cb107-169"><a href="nonlinear-regression.html#cb107-169" aria-hidden="true" tabindex="-1"></a><span class="do">## [7]  4.2500000  5.0000000 23.0000000</span></span>
<span id="cb107-170"><a href="nonlinear-regression.html#cb107-170" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-171"><a href="nonlinear-regression.html#cb107-171" aria-hidden="true" tabindex="-1"></a><span class="do">## $method</span></span>
<span id="cb107-172"><a href="nonlinear-regression.html#cb107-172" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;misclass&quot;</span></span>
<span id="cb107-173"><a href="nonlinear-regression.html#cb107-173" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-174"><a href="nonlinear-regression.html#cb107-174" aria-hidden="true" tabindex="-1"></a><span class="do">## attr(,&quot;class&quot;)</span></span>
<span id="cb107-175"><a href="nonlinear-regression.html#cb107-175" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;prune&quot;         &quot;tree.sequence&quot;</span></span>
<span id="cb107-176"><a href="nonlinear-regression.html#cb107-176" aria-hidden="true" tabindex="-1"></a><span class="co"># графики изменения параметров метода по ходу обрезки дерева ###################</span></span>
<span id="cb107-177"><a href="nonlinear-regression.html#cb107-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-178"><a href="nonlinear-regression.html#cb107-178" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. ошибка с кросс-валидацией в зависимости от числа узлов</span></span>
<span id="cb107-179"><a href="nonlinear-regression.html#cb107-179" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb107-180"><a href="nonlinear-regression.html#cb107-180" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>size, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb107-181"><a href="nonlinear-regression.html#cb107-181" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb107-182"><a href="nonlinear-regression.html#cb107-182" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Число узлов (size)&#39;</span>)</span>
<span id="cb107-183"><a href="nonlinear-regression.html#cb107-183" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb107-184"><a href="nonlinear-regression.html#cb107-184" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.carseats<span class="sc">$</span>size[cv.carseats<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.carseats<span class="sc">$</span>dev)]</span>
<span id="cb107-185"><a href="nonlinear-regression.html#cb107-185" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb107-186"><a href="nonlinear-regression.html#cb107-186" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb107-187"><a href="nonlinear-regression.html#cb107-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-188"><a href="nonlinear-regression.html#cb107-188" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. ошибка с кросс-валидацией в зависимости от штрафа на сложность</span></span>
<span id="cb107-189"><a href="nonlinear-regression.html#cb107-189" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>k, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb107-190"><a href="nonlinear-regression.html#cb107-190" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb107-191"><a href="nonlinear-regression.html#cb107-191" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Штраф за сложность (k)&#39;</span>)</span>
<span id="cb107-192"><a href="nonlinear-regression.html#cb107-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-193"><a href="nonlinear-regression.html#cb107-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-194"><a href="nonlinear-regression.html#cb107-194" aria-hidden="true" tabindex="-1"></a>Как видно на графике слева, минимум частоты ошибок достигается при числе узлов <span class="fl">9.</span> Оценим точность дерева с <span class="dv">9</span> узлами.</span>
<span id="cb107-195"><a href="nonlinear-regression.html#cb107-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-196"><a href="nonlinear-regression.html#cb107-196" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 9 узлами</span></span>
<span id="cb107-197"><a href="nonlinear-regression.html#cb107-197" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">9</span>)</span>
<span id="cb107-198"><a href="nonlinear-regression.html#cb107-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-199"><a href="nonlinear-regression.html#cb107-199" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb107-200"><a href="nonlinear-regression.html#cb107-200" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb107-201"><a href="nonlinear-regression.html#cb107-201" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb107-202"><a href="nonlinear-regression.html#cb107-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-203"><a href="nonlinear-regression.html#cb107-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-204"><a href="nonlinear-regression.html#cb107-204" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb107-205"><a href="nonlinear-regression.html#cb107-205" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb107-206"><a href="nonlinear-regression.html#cb107-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-207"><a href="nonlinear-regression.html#cb107-207" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb107-208"><a href="nonlinear-regression.html#cb107-208" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb107-209"><a href="nonlinear-regression.html#cb107-209" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb107-210"><a href="nonlinear-regression.html#cb107-210" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb107-211"><a href="nonlinear-regression.html#cb107-211" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb107-212"><a href="nonlinear-regression.html#cb107-212" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  94  24</span></span>
<span id="cb107-213"><a href="nonlinear-regression.html#cb107-213" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 22  60</span></span>
<span id="cb107-214"><a href="nonlinear-regression.html#cb107-214" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb107-215"><a href="nonlinear-regression.html#cb107-215" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb107-216"><a href="nonlinear-regression.html#cb107-216" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb107-217"><a href="nonlinear-regression.html#cb107-217" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.77</span></span>
<span id="cb107-218"><a href="nonlinear-regression.html#cb107-218" aria-hidden="true" tabindex="-1"></a>Точность этой модели чуть выше точности исходного дерева и составляет <span class="dv">0</span>.<span class="fl">77.</span> Увеличив количество узлов, получим более глубокое дерево, но менее точное.</span>
<span id="cb107-219"><a href="nonlinear-regression.html#cb107-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-220"><a href="nonlinear-regression.html#cb107-220" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 13 узлами</span></span>
<span id="cb107-221"><a href="nonlinear-regression.html#cb107-221" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">15</span>)</span>
<span id="cb107-222"><a href="nonlinear-regression.html#cb107-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-223"><a href="nonlinear-regression.html#cb107-223" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb107-224"><a href="nonlinear-regression.html#cb107-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb107-225"><a href="nonlinear-regression.html#cb107-225" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb107-226"><a href="nonlinear-regression.html#cb107-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-227"><a href="nonlinear-regression.html#cb107-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-228"><a href="nonlinear-regression.html#cb107-228" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb107-229"><a href="nonlinear-regression.html#cb107-229" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb107-230"><a href="nonlinear-regression.html#cb107-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-231"><a href="nonlinear-regression.html#cb107-231" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb107-232"><a href="nonlinear-regression.html#cb107-232" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb107-233"><a href="nonlinear-regression.html#cb107-233" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb107-234"><a href="nonlinear-regression.html#cb107-234" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb107-235"><a href="nonlinear-regression.html#cb107-235" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb107-236"><a href="nonlinear-regression.html#cb107-236" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  22</span></span>
<span id="cb107-237"><a href="nonlinear-regression.html#cb107-237" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  62</span></span>
<span id="cb107-238"><a href="nonlinear-regression.html#cb107-238" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb107-239"><a href="nonlinear-regression.html#cb107-239" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb107-240"><a href="nonlinear-regression.html#cb107-240" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb107-241"><a href="nonlinear-regression.html#cb107-241" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.74</span></span>
<span id="cb107-242"><a href="nonlinear-regression.html#cb107-242" aria-hidden="true" tabindex="-1"></a><span class="co"># сбрасываем графические параметры</span></span>
<span id="cb107-243"><a href="nonlinear-regression.html#cb107-243" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb107-244"><a href="nonlinear-regression.html#cb107-244" aria-hidden="true" tabindex="-1"></a>Регрессионные деревья</span>
<span id="cb107-245"><a href="nonlinear-regression.html#cb107-245" aria-hidden="true" tabindex="-1"></a>Воспользуемся набором данных Boston.</span>
<span id="cb107-246"><a href="nonlinear-regression.html#cb107-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-247"><a href="nonlinear-regression.html#cb107-247" aria-hidden="true" tabindex="-1"></a>?Boston</span>
<span id="cb107-248"><a href="nonlinear-regression.html#cb107-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-249"><a href="nonlinear-regression.html#cb107-249" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb107-250"><a href="nonlinear-regression.html#cb107-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb107-251"><a href="nonlinear-regression.html#cb107-251" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Boston), <span class="fu">nrow</span>(Boston)<span class="sc">/</span><span class="dv">2</span>) <span class="co"># обучающая выборка -- 50%</span></span>
<span id="cb107-252"><a href="nonlinear-regression.html#cb107-252" aria-hidden="true" tabindex="-1"></a>Построим дерево регрессии для зависимой переменной medv<span class="sc">:</span> медианная стоимости домов, в которых живут собственники (тыс. долл.).</span>
<span id="cb107-253"><a href="nonlinear-regression.html#cb107-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-254"><a href="nonlinear-regression.html#cb107-254" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb107-255"><a href="nonlinear-regression.html#cb107-255" aria-hidden="true" tabindex="-1"></a>tree.boston <span class="ot">&lt;-</span> <span class="fu">tree</span>(medv <span class="sc">~</span> ., Boston, <span class="at">subset =</span> train)</span>
<span id="cb107-256"><a href="nonlinear-regression.html#cb107-256" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.boston)</span>
<span id="cb107-257"><a href="nonlinear-regression.html#cb107-257" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-258"><a href="nonlinear-regression.html#cb107-258" aria-hidden="true" tabindex="-1"></a><span class="do">## Regression tree:</span></span>
<span id="cb107-259"><a href="nonlinear-regression.html#cb107-259" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = medv ~ ., data = Boston, subset = train)</span></span>
<span id="cb107-260"><a href="nonlinear-regression.html#cb107-260" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb107-261"><a href="nonlinear-regression.html#cb107-261" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;lstat&quot; &quot;rm&quot;    &quot;dis&quot;  </span></span>
<span id="cb107-262"><a href="nonlinear-regression.html#cb107-262" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  8 </span></span>
<span id="cb107-263"><a href="nonlinear-regression.html#cb107-263" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  12.65 = 3099 / 245 </span></span>
<span id="cb107-264"><a href="nonlinear-regression.html#cb107-264" aria-hidden="true" tabindex="-1"></a><span class="do">## Distribution of residuals:</span></span>
<span id="cb107-265"><a href="nonlinear-regression.html#cb107-265" aria-hidden="true" tabindex="-1"></a><span class="do">##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. </span></span>
<span id="cb107-266"><a href="nonlinear-regression.html#cb107-266" aria-hidden="true" tabindex="-1"></a><span class="do">## -14.10000  -2.04200  -0.05357   0.00000   1.96000  12.60000</span></span>
<span id="cb107-267"><a href="nonlinear-regression.html#cb107-267" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb107-268"><a href="nonlinear-regression.html#cb107-268" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.boston)</span>
<span id="cb107-269"><a href="nonlinear-regression.html#cb107-269" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb107-270"><a href="nonlinear-regression.html#cb107-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-271"><a href="nonlinear-regression.html#cb107-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-272"><a href="nonlinear-regression.html#cb107-272" aria-hidden="true" tabindex="-1"></a>Снова сделаем обрезку дерева в целях улучшения качества прогноза.</span>
<span id="cb107-273"><a href="nonlinear-regression.html#cb107-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-274"><a href="nonlinear-regression.html#cb107-274" aria-hidden="true" tabindex="-1"></a>cv.boston <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.boston)</span>
<span id="cb107-275"><a href="nonlinear-regression.html#cb107-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-276"><a href="nonlinear-regression.html#cb107-276" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb107-277"><a href="nonlinear-regression.html#cb107-277" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.boston<span class="sc">$</span>size, cv.boston<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&#39;b&#39;</span>)</span>
<span id="cb107-278"><a href="nonlinear-regression.html#cb107-278" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.boston<span class="sc">$</span>size[cv.boston<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.boston<span class="sc">$</span>dev)]</span>
<span id="cb107-279"><a href="nonlinear-regression.html#cb107-279" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb107-280"><a href="nonlinear-regression.html#cb107-280" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb107-281"><a href="nonlinear-regression.html#cb107-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-282"><a href="nonlinear-regression.html#cb107-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-283"><a href="nonlinear-regression.html#cb107-283" aria-hidden="true" tabindex="-1"></a>В данном случаем минимум ошибки соответствует самому сложному дереву, с <span class="dv">8</span> узлами. Покажем, как при желании можно обрезать дерево до <span class="dv">7</span> узлов (ошибка ненамного выше, чем минимальная).</span>
<span id="cb107-284"><a href="nonlinear-regression.html#cb107-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-285"><a href="nonlinear-regression.html#cb107-285" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 7 узлами</span></span>
<span id="cb107-286"><a href="nonlinear-regression.html#cb107-286" aria-hidden="true" tabindex="-1"></a>prune.boston <span class="ot">=</span> <span class="fu">prune.tree</span>(tree.boston, <span class="at">best =</span> <span class="dv">7</span>)</span>
<span id="cb107-287"><a href="nonlinear-regression.html#cb107-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-288"><a href="nonlinear-regression.html#cb107-288" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb107-289"><a href="nonlinear-regression.html#cb107-289" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.boston)</span>
<span id="cb107-290"><a href="nonlinear-regression.html#cb107-290" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb107-291"><a href="nonlinear-regression.html#cb107-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-292"><a href="nonlinear-regression.html#cb107-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-293"><a href="nonlinear-regression.html#cb107-293" aria-hidden="true" tabindex="-1"></a>Прогноз сделаем по необрезанному дереву, т.к. там ошибка, оцененная по методу перекрёстной проверки, минимальна.</span>
<span id="cb107-294"><a href="nonlinear-regression.html#cb107-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-295"><a href="nonlinear-regression.html#cb107-295" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по лучшей модели (8 узлов)</span></span>
<span id="cb107-296"><a href="nonlinear-regression.html#cb107-296" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb107-297"><a href="nonlinear-regression.html#cb107-297" aria-hidden="true" tabindex="-1"></a>boston.test <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>train, <span class="st">&quot;medv&quot;</span>]</span>
<span id="cb107-298"><a href="nonlinear-regression.html#cb107-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-299"><a href="nonlinear-regression.html#cb107-299" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb107-300"><a href="nonlinear-regression.html#cb107-300" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat, boston.test)</span>
<span id="cb107-301"><a href="nonlinear-regression.html#cb107-301" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb107-302"><a href="nonlinear-regression.html#cb107-302" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb107-303"><a href="nonlinear-regression.html#cb107-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-304"><a href="nonlinear-regression.html#cb107-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-305"><a href="nonlinear-regression.html#cb107-305" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb107-306"><a href="nonlinear-regression.html#cb107-306" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb107-307"><a href="nonlinear-regression.html#cb107-307" aria-hidden="true" tabindex="-1"></a>MSE на тестовой выборке равна <span class="fl">25.05</span> (тыс.долл.).</span>
<span id="cb107-308"><a href="nonlinear-regression.html#cb107-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-309"><a href="nonlinear-regression.html#cb107-309" aria-hidden="true" tabindex="-1"></a>Бэггинг и метод случайного леса</span>
<span id="cb107-310"><a href="nonlinear-regression.html#cb107-310" aria-hidden="true" tabindex="-1"></a>Рассмотрим более сложные методы улучшения качества дерева. Бэггинг – частный случай случайного леса с m<span class="ot">=</span>p, поэтому и то, и другое можно построить функцией <span class="fu">randomForest</span>().</span>
<span id="cb107-311"><a href="nonlinear-regression.html#cb107-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-312"><a href="nonlinear-regression.html#cb107-312" aria-hidden="true" tabindex="-1"></a>Для начала используем бэггинг, причём возьмём все <span class="dv">13</span> предикторов на каждом шаге (аргумент mtry).</span>
<span id="cb107-313"><a href="nonlinear-regression.html#cb107-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-314"><a href="nonlinear-regression.html#cb107-314" aria-hidden="true" tabindex="-1"></a><span class="co"># бэггинг с 13 предикторами</span></span>
<span id="cb107-315"><a href="nonlinear-regression.html#cb107-315" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb107-316"><a href="nonlinear-regression.html#cb107-316" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train, </span>
<span id="cb107-317"><a href="nonlinear-regression.html#cb107-317" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb107-318"><a href="nonlinear-regression.html#cb107-318" aria-hidden="true" tabindex="-1"></a>bag.boston</span>
<span id="cb107-319"><a href="nonlinear-regression.html#cb107-319" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-320"><a href="nonlinear-regression.html#cb107-320" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb107-321"><a href="nonlinear-regression.html#cb107-321" aria-hidden="true" tabindex="-1"></a><span class="do">##  randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE,      subset = train) </span></span>
<span id="cb107-322"><a href="nonlinear-regression.html#cb107-322" aria-hidden="true" tabindex="-1"></a><span class="do">##                Type of random forest: regression</span></span>
<span id="cb107-323"><a href="nonlinear-regression.html#cb107-323" aria-hidden="true" tabindex="-1"></a><span class="do">##                      Number of trees: 500</span></span>
<span id="cb107-324"><a href="nonlinear-regression.html#cb107-324" aria-hidden="true" tabindex="-1"></a><span class="do">## No. of variables tried at each split: 13</span></span>
<span id="cb107-325"><a href="nonlinear-regression.html#cb107-325" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb107-326"><a href="nonlinear-regression.html#cb107-326" aria-hidden="true" tabindex="-1"></a><span class="do">##           Mean of squared residuals: 11.15723</span></span>
<span id="cb107-327"><a href="nonlinear-regression.html#cb107-327" aria-hidden="true" tabindex="-1"></a><span class="do">##                     % Var explained: 86.49</span></span>
<span id="cb107-328"><a href="nonlinear-regression.html#cb107-328" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb107-329"><a href="nonlinear-regression.html#cb107-329" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">=</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb107-330"><a href="nonlinear-regression.html#cb107-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-331"><a href="nonlinear-regression.html#cb107-331" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb107-332"><a href="nonlinear-regression.html#cb107-332" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat.bag, boston.test)</span>
<span id="cb107-333"><a href="nonlinear-regression.html#cb107-333" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb107-334"><a href="nonlinear-regression.html#cb107-334" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb107-335"><a href="nonlinear-regression.html#cb107-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-336"><a href="nonlinear-regression.html#cb107-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-337"><a href="nonlinear-regression.html#cb107-337" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb107-338"><a href="nonlinear-regression.html#cb107-338" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb107-339"><a href="nonlinear-regression.html#cb107-339" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb107-340"><a href="nonlinear-regression.html#cb107-340" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.50808</span></span>
<span id="cb107-341"><a href="nonlinear-regression.html#cb107-341" aria-hidden="true" tabindex="-1"></a>Ошибка на тестовой выборке равна <span class="dv">13</span>.<span class="fl">51.</span></span>
<span id="cb107-342"><a href="nonlinear-regression.html#cb107-342" aria-hidden="true" tabindex="-1"></a>Можно изменить число деревьев с помощью аргумента ntree.</span>
<span id="cb107-343"><a href="nonlinear-regression.html#cb107-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-344"><a href="nonlinear-regression.html#cb107-344" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb107-345"><a href="nonlinear-regression.html#cb107-345" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">ntree =</span> <span class="dv">25</span>)</span>
<span id="cb107-346"><a href="nonlinear-regression.html#cb107-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-347"><a href="nonlinear-regression.html#cb107-347" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb107-348"><a href="nonlinear-regression.html#cb107-348" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">&lt;-</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb107-349"><a href="nonlinear-regression.html#cb107-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-350"><a href="nonlinear-regression.html#cb107-350" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb107-351"><a href="nonlinear-regression.html#cb107-351" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb107-352"><a href="nonlinear-regression.html#cb107-352" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb107-353"><a href="nonlinear-regression.html#cb107-353" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.94835</span></span>
<span id="cb107-354"><a href="nonlinear-regression.html#cb107-354" aria-hidden="true" tabindex="-1"></a>Но, как видно, это только ухудшает прогноз.</span>
<span id="cb107-355"><a href="nonlinear-regression.html#cb107-355" aria-hidden="true" tabindex="-1"></a>Теперь попробуем вырастить случайный лес. Берём <span class="dv">6</span> предикторов на каждом шаге.</span>
<span id="cb107-356"><a href="nonlinear-regression.html#cb107-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-357"><a href="nonlinear-regression.html#cb107-357" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb107-358"><a href="nonlinear-regression.html#cb107-358" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb107-359"><a href="nonlinear-regression.html#cb107-359" aria-hidden="true" tabindex="-1"></a>rf.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb107-360"><a href="nonlinear-regression.html#cb107-360" aria-hidden="true" tabindex="-1"></a>                          <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb107-361"><a href="nonlinear-regression.html#cb107-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-362"><a href="nonlinear-regression.html#cb107-362" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb107-363"><a href="nonlinear-regression.html#cb107-363" aria-hidden="true" tabindex="-1"></a>yhat.rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb107-364"><a href="nonlinear-regression.html#cb107-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-365"><a href="nonlinear-regression.html#cb107-365" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb107-366"><a href="nonlinear-regression.html#cb107-366" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.rf <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb107-367"><a href="nonlinear-regression.html#cb107-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-368"><a href="nonlinear-regression.html#cb107-368" aria-hidden="true" tabindex="-1"></a><span class="co"># важность предикторов</span></span>
<span id="cb107-369"><a href="nonlinear-regression.html#cb107-369" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf.boston)  <span class="co"># оценки </span></span>
<span id="cb107-370"><a href="nonlinear-regression.html#cb107-370" aria-hidden="true" tabindex="-1"></a><span class="do">##           %IncMSE IncNodePurity</span></span>
<span id="cb107-371"><a href="nonlinear-regression.html#cb107-371" aria-hidden="true" tabindex="-1"></a><span class="do">## crim    12.132320     986.50338</span></span>
<span id="cb107-372"><a href="nonlinear-regression.html#cb107-372" aria-hidden="true" tabindex="-1"></a><span class="do">## zn       1.955579      57.96945</span></span>
<span id="cb107-373"><a href="nonlinear-regression.html#cb107-373" aria-hidden="true" tabindex="-1"></a><span class="do">## indus    9.069302     882.78261</span></span>
<span id="cb107-374"><a href="nonlinear-regression.html#cb107-374" aria-hidden="true" tabindex="-1"></a><span class="do">## chas     2.210835      45.22941</span></span>
<span id="cb107-375"><a href="nonlinear-regression.html#cb107-375" aria-hidden="true" tabindex="-1"></a><span class="do">## nox     11.104823    1044.33776</span></span>
<span id="cb107-376"><a href="nonlinear-regression.html#cb107-376" aria-hidden="true" tabindex="-1"></a><span class="do">## rm      31.784033    6359.31971</span></span>
<span id="cb107-377"><a href="nonlinear-regression.html#cb107-377" aria-hidden="true" tabindex="-1"></a><span class="do">## age     10.962684     516.82969</span></span>
<span id="cb107-378"><a href="nonlinear-regression.html#cb107-378" aria-hidden="true" tabindex="-1"></a><span class="do">## dis     15.015236    1224.11605</span></span>
<span id="cb107-379"><a href="nonlinear-regression.html#cb107-379" aria-hidden="true" tabindex="-1"></a><span class="do">## rad      4.118011      95.94586</span></span>
<span id="cb107-380"><a href="nonlinear-regression.html#cb107-380" aria-hidden="true" tabindex="-1"></a><span class="do">## tax      8.587932     502.96719</span></span>
<span id="cb107-381"><a href="nonlinear-regression.html#cb107-381" aria-hidden="true" tabindex="-1"></a><span class="do">## ptratio 12.503896     830.77523</span></span>
<span id="cb107-382"><a href="nonlinear-regression.html#cb107-382" aria-hidden="true" tabindex="-1"></a><span class="do">## black    6.702609     341.30361</span></span>
<span id="cb107-383"><a href="nonlinear-regression.html#cb107-383" aria-hidden="true" tabindex="-1"></a><span class="do">## lstat   30.695224    7505.73936</span></span>
<span id="cb107-384"><a href="nonlinear-regression.html#cb107-384" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.boston)  <span class="co"># графики</span></span>
<span id="cb107-385"><a href="nonlinear-regression.html#cb107-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-386"><a href="nonlinear-regression.html#cb107-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-387"><a href="nonlinear-regression.html#cb107-387" aria-hidden="true" tabindex="-1"></a>Ошибка по модели случайного леса равна <span class="fl">11.66</span>, что ниже, чем для бэггинга.</span>
<span id="cb107-388"><a href="nonlinear-regression.html#cb107-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-389"><a href="nonlinear-regression.html#cb107-389" aria-hidden="true" tabindex="-1"></a>Бустинг</span>
<span id="cb107-390"><a href="nonlinear-regression.html#cb107-390" aria-hidden="true" tabindex="-1"></a>Построим <span class="dv">5000</span> регрессионных деревьев с глубиной <span class="fl">4.</span></span>
<span id="cb107-391"><a href="nonlinear-regression.html#cb107-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-392"><a href="nonlinear-regression.html#cb107-392" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb107-393"><a href="nonlinear-regression.html#cb107-393" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb107-394"><a href="nonlinear-regression.html#cb107-394" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>)</span>
<span id="cb107-395"><a href="nonlinear-regression.html#cb107-395" aria-hidden="true" tabindex="-1"></a><span class="co"># график и таблица относительной важности переменных</span></span>
<span id="cb107-396"><a href="nonlinear-regression.html#cb107-396" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boost.boston)</span>
<span id="cb107-397"><a href="nonlinear-regression.html#cb107-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-398"><a href="nonlinear-regression.html#cb107-398" aria-hidden="true" tabindex="-1"></a><span class="co"># графики частной зависимости для двух наиболее важных предикторов</span></span>
<span id="cb107-399"><a href="nonlinear-regression.html#cb107-399" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb107-400"><a href="nonlinear-regression.html#cb107-400" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;rm&quot;</span>)</span>
<span id="cb107-401"><a href="nonlinear-regression.html#cb107-401" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb107-402"><a href="nonlinear-regression.html#cb107-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-403"><a href="nonlinear-regression.html#cb107-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-404"><a href="nonlinear-regression.html#cb107-404" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb107-405"><a href="nonlinear-regression.html#cb107-405" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb107-406"><a href="nonlinear-regression.html#cb107-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-407"><a href="nonlinear-regression.html#cb107-407" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb107-408"><a href="nonlinear-regression.html#cb107-408" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb107-409"><a href="nonlinear-regression.html#cb107-409" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb107-410"><a href="nonlinear-regression.html#cb107-410" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.84434</span></span>
<span id="cb107-411"><a href="nonlinear-regression.html#cb107-411" aria-hidden="true" tabindex="-1"></a>Настройку бустинга можно делать с помощью гиперпараметра λ (аргумент shrinkage). Установим его равным <span class="dv">0</span>.<span class="fl">2.</span></span>
<span id="cb107-412"><a href="nonlinear-regression.html#cb107-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-413"><a href="nonlinear-regression.html#cb107-413" aria-hidden="true" tabindex="-1"></a><span class="co"># меняем значение гиперпараметра (lambda) на 0.2 -- аргумент shrinkage</span></span>
<span id="cb107-414"><a href="nonlinear-regression.html#cb107-414" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb107-415"><a href="nonlinear-regression.html#cb107-415" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>, </span>
<span id="cb107-416"><a href="nonlinear-regression.html#cb107-416" aria-hidden="true" tabindex="-1"></a>                    <span class="at">shrinkage =</span> <span class="fl">0.2</span>, <span class="at">verbose =</span> F)</span>
<span id="cb107-417"><a href="nonlinear-regression.html#cb107-417" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb107-418"><a href="nonlinear-regression.html#cb107-418" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb107-419"><a href="nonlinear-regression.html#cb107-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-420"><a href="nonlinear-regression.html#cb107-420" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE а тестовой</span></span>
<span id="cb107-421"><a href="nonlinear-regression.html#cb107-421" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb107-422"><a href="nonlinear-regression.html#cb107-422" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb107-423"><a href="nonlinear-regression.html#cb107-423" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.51109</span></span>
<span id="cb107-424"><a href="nonlinear-regression.html#cb107-424" aria-hidden="true" tabindex="-1"></a>Таким образом, изменив гиперпараметр, мы ещё немного снизили ошибку прогноза.</span></code></pre></div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="next-part-3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="spline-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/35_nonlinear_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
