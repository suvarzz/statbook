<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 21 Nonlinear regression | R statistics</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 21 Nonlinear regression | R statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 21 Nonlinear regression | R statistics" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Mark Goldberg" />


<meta name="date" content="2021-04-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="next-part-3.html"/>
<link rel="next" href="spline-model.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html"><i class="fa fa-check"></i><b>2</b> Statistics R functions reference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-r-functions-reference.html"><a href="statistics-r-functions-reference.html#data-inspection"><i class="fa fa-check"></i><b>2.1</b> Data inspection</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis-of-the-distribution.html"><a href="analysis-of-the-distribution.html"><i class="fa fa-check"></i><b>3</b> Analysis of the distribution</a>
<ul>
<li class="chapter" data-level="3.1" data-path="analysis-of-the-distribution.html"><a href="analysis-of-the-distribution.html#t-test"><i class="fa fa-check"></i><b>3.1</b> t-Test</a></li>
<li class="chapter" data-level="3.2" data-path="analysis-of-the-distribution.html"><a href="analysis-of-the-distribution.html#anova"><i class="fa fa-check"></i><b>3.2</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>4</b> Basic Statistics</a>
<ul>
<li class="chapter" data-level="4.1" data-path="basic-statistics.html"><a href="basic-statistics.html#outliers"><i class="fa fa-check"></i><b>4.1</b> Outliers</a></li>
<li class="chapter" data-level="4.2" data-path="basic-statistics.html"><a href="basic-statistics.html#normality"><i class="fa fa-check"></i><b>4.2</b> Normality</a></li>
<li class="chapter" data-level="4.3" data-path="basic-statistics.html"><a href="basic-statistics.html#normal-distribution"><i class="fa fa-check"></i><b>4.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="4.4" data-path="basic-statistics.html"><a href="basic-statistics.html#confidence-interval"><i class="fa fa-check"></i><b>4.4</b> Confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="primary-analysis.html"><a href="primary-analysis.html"><i class="fa fa-check"></i><b>5</b> Primary analysis</a></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-practice"><i class="fa fa-check"></i><b>6.1</b> Hypothesis test (Practice)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="t-procedures.html"><a href="t-procedures.html"><i class="fa fa-check"></i><b>7</b> t-Procedures</a>
<ul>
<li class="chapter" data-level="7.1" data-path="t-procedures.html"><a href="t-procedures.html#t-test-and-normal-distribution"><i class="fa fa-check"></i><b>7.1</b> t-test and normal distribution</a></li>
<li class="chapter" data-level="7.2" data-path="t-procedures.html"><a href="t-procedures.html#one-sample-t-test"><i class="fa fa-check"></i><b>7.2</b> One-sample t-test</a></li>
<li class="chapter" data-level="7.3" data-path="t-procedures.html"><a href="t-procedures.html#practical-example-t-test-in-r"><i class="fa fa-check"></i><b>7.3</b> Practical example: t-test in R</a></li>
<li class="chapter" data-level="7.4" data-path="t-procedures.html"><a href="t-procedures.html#two-samples-t-test"><i class="fa fa-check"></i><b>7.4</b> Two samples t-test</a></li>
<li class="chapter" data-level="7.5" data-path="t-procedures.html"><a href="t-procedures.html#compare-students-t-and-normal-distributions"><i class="fa fa-check"></i><b>7.5</b> Compare Student’s t and normal distributions</a></li>
<li class="chapter" data-level="7.6" data-path="t-procedures.html"><a href="t-procedures.html#non-parametric-tests"><i class="fa fa-check"></i><b>7.6</b> Non-parametric tests</a></li>
<li class="chapter" data-level="7.7" data-path="t-procedures.html"><a href="t-procedures.html#mann-whitney-u-rank-sum-test"><i class="fa fa-check"></i><b>7.7</b> Mann-Whitney U Rank Sum Test</a></li>
<li class="chapter" data-level="7.8" data-path="t-procedures.html"><a href="t-procedures.html#wilcoxon-test"><i class="fa fa-check"></i><b>7.8</b> Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html"><i class="fa fa-check"></i><b>8</b> Tests for categorical variables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="tests-for-categorical-variables.html"><a href="tests-for-categorical-variables.html#chi-squared-tests"><i class="fa fa-check"></i><b>8.1</b> Chi-squared tests</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>9</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="9.1" data-path="multiple-testing.html"><a href="multiple-testing.html#the-bonferroni-correction"><i class="fa fa-check"></i><b>9.1</b> The Bonferroni correction</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sources.html"><a href="sources.html"><i class="fa fa-check"></i><b>10</b> Sources</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sources.html"><a href="sources.html#t-test-1"><i class="fa fa-check"></i><b>10.1</b> t-test</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="sources.html"><a href="sources.html#two-tailed-test"><i class="fa fa-check"></i><b>10.1.1</b> Two-tailed test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>11</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#one-way-anova"><i class="fa fa-check"></i><b>11.1</b> One-way ANOVA</a></li>
<li class="chapter" data-level="11.2" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html#sources-1"><i class="fa fa-check"></i><b>11.2</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>12</b> Correlation</a></li>
<li class="chapter" data-level="13" data-path="t-test-anova-difference.html"><a href="t-test-anova-difference.html"><i class="fa fa-check"></i><b>13</b> t-test ANOVA difference</a></li>
<li class="chapter" data-level="14" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>14</b> Clustering</a>
<ul>
<li class="chapter" data-level="14.1" data-path="clustering.html"><a href="clustering.html#next-part"><i class="fa fa-check"></i><b>14.1</b> Next part</a></li>
<li class="chapter" data-level="14.2" data-path="clustering.html"><a href="clustering.html#example"><i class="fa fa-check"></i><b>14.2</b> Example</a></li>
<li class="chapter" data-level="14.3" data-path="clustering.html"><a href="clustering.html#next-part-1"><i class="fa fa-check"></i><b>14.3</b> NEXT PART</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="support-vector-machine.html"><a href="support-vector-machine.html"><i class="fa fa-check"></i><b>15</b> Support Vector Machine</a></li>
<li class="chapter" data-level="16" data-path="methods-and-algorithms-of-machine-learning.html"><a href="methods-and-algorithms-of-machine-learning.html"><i class="fa fa-check"></i><b>16</b> Methods and algorithms of machine learning</a></li>
<li class="chapter" data-level="17" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html"><i class="fa fa-check"></i><b>17</b> Machine Learning Functions Reference</a>
<ul>
<li class="chapter" data-level="17.1" data-path="machine-learning-functions-reference.html"><a href="machine-learning-functions-reference.html#linear-regression"><i class="fa fa-check"></i><b>17.1</b> Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="split-data-into-train-and-test-subsets.html"><a href="split-data-into-train-and-test-subsets.html"><i class="fa fa-check"></i><b>18</b> Split data into train and test subsets</a></li>
<li class="chapter" data-level="19" data-path="linear-regression-1.html"><a href="linear-regression-1.html"><i class="fa fa-check"></i><b>19</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="19.1" data-path="linear-regression-1.html"><a href="linear-regression-1.html#generate-random-data-set-a-linear-model"><i class="fa fa-check"></i><b>19.1</b> Generate Random Data Set a Linear Model</a></li>
<li class="chapter" data-level="19.2" data-path="linear-regression-1.html"><a href="linear-regression-1.html#linear-regression---theory"><i class="fa fa-check"></i><b>19.2</b> Linear regression - theory</a></li>
<li class="chapter" data-level="19.3" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-example"><i class="fa fa-check"></i><b>19.3</b> Practical example</a></li>
<li class="chapter" data-level="19.4" data-path="linear-regression-1.html"><a href="linear-regression-1.html#example-of-linear-regression"><i class="fa fa-check"></i><b>19.4</b> Example of linear regression</a></li>
<li class="chapter" data-level="19.5" data-path="linear-regression-1.html"><a href="linear-regression-1.html#standard-error-of-train-data"><i class="fa fa-check"></i><b>19.5</b> Standard error of train data</a></li>
<li class="chapter" data-level="19.6" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression"><i class="fa fa-check"></i><b>19.6</b> Practical examples for linear model regression</a></li>
<li class="chapter" data-level="19.7" data-path="linear-regression-1.html"><a href="linear-regression-1.html#practical-examples-for-linear-model-regression-1"><i class="fa fa-check"></i><b>19.7</b> Practical examples for linear model regression</a></li>
<li class="chapter" data-level="19.8" data-path="linear-regression-1.html"><a href="linear-regression-1.html#next-part-2"><i class="fa fa-check"></i><b>19.8</b> NEXT part</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="next-part-3.html"><a href="next-part-3.html"><i class="fa fa-check"></i><b>20</b> NEXT part</a>
<ul>
<li class="chapter" data-level="20.1" data-path="next-part-3.html"><a href="next-part-3.html#next-part-4"><i class="fa fa-check"></i><b>20.1</b> NEXT part</a></li>
<li class="chapter" data-level="20.2" data-path="next-part-3.html"><a href="next-part-3.html#next-part-5"><i class="fa fa-check"></i><b>20.2</b> NEXT Part</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="nonlinear-regression.html"><a href="nonlinear-regression.html"><i class="fa fa-check"></i><b>21</b> Nonlinear regression</a></li>
<li class="chapter" data-level="22" data-path="spline-model.html"><a href="spline-model.html"><i class="fa fa-check"></i><b>22</b> Spline model</a>
<ul>
<li class="chapter" data-level="22.1" data-path="spline-model.html"><a href="spline-model.html#generate-dataset-from-a-given-function"><i class="fa fa-check"></i><b>22.1</b> Generate dataset from a given function</a></li>
<li class="chapter" data-level="22.2" data-path="spline-model.html"><a href="spline-model.html#split-data-for-train-and-test"><i class="fa fa-check"></i><b>22.2</b> Split data for train and test</a></li>
<li class="chapter" data-level="22.3" data-path="spline-model.html"><a href="spline-model.html#diagram-of-the-given-function-and-generated-datasets"><i class="fa fa-check"></i><b>22.3</b> Diagram of the given function and generated datasets</a></li>
<li class="chapter" data-level="22.4" data-path="spline-model.html"><a href="spline-model.html#build-a-model-using-splines"><i class="fa fa-check"></i><b>22.4</b> Build a model using splines</a></li>
<li class="chapter" data-level="22.5" data-path="spline-model.html"><a href="spline-model.html#diagram-of-mse-for-train-and-test-data"><i class="fa fa-check"></i><b>22.5</b> Diagram of MSE for train and test data</a></li>
<li class="chapter" data-level="22.6" data-path="spline-model.html"><a href="spline-model.html#build-optimal-model-and-plot-for-the-model"><i class="fa fa-check"></i><b>22.6</b> Build optimal model and plot for the model</a></li>
<li class="chapter" data-level="22.7" data-path="spline-model.html"><a href="spline-model.html#bibliograpy"><i class="fa fa-check"></i><b>22.7</b> Bibliograpy</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>23</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="23.1" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-6"><i class="fa fa-check"></i><b>23.1</b> Next part</a></li>
<li class="chapter" data-level="23.2" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-7"><i class="fa fa-check"></i><b>23.2</b> NEXT Part</a></li>
<li class="chapter" data-level="23.3" data-path="logistic-regression.html"><a href="logistic-regression.html#next-part-8"><i class="fa fa-check"></i><b>23.3</b> NExt part</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>24</b> Multiple linear regression</a></li>
<li class="chapter" data-level="25" data-path="simple-markov-process.html"><a href="simple-markov-process.html"><i class="fa fa-check"></i><b>25</b> Simple Markov process</a>
<ul>
<li class="chapter" data-level="25.0.1" data-path="simple-markov-process.html"><a href="simple-markov-process.html#sources-2"><i class="fa fa-check"></i><b>25.0.1</b> Sources</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>26</b> Naive Bayes</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonlinear-regression" class="section level1" number="21">
<h1><span class="header-section-number">Chapter 21</span> Nonlinear regression</h1>
<p>Nonlinear regression is a form of regression analysis in which observational data are modeled by a function which is a nonlinear combination of the model parameters and <strong>depends on one or more independent variables</strong>.<br />
Some nonlinear data sets can be transformed to a linear model.<br />
Sone can not be transformed. For such modeling methods of Numerical analysis should be applied such as Newton’s method, Gauss-Newton method and Levenberg–Marquardt method.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="nonlinear-regression.html#cb99-1" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb99-2"><a href="nonlinear-regression.html#cb99-2" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">7</span></span>
<span id="cb99-3"><a href="nonlinear-regression.html#cb99-3" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb99-4"><a href="nonlinear-regression.html#cb99-4" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb99-5"><a href="nonlinear-regression.html#cb99-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-6"><a href="nonlinear-regression.html#cb99-6" aria-hidden="true" tabindex="-1"></a>    оценивать полиномиальную регрессию;</span>
<span id="cb99-7"><a href="nonlinear-regression.html#cb99-7" aria-hidden="true" tabindex="-1"></a>аппроксимировать нелинейные модели ступенчатыми функциями;</span>
<span id="cb99-8"><a href="nonlinear-regression.html#cb99-8" aria-hidden="true" tabindex="-1"></a>строить сплайны;</span>
<span id="cb99-9"><a href="nonlinear-regression.html#cb99-9" aria-hidden="true" tabindex="-1"></a>работать с локальной регрессией;</span>
<span id="cb99-10"><a href="nonlinear-regression.html#cb99-10" aria-hidden="true" tabindex="-1"></a>строить обобщённые линейные модели (GAM).</span>
<span id="cb99-11"><a href="nonlinear-regression.html#cb99-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> полиномиальная регрессия, полиномиальная логистическая регрессия, ступенчатая модель, обобщённая линейная модель.</span>
<span id="cb99-12"><a href="nonlinear-regression.html#cb99-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Wage {ISLR}</span>
<span id="cb99-13"><a href="nonlinear-regression.html#cb99-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-14"><a href="nonlinear-regression.html#cb99-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">7.</span></span>
<span id="cb99-15"><a href="nonlinear-regression.html#cb99-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-16"><a href="nonlinear-regression.html#cb99-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># набор данных Auto</span></span>
<span id="cb99-17"><a href="nonlinear-regression.html#cb99-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;splines&#39;</span>)           <span class="co"># сплайны</span></span>
<span id="cb99-18"><a href="nonlinear-regression.html#cb99-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gam&#39;</span>)               <span class="co"># обобщённые аддитивные модели</span></span>
<span id="cb99-19"><a href="nonlinear-regression.html#cb99-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gam&#39; was built under R version 3.3.3</span></span>
<span id="cb99-20"><a href="nonlinear-regression.html#cb99-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: foreach</span></span>
<span id="cb99-21"><a href="nonlinear-regression.html#cb99-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;foreach&#39; was built under R version 3.3.3</span></span>
<span id="cb99-22"><a href="nonlinear-regression.html#cb99-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gam 1.14</span></span>
<span id="cb99-23"><a href="nonlinear-regression.html#cb99-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;akima&#39;</span>)             <span class="co"># график двумерной плоскости</span></span>
<span id="cb99-24"><a href="nonlinear-regression.html#cb99-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;akima&#39; was built under R version 3.3.3</span></span>
<span id="cb99-25"><a href="nonlinear-regression.html#cb99-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ggplot2&#39;</span>)           <span class="co"># красивые графики</span></span>
<span id="cb99-26"><a href="nonlinear-regression.html#cb99-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;ggplot2&#39; was built under R version 3.3.3</span></span>
<span id="cb99-27"><a href="nonlinear-regression.html#cb99-27" aria-hidden="true" tabindex="-1"></a>my.seed <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb99-28"><a href="nonlinear-regression.html#cb99-28" aria-hidden="true" tabindex="-1"></a>Работаем с набором данных по зарплатам <span class="dv">3000</span> работников<span class="sc">-</span>мужчин среднеатлантического региона Wage. Присоединяем его к пространству имён функцией <span class="fu">attach</span>(), и дальше обращаемся напрямую к столбцам таблицы.</span>
<span id="cb99-29"><a href="nonlinear-regression.html#cb99-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-30"><a href="nonlinear-regression.html#cb99-30" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Wage)</span>
<span id="cb99-31"><a href="nonlinear-regression.html#cb99-31" aria-hidden="true" tabindex="-1"></a>Работаем со столбцами<span class="sc">:</span></span>
<span id="cb99-32"><a href="nonlinear-regression.html#cb99-32" aria-hidden="true" tabindex="-1"></a>    <span class="er">*</span> wage – заработная плата работника до уплаты налогов;</span>
<span id="cb99-33"><a href="nonlinear-regression.html#cb99-33" aria-hidden="true" tabindex="-1"></a><span class="sc">*</span> age – возраст работника в годах.</span>
<span id="cb99-34"><a href="nonlinear-regression.html#cb99-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-35"><a href="nonlinear-regression.html#cb99-35" aria-hidden="true" tabindex="-1"></a>Полиномиальная регрессия</span>
<span id="cb99-36"><a href="nonlinear-regression.html#cb99-36" aria-hidden="true" tabindex="-1"></a>Зависимость зарплаты от возраста</span>
<span id="cb99-37"><a href="nonlinear-regression.html#cb99-37" aria-hidden="true" tabindex="-1"></a>Судя по графику ниже, ззаимосвязь заработной платы и возраста нелинейна. Наблюдается также группа наблюдений с высоким значением wage, граница проходит примерно на уровне <span class="fl">250.</span></span>
<span id="cb99-38"><a href="nonlinear-regression.html#cb99-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-39"><a href="nonlinear-regression.html#cb99-39" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> Wage, <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> wage))</span>
<span id="cb99-40"><a href="nonlinear-regression.html#cb99-40" aria-hidden="true" tabindex="-1"></a>gp <span class="ot">&lt;-</span> gp <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">0</span>, <span class="at">intercept =</span> <span class="dv">250</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb99-41"><a href="nonlinear-regression.html#cb99-41" aria-hidden="true" tabindex="-1"></a>gp</span>
<span id="cb99-42"><a href="nonlinear-regression.html#cb99-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-43"><a href="nonlinear-regression.html#cb99-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-44"><a href="nonlinear-regression.html#cb99-44" aria-hidden="true" tabindex="-1"></a>Подгоняем полином четвёртой степени для зависимости заработной платы от возраста.</span>
<span id="cb99-45"><a href="nonlinear-regression.html#cb99-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-46"><a href="nonlinear-regression.html#cb99-46" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb99-47"><a href="nonlinear-regression.html#cb99-47" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb99-48"><a href="nonlinear-regression.html#cb99-48" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb99-49"><a href="nonlinear-regression.html#cb99-49" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)     111.70       0.73  153.28     0.00</span></span>
<span id="cb99-50"><a href="nonlinear-regression.html#cb99-50" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)1   447.07      39.91   11.20     0.00</span></span>
<span id="cb99-51"><a href="nonlinear-regression.html#cb99-51" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)2  -478.32      39.91  -11.98     0.00</span></span>
<span id="cb99-52"><a href="nonlinear-regression.html#cb99-52" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)3   125.52      39.91    3.14     0.00</span></span>
<span id="cb99-53"><a href="nonlinear-regression.html#cb99-53" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4)4   -77.91      39.91   -1.95     0.05</span></span>
<span id="cb99-54"><a href="nonlinear-regression.html#cb99-54" aria-hidden="true" tabindex="-1"></a>Функция <span class="fu">poly</span>(age, <span class="dv">4</span>) создаёт таблицу с базисом ортогональных полиномов<span class="sc">:</span> линейные комбинации значений переменной age в степенях от <span class="dv">1</span> до <span class="fl">4.</span></span>
<span id="cb99-55"><a href="nonlinear-regression.html#cb99-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-56"><a href="nonlinear-regression.html#cb99-56" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>)), <span class="dv">3</span>)</span>
<span id="cb99-57"><a href="nonlinear-regression.html#cb99-57" aria-hidden="true" tabindex="-1"></a><span class="do">##           1      2      3      4</span></span>
<span id="cb99-58"><a href="nonlinear-regression.html#cb99-58" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] -0.039  0.056 -0.072  0.087</span></span>
<span id="cb99-59"><a href="nonlinear-regression.html#cb99-59" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] -0.029  0.026 -0.015 -0.003</span></span>
<span id="cb99-60"><a href="nonlinear-regression.html#cb99-60" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,]  0.004 -0.015  0.000  0.014</span></span>
<span id="cb99-61"><a href="nonlinear-regression.html#cb99-61" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,]  0.001 -0.015  0.005  0.013</span></span>
<span id="cb99-62"><a href="nonlinear-regression.html#cb99-62" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,]  0.012 -0.010 -0.011  0.010</span></span>
<span id="cb99-63"><a href="nonlinear-regression.html#cb99-63" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,]  0.018 -0.002 -0.017 -0.001</span></span>
<span id="cb99-64"><a href="nonlinear-regression.html#cb99-64" aria-hidden="true" tabindex="-1"></a><span class="co"># можно получить сами значения age в заданных степенях</span></span>
<span id="cb99-65"><a href="nonlinear-regression.html#cb99-65" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(<span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T)), <span class="dv">3</span>)</span>
<span id="cb99-66"><a href="nonlinear-regression.html#cb99-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       1    2      3       4</span></span>
<span id="cb99-67"><a href="nonlinear-regression.html#cb99-67" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,] 18  324   5832  104976</span></span>
<span id="cb99-68"><a href="nonlinear-regression.html#cb99-68" aria-hidden="true" tabindex="-1"></a><span class="do">## [2,] 24  576  13824  331776</span></span>
<span id="cb99-69"><a href="nonlinear-regression.html#cb99-69" aria-hidden="true" tabindex="-1"></a><span class="do">## [3,] 45 2025  91125 4100625</span></span>
<span id="cb99-70"><a href="nonlinear-regression.html#cb99-70" aria-hidden="true" tabindex="-1"></a><span class="do">## [4,] 43 1849  79507 3418801</span></span>
<span id="cb99-71"><a href="nonlinear-regression.html#cb99-71" aria-hidden="true" tabindex="-1"></a><span class="do">## [5,] 50 2500 125000 6250000</span></span>
<span id="cb99-72"><a href="nonlinear-regression.html#cb99-72" aria-hidden="true" tabindex="-1"></a><span class="do">## [6,] 54 2916 157464 8503056</span></span>
<span id="cb99-73"><a href="nonlinear-regression.html#cb99-73" aria-hidden="true" tabindex="-1"></a><span class="co"># на прогноз не повлияет, но оценки параметров изменяются</span></span>
<span id="cb99-74"><a href="nonlinear-regression.html#cb99-74" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>, <span class="at">raw =</span> T), <span class="at">data =</span> Wage)</span>
<span id="cb99-75"><a href="nonlinear-regression.html#cb99-75" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit<span class="fl">.2</span>)), <span class="dv">2</span>)</span>
<span id="cb99-76"><a href="nonlinear-regression.html#cb99-76" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb99-77"><a href="nonlinear-regression.html#cb99-77" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)             -184.15      60.04   -3.07     0.00</span></span>
<span id="cb99-78"><a href="nonlinear-regression.html#cb99-78" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)1    21.25       5.89    3.61     0.00</span></span>
<span id="cb99-79"><a href="nonlinear-regression.html#cb99-79" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)2    -0.56       0.21   -2.74     0.01</span></span>
<span id="cb99-80"><a href="nonlinear-regression.html#cb99-80" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)3     0.01       0.00    2.22     0.03</span></span>
<span id="cb99-81"><a href="nonlinear-regression.html#cb99-81" aria-hidden="true" tabindex="-1"></a><span class="do">## poly(age, 4, raw = T)4     0.00       0.00   -1.95     0.05</span></span>
<span id="cb99-82"><a href="nonlinear-regression.html#cb99-82" aria-hidden="true" tabindex="-1"></a><span class="co"># границы изменения переменной age</span></span>
<span id="cb99-83"><a href="nonlinear-regression.html#cb99-83" aria-hidden="true" tabindex="-1"></a>agelims <span class="ot">&lt;-</span> <span class="fu">range</span>(age)</span>
<span id="cb99-84"><a href="nonlinear-regression.html#cb99-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-85"><a href="nonlinear-regression.html#cb99-85" aria-hidden="true" tabindex="-1"></a><span class="co"># значения age, для которых делаем прогноз (от min до max с шагом 1)</span></span>
<span id="cb99-86"><a href="nonlinear-regression.html#cb99-86" aria-hidden="true" tabindex="-1"></a>age.grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> agelims[<span class="dv">1</span>], <span class="at">to =</span> agelims[<span class="dv">2</span>])</span>
<span id="cb99-87"><a href="nonlinear-regression.html#cb99-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-88"><a href="nonlinear-regression.html#cb99-88" aria-hidden="true" tabindex="-1"></a><span class="co"># рассчитать прогнозы и их стандартные ошибки</span></span>
<span id="cb99-89"><a href="nonlinear-regression.html#cb99-89" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb99-90"><a href="nonlinear-regression.html#cb99-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-91"><a href="nonlinear-regression.html#cb99-91" aria-hidden="true" tabindex="-1"></a><span class="co"># границы доверительного интервала для заработной платы</span></span>
<span id="cb99-92"><a href="nonlinear-regression.html#cb99-92" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb99-93"><a href="nonlinear-regression.html#cb99-93" aria-hidden="true" tabindex="-1"></a>                  <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb99-94"><a href="nonlinear-regression.html#cb99-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-95"><a href="nonlinear-regression.html#cb99-95" aria-hidden="true" tabindex="-1"></a><span class="co"># смотрим результат</span></span>
<span id="cb99-96"><a href="nonlinear-regression.html#cb99-96" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">2</span>)</span>
<span id="cb99-97"><a href="nonlinear-regression.html#cb99-97" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb99-98"><a href="nonlinear-regression.html#cb99-98" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       41.33       62.53</span></span>
<span id="cb99-99"><a href="nonlinear-regression.html#cb99-99" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       49.76       67.24</span></span>
<span id="cb99-100"><a href="nonlinear-regression.html#cb99-100" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       57.39       71.76</span></span>
<span id="cb99-101"><a href="nonlinear-regression.html#cb99-101" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       64.27       76.09</span></span>
<span id="cb99-102"><a href="nonlinear-regression.html#cb99-102" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       70.44       80.27</span></span>
<span id="cb99-103"><a href="nonlinear-regression.html#cb99-103" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       75.94       84.28</span></span>
<span id="cb99-104"><a href="nonlinear-regression.html#cb99-104" aria-hidden="true" tabindex="-1"></a>Рисуем левую панель графика со слайда <span class="dv">4</span> презентации (рис. <span class="fl">7.1</span> книги). Функция <span class="fu">matlines</span>() рисует грфик столбцов одной матрицы против столбцов другой.</span>
<span id="cb99-105"><a href="nonlinear-regression.html#cb99-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-106"><a href="nonlinear-regression.html#cb99-106" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb99-107"><a href="nonlinear-regression.html#cb99-107" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb99-108"><a href="nonlinear-regression.html#cb99-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-109"><a href="nonlinear-regression.html#cb99-109" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb99-110"><a href="nonlinear-regression.html#cb99-110" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb99-111"><a href="nonlinear-regression.html#cb99-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-112"><a href="nonlinear-regression.html#cb99-112" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb99-113"><a href="nonlinear-regression.html#cb99-113" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb99-114"><a href="nonlinear-regression.html#cb99-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-115"><a href="nonlinear-regression.html#cb99-115" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb99-116"><a href="nonlinear-regression.html#cb99-116" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb99-117"><a href="nonlinear-regression.html#cb99-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-118"><a href="nonlinear-regression.html#cb99-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-119"><a href="nonlinear-regression.html#cb99-119" aria-hidden="true" tabindex="-1"></a>Убедимся, что прогнозы по моделям с различными вызовами <span class="fu">poly</span>() совпадают.</span>
<span id="cb99-120"><a href="nonlinear-regression.html#cb99-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-121"><a href="nonlinear-regression.html#cb99-121" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы по второму вызову модели</span></span>
<span id="cb99-122"><a href="nonlinear-regression.html#cb99-122" aria-hidden="true" tabindex="-1"></a>preds2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit<span class="fl">.2</span>, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb99-123"><a href="nonlinear-regression.html#cb99-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-124"><a href="nonlinear-regression.html#cb99-124" aria-hidden="true" tabindex="-1"></a><span class="co"># максимальное расхождение между прогнозами по двум вариантам вызова модели</span></span>
<span id="cb99-125"><a href="nonlinear-regression.html#cb99-125" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(preds<span class="sc">$</span>fit <span class="sc">-</span> preds2<span class="sc">$</span>fit))</span>
<span id="cb99-126"><a href="nonlinear-regression.html#cb99-126" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 7.389644e-13</span></span>
<span id="cb99-127"><a href="nonlinear-regression.html#cb99-127" aria-hidden="true" tabindex="-1"></a>Теперь подбираем степень полинома, сравнивая модели со степенями от <span class="dv">1</span> до <span class="dv">5</span> с помощью дисперсионного анализа (ANOVA).</span>
<span id="cb99-128"><a href="nonlinear-regression.html#cb99-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-129"><a href="nonlinear-regression.html#cb99-129" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> age, <span class="at">data =</span> Wage)</span>
<span id="cb99-130"><a href="nonlinear-regression.html#cb99-130" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">2</span>), <span class="at">data =</span> Wage)</span>
<span id="cb99-131"><a href="nonlinear-regression.html#cb99-131" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">3</span>), <span class="at">data =</span> Wage)</span>
<span id="cb99-132"><a href="nonlinear-regression.html#cb99-132" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb99-133"><a href="nonlinear-regression.html#cb99-133" aria-hidden="true" tabindex="-1"></a>fit<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">5</span>), <span class="at">data =</span> Wage)</span>
<span id="cb99-134"><a href="nonlinear-regression.html#cb99-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-135"><a href="nonlinear-regression.html#cb99-135" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">anova</span>(fit<span class="fl">.1</span>, fit<span class="fl">.2</span>, fit<span class="fl">.3</span>, fit<span class="fl">.4</span>, fit<span class="fl">.5</span>), <span class="dv">2</span>)</span>
<span id="cb99-136"><a href="nonlinear-regression.html#cb99-136" aria-hidden="true" tabindex="-1"></a>Res.Df</span>
<span id="cb99-137"><a href="nonlinear-regression.html#cb99-137" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-138"><a href="nonlinear-regression.html#cb99-138" aria-hidden="true" tabindex="-1"></a>    RSS</span>
<span id="cb99-139"><a href="nonlinear-regression.html#cb99-139" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-140"><a href="nonlinear-regression.html#cb99-140" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb99-141"><a href="nonlinear-regression.html#cb99-141" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-142"><a href="nonlinear-regression.html#cb99-142" aria-hidden="true" tabindex="-1"></a>    Sum of Sq</span>
<span id="cb99-143"><a href="nonlinear-regression.html#cb99-143" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-144"><a href="nonlinear-regression.html#cb99-144" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb99-145"><a href="nonlinear-regression.html#cb99-145" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-146"><a href="nonlinear-regression.html#cb99-146" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb99-147"><a href="nonlinear-regression.html#cb99-147" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-148"><a href="nonlinear-regression.html#cb99-148" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2998</span>    <span class="dv">5022216</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb99-149"><a href="nonlinear-regression.html#cb99-149" aria-hidden="true" tabindex="-1"></a><span class="dv">2997</span>    <span class="dv">4793430</span> <span class="dv">1</span>   <span class="fl">228786.01</span>   <span class="fl">143.59</span>  <span class="fl">0.00</span></span>
<span id="cb99-150"><a href="nonlinear-regression.html#cb99-150" aria-hidden="true" tabindex="-1"></a><span class="dv">2996</span>    <span class="dv">4777674</span> <span class="dv">1</span>   <span class="fl">15755.69</span>    <span class="fl">9.89</span>    <span class="fl">0.00</span></span>
<span id="cb99-151"><a href="nonlinear-regression.html#cb99-151" aria-hidden="true" tabindex="-1"></a><span class="dv">2995</span>    <span class="dv">4771604</span> <span class="dv">1</span>   <span class="fl">6070.15</span> <span class="fl">3.81</span>    <span class="fl">0.05</span></span>
<span id="cb99-152"><a href="nonlinear-regression.html#cb99-152" aria-hidden="true" tabindex="-1"></a><span class="dv">2994</span>    <span class="dv">4770322</span> <span class="dv">1</span>   <span class="fl">1282.56</span> <span class="fl">0.80</span>    <span class="fl">0.37</span></span>
<span id="cb99-153"><a href="nonlinear-regression.html#cb99-153" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> rows</span>
<span id="cb99-154"><a href="nonlinear-regression.html#cb99-154" aria-hidden="true" tabindex="-1"></a>Рассматриваются пять моделей, в которых степени полинома от age идут по возрастанию. В крайнем правом столбце таблице приводятся p<span class="sc">-</span>значения для проверки нулевой гипотезы<span class="sc">:</span> текущая модель не даёт статистически значимого сокращения RSS по сравнению с предыдущей моделью. Можно сделать вывод, что степени <span class="dv">3</span> достаточно, дальнейшее увеличение степени не даёт значимого улучшения качества модели.</span>
<span id="cb99-155"><a href="nonlinear-regression.html#cb99-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-156"><a href="nonlinear-regression.html#cb99-156" aria-hidden="true" tabindex="-1"></a>Зависимость вероятности получать зарплату <span class="sc">&gt;</span> <span class="dv">250</span> от возраста</span>
<span id="cb99-157"><a href="nonlinear-regression.html#cb99-157" aria-hidden="true" tabindex="-1"></a>Теперь вернёмся к группе наблюдений с высоким wage. Рассмотрим зависимость вероятности того, что величина зарплаты больше <span class="dv">250</span>, от возраста.</span>
<span id="cb99-158"><a href="nonlinear-regression.html#cb99-158" aria-hidden="true" tabindex="-1"></a>Подгоняем логистическую регрессию и делаем прогнозы, для этого используем функцию для оценки обобщённой линейной модели  <span class="fu">glm</span>() и указываем тип модели binomial<span class="sc">:</span></span>
<span id="cb99-159"><a href="nonlinear-regression.html#cb99-159" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-160"><a href="nonlinear-regression.html#cb99-160" aria-hidden="true" tabindex="-1"></a>    fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">poly</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb99-161"><a href="nonlinear-regression.html#cb99-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-162"><a href="nonlinear-regression.html#cb99-162" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb99-163"><a href="nonlinear-regression.html#cb99-163" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb99-164"><a href="nonlinear-regression.html#cb99-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-165"><a href="nonlinear-regression.html#cb99-165" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb99-166"><a href="nonlinear-regression.html#cb99-166" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb99-167"><a href="nonlinear-regression.html#cb99-167" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb99-168"><a href="nonlinear-regression.html#cb99-168" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb99-169"><a href="nonlinear-regression.html#cb99-169" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb99-170"><a href="nonlinear-regression.html#cb99-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-171"><a href="nonlinear-regression.html#cb99-171" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb99-172"><a href="nonlinear-regression.html#cb99-172" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb99-173"><a href="nonlinear-regression.html#cb99-173" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb99-174"><a href="nonlinear-regression.html#cb99-174" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb99-175"><a href="nonlinear-regression.html#cb99-175" aria-hidden="true" tabindex="-1"></a><span class="do">## 1           0       0.002</span></span>
<span id="cb99-176"><a href="nonlinear-regression.html#cb99-176" aria-hidden="true" tabindex="-1"></a><span class="do">## 2           0       0.003</span></span>
<span id="cb99-177"><a href="nonlinear-regression.html#cb99-177" aria-hidden="true" tabindex="-1"></a><span class="do">## 3           0       0.004</span></span>
<span id="cb99-178"><a href="nonlinear-regression.html#cb99-178" aria-hidden="true" tabindex="-1"></a><span class="do">## 4           0       0.005</span></span>
<span id="cb99-179"><a href="nonlinear-regression.html#cb99-179" aria-hidden="true" tabindex="-1"></a><span class="do">## 5           0       0.006</span></span>
<span id="cb99-180"><a href="nonlinear-regression.html#cb99-180" aria-hidden="true" tabindex="-1"></a><span class="do">## 6           0       0.007</span></span>
<span id="cb99-181"><a href="nonlinear-regression.html#cb99-181" aria-hidden="true" tabindex="-1"></a>Достраиваем график с <span class="dv">4</span> слайда презентации (рис. <span class="fl">7.1</span> книги). Рисуем правую панель.</span>
<span id="cb99-182"><a href="nonlinear-regression.html#cb99-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-183"><a href="nonlinear-regression.html#cb99-183" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb99-184"><a href="nonlinear-regression.html#cb99-184" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb99-185"><a href="nonlinear-regression.html#cb99-185" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb99-186"><a href="nonlinear-regression.html#cb99-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-187"><a href="nonlinear-regression.html#cb99-187" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb99-188"><a href="nonlinear-regression.html#cb99-188" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb99-189"><a href="nonlinear-regression.html#cb99-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-190"><a href="nonlinear-regression.html#cb99-190" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb99-191"><a href="nonlinear-regression.html#cb99-191" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb99-192"><a href="nonlinear-regression.html#cb99-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-193"><a href="nonlinear-regression.html#cb99-193" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb99-194"><a href="nonlinear-regression.html#cb99-194" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb99-195"><a href="nonlinear-regression.html#cb99-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-196"><a href="nonlinear-regression.html#cb99-196" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb99-197"><a href="nonlinear-regression.html#cb99-197" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Полином четвёртой степени&#39;</span>)</span>
<span id="cb99-198"><a href="nonlinear-regression.html#cb99-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-199"><a href="nonlinear-regression.html#cb99-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-200"><a href="nonlinear-regression.html#cb99-200" aria-hidden="true" tabindex="-1"></a>Ступенчатые функции</span>
<span id="cb99-201"><a href="nonlinear-regression.html#cb99-201" aria-hidden="true" tabindex="-1"></a>Для начала определим несколько интервалов, на каждом из которых будем моделировать зависимость wage от age своим средним уровнем.</span>
<span id="cb99-202"><a href="nonlinear-regression.html#cb99-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-203"><a href="nonlinear-regression.html#cb99-203" aria-hidden="true" tabindex="-1"></a><span class="co"># нарезаем предиктор age на 4 равных интервала</span></span>
<span id="cb99-204"><a href="nonlinear-regression.html#cb99-204" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(<span class="fu">cut</span>(age, <span class="dv">4</span>))</span>
<span id="cb99-205"><a href="nonlinear-regression.html#cb99-205" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb99-206"><a href="nonlinear-regression.html#cb99-206" aria-hidden="true" tabindex="-1"></a><span class="do">## (17.9,33.5]   (33.5,49]   (49,64.5] (64.5,80.1] </span></span>
<span id="cb99-207"><a href="nonlinear-regression.html#cb99-207" aria-hidden="true" tabindex="-1"></a><span class="do">##         750        1399         779          72</span></span>
<span id="cb99-208"><a href="nonlinear-regression.html#cb99-208" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем линейную модель на интервалах</span></span>
<span id="cb99-209"><a href="nonlinear-regression.html#cb99-209" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb99-210"><a href="nonlinear-regression.html#cb99-210" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">coef</span>(<span class="fu">summary</span>(fit)), <span class="dv">2</span>)</span>
<span id="cb99-211"><a href="nonlinear-regression.html#cb99-211" aria-hidden="true" tabindex="-1"></a><span class="do">##                        Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb99-212"><a href="nonlinear-regression.html#cb99-212" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)               94.16       1.48   63.79     0.00</span></span>
<span id="cb99-213"><a href="nonlinear-regression.html#cb99-213" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(33.5,49]      24.05       1.83   13.15     0.00</span></span>
<span id="cb99-214"><a href="nonlinear-regression.html#cb99-214" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(49,64.5]      23.66       2.07   11.44     0.00</span></span>
<span id="cb99-215"><a href="nonlinear-regression.html#cb99-215" aria-hidden="true" tabindex="-1"></a><span class="do">## cut(age, 4)(64.5,80.1]     7.64       4.99    1.53     0.13</span></span>
<span id="cb99-216"><a href="nonlinear-regression.html#cb99-216" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз -- это средние по `wage` на каждом интервале</span></span>
<span id="cb99-217"><a href="nonlinear-regression.html#cb99-217" aria-hidden="true" tabindex="-1"></a>preds.cut <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb99-218"><a href="nonlinear-regression.html#cb99-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-219"><a href="nonlinear-regression.html#cb99-219" aria-hidden="true" tabindex="-1"></a><span class="co"># интервальный прогноз</span></span>
<span id="cb99-220"><a href="nonlinear-regression.html#cb99-220" aria-hidden="true" tabindex="-1"></a>se.bands.cut <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit,</span>
<span id="cb99-221"><a href="nonlinear-regression.html#cb99-221" aria-hidden="true" tabindex="-1"></a>                      <span class="at">upper.bound =</span> preds.cut<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.cut<span class="sc">$</span>se.fit)</span>
<span id="cb99-222"><a href="nonlinear-regression.html#cb99-222" aria-hidden="true" tabindex="-1"></a>Воспроизведём график со слайда <span class="dv">7</span> презентации (рис. <span class="fl">7.2</span> книги).</span>
<span id="cb99-223"><a href="nonlinear-regression.html#cb99-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-224"><a href="nonlinear-regression.html#cb99-224" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb99-225"><a href="nonlinear-regression.html#cb99-225" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb99-226"><a href="nonlinear-regression.html#cb99-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-227"><a href="nonlinear-regression.html#cb99-227" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb99-228"><a href="nonlinear-regression.html#cb99-228" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.cut<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb99-229"><a href="nonlinear-regression.html#cb99-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-230"><a href="nonlinear-regression.html#cb99-230" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы прогноза</span></span>
<span id="cb99-231"><a href="nonlinear-regression.html#cb99-231" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(<span class="at">x =</span> age.grid, <span class="at">y =</span> se.bands.cut, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb99-232"><a href="nonlinear-regression.html#cb99-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-233"><a href="nonlinear-regression.html#cb99-233" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb99-234"><a href="nonlinear-regression.html#cb99-234" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb99-235"><a href="nonlinear-regression.html#cb99-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-236"><a href="nonlinear-regression.html#cb99-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-237"><a href="nonlinear-regression.html#cb99-237" aria-hidden="true" tabindex="-1"></a>Правая часть графика, для вероятности того, что зарплата выше <span class="fl">250.</span></span>
<span id="cb99-238"><a href="nonlinear-regression.html#cb99-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-239"><a href="nonlinear-regression.html#cb99-239" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> <span class="fu">cut</span>(age, <span class="dv">4</span>), <span class="at">data =</span> Wage, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb99-240"><a href="nonlinear-regression.html#cb99-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-241"><a href="nonlinear-regression.html#cb99-241" aria-hidden="true" tabindex="-1"></a><span class="co"># прогнозы</span></span>
<span id="cb99-242"><a href="nonlinear-regression.html#cb99-242" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb99-243"><a href="nonlinear-regression.html#cb99-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-244"><a href="nonlinear-regression.html#cb99-244" aria-hidden="true" tabindex="-1"></a><span class="co"># пересчитываем доверительные интервалы и прогнозы в исходные ЕИ</span></span>
<span id="cb99-245"><a href="nonlinear-regression.html#cb99-245" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">&lt;-</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(preds<span class="sc">$</span>fit))</span>
<span id="cb99-246"><a href="nonlinear-regression.html#cb99-246" aria-hidden="true" tabindex="-1"></a>se.bands.logit <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">lower.bound =</span> preds<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit,</span>
<span id="cb99-247"><a href="nonlinear-regression.html#cb99-247" aria-hidden="true" tabindex="-1"></a>                        <span class="at">upper.bound =</span> preds<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds<span class="sc">$</span>se.fit)</span>
<span id="cb99-248"><a href="nonlinear-regression.html#cb99-248" aria-hidden="true" tabindex="-1"></a>se.bands <span class="ot">&lt;-</span> <span class="fu">exp</span>(se.bands.logit)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(se.bands.logit))</span>
<span id="cb99-249"><a href="nonlinear-regression.html#cb99-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-250"><a href="nonlinear-regression.html#cb99-250" aria-hidden="true" tabindex="-1"></a><span class="co"># результат - доверительный интервал для вероятности события </span></span>
<span id="cb99-251"><a href="nonlinear-regression.html#cb99-251" aria-hidden="true" tabindex="-1"></a><span class="co">#   &quot;Заработная плата выше 250&quot;.   </span></span>
<span id="cb99-252"><a href="nonlinear-regression.html#cb99-252" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(se.bands), <span class="dv">3</span>)</span>
<span id="cb99-253"><a href="nonlinear-regression.html#cb99-253" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound upper.bound</span></span>
<span id="cb99-254"><a href="nonlinear-regression.html#cb99-254" aria-hidden="true" tabindex="-1"></a><span class="do">## 1       0.003       0.016</span></span>
<span id="cb99-255"><a href="nonlinear-regression.html#cb99-255" aria-hidden="true" tabindex="-1"></a><span class="do">## 2       0.003       0.016</span></span>
<span id="cb99-256"><a href="nonlinear-regression.html#cb99-256" aria-hidden="true" tabindex="-1"></a><span class="do">## 3       0.003       0.016</span></span>
<span id="cb99-257"><a href="nonlinear-regression.html#cb99-257" aria-hidden="true" tabindex="-1"></a><span class="do">## 4       0.003       0.016</span></span>
<span id="cb99-258"><a href="nonlinear-regression.html#cb99-258" aria-hidden="true" tabindex="-1"></a><span class="do">## 5       0.003       0.016</span></span>
<span id="cb99-259"><a href="nonlinear-regression.html#cb99-259" aria-hidden="true" tabindex="-1"></a><span class="do">## 6       0.003       0.016</span></span>
<span id="cb99-260"><a href="nonlinear-regression.html#cb99-260" aria-hidden="true" tabindex="-1"></a><span class="co"># сетка для графика (изображаем вероятности, поэтому интервал изменения y мал)</span></span>
<span id="cb99-261"><a href="nonlinear-regression.html#cb99-261" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>), <span class="at">xlim =</span> agelims, <span class="at">type =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>),</span>
<span id="cb99-262"><a href="nonlinear-regression.html#cb99-262" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;P(Wage &gt; 250 | Age)&#39;</span>)</span>
<span id="cb99-263"><a href="nonlinear-regression.html#cb99-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-264"><a href="nonlinear-regression.html#cb99-264" aria-hidden="true" tabindex="-1"></a><span class="co"># фактические наблюдения показываем засечками</span></span>
<span id="cb99-265"><a href="nonlinear-regression.html#cb99-265" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">jitter</span>(age), <span class="fu">I</span>((wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">/</span> <span class="dv">5</span>), <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">pch =</span> <span class="st">&#39;|&#39;</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb99-266"><a href="nonlinear-regression.html#cb99-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-267"><a href="nonlinear-regression.html#cb99-267" aria-hidden="true" tabindex="-1"></a><span class="co"># модель</span></span>
<span id="cb99-268"><a href="nonlinear-regression.html#cb99-268" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, pfit, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb99-269"><a href="nonlinear-regression.html#cb99-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-270"><a href="nonlinear-regression.html#cb99-270" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительные интервалы</span></span>
<span id="cb99-271"><a href="nonlinear-regression.html#cb99-271" aria-hidden="true" tabindex="-1"></a><span class="fu">matlines</span>(age.grid, se.bands, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;darkgreen&#39;</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb99-272"><a href="nonlinear-regression.html#cb99-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-273"><a href="nonlinear-regression.html#cb99-273" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb99-274"><a href="nonlinear-regression.html#cb99-274" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Ступенчатая функция&#39;</span>)</span>
<span id="cb99-275"><a href="nonlinear-regression.html#cb99-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-276"><a href="nonlinear-regression.html#cb99-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-277"><a href="nonlinear-regression.html#cb99-277" aria-hidden="true" tabindex="-1"></a>Сплайны</span>
<span id="cb99-278"><a href="nonlinear-regression.html#cb99-278" aria-hidden="true" tabindex="-1"></a>Построим кубический сплайн с тремя узлами.</span>
<span id="cb99-279"><a href="nonlinear-regression.html#cb99-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-280"><a href="nonlinear-regression.html#cb99-280" aria-hidden="true" tabindex="-1"></a><span class="co"># кубический сплайн с тремя узлами</span></span>
<span id="cb99-281"><a href="nonlinear-regression.html#cb99-281" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)), <span class="at">data =</span> Wage)</span>
<span id="cb99-282"><a href="nonlinear-regression.html#cb99-282" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb99-283"><a href="nonlinear-regression.html#cb99-283" aria-hidden="true" tabindex="-1"></a>preds.spl <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb99-284"><a href="nonlinear-regression.html#cb99-284" aria-hidden="true" tabindex="-1"></a>Теперь построим натуральный по трём узлам. Три узла это <span class="dv">6</span> степеней свободы. Если функции <span class="fu">bs</span>(), которая создаёт матрицу с базисом для полиномиального сплайна, передать только степени свободы, она распределит узлы равномерно. В данном случае это квартили распределения age.</span>
<span id="cb99-285"><a href="nonlinear-regression.html#cb99-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-286"><a href="nonlinear-regression.html#cb99-286" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 узла -- 6 степеней свободы (столбцы матрицы)</span></span>
<span id="cb99-287"><a href="nonlinear-regression.html#cb99-287" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">knots =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">60</span>)))</span>
<span id="cb99-288"><a href="nonlinear-regression.html#cb99-288" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb99-289"><a href="nonlinear-regression.html#cb99-289" aria-hidden="true" tabindex="-1"></a><span class="co"># если не указываем узлы явно...</span></span>
<span id="cb99-290"><a href="nonlinear-regression.html#cb99-290" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>))</span>
<span id="cb99-291"><a href="nonlinear-regression.html#cb99-291" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 3000    6</span></span>
<span id="cb99-292"><a href="nonlinear-regression.html#cb99-292" aria-hidden="true" tabindex="-1"></a><span class="co">#  они привязываются к квартилям</span></span>
<span id="cb99-293"><a href="nonlinear-regression.html#cb99-293" aria-hidden="true" tabindex="-1"></a><span class="fu">attr</span>(<span class="fu">bs</span>(age, <span class="at">df =</span> <span class="dv">6</span>), <span class="st">&#39;knots&#39;</span>)</span>
<span id="cb99-294"><a href="nonlinear-regression.html#cb99-294" aria-hidden="true" tabindex="-1"></a><span class="do">##   25%   50%   75% </span></span>
<span id="cb99-295"><a href="nonlinear-regression.html#cb99-295" aria-hidden="true" tabindex="-1"></a><span class="do">## 33.75 42.00 51.00</span></span>
<span id="cb99-296"><a href="nonlinear-regression.html#cb99-296" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb99-297"><a href="nonlinear-regression.html#cb99-297" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(age, <span class="at">df =</span> <span class="dv">4</span>), <span class="at">data =</span> Wage)</span>
<span id="cb99-298"><a href="nonlinear-regression.html#cb99-298" aria-hidden="true" tabindex="-1"></a>preds.spl2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit2, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">age =</span> age.grid), <span class="at">se =</span> T)</span>
<span id="cb99-299"><a href="nonlinear-regression.html#cb99-299" aria-hidden="true" tabindex="-1"></a>График сравнения кубического и натурального сплайнов.</span>
<span id="cb99-300"><a href="nonlinear-regression.html#cb99-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-301"><a href="nonlinear-regression.html#cb99-301" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="fl">8.5</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="at">xpd =</span> T)</span>
<span id="cb99-302"><a href="nonlinear-regression.html#cb99-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-303"><a href="nonlinear-regression.html#cb99-303" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb99-304"><a href="nonlinear-regression.html#cb99-304" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">col =</span> <span class="st">&#39;grey&#39;</span>)</span>
<span id="cb99-305"><a href="nonlinear-regression.html#cb99-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-306"><a href="nonlinear-regression.html#cb99-306" aria-hidden="true" tabindex="-1"></a><span class="co"># модель кубического сплайна</span></span>
<span id="cb99-307"><a href="nonlinear-regression.html#cb99-307" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb99-308"><a href="nonlinear-regression.html#cb99-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-309"><a href="nonlinear-regression.html#cb99-309" aria-hidden="true" tabindex="-1"></a><span class="co"># доверительный интервал</span></span>
<span id="cb99-310"><a href="nonlinear-regression.html#cb99-310" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb99-311"><a href="nonlinear-regression.html#cb99-311" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl<span class="sc">$</span>fit <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>preds.spl<span class="sc">$</span>se, <span class="at">lty =</span> <span class="st">&#39;dashed&#39;</span>)</span>
<span id="cb99-312"><a href="nonlinear-regression.html#cb99-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-313"><a href="nonlinear-regression.html#cb99-313" aria-hidden="true" tabindex="-1"></a><span class="co"># натуральный сплайн</span></span>
<span id="cb99-314"><a href="nonlinear-regression.html#cb99-314" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, preds.spl2<span class="sc">$</span>fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb99-315"><a href="nonlinear-regression.html#cb99-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-316"><a href="nonlinear-regression.html#cb99-316" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb99-317"><a href="nonlinear-regression.html#cb99-317" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">inset =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.7</span>, <span class="dv">0</span>),</span>
<span id="cb99-318"><a href="nonlinear-regression.html#cb99-318" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;Кубический </span><span class="sc">\n</span><span class="st"> с 3 узлами&#39;</span>, <span class="st">&#39;Натуральный&#39;</span>),</span>
<span id="cb99-319"><a href="nonlinear-regression.html#cb99-319" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="fu">rep</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;red&#39;</span>))</span>
<span id="cb99-320"><a href="nonlinear-regression.html#cb99-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-321"><a href="nonlinear-regression.html#cb99-321" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb99-322"><a href="nonlinear-regression.html#cb99-322" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Сплайны&quot;</span>)</span>
<span id="cb99-323"><a href="nonlinear-regression.html#cb99-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-324"><a href="nonlinear-regression.html#cb99-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-325"><a href="nonlinear-regression.html#cb99-325" aria-hidden="true" tabindex="-1"></a>Построим график со слайда <span class="dv">20</span> (рисунок <span class="fl">7.8</span> книги).</span>
<span id="cb99-326"><a href="nonlinear-regression.html#cb99-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-327"><a href="nonlinear-regression.html#cb99-327" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">0</span>))</span>
<span id="cb99-328"><a href="nonlinear-regression.html#cb99-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-329"><a href="nonlinear-regression.html#cb99-329" aria-hidden="true" tabindex="-1"></a><span class="co"># наблюдения</span></span>
<span id="cb99-330"><a href="nonlinear-regression.html#cb99-330" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb99-331"><a href="nonlinear-regression.html#cb99-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-332"><a href="nonlinear-regression.html#cb99-332" aria-hidden="true" tabindex="-1"></a><span class="co"># заголовок</span></span>
<span id="cb99-333"><a href="nonlinear-regression.html#cb99-333" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Сглаживающий сплайн&#39;</span>)</span>
<span id="cb99-334"><a href="nonlinear-regression.html#cb99-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-335"><a href="nonlinear-regression.html#cb99-335" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с 16 степенями свободы</span></span>
<span id="cb99-336"><a href="nonlinear-regression.html#cb99-336" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">df =</span> <span class="dv">16</span>)</span>
<span id="cb99-337"><a href="nonlinear-regression.html#cb99-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-338"><a href="nonlinear-regression.html#cb99-338" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель с подбором лямбды с помощью перекрёстной проверки</span></span>
<span id="cb99-339"><a href="nonlinear-regression.html#cb99-339" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">smooth.spline</span>(age, wage, <span class="at">cv =</span> T)</span>
<span id="cb99-340"><a href="nonlinear-regression.html#cb99-340" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in smooth.spline(age, wage, cv = T): cross-validation with non-</span></span>
<span id="cb99-341"><a href="nonlinear-regression.html#cb99-341" aria-hidden="true" tabindex="-1"></a><span class="do">## unique &#39;x&#39; values seems doubtful</span></span>
<span id="cb99-342"><a href="nonlinear-regression.html#cb99-342" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span>df</span>
<span id="cb99-343"><a href="nonlinear-regression.html#cb99-343" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 6.794596</span></span>
<span id="cb99-344"><a href="nonlinear-regression.html#cb99-344" aria-hidden="true" tabindex="-1"></a><span class="co"># рисуем модель</span></span>
<span id="cb99-345"><a href="nonlinear-regression.html#cb99-345" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb99-346"><a href="nonlinear-regression.html#cb99-346" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(fit2, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb99-347"><a href="nonlinear-regression.html#cb99-347" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb99-348"><a href="nonlinear-regression.html#cb99-348" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;16 df&#39;</span>, <span class="st">&#39;6.8 df&#39;</span>),</span>
<span id="cb99-349"><a href="nonlinear-regression.html#cb99-349" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb99-350"><a href="nonlinear-regression.html#cb99-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-351"><a href="nonlinear-regression.html#cb99-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-352"><a href="nonlinear-regression.html#cb99-352" aria-hidden="true" tabindex="-1"></a>Локальная регрессия</span>
<span id="cb99-353"><a href="nonlinear-regression.html#cb99-353" aria-hidden="true" tabindex="-1"></a>Строим график со слайда <span class="dv">24</span> (рис. <span class="fl">7.10</span>).</span>
<span id="cb99-354"><a href="nonlinear-regression.html#cb99-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-355"><a href="nonlinear-regression.html#cb99-355" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(age, wage, <span class="at">xlim =</span> agelims, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb99-356"><a href="nonlinear-regression.html#cb99-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-357"><a href="nonlinear-regression.html#cb99-357" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Локальная регрессия&#39;</span>)</span>
<span id="cb99-358"><a href="nonlinear-regression.html#cb99-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-359"><a href="nonlinear-regression.html#cb99-359" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.2</span></span>
<span id="cb99-360"><a href="nonlinear-regression.html#cb99-360" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.2</span>, <span class="at">data =</span> Wage)</span>
<span id="cb99-361"><a href="nonlinear-regression.html#cb99-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-362"><a href="nonlinear-regression.html#cb99-362" aria-hidden="true" tabindex="-1"></a><span class="co"># подгоняем модель c окном 0.5</span></span>
<span id="cb99-363"><a href="nonlinear-regression.html#cb99-363" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">loess</span>(wage <span class="sc">~</span> age, <span class="at">span =</span> <span class="fl">0.5</span>, <span class="at">data =</span> Wage)</span>
<span id="cb99-364"><a href="nonlinear-regression.html#cb99-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-365"><a href="nonlinear-regression.html#cb99-365" aria-hidden="true" tabindex="-1"></a><span class="co"># рисум модели</span></span>
<span id="cb99-366"><a href="nonlinear-regression.html#cb99-366" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb99-367"><a href="nonlinear-regression.html#cb99-367" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb99-368"><a href="nonlinear-regression.html#cb99-368" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(age.grid, <span class="fu">predict</span>(fit2, <span class="fu">data.frame</span>(<span class="at">age =</span> age.grid)),</span>
<span id="cb99-369"><a href="nonlinear-regression.html#cb99-369" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb99-370"><a href="nonlinear-regression.html#cb99-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-371"><a href="nonlinear-regression.html#cb99-371" aria-hidden="true" tabindex="-1"></a><span class="co"># легенда</span></span>
<span id="cb99-372"><a href="nonlinear-regression.html#cb99-372" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, </span>
<span id="cb99-373"><a href="nonlinear-regression.html#cb99-373" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&#39;s = 0.2&#39;</span>, <span class="st">&#39;s = 0.5&#39;</span>),</span>
<span id="cb99-374"><a href="nonlinear-regression.html#cb99-374" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;red&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb99-375"><a href="nonlinear-regression.html#cb99-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-376"><a href="nonlinear-regression.html#cb99-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-377"><a href="nonlinear-regression.html#cb99-377" aria-hidden="true" tabindex="-1"></a>Обобщённые аддитивные модели (GAM) с непрерывным откликом</span>
<span id="cb99-378"><a href="nonlinear-regression.html#cb99-378" aria-hidden="true" tabindex="-1"></a>Построим GAM на натуральных сплайнах степеней <span class="dv">4</span> (year), <span class="dv">5</span> (age) с категориальным предиктором edication.</span>
<span id="cb99-379"><a href="nonlinear-regression.html#cb99-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-380"><a href="nonlinear-regression.html#cb99-380" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на натуральных сплайнах</span></span>
<span id="cb99-381"><a href="nonlinear-regression.html#cb99-381" aria-hidden="true" tabindex="-1"></a>gam.ns <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">ns</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">ns</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb99-382"><a href="nonlinear-regression.html#cb99-382" aria-hidden="true" tabindex="-1"></a>Также построим модель на сглаживающих сплайнах.</span>
<span id="cb99-383"><a href="nonlinear-regression.html#cb99-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-384"><a href="nonlinear-regression.html#cb99-384" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на сглаживающих сплайнах</span></span>
<span id="cb99-385"><a href="nonlinear-regression.html#cb99-385" aria-hidden="true" tabindex="-1"></a>gam.m3 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb99-386"><a href="nonlinear-regression.html#cb99-386" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">28</span> (рис. <span class="fl">7.12</span>).</span>
<span id="cb99-387"><a href="nonlinear-regression.html#cb99-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-388"><a href="nonlinear-regression.html#cb99-388" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb99-389"><a href="nonlinear-regression.html#cb99-389" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.m3, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span>
<span id="cb99-390"><a href="nonlinear-regression.html#cb99-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-391"><a href="nonlinear-regression.html#cb99-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-392"><a href="nonlinear-regression.html#cb99-392" aria-hidden="true" tabindex="-1"></a>График со слайда <span class="dv">27</span> (рис. <span class="fl">7.11</span>).</span>
<span id="cb99-393"><a href="nonlinear-regression.html#cb99-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-394"><a href="nonlinear-regression.html#cb99-394" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb99-395"><a href="nonlinear-regression.html#cb99-395" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.ns, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb99-396"><a href="nonlinear-regression.html#cb99-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-397"><a href="nonlinear-regression.html#cb99-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-398"><a href="nonlinear-regression.html#cb99-398" aria-hidden="true" tabindex="-1"></a>График функции от year похож на прямую. Сделаем ANOVA, чтобы понять, какая степень для year лучше.</span>
<span id="cb99-399"><a href="nonlinear-regression.html#cb99-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-400"><a href="nonlinear-regression.html#cb99-400" aria-hidden="true" tabindex="-1"></a>gam.m1 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)          <span class="co"># без year</span></span>
<span id="cb99-401"><a href="nonlinear-regression.html#cb99-401" aria-hidden="true" tabindex="-1"></a>gam.m2 <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="dv">5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)   <span class="co"># year^1</span></span>
<span id="cb99-402"><a href="nonlinear-regression.html#cb99-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-403"><a href="nonlinear-regression.html#cb99-403" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(gam.m1, gam.m2, gam.m3, <span class="at">test =</span> <span class="st">&#39;F&#39;</span>)</span>
<span id="cb99-404"><a href="nonlinear-regression.html#cb99-404" aria-hidden="true" tabindex="-1"></a>Resid. Df</span>
<span id="cb99-405"><a href="nonlinear-regression.html#cb99-405" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-406"><a href="nonlinear-regression.html#cb99-406" aria-hidden="true" tabindex="-1"></a>    Resid. Dev</span>
<span id="cb99-407"><a href="nonlinear-regression.html#cb99-407" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-408"><a href="nonlinear-regression.html#cb99-408" aria-hidden="true" tabindex="-1"></a>    Df</span>
<span id="cb99-409"><a href="nonlinear-regression.html#cb99-409" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-410"><a href="nonlinear-regression.html#cb99-410" aria-hidden="true" tabindex="-1"></a>    Deviance</span>
<span id="cb99-411"><a href="nonlinear-regression.html#cb99-411" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-412"><a href="nonlinear-regression.html#cb99-412" aria-hidden="true" tabindex="-1"></a>    F</span>
<span id="cb99-413"><a href="nonlinear-regression.html#cb99-413" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-414"><a href="nonlinear-regression.html#cb99-414" aria-hidden="true" tabindex="-1"></a>    <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb99-415"><a href="nonlinear-regression.html#cb99-415" aria-hidden="true" tabindex="-1"></a><span class="sc">&lt;</span>dbl<span class="sc">&gt;</span></span>
<span id="cb99-416"><a href="nonlinear-regression.html#cb99-416" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2990</span>    <span class="dv">3711731</span> <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span>  <span class="cn">NA</span></span>
<span id="cb99-417"><a href="nonlinear-regression.html#cb99-417" aria-hidden="true" tabindex="-1"></a><span class="dv">2989</span>    <span class="dv">3693842</span> <span class="fl">1.000000</span>    <span class="fl">17889.243</span>   <span class="fl">14.477130</span>   <span class="fl">0.0001447167</span></span>
<span id="cb99-418"><a href="nonlinear-regression.html#cb99-418" aria-hidden="true" tabindex="-1"></a><span class="dv">2986</span>    <span class="dv">3689770</span> <span class="fl">2.999989</span>    <span class="fl">4071.134</span>    <span class="fl">1.098212</span>    <span class="fl">0.3485661430</span></span>
<span id="cb99-419"><a href="nonlinear-regression.html#cb99-419" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> rows</span>
<span id="cb99-420"><a href="nonlinear-regression.html#cb99-420" aria-hidden="true" tabindex="-1"></a>Третья модель статистически не лучше второй. Кроме того, один из параметров этой модели незначим.</span>
<span id="cb99-421"><a href="nonlinear-regression.html#cb99-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-422"><a href="nonlinear-regression.html#cb99-422" aria-hidden="true" tabindex="-1"></a><span class="co"># сводка по модели gam.m3</span></span>
<span id="cb99-423"><a href="nonlinear-regression.html#cb99-423" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gam.m3)</span>
<span id="cb99-424"><a href="nonlinear-regression.html#cb99-424" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb99-425"><a href="nonlinear-regression.html#cb99-425" aria-hidden="true" tabindex="-1"></a><span class="do">## Call: gam(formula = wage ~ s(year, 4) + s(age, 5) + education, data = Wage)</span></span>
<span id="cb99-426"><a href="nonlinear-regression.html#cb99-426" aria-hidden="true" tabindex="-1"></a><span class="do">## Deviance Residuals:</span></span>
<span id="cb99-427"><a href="nonlinear-regression.html#cb99-427" aria-hidden="true" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb99-428"><a href="nonlinear-regression.html#cb99-428" aria-hidden="true" tabindex="-1"></a><span class="do">## -119.43  -19.70   -3.33   14.17  213.48 </span></span>
<span id="cb99-429"><a href="nonlinear-regression.html#cb99-429" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb99-430"><a href="nonlinear-regression.html#cb99-430" aria-hidden="true" tabindex="-1"></a><span class="do">## (Dispersion Parameter for gaussian family taken to be 1235.69)</span></span>
<span id="cb99-431"><a href="nonlinear-regression.html#cb99-431" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb99-432"><a href="nonlinear-regression.html#cb99-432" aria-hidden="true" tabindex="-1"></a><span class="do">##     Null Deviance: 5222086 on 2999 degrees of freedom</span></span>
<span id="cb99-433"><a href="nonlinear-regression.html#cb99-433" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual Deviance: 3689770 on 2986 degrees of freedom</span></span>
<span id="cb99-434"><a href="nonlinear-regression.html#cb99-434" aria-hidden="true" tabindex="-1"></a><span class="do">## AIC: 29887.75 </span></span>
<span id="cb99-435"><a href="nonlinear-regression.html#cb99-435" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb99-436"><a href="nonlinear-regression.html#cb99-436" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Local Scoring Iterations: 2 </span></span>
<span id="cb99-437"><a href="nonlinear-regression.html#cb99-437" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb99-438"><a href="nonlinear-regression.html#cb99-438" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Parametric Effects</span></span>
<span id="cb99-439"><a href="nonlinear-regression.html#cb99-439" aria-hidden="true" tabindex="-1"></a><span class="do">##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    </span></span>
<span id="cb99-440"><a href="nonlinear-regression.html#cb99-440" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)    1   27162   27162  21.981 2.877e-06 ***</span></span>
<span id="cb99-441"><a href="nonlinear-regression.html#cb99-441" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)     1  195338  195338 158.081 &lt; 2.2e-16 ***</span></span>
<span id="cb99-442"><a href="nonlinear-regression.html#cb99-442" aria-hidden="true" tabindex="-1"></a><span class="do">## education     4 1069726  267432 216.423 &lt; 2.2e-16 ***</span></span>
<span id="cb99-443"><a href="nonlinear-regression.html#cb99-443" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals  2986 3689770    1236                      </span></span>
<span id="cb99-444"><a href="nonlinear-regression.html#cb99-444" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb99-445"><a href="nonlinear-regression.html#cb99-445" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb99-446"><a href="nonlinear-regression.html#cb99-446" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb99-447"><a href="nonlinear-regression.html#cb99-447" aria-hidden="true" tabindex="-1"></a><span class="do">## Anova for Nonparametric Effects</span></span>
<span id="cb99-448"><a href="nonlinear-regression.html#cb99-448" aria-hidden="true" tabindex="-1"></a><span class="do">##             Npar Df Npar F  Pr(F)    </span></span>
<span id="cb99-449"><a href="nonlinear-regression.html#cb99-449" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)                          </span></span>
<span id="cb99-450"><a href="nonlinear-regression.html#cb99-450" aria-hidden="true" tabindex="-1"></a><span class="do">## s(year, 4)        3  1.086 0.3537    </span></span>
<span id="cb99-451"><a href="nonlinear-regression.html#cb99-451" aria-hidden="true" tabindex="-1"></a><span class="do">## s(age, 5)         4 32.380 &lt;2e-16 ***</span></span>
<span id="cb99-452"><a href="nonlinear-regression.html#cb99-452" aria-hidden="true" tabindex="-1"></a><span class="do">## education                            </span></span>
<span id="cb99-453"><a href="nonlinear-regression.html#cb99-453" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb99-454"><a href="nonlinear-regression.html#cb99-454" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb99-455"><a href="nonlinear-regression.html#cb99-455" aria-hidden="true" tabindex="-1"></a>Работаем с моделью gam.m2.</span>
<span id="cb99-456"><a href="nonlinear-regression.html#cb99-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-457"><a href="nonlinear-regression.html#cb99-457" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по обучающей выборке</span></span>
<span id="cb99-458"><a href="nonlinear-regression.html#cb99-458" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(gam.m2, <span class="at">newdata =</span> Wage)</span>
<span id="cb99-459"><a href="nonlinear-regression.html#cb99-459" aria-hidden="true" tabindex="-1"></a>Также можно использовать в GAM локальные регрессии.</span>
<span id="cb99-460"><a href="nonlinear-regression.html#cb99-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-461"><a href="nonlinear-regression.html#cb99-461" aria-hidden="true" tabindex="-1"></a><span class="co"># GAM на локальных регрессиях</span></span>
<span id="cb99-462"><a href="nonlinear-regression.html#cb99-462" aria-hidden="true" tabindex="-1"></a>gam.lo <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">s</span>(year, <span class="at">df =</span> <span class="dv">4</span>) <span class="sc">+</span> <span class="fu">lo</span>(age, <span class="at">span =</span> <span class="fl">0.7</span>) <span class="sc">+</span> education, </span>
<span id="cb99-463"><a href="nonlinear-regression.html#cb99-463" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> Wage)</span>
<span id="cb99-464"><a href="nonlinear-regression.html#cb99-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-465"><a href="nonlinear-regression.html#cb99-465" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb99-466"><a href="nonlinear-regression.html#cb99-466" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.gam</span>(gam.lo, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb99-467"><a href="nonlinear-regression.html#cb99-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-468"><a href="nonlinear-regression.html#cb99-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-469"><a href="nonlinear-regression.html#cb99-469" aria-hidden="true" tabindex="-1"></a><span class="co"># модель со взаимодействием регрессоров year и age</span></span>
<span id="cb99-470"><a href="nonlinear-regression.html#cb99-470" aria-hidden="true" tabindex="-1"></a>gam.lo.i <span class="ot">&lt;-</span> <span class="fu">gam</span>(wage <span class="sc">~</span> <span class="fu">lo</span>(year, age, <span class="at">span =</span> <span class="fl">0.5</span>) <span class="sc">+</span> education, <span class="at">data =</span> Wage)</span>
<span id="cb99-471"><a href="nonlinear-regression.html#cb99-471" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb99-472"><a href="nonlinear-regression.html#cb99-472" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb99-473"><a href="nonlinear-regression.html#cb99-473" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb99-474"><a href="nonlinear-regression.html#cb99-474" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb99-475"><a href="nonlinear-regression.html#cb99-475" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb99-476"><a href="nonlinear-regression.html#cb99-476" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : liv too small. (Discovered by lowesd)</span></span>
<span id="cb99-477"><a href="nonlinear-regression.html#cb99-477" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in lo.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,</span></span>
<span id="cb99-478"><a href="nonlinear-regression.html#cb99-478" aria-hidden="true" tabindex="-1"></a><span class="do">## bf.maxit, : lv too small. (Discovered by lowesd)</span></span>
<span id="cb99-479"><a href="nonlinear-regression.html#cb99-479" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lo.i)</span>
<span id="cb99-480"><a href="nonlinear-regression.html#cb99-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-481"><a href="nonlinear-regression.html#cb99-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-482"><a href="nonlinear-regression.html#cb99-482" aria-hidden="true" tabindex="-1"></a>Логистическая GAM</span>
<span id="cb99-483"><a href="nonlinear-regression.html#cb99-483" aria-hidden="true" tabindex="-1"></a>Построим логистическую GAM для всероятности того, что wage превышает <span class="fl">250.</span></span>
<span id="cb99-484"><a href="nonlinear-regression.html#cb99-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-485"><a href="nonlinear-regression.html#cb99-485" aria-hidden="true" tabindex="-1"></a>gam.lr <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education, </span>
<span id="cb99-486"><a href="nonlinear-regression.html#cb99-486" aria-hidden="true" tabindex="-1"></a>              <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage)</span>
<span id="cb99-487"><a href="nonlinear-regression.html#cb99-487" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb99-488"><a href="nonlinear-regression.html#cb99-488" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb99-489"><a href="nonlinear-regression.html#cb99-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-490"><a href="nonlinear-regression.html#cb99-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-491"><a href="nonlinear-regression.html#cb99-491" aria-hidden="true" tabindex="-1"></a><span class="co"># уровни образования по группам разного достатка</span></span>
<span id="cb99-492"><a href="nonlinear-regression.html#cb99-492" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(education, <span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>))</span>
<span id="cb99-493"><a href="nonlinear-regression.html#cb99-493" aria-hidden="true" tabindex="-1"></a><span class="do">##                     </span></span>
<span id="cb99-494"><a href="nonlinear-regression.html#cb99-494" aria-hidden="true" tabindex="-1"></a><span class="do">## education            FALSE TRUE</span></span>
<span id="cb99-495"><a href="nonlinear-regression.html#cb99-495" aria-hidden="true" tabindex="-1"></a><span class="do">##   1. &lt; HS Grad         268    0</span></span>
<span id="cb99-496"><a href="nonlinear-regression.html#cb99-496" aria-hidden="true" tabindex="-1"></a><span class="do">##   2. HS Grad           966    5</span></span>
<span id="cb99-497"><a href="nonlinear-regression.html#cb99-497" aria-hidden="true" tabindex="-1"></a><span class="do">##   3. Some College      643    7</span></span>
<span id="cb99-498"><a href="nonlinear-regression.html#cb99-498" aria-hidden="true" tabindex="-1"></a><span class="do">##   4. College Grad      663   22</span></span>
<span id="cb99-499"><a href="nonlinear-regression.html#cb99-499" aria-hidden="true" tabindex="-1"></a><span class="do">##   5. Advanced Degree   381   45</span></span>
<span id="cb99-500"><a href="nonlinear-regression.html#cb99-500" aria-hidden="true" tabindex="-1"></a>В категории с самым низким уровнем образования нет wage <span class="sc">&gt;</span> <span class="dv">250</span>, поэтому убираем её.</span>
<span id="cb99-501"><a href="nonlinear-regression.html#cb99-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-502"><a href="nonlinear-regression.html#cb99-502" aria-hidden="true" tabindex="-1"></a>gam.lr.s <span class="ot">&lt;-</span> <span class="fu">gam</span>(<span class="fu">I</span>(wage <span class="sc">&gt;</span> <span class="dv">250</span>) <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">s</span>(age, <span class="at">df =</span> <span class="dv">5</span>) <span class="sc">+</span> education,</span>
<span id="cb99-503"><a href="nonlinear-regression.html#cb99-503" aria-hidden="true" tabindex="-1"></a>                <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>, <span class="at">data =</span> Wage, </span>
<span id="cb99-504"><a href="nonlinear-regression.html#cb99-504" aria-hidden="true" tabindex="-1"></a>                <span class="at">subset =</span> (education <span class="sc">!=</span> <span class="st">&quot;1. &lt; HS Grad&quot;</span>))</span>
<span id="cb99-505"><a href="nonlinear-regression.html#cb99-505" aria-hidden="true" tabindex="-1"></a><span class="co"># график</span></span>
<span id="cb99-506"><a href="nonlinear-regression.html#cb99-506" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb99-507"><a href="nonlinear-regression.html#cb99-507" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gam.lr.s, <span class="at">se =</span> T, <span class="at">col =</span> <span class="st">&#39;green&#39;</span>)</span>
<span id="cb99-508"><a href="nonlinear-regression.html#cb99-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-509"><a href="nonlinear-regression.html#cb99-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-510"><a href="nonlinear-regression.html#cb99-510" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(Wage)</span></code></pre></div>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="nonlinear-regression.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonlinear modeling</span></span>
<span id="cb100-2"><a href="nonlinear-regression.html#cb100-2" aria-hidden="true" tabindex="-1"></a>Математическое моделирование</span>
<span id="cb100-3"><a href="nonlinear-regression.html#cb100-3" aria-hidden="true" tabindex="-1"></a>Практика <span class="dv">8</span></span>
<span id="cb100-4"><a href="nonlinear-regression.html#cb100-4" aria-hidden="true" tabindex="-1"></a>Нелинейные модели</span>
<span id="cb100-5"><a href="nonlinear-regression.html#cb100-5" aria-hidden="true" tabindex="-1"></a>В практических примерах ниже показано как<span class="sc">:</span></span>
<span id="cb100-6"><a href="nonlinear-regression.html#cb100-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb100-7"><a href="nonlinear-regression.html#cb100-7" aria-hidden="true" tabindex="-1"></a>    строить регрессионные деревья;</span>
<span id="cb100-8"><a href="nonlinear-regression.html#cb100-8" aria-hidden="true" tabindex="-1"></a>строить деревья классификации;</span>
<span id="cb100-9"><a href="nonlinear-regression.html#cb100-9" aria-hidden="true" tabindex="-1"></a>делать обрезку дерева;</span>
<span id="cb100-10"><a href="nonlinear-regression.html#cb100-10" aria-hidden="true" tabindex="-1"></a>использовать бэггинг, бустинг, случайный лес для улучшения качества прогнозирования.</span>
<span id="cb100-11"><a href="nonlinear-regression.html#cb100-11" aria-hidden="true" tabindex="-1"></a>Модели<span class="sc">:</span> деревья решений.</span>
<span id="cb100-12"><a href="nonlinear-regression.html#cb100-12" aria-hidden="true" tabindex="-1"></a>Данные<span class="sc">:</span> Sales {ISLR}, Boston {ISLR}</span>
<span id="cb100-13"><a href="nonlinear-regression.html#cb100-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-14"><a href="nonlinear-regression.html#cb100-14" aria-hidden="true" tabindex="-1"></a>Подробные комментарии к коду лабораторных см. в [<span class="dv">1</span>], глава <span class="fl">8.</span></span>
<span id="cb100-15"><a href="nonlinear-regression.html#cb100-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-16"><a href="nonlinear-regression.html#cb100-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;tree&#39;</span>)              <span class="co"># деревья</span></span>
<span id="cb100-17"><a href="nonlinear-regression.html#cb100-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;tree&#39; was built under R version 3.4.4</span></span>
<span id="cb100-18"><a href="nonlinear-regression.html#cb100-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;ISLR&#39;</span>)              <span class="co"># наборы данных</span></span>
<span id="cb100-19"><a href="nonlinear-regression.html#cb100-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;MASS&#39;</span>)</span>
<span id="cb100-20"><a href="nonlinear-regression.html#cb100-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;randomForest&#39;</span>)      <span class="co"># случайный лес</span></span>
<span id="cb100-21"><a href="nonlinear-regression.html#cb100-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;randomForest&#39; was built under R version 3.4.4</span></span>
<span id="cb100-22"><a href="nonlinear-regression.html#cb100-22" aria-hidden="true" tabindex="-1"></a><span class="do">## randomForest 4.6-14</span></span>
<span id="cb100-23"><a href="nonlinear-regression.html#cb100-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Type rfNews() to see new features/changes/bug fixes.</span></span>
<span id="cb100-24"><a href="nonlinear-regression.html#cb100-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&#39;gbm&#39;</span>)</span>
<span id="cb100-25"><a href="nonlinear-regression.html#cb100-25" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: package &#39;gbm&#39; was built under R version 3.4.4</span></span>
<span id="cb100-26"><a href="nonlinear-regression.html#cb100-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: survival</span></span>
<span id="cb100-27"><a href="nonlinear-regression.html#cb100-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: lattice</span></span>
<span id="cb100-28"><a href="nonlinear-regression.html#cb100-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: splines</span></span>
<span id="cb100-29"><a href="nonlinear-regression.html#cb100-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Loading required package: parallel</span></span>
<span id="cb100-30"><a href="nonlinear-regression.html#cb100-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Loaded gbm 2.1.3</span></span>
<span id="cb100-31"><a href="nonlinear-regression.html#cb100-31" aria-hidden="true" tabindex="-1"></a>Деревья решений</span>
<span id="cb100-32"><a href="nonlinear-regression.html#cb100-32" aria-hidden="true" tabindex="-1"></a>Загрузим таблицу с данными по продажам детских кресел и добавим к ней переменную High – “высокие продажи” со значениями<span class="sc">:</span></span>
<span id="cb100-33"><a href="nonlinear-regression.html#cb100-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb100-34"><a href="nonlinear-regression.html#cb100-34" aria-hidden="true" tabindex="-1"></a>    Yes если продажи больше <span class="dv">8</span> (тыс. шт.);</span>
<span id="cb100-35"><a href="nonlinear-regression.html#cb100-35" aria-hidden="true" tabindex="-1"></a>No в противном случае.</span>
<span id="cb100-36"><a href="nonlinear-regression.html#cb100-36" aria-hidden="true" tabindex="-1"></a>?Carseats</span>
<span id="cb100-37"><a href="nonlinear-regression.html#cb100-37" aria-hidden="true" tabindex="-1"></a><span class="do">## starting httpd help server ... done</span></span>
<span id="cb100-38"><a href="nonlinear-regression.html#cb100-38" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(Carseats)</span>
<span id="cb100-39"><a href="nonlinear-regression.html#cb100-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-40"><a href="nonlinear-regression.html#cb100-40" aria-hidden="true" tabindex="-1"></a><span class="co"># новая переменная</span></span>
<span id="cb100-41"><a href="nonlinear-regression.html#cb100-41" aria-hidden="true" tabindex="-1"></a>High <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(Sales <span class="sc">&lt;=</span> <span class="dv">8</span>, <span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb100-42"><a href="nonlinear-regression.html#cb100-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-43"><a href="nonlinear-regression.html#cb100-43" aria-hidden="true" tabindex="-1"></a><span class="co"># присоединяем к таблице данных</span></span>
<span id="cb100-44"><a href="nonlinear-regression.html#cb100-44" aria-hidden="true" tabindex="-1"></a>Carseats <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Carseats, High)</span>
<span id="cb100-45"><a href="nonlinear-regression.html#cb100-45" aria-hidden="true" tabindex="-1"></a>Строим дерево для категориального отклика High, отбросив непрерывный отклик Sales.</span>
<span id="cb100-46"><a href="nonlinear-regression.html#cb100-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-47"><a href="nonlinear-regression.html#cb100-47" aria-hidden="true" tabindex="-1"></a><span class="co"># модель бинарного  дерева</span></span>
<span id="cb100-48"><a href="nonlinear-regression.html#cb100-48" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats)</span>
<span id="cb100-49"><a href="nonlinear-regression.html#cb100-49" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.carseats)</span>
<span id="cb100-50"><a href="nonlinear-regression.html#cb100-50" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-51"><a href="nonlinear-regression.html#cb100-51" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification tree:</span></span>
<span id="cb100-52"><a href="nonlinear-regression.html#cb100-52" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = High ~ . - Sales, data = Carseats)</span></span>
<span id="cb100-53"><a href="nonlinear-regression.html#cb100-53" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb100-54"><a href="nonlinear-regression.html#cb100-54" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;ShelveLoc&quot;   &quot;Price&quot;       &quot;Income&quot;      &quot;CompPrice&quot;   &quot;Population&quot; </span></span>
<span id="cb100-55"><a href="nonlinear-regression.html#cb100-55" aria-hidden="true" tabindex="-1"></a><span class="do">## [6] &quot;Advertising&quot; &quot;Age&quot;         &quot;US&quot;         </span></span>
<span id="cb100-56"><a href="nonlinear-regression.html#cb100-56" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  27 </span></span>
<span id="cb100-57"><a href="nonlinear-regression.html#cb100-57" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  0.4575 = 170.7 / 373 </span></span>
<span id="cb100-58"><a href="nonlinear-regression.html#cb100-58" aria-hidden="true" tabindex="-1"></a><span class="do">## Misclassification error rate: 0.09 = 36 / 400</span></span>
<span id="cb100-59"><a href="nonlinear-regression.html#cb100-59" aria-hidden="true" tabindex="-1"></a><span class="co"># график результата</span></span>
<span id="cb100-60"><a href="nonlinear-regression.html#cb100-60" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.carseats)            <span class="co"># ветви</span></span>
<span id="cb100-61"><a href="nonlinear-regression.html#cb100-61" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.carseats, <span class="at">pretty=</span><span class="dv">0</span>)  <span class="co"># подписи</span></span>
<span id="cb100-62"><a href="nonlinear-regression.html#cb100-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-63"><a href="nonlinear-regression.html#cb100-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-64"><a href="nonlinear-regression.html#cb100-64" aria-hidden="true" tabindex="-1"></a>tree.carseats                  <span class="co"># посмотреть всё дерево в консоли</span></span>
<span id="cb100-65"><a href="nonlinear-regression.html#cb100-65" aria-hidden="true" tabindex="-1"></a><span class="do">## node), split, n, deviance, yval, (yprob)</span></span>
<span id="cb100-66"><a href="nonlinear-regression.html#cb100-66" aria-hidden="true" tabindex="-1"></a><span class="do">##       * denotes terminal node</span></span>
<span id="cb100-67"><a href="nonlinear-regression.html#cb100-67" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-68"><a href="nonlinear-regression.html#cb100-68" aria-hidden="true" tabindex="-1"></a><span class="do">##   1) root 400 541.500 No ( 0.59000 0.41000 )  </span></span>
<span id="cb100-69"><a href="nonlinear-regression.html#cb100-69" aria-hidden="true" tabindex="-1"></a><span class="do">##     2) ShelveLoc: Bad,Medium 315 390.600 No ( 0.68889 0.31111 )  </span></span>
<span id="cb100-70"><a href="nonlinear-regression.html#cb100-70" aria-hidden="true" tabindex="-1"></a><span class="do">##       4) Price &lt; 92.5 46  56.530 Yes ( 0.30435 0.69565 )  </span></span>
<span id="cb100-71"><a href="nonlinear-regression.html#cb100-71" aria-hidden="true" tabindex="-1"></a><span class="do">##         8) Income &lt; 57 10  12.220 No ( 0.70000 0.30000 )  </span></span>
<span id="cb100-72"><a href="nonlinear-regression.html#cb100-72" aria-hidden="true" tabindex="-1"></a><span class="do">##          16) CompPrice &lt; 110.5 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb100-73"><a href="nonlinear-regression.html#cb100-73" aria-hidden="true" tabindex="-1"></a><span class="do">##          17) CompPrice &gt; 110.5 5   6.730 Yes ( 0.40000 0.60000 ) *</span></span>
<span id="cb100-74"><a href="nonlinear-regression.html#cb100-74" aria-hidden="true" tabindex="-1"></a><span class="do">##         9) Income &gt; 57 36  35.470 Yes ( 0.19444 0.80556 )  </span></span>
<span id="cb100-75"><a href="nonlinear-regression.html#cb100-75" aria-hidden="true" tabindex="-1"></a><span class="do">##          18) Population &lt; 207.5 16  21.170 Yes ( 0.37500 0.62500 ) *</span></span>
<span id="cb100-76"><a href="nonlinear-regression.html#cb100-76" aria-hidden="true" tabindex="-1"></a><span class="do">##          19) Population &gt; 207.5 20   7.941 Yes ( 0.05000 0.95000 ) *</span></span>
<span id="cb100-77"><a href="nonlinear-regression.html#cb100-77" aria-hidden="true" tabindex="-1"></a><span class="do">##       5) Price &gt; 92.5 269 299.800 No ( 0.75465 0.24535 )  </span></span>
<span id="cb100-78"><a href="nonlinear-regression.html#cb100-78" aria-hidden="true" tabindex="-1"></a><span class="do">##        10) Advertising &lt; 13.5 224 213.200 No ( 0.81696 0.18304 )  </span></span>
<span id="cb100-79"><a href="nonlinear-regression.html#cb100-79" aria-hidden="true" tabindex="-1"></a><span class="do">##          20) CompPrice &lt; 124.5 96  44.890 No ( 0.93750 0.06250 )  </span></span>
<span id="cb100-80"><a href="nonlinear-regression.html#cb100-80" aria-hidden="true" tabindex="-1"></a><span class="do">##            40) Price &lt; 106.5 38  33.150 No ( 0.84211 0.15789 )  </span></span>
<span id="cb100-81"><a href="nonlinear-regression.html#cb100-81" aria-hidden="true" tabindex="-1"></a><span class="do">##              80) Population &lt; 177 12  16.300 No ( 0.58333 0.41667 )  </span></span>
<span id="cb100-82"><a href="nonlinear-regression.html#cb100-82" aria-hidden="true" tabindex="-1"></a><span class="do">##               160) Income &lt; 60.5 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb100-83"><a href="nonlinear-regression.html#cb100-83" aria-hidden="true" tabindex="-1"></a><span class="do">##               161) Income &gt; 60.5 6   5.407 Yes ( 0.16667 0.83333 ) *</span></span>
<span id="cb100-84"><a href="nonlinear-regression.html#cb100-84" aria-hidden="true" tabindex="-1"></a><span class="do">##              81) Population &gt; 177 26   8.477 No ( 0.96154 0.03846 ) *</span></span>
<span id="cb100-85"><a href="nonlinear-regression.html#cb100-85" aria-hidden="true" tabindex="-1"></a><span class="do">##            41) Price &gt; 106.5 58   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb100-86"><a href="nonlinear-regression.html#cb100-86" aria-hidden="true" tabindex="-1"></a><span class="do">##          21) CompPrice &gt; 124.5 128 150.200 No ( 0.72656 0.27344 )  </span></span>
<span id="cb100-87"><a href="nonlinear-regression.html#cb100-87" aria-hidden="true" tabindex="-1"></a><span class="do">##            42) Price &lt; 122.5 51  70.680 Yes ( 0.49020 0.50980 )  </span></span>
<span id="cb100-88"><a href="nonlinear-regression.html#cb100-88" aria-hidden="true" tabindex="-1"></a><span class="do">##              84) ShelveLoc: Bad 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb100-89"><a href="nonlinear-regression.html#cb100-89" aria-hidden="true" tabindex="-1"></a><span class="do">##              85) ShelveLoc: Medium 40  52.930 Yes ( 0.37500 0.62500 )  </span></span>
<span id="cb100-90"><a href="nonlinear-regression.html#cb100-90" aria-hidden="true" tabindex="-1"></a><span class="do">##               170) Price &lt; 109.5 16   7.481 Yes ( 0.06250 0.93750 ) *</span></span>
<span id="cb100-91"><a href="nonlinear-regression.html#cb100-91" aria-hidden="true" tabindex="-1"></a><span class="do">##               171) Price &gt; 109.5 24  32.600 No ( 0.58333 0.41667 )  </span></span>
<span id="cb100-92"><a href="nonlinear-regression.html#cb100-92" aria-hidden="true" tabindex="-1"></a><span class="do">##                 342) Age &lt; 49.5 13  16.050 Yes ( 0.30769 0.69231 ) *</span></span>
<span id="cb100-93"><a href="nonlinear-regression.html#cb100-93" aria-hidden="true" tabindex="-1"></a><span class="do">##                 343) Age &gt; 49.5 11   6.702 No ( 0.90909 0.09091 ) *</span></span>
<span id="cb100-94"><a href="nonlinear-regression.html#cb100-94" aria-hidden="true" tabindex="-1"></a><span class="do">##            43) Price &gt; 122.5 77  55.540 No ( 0.88312 0.11688 )  </span></span>
<span id="cb100-95"><a href="nonlinear-regression.html#cb100-95" aria-hidden="true" tabindex="-1"></a><span class="do">##              86) CompPrice &lt; 147.5 58  17.400 No ( 0.96552 0.03448 ) *</span></span>
<span id="cb100-96"><a href="nonlinear-regression.html#cb100-96" aria-hidden="true" tabindex="-1"></a><span class="do">##              87) CompPrice &gt; 147.5 19  25.010 No ( 0.63158 0.36842 )  </span></span>
<span id="cb100-97"><a href="nonlinear-regression.html#cb100-97" aria-hidden="true" tabindex="-1"></a><span class="do">##               174) Price &lt; 147 12  16.300 Yes ( 0.41667 0.58333 )  </span></span>
<span id="cb100-98"><a href="nonlinear-regression.html#cb100-98" aria-hidden="true" tabindex="-1"></a><span class="do">##                 348) CompPrice &lt; 152.5 7   5.742 Yes ( 0.14286 0.85714 ) *</span></span>
<span id="cb100-99"><a href="nonlinear-regression.html#cb100-99" aria-hidden="true" tabindex="-1"></a><span class="do">##                 349) CompPrice &gt; 152.5 5   5.004 No ( 0.80000 0.20000 ) *</span></span>
<span id="cb100-100"><a href="nonlinear-regression.html#cb100-100" aria-hidden="true" tabindex="-1"></a><span class="do">##               175) Price &gt; 147 7   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb100-101"><a href="nonlinear-regression.html#cb100-101" aria-hidden="true" tabindex="-1"></a><span class="do">##        11) Advertising &gt; 13.5 45  61.830 Yes ( 0.44444 0.55556 )  </span></span>
<span id="cb100-102"><a href="nonlinear-regression.html#cb100-102" aria-hidden="true" tabindex="-1"></a><span class="do">##          22) Age &lt; 54.5 25  25.020 Yes ( 0.20000 0.80000 )  </span></span>
<span id="cb100-103"><a href="nonlinear-regression.html#cb100-103" aria-hidden="true" tabindex="-1"></a><span class="do">##            44) CompPrice &lt; 130.5 14  18.250 Yes ( 0.35714 0.64286 )  </span></span>
<span id="cb100-104"><a href="nonlinear-regression.html#cb100-104" aria-hidden="true" tabindex="-1"></a><span class="do">##              88) Income &lt; 100 9  12.370 No ( 0.55556 0.44444 ) *</span></span>
<span id="cb100-105"><a href="nonlinear-regression.html#cb100-105" aria-hidden="true" tabindex="-1"></a><span class="do">##              89) Income &gt; 100 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb100-106"><a href="nonlinear-regression.html#cb100-106" aria-hidden="true" tabindex="-1"></a><span class="do">##            45) CompPrice &gt; 130.5 11   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb100-107"><a href="nonlinear-regression.html#cb100-107" aria-hidden="true" tabindex="-1"></a><span class="do">##          23) Age &gt; 54.5 20  22.490 No ( 0.75000 0.25000 )  </span></span>
<span id="cb100-108"><a href="nonlinear-regression.html#cb100-108" aria-hidden="true" tabindex="-1"></a><span class="do">##            46) CompPrice &lt; 122.5 10   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb100-109"><a href="nonlinear-regression.html#cb100-109" aria-hidden="true" tabindex="-1"></a><span class="do">##            47) CompPrice &gt; 122.5 10  13.860 No ( 0.50000 0.50000 )  </span></span>
<span id="cb100-110"><a href="nonlinear-regression.html#cb100-110" aria-hidden="true" tabindex="-1"></a><span class="do">##              94) Price &lt; 125 5   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb100-111"><a href="nonlinear-regression.html#cb100-111" aria-hidden="true" tabindex="-1"></a><span class="do">##              95) Price &gt; 125 5   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb100-112"><a href="nonlinear-regression.html#cb100-112" aria-hidden="true" tabindex="-1"></a><span class="do">##     3) ShelveLoc: Good 85  90.330 Yes ( 0.22353 0.77647 )  </span></span>
<span id="cb100-113"><a href="nonlinear-regression.html#cb100-113" aria-hidden="true" tabindex="-1"></a><span class="do">##       6) Price &lt; 135 68  49.260 Yes ( 0.11765 0.88235 )  </span></span>
<span id="cb100-114"><a href="nonlinear-regression.html#cb100-114" aria-hidden="true" tabindex="-1"></a><span class="do">##        12) US: No 17  22.070 Yes ( 0.35294 0.64706 )  </span></span>
<span id="cb100-115"><a href="nonlinear-regression.html#cb100-115" aria-hidden="true" tabindex="-1"></a><span class="do">##          24) Price &lt; 109 8   0.000 Yes ( 0.00000 1.00000 ) *</span></span>
<span id="cb100-116"><a href="nonlinear-regression.html#cb100-116" aria-hidden="true" tabindex="-1"></a><span class="do">##          25) Price &gt; 109 9  11.460 No ( 0.66667 0.33333 ) *</span></span>
<span id="cb100-117"><a href="nonlinear-regression.html#cb100-117" aria-hidden="true" tabindex="-1"></a><span class="do">##        13) US: Yes 51  16.880 Yes ( 0.03922 0.96078 ) *</span></span>
<span id="cb100-118"><a href="nonlinear-regression.html#cb100-118" aria-hidden="true" tabindex="-1"></a><span class="do">##       7) Price &gt; 135 17  22.070 No ( 0.64706 0.35294 )  </span></span>
<span id="cb100-119"><a href="nonlinear-regression.html#cb100-119" aria-hidden="true" tabindex="-1"></a><span class="do">##        14) Income &lt; 46 6   0.000 No ( 1.00000 0.00000 ) *</span></span>
<span id="cb100-120"><a href="nonlinear-regression.html#cb100-120" aria-hidden="true" tabindex="-1"></a><span class="do">##        15) Income &gt; 46 11  15.160 Yes ( 0.45455 0.54545 ) *</span></span>
<span id="cb100-121"><a href="nonlinear-regression.html#cb100-121" aria-hidden="true" tabindex="-1"></a>Теперь построим дерево на обучающей выборке и оценим ошибку на тестовой.</span>
<span id="cb100-122"><a href="nonlinear-regression.html#cb100-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-123"><a href="nonlinear-regression.html#cb100-123" aria-hidden="true" tabindex="-1"></a><span class="co"># ядро генератора случайных чисел</span></span>
<span id="cb100-124"><a href="nonlinear-regression.html#cb100-124" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb100-125"><a href="nonlinear-regression.html#cb100-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-126"><a href="nonlinear-regression.html#cb100-126" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb100-127"><a href="nonlinear-regression.html#cb100-127" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Carseats), <span class="dv">200</span>)</span>
<span id="cb100-128"><a href="nonlinear-regression.html#cb100-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-129"><a href="nonlinear-regression.html#cb100-129" aria-hidden="true" tabindex="-1"></a><span class="co"># тестовая выборка</span></span>
<span id="cb100-130"><a href="nonlinear-regression.html#cb100-130" aria-hidden="true" tabindex="-1"></a>Carseats.test <span class="ot">&lt;-</span> Carseats[<span class="sc">-</span>train,]</span>
<span id="cb100-131"><a href="nonlinear-regression.html#cb100-131" aria-hidden="true" tabindex="-1"></a>High.test <span class="ot">&lt;-</span> High[<span class="sc">-</span>train]</span>
<span id="cb100-132"><a href="nonlinear-regression.html#cb100-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-133"><a href="nonlinear-regression.html#cb100-133" aria-hidden="true" tabindex="-1"></a><span class="co"># строим дерево на обучающей выборке</span></span>
<span id="cb100-134"><a href="nonlinear-regression.html#cb100-134" aria-hidden="true" tabindex="-1"></a>tree.carseats <span class="ot">&lt;-</span> <span class="fu">tree</span>(High <span class="sc">~</span> . <span class="sc">-</span>Sales, Carseats, <span class="at">subset =</span> train)</span>
<span id="cb100-135"><a href="nonlinear-regression.html#cb100-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-136"><a href="nonlinear-regression.html#cb100-136" aria-hidden="true" tabindex="-1"></a><span class="co"># делаем прогноз</span></span>
<span id="cb100-137"><a href="nonlinear-regression.html#cb100-137" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb100-138"><a href="nonlinear-regression.html#cb100-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-139"><a href="nonlinear-regression.html#cb100-139" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb100-140"><a href="nonlinear-regression.html#cb100-140" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb100-141"><a href="nonlinear-regression.html#cb100-141" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb100-142"><a href="nonlinear-regression.html#cb100-142" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb100-143"><a href="nonlinear-regression.html#cb100-143" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb100-144"><a href="nonlinear-regression.html#cb100-144" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  27</span></span>
<span id="cb100-145"><a href="nonlinear-regression.html#cb100-145" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  57</span></span>
<span id="cb100-146"><a href="nonlinear-regression.html#cb100-146" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb100-147"><a href="nonlinear-regression.html#cb100-147" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb100-148"><a href="nonlinear-regression.html#cb100-148" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb100-149"><a href="nonlinear-regression.html#cb100-149" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.715</span></span>
<span id="cb100-150"><a href="nonlinear-regression.html#cb100-150" aria-hidden="true" tabindex="-1"></a>Обобщённая характеристика точности<span class="sc">:</span> доля верных прогнозов<span class="sc">:</span> <span class="dv">0</span>.<span class="fl">72.</span></span>
<span id="cb100-151"><a href="nonlinear-regression.html#cb100-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-152"><a href="nonlinear-regression.html#cb100-152" aria-hidden="true" tabindex="-1"></a>Теперь обрезаем дерево, используя в качестве критерия частоту ошибок классификации. Функция <span class="fu">cv.tree</span>() проводит кросс<span class="sc">-</span>валидацию для выбора лучшего дерева, аргумент prune.misclass означает, что мы минимизируем ошибку классификации.</span>
<span id="cb100-153"><a href="nonlinear-regression.html#cb100-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-154"><a href="nonlinear-regression.html#cb100-154" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb100-155"><a href="nonlinear-regression.html#cb100-155" aria-hidden="true" tabindex="-1"></a>cv.carseats <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.carseats, <span class="at">FUN =</span> prune.misclass)</span>
<span id="cb100-156"><a href="nonlinear-regression.html#cb100-156" aria-hidden="true" tabindex="-1"></a><span class="co"># имена элементов полученного объекта</span></span>
<span id="cb100-157"><a href="nonlinear-regression.html#cb100-157" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(cv.carseats)</span>
<span id="cb100-158"><a href="nonlinear-regression.html#cb100-158" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;size&quot;   &quot;dev&quot;    &quot;k&quot;      &quot;method&quot;</span></span>
<span id="cb100-159"><a href="nonlinear-regression.html#cb100-159" aria-hidden="true" tabindex="-1"></a><span class="co"># сам объект</span></span>
<span id="cb100-160"><a href="nonlinear-regression.html#cb100-160" aria-hidden="true" tabindex="-1"></a>cv.carseats</span>
<span id="cb100-161"><a href="nonlinear-regression.html#cb100-161" aria-hidden="true" tabindex="-1"></a><span class="do">## $size</span></span>
<span id="cb100-162"><a href="nonlinear-regression.html#cb100-162" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 19 17 14 13  9  7  3  2  1</span></span>
<span id="cb100-163"><a href="nonlinear-regression.html#cb100-163" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-164"><a href="nonlinear-regression.html#cb100-164" aria-hidden="true" tabindex="-1"></a><span class="do">## $dev</span></span>
<span id="cb100-165"><a href="nonlinear-regression.html#cb100-165" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 55 55 53 52 50 56 69 65 80</span></span>
<span id="cb100-166"><a href="nonlinear-regression.html#cb100-166" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-167"><a href="nonlinear-regression.html#cb100-167" aria-hidden="true" tabindex="-1"></a><span class="do">## $k</span></span>
<span id="cb100-168"><a href="nonlinear-regression.html#cb100-168" aria-hidden="true" tabindex="-1"></a><span class="do">## [1]       -Inf  0.0000000  0.6666667  1.0000000  1.7500000  2.0000000</span></span>
<span id="cb100-169"><a href="nonlinear-regression.html#cb100-169" aria-hidden="true" tabindex="-1"></a><span class="do">## [7]  4.2500000  5.0000000 23.0000000</span></span>
<span id="cb100-170"><a href="nonlinear-regression.html#cb100-170" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-171"><a href="nonlinear-regression.html#cb100-171" aria-hidden="true" tabindex="-1"></a><span class="do">## $method</span></span>
<span id="cb100-172"><a href="nonlinear-regression.html#cb100-172" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;misclass&quot;</span></span>
<span id="cb100-173"><a href="nonlinear-regression.html#cb100-173" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-174"><a href="nonlinear-regression.html#cb100-174" aria-hidden="true" tabindex="-1"></a><span class="do">## attr(,&quot;class&quot;)</span></span>
<span id="cb100-175"><a href="nonlinear-regression.html#cb100-175" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;prune&quot;         &quot;tree.sequence&quot;</span></span>
<span id="cb100-176"><a href="nonlinear-regression.html#cb100-176" aria-hidden="true" tabindex="-1"></a><span class="co"># графики изменения параметров метода по ходу обрезки дерева ###################</span></span>
<span id="cb100-177"><a href="nonlinear-regression.html#cb100-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-178"><a href="nonlinear-regression.html#cb100-178" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. ошибка с кросс-валидацией в зависимости от числа узлов</span></span>
<span id="cb100-179"><a href="nonlinear-regression.html#cb100-179" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb100-180"><a href="nonlinear-regression.html#cb100-180" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>size, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb100-181"><a href="nonlinear-regression.html#cb100-181" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb100-182"><a href="nonlinear-regression.html#cb100-182" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Число узлов (size)&#39;</span>)</span>
<span id="cb100-183"><a href="nonlinear-regression.html#cb100-183" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb100-184"><a href="nonlinear-regression.html#cb100-184" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.carseats<span class="sc">$</span>size[cv.carseats<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.carseats<span class="sc">$</span>dev)]</span>
<span id="cb100-185"><a href="nonlinear-regression.html#cb100-185" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb100-186"><a href="nonlinear-regression.html#cb100-186" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb100-187"><a href="nonlinear-regression.html#cb100-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-188"><a href="nonlinear-regression.html#cb100-188" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. ошибка с кросс-валидацией в зависимости от штрафа на сложность</span></span>
<span id="cb100-189"><a href="nonlinear-regression.html#cb100-189" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.carseats<span class="sc">$</span>k, cv.carseats<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&quot;b&quot;</span>,</span>
<span id="cb100-190"><a href="nonlinear-regression.html#cb100-190" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&#39;Частота ошибок с кросс-вал. (dev)&#39;</span>,</span>
<span id="cb100-191"><a href="nonlinear-regression.html#cb100-191" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Штраф за сложность (k)&#39;</span>)</span>
<span id="cb100-192"><a href="nonlinear-regression.html#cb100-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-193"><a href="nonlinear-regression.html#cb100-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-194"><a href="nonlinear-regression.html#cb100-194" aria-hidden="true" tabindex="-1"></a>Как видно на графике слева, минимум частоты ошибок достигается при числе узлов <span class="fl">9.</span> Оценим точность дерева с <span class="dv">9</span> узлами.</span>
<span id="cb100-195"><a href="nonlinear-regression.html#cb100-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-196"><a href="nonlinear-regression.html#cb100-196" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 9 узлами</span></span>
<span id="cb100-197"><a href="nonlinear-regression.html#cb100-197" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">9</span>)</span>
<span id="cb100-198"><a href="nonlinear-regression.html#cb100-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-199"><a href="nonlinear-regression.html#cb100-199" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb100-200"><a href="nonlinear-regression.html#cb100-200" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb100-201"><a href="nonlinear-regression.html#cb100-201" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb100-202"><a href="nonlinear-regression.html#cb100-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-203"><a href="nonlinear-regression.html#cb100-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-204"><a href="nonlinear-regression.html#cb100-204" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb100-205"><a href="nonlinear-regression.html#cb100-205" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb100-206"><a href="nonlinear-regression.html#cb100-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-207"><a href="nonlinear-regression.html#cb100-207" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb100-208"><a href="nonlinear-regression.html#cb100-208" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb100-209"><a href="nonlinear-regression.html#cb100-209" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb100-210"><a href="nonlinear-regression.html#cb100-210" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb100-211"><a href="nonlinear-regression.html#cb100-211" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb100-212"><a href="nonlinear-regression.html#cb100-212" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  94  24</span></span>
<span id="cb100-213"><a href="nonlinear-regression.html#cb100-213" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 22  60</span></span>
<span id="cb100-214"><a href="nonlinear-regression.html#cb100-214" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb100-215"><a href="nonlinear-regression.html#cb100-215" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb100-216"><a href="nonlinear-regression.html#cb100-216" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb100-217"><a href="nonlinear-regression.html#cb100-217" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.77</span></span>
<span id="cb100-218"><a href="nonlinear-regression.html#cb100-218" aria-hidden="true" tabindex="-1"></a>Точность этой модели чуть выше точности исходного дерева и составляет <span class="dv">0</span>.<span class="fl">77.</span> Увеличив количество узлов, получим более глубокое дерево, но менее точное.</span>
<span id="cb100-219"><a href="nonlinear-regression.html#cb100-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-220"><a href="nonlinear-regression.html#cb100-220" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 13 узлами</span></span>
<span id="cb100-221"><a href="nonlinear-regression.html#cb100-221" aria-hidden="true" tabindex="-1"></a>prune.carseats <span class="ot">&lt;-</span> <span class="fu">prune.misclass</span>(tree.carseats, <span class="at">best =</span> <span class="dv">15</span>)</span>
<span id="cb100-222"><a href="nonlinear-regression.html#cb100-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-223"><a href="nonlinear-regression.html#cb100-223" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb100-224"><a href="nonlinear-regression.html#cb100-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.carseats)</span>
<span id="cb100-225"><a href="nonlinear-regression.html#cb100-225" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.carseats, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb100-226"><a href="nonlinear-regression.html#cb100-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-227"><a href="nonlinear-regression.html#cb100-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-228"><a href="nonlinear-regression.html#cb100-228" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз на тестовую выборку</span></span>
<span id="cb100-229"><a href="nonlinear-regression.html#cb100-229" aria-hidden="true" tabindex="-1"></a>tree.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.carseats, Carseats.test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb100-230"><a href="nonlinear-regression.html#cb100-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-231"><a href="nonlinear-regression.html#cb100-231" aria-hidden="true" tabindex="-1"></a><span class="co"># матрица неточностей</span></span>
<span id="cb100-232"><a href="nonlinear-regression.html#cb100-232" aria-hidden="true" tabindex="-1"></a>tbl <span class="ot">&lt;-</span> <span class="fu">table</span>(tree.pred, High.test)</span>
<span id="cb100-233"><a href="nonlinear-regression.html#cb100-233" aria-hidden="true" tabindex="-1"></a>tbl</span>
<span id="cb100-234"><a href="nonlinear-regression.html#cb100-234" aria-hidden="true" tabindex="-1"></a><span class="do">##          High.test</span></span>
<span id="cb100-235"><a href="nonlinear-regression.html#cb100-235" aria-hidden="true" tabindex="-1"></a><span class="do">## tree.pred No Yes</span></span>
<span id="cb100-236"><a href="nonlinear-regression.html#cb100-236" aria-hidden="true" tabindex="-1"></a><span class="do">##       No  86  22</span></span>
<span id="cb100-237"><a href="nonlinear-regression.html#cb100-237" aria-hidden="true" tabindex="-1"></a><span class="do">##       Yes 30  62</span></span>
<span id="cb100-238"><a href="nonlinear-regression.html#cb100-238" aria-hidden="true" tabindex="-1"></a><span class="co"># оценка точности</span></span>
<span id="cb100-239"><a href="nonlinear-regression.html#cb100-239" aria-hidden="true" tabindex="-1"></a>acc.test <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(tbl))<span class="sc">/</span><span class="fu">sum</span>(tbl)</span>
<span id="cb100-240"><a href="nonlinear-regression.html#cb100-240" aria-hidden="true" tabindex="-1"></a>acc.test</span>
<span id="cb100-241"><a href="nonlinear-regression.html#cb100-241" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.74</span></span>
<span id="cb100-242"><a href="nonlinear-regression.html#cb100-242" aria-hidden="true" tabindex="-1"></a><span class="co"># сбрасываем графические параметры</span></span>
<span id="cb100-243"><a href="nonlinear-regression.html#cb100-243" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb100-244"><a href="nonlinear-regression.html#cb100-244" aria-hidden="true" tabindex="-1"></a>Регрессионные деревья</span>
<span id="cb100-245"><a href="nonlinear-regression.html#cb100-245" aria-hidden="true" tabindex="-1"></a>Воспользуемся набором данных Boston.</span>
<span id="cb100-246"><a href="nonlinear-regression.html#cb100-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-247"><a href="nonlinear-regression.html#cb100-247" aria-hidden="true" tabindex="-1"></a>?Boston</span>
<span id="cb100-248"><a href="nonlinear-regression.html#cb100-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-249"><a href="nonlinear-regression.html#cb100-249" aria-hidden="true" tabindex="-1"></a><span class="co"># обучающая выборка</span></span>
<span id="cb100-250"><a href="nonlinear-regression.html#cb100-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb100-251"><a href="nonlinear-regression.html#cb100-251" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Boston), <span class="fu">nrow</span>(Boston)<span class="sc">/</span><span class="dv">2</span>) <span class="co"># обучающая выборка -- 50%</span></span>
<span id="cb100-252"><a href="nonlinear-regression.html#cb100-252" aria-hidden="true" tabindex="-1"></a>Построим дерево регрессии для зависимой переменной medv<span class="sc">:</span> медианная стоимости домов, в которых живут собственники (тыс. долл.).</span>
<span id="cb100-253"><a href="nonlinear-regression.html#cb100-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-254"><a href="nonlinear-regression.html#cb100-254" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb100-255"><a href="nonlinear-regression.html#cb100-255" aria-hidden="true" tabindex="-1"></a>tree.boston <span class="ot">&lt;-</span> <span class="fu">tree</span>(medv <span class="sc">~</span> ., Boston, <span class="at">subset =</span> train)</span>
<span id="cb100-256"><a href="nonlinear-regression.html#cb100-256" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tree.boston)</span>
<span id="cb100-257"><a href="nonlinear-regression.html#cb100-257" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-258"><a href="nonlinear-regression.html#cb100-258" aria-hidden="true" tabindex="-1"></a><span class="do">## Regression tree:</span></span>
<span id="cb100-259"><a href="nonlinear-regression.html#cb100-259" aria-hidden="true" tabindex="-1"></a><span class="do">## tree(formula = medv ~ ., data = Boston, subset = train)</span></span>
<span id="cb100-260"><a href="nonlinear-regression.html#cb100-260" aria-hidden="true" tabindex="-1"></a><span class="do">## Variables actually used in tree construction:</span></span>
<span id="cb100-261"><a href="nonlinear-regression.html#cb100-261" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;lstat&quot; &quot;rm&quot;    &quot;dis&quot;  </span></span>
<span id="cb100-262"><a href="nonlinear-regression.html#cb100-262" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of terminal nodes:  8 </span></span>
<span id="cb100-263"><a href="nonlinear-regression.html#cb100-263" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual mean deviance:  12.65 = 3099 / 245 </span></span>
<span id="cb100-264"><a href="nonlinear-regression.html#cb100-264" aria-hidden="true" tabindex="-1"></a><span class="do">## Distribution of residuals:</span></span>
<span id="cb100-265"><a href="nonlinear-regression.html#cb100-265" aria-hidden="true" tabindex="-1"></a><span class="do">##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. </span></span>
<span id="cb100-266"><a href="nonlinear-regression.html#cb100-266" aria-hidden="true" tabindex="-1"></a><span class="do">## -14.10000  -2.04200  -0.05357   0.00000   1.96000  12.60000</span></span>
<span id="cb100-267"><a href="nonlinear-regression.html#cb100-267" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb100-268"><a href="nonlinear-regression.html#cb100-268" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tree.boston)</span>
<span id="cb100-269"><a href="nonlinear-regression.html#cb100-269" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(tree.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb100-270"><a href="nonlinear-regression.html#cb100-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-271"><a href="nonlinear-regression.html#cb100-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-272"><a href="nonlinear-regression.html#cb100-272" aria-hidden="true" tabindex="-1"></a>Снова сделаем обрезку дерева в целях улучшения качества прогноза.</span>
<span id="cb100-273"><a href="nonlinear-regression.html#cb100-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-274"><a href="nonlinear-regression.html#cb100-274" aria-hidden="true" tabindex="-1"></a>cv.boston <span class="ot">&lt;-</span> <span class="fu">cv.tree</span>(tree.boston)</span>
<span id="cb100-275"><a href="nonlinear-regression.html#cb100-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-276"><a href="nonlinear-regression.html#cb100-276" aria-hidden="true" tabindex="-1"></a><span class="co"># размер дерева с минимальной ошибкой</span></span>
<span id="cb100-277"><a href="nonlinear-regression.html#cb100-277" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.boston<span class="sc">$</span>size, cv.boston<span class="sc">$</span>dev, <span class="at">type =</span> <span class="st">&#39;b&#39;</span>)</span>
<span id="cb100-278"><a href="nonlinear-regression.html#cb100-278" aria-hidden="true" tabindex="-1"></a>opt.size <span class="ot">&lt;-</span> cv.boston<span class="sc">$</span>size[cv.boston<span class="sc">$</span>dev <span class="sc">==</span> <span class="fu">min</span>(cv.boston<span class="sc">$</span>dev)]</span>
<span id="cb100-279"><a href="nonlinear-regression.html#cb100-279" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> opt.size, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="st">&#39;lwd&#39;</span> <span class="ot">=</span> <span class="dv">2</span>)     <span class="co"># соотв. вертикальная прямая</span></span>
<span id="cb100-280"><a href="nonlinear-regression.html#cb100-280" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(opt.size, <span class="at">at =</span> opt.size, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb100-281"><a href="nonlinear-regression.html#cb100-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-282"><a href="nonlinear-regression.html#cb100-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-283"><a href="nonlinear-regression.html#cb100-283" aria-hidden="true" tabindex="-1"></a>В данном случаем минимум ошибки соответствует самому сложному дереву, с <span class="dv">8</span> узлами. Покажем, как при желании можно обрезать дерево до <span class="dv">7</span> узлов (ошибка ненамного выше, чем минимальная).</span>
<span id="cb100-284"><a href="nonlinear-regression.html#cb100-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-285"><a href="nonlinear-regression.html#cb100-285" aria-hidden="true" tabindex="-1"></a><span class="co"># дерево с 7 узлами</span></span>
<span id="cb100-286"><a href="nonlinear-regression.html#cb100-286" aria-hidden="true" tabindex="-1"></a>prune.boston <span class="ot">=</span> <span class="fu">prune.tree</span>(tree.boston, <span class="at">best =</span> <span class="dv">7</span>)</span>
<span id="cb100-287"><a href="nonlinear-regression.html#cb100-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-288"><a href="nonlinear-regression.html#cb100-288" aria-hidden="true" tabindex="-1"></a><span class="co"># визуализация</span></span>
<span id="cb100-289"><a href="nonlinear-regression.html#cb100-289" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prune.boston)</span>
<span id="cb100-290"><a href="nonlinear-regression.html#cb100-290" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(prune.boston, <span class="at">pretty =</span> <span class="dv">0</span>)</span>
<span id="cb100-291"><a href="nonlinear-regression.html#cb100-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-292"><a href="nonlinear-regression.html#cb100-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-293"><a href="nonlinear-regression.html#cb100-293" aria-hidden="true" tabindex="-1"></a>Прогноз сделаем по необрезанному дереву, т.к. там ошибка, оцененная по методу перекрёстной проверки, минимальна.</span>
<span id="cb100-294"><a href="nonlinear-regression.html#cb100-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-295"><a href="nonlinear-regression.html#cb100-295" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз по лучшей модели (8 узлов)</span></span>
<span id="cb100-296"><a href="nonlinear-regression.html#cb100-296" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb100-297"><a href="nonlinear-regression.html#cb100-297" aria-hidden="true" tabindex="-1"></a>boston.test <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>train, <span class="st">&quot;medv&quot;</span>]</span>
<span id="cb100-298"><a href="nonlinear-regression.html#cb100-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-299"><a href="nonlinear-regression.html#cb100-299" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb100-300"><a href="nonlinear-regression.html#cb100-300" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat, boston.test)</span>
<span id="cb100-301"><a href="nonlinear-regression.html#cb100-301" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb100-302"><a href="nonlinear-regression.html#cb100-302" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb100-303"><a href="nonlinear-regression.html#cb100-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-304"><a href="nonlinear-regression.html#cb100-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-305"><a href="nonlinear-regression.html#cb100-305" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb100-306"><a href="nonlinear-regression.html#cb100-306" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb100-307"><a href="nonlinear-regression.html#cb100-307" aria-hidden="true" tabindex="-1"></a>MSE на тестовой выборке равна <span class="fl">25.05</span> (тыс.долл.).</span>
<span id="cb100-308"><a href="nonlinear-regression.html#cb100-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-309"><a href="nonlinear-regression.html#cb100-309" aria-hidden="true" tabindex="-1"></a>Бэггинг и метод случайного леса</span>
<span id="cb100-310"><a href="nonlinear-regression.html#cb100-310" aria-hidden="true" tabindex="-1"></a>Рассмотрим более сложные методы улучшения качества дерева. Бэггинг – частный случай случайного леса с m<span class="ot">=</span>p, поэтому и то, и другое можно построить функцией <span class="fu">randomForest</span>().</span>
<span id="cb100-311"><a href="nonlinear-regression.html#cb100-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-312"><a href="nonlinear-regression.html#cb100-312" aria-hidden="true" tabindex="-1"></a>Для начала используем бэггинг, причём возьмём все <span class="dv">13</span> предикторов на каждом шаге (аргумент mtry).</span>
<span id="cb100-313"><a href="nonlinear-regression.html#cb100-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-314"><a href="nonlinear-regression.html#cb100-314" aria-hidden="true" tabindex="-1"></a><span class="co"># бэггинг с 13 предикторами</span></span>
<span id="cb100-315"><a href="nonlinear-regression.html#cb100-315" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb100-316"><a href="nonlinear-regression.html#cb100-316" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train, </span>
<span id="cb100-317"><a href="nonlinear-regression.html#cb100-317" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb100-318"><a href="nonlinear-regression.html#cb100-318" aria-hidden="true" tabindex="-1"></a>bag.boston</span>
<span id="cb100-319"><a href="nonlinear-regression.html#cb100-319" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-320"><a href="nonlinear-regression.html#cb100-320" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb100-321"><a href="nonlinear-regression.html#cb100-321" aria-hidden="true" tabindex="-1"></a><span class="do">##  randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE,      subset = train) </span></span>
<span id="cb100-322"><a href="nonlinear-regression.html#cb100-322" aria-hidden="true" tabindex="-1"></a><span class="do">##                Type of random forest: regression</span></span>
<span id="cb100-323"><a href="nonlinear-regression.html#cb100-323" aria-hidden="true" tabindex="-1"></a><span class="do">##                      Number of trees: 500</span></span>
<span id="cb100-324"><a href="nonlinear-regression.html#cb100-324" aria-hidden="true" tabindex="-1"></a><span class="do">## No. of variables tried at each split: 13</span></span>
<span id="cb100-325"><a href="nonlinear-regression.html#cb100-325" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb100-326"><a href="nonlinear-regression.html#cb100-326" aria-hidden="true" tabindex="-1"></a><span class="do">##           Mean of squared residuals: 11.15723</span></span>
<span id="cb100-327"><a href="nonlinear-regression.html#cb100-327" aria-hidden="true" tabindex="-1"></a><span class="do">##                     % Var explained: 86.49</span></span>
<span id="cb100-328"><a href="nonlinear-regression.html#cb100-328" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb100-329"><a href="nonlinear-regression.html#cb100-329" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">=</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb100-330"><a href="nonlinear-regression.html#cb100-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-331"><a href="nonlinear-regression.html#cb100-331" aria-hidden="true" tabindex="-1"></a><span class="co"># график &quot;прогноз -- реализация&quot;</span></span>
<span id="cb100-332"><a href="nonlinear-regression.html#cb100-332" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat.bag, boston.test)</span>
<span id="cb100-333"><a href="nonlinear-regression.html#cb100-333" aria-hidden="true" tabindex="-1"></a><span class="co"># линия идеального прогноза</span></span>
<span id="cb100-334"><a href="nonlinear-regression.html#cb100-334" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb100-335"><a href="nonlinear-regression.html#cb100-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-336"><a href="nonlinear-regression.html#cb100-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-337"><a href="nonlinear-regression.html#cb100-337" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb100-338"><a href="nonlinear-regression.html#cb100-338" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb100-339"><a href="nonlinear-regression.html#cb100-339" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb100-340"><a href="nonlinear-regression.html#cb100-340" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.50808</span></span>
<span id="cb100-341"><a href="nonlinear-regression.html#cb100-341" aria-hidden="true" tabindex="-1"></a>Ошибка на тестовой выборке равна <span class="dv">13</span>.<span class="fl">51.</span></span>
<span id="cb100-342"><a href="nonlinear-regression.html#cb100-342" aria-hidden="true" tabindex="-1"></a>Можно изменить число деревьев с помощью аргумента ntree.</span>
<span id="cb100-343"><a href="nonlinear-regression.html#cb100-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-344"><a href="nonlinear-regression.html#cb100-344" aria-hidden="true" tabindex="-1"></a>bag.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb100-345"><a href="nonlinear-regression.html#cb100-345" aria-hidden="true" tabindex="-1"></a>                           <span class="at">mtry =</span> <span class="dv">13</span>, <span class="at">ntree =</span> <span class="dv">25</span>)</span>
<span id="cb100-346"><a href="nonlinear-regression.html#cb100-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-347"><a href="nonlinear-regression.html#cb100-347" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb100-348"><a href="nonlinear-regression.html#cb100-348" aria-hidden="true" tabindex="-1"></a>yhat.bag <span class="ot">&lt;-</span> <span class="fu">predict</span>(bag.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb100-349"><a href="nonlinear-regression.html#cb100-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-350"><a href="nonlinear-regression.html#cb100-350" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb100-351"><a href="nonlinear-regression.html#cb100-351" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.bag <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb100-352"><a href="nonlinear-regression.html#cb100-352" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb100-353"><a href="nonlinear-regression.html#cb100-353" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 13.94835</span></span>
<span id="cb100-354"><a href="nonlinear-regression.html#cb100-354" aria-hidden="true" tabindex="-1"></a>Но, как видно, это только ухудшает прогноз.</span>
<span id="cb100-355"><a href="nonlinear-regression.html#cb100-355" aria-hidden="true" tabindex="-1"></a>Теперь попробуем вырастить случайный лес. Берём <span class="dv">6</span> предикторов на каждом шаге.</span>
<span id="cb100-356"><a href="nonlinear-regression.html#cb100-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-357"><a href="nonlinear-regression.html#cb100-357" aria-hidden="true" tabindex="-1"></a><span class="co"># обучаем модель</span></span>
<span id="cb100-358"><a href="nonlinear-regression.html#cb100-358" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb100-359"><a href="nonlinear-regression.html#cb100-359" aria-hidden="true" tabindex="-1"></a>rf.boston <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston, <span class="at">subset =</span> train,</span>
<span id="cb100-360"><a href="nonlinear-regression.html#cb100-360" aria-hidden="true" tabindex="-1"></a>                          <span class="at">mtry =</span> <span class="dv">6</span>, <span class="at">importance =</span> <span class="cn">TRUE</span>)</span>
<span id="cb100-361"><a href="nonlinear-regression.html#cb100-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-362"><a href="nonlinear-regression.html#cb100-362" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb100-363"><a href="nonlinear-regression.html#cb100-363" aria-hidden="true" tabindex="-1"></a>yhat.rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ])</span>
<span id="cb100-364"><a href="nonlinear-regression.html#cb100-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-365"><a href="nonlinear-regression.html#cb100-365" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой выборке</span></span>
<span id="cb100-366"><a href="nonlinear-regression.html#cb100-366" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.rf <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb100-367"><a href="nonlinear-regression.html#cb100-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-368"><a href="nonlinear-regression.html#cb100-368" aria-hidden="true" tabindex="-1"></a><span class="co"># важность предикторов</span></span>
<span id="cb100-369"><a href="nonlinear-regression.html#cb100-369" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf.boston)  <span class="co"># оценки </span></span>
<span id="cb100-370"><a href="nonlinear-regression.html#cb100-370" aria-hidden="true" tabindex="-1"></a><span class="do">##           %IncMSE IncNodePurity</span></span>
<span id="cb100-371"><a href="nonlinear-regression.html#cb100-371" aria-hidden="true" tabindex="-1"></a><span class="do">## crim    12.132320     986.50338</span></span>
<span id="cb100-372"><a href="nonlinear-regression.html#cb100-372" aria-hidden="true" tabindex="-1"></a><span class="do">## zn       1.955579      57.96945</span></span>
<span id="cb100-373"><a href="nonlinear-regression.html#cb100-373" aria-hidden="true" tabindex="-1"></a><span class="do">## indus    9.069302     882.78261</span></span>
<span id="cb100-374"><a href="nonlinear-regression.html#cb100-374" aria-hidden="true" tabindex="-1"></a><span class="do">## chas     2.210835      45.22941</span></span>
<span id="cb100-375"><a href="nonlinear-regression.html#cb100-375" aria-hidden="true" tabindex="-1"></a><span class="do">## nox     11.104823    1044.33776</span></span>
<span id="cb100-376"><a href="nonlinear-regression.html#cb100-376" aria-hidden="true" tabindex="-1"></a><span class="do">## rm      31.784033    6359.31971</span></span>
<span id="cb100-377"><a href="nonlinear-regression.html#cb100-377" aria-hidden="true" tabindex="-1"></a><span class="do">## age     10.962684     516.82969</span></span>
<span id="cb100-378"><a href="nonlinear-regression.html#cb100-378" aria-hidden="true" tabindex="-1"></a><span class="do">## dis     15.015236    1224.11605</span></span>
<span id="cb100-379"><a href="nonlinear-regression.html#cb100-379" aria-hidden="true" tabindex="-1"></a><span class="do">## rad      4.118011      95.94586</span></span>
<span id="cb100-380"><a href="nonlinear-regression.html#cb100-380" aria-hidden="true" tabindex="-1"></a><span class="do">## tax      8.587932     502.96719</span></span>
<span id="cb100-381"><a href="nonlinear-regression.html#cb100-381" aria-hidden="true" tabindex="-1"></a><span class="do">## ptratio 12.503896     830.77523</span></span>
<span id="cb100-382"><a href="nonlinear-regression.html#cb100-382" aria-hidden="true" tabindex="-1"></a><span class="do">## black    6.702609     341.30361</span></span>
<span id="cb100-383"><a href="nonlinear-regression.html#cb100-383" aria-hidden="true" tabindex="-1"></a><span class="do">## lstat   30.695224    7505.73936</span></span>
<span id="cb100-384"><a href="nonlinear-regression.html#cb100-384" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.boston)  <span class="co"># графики</span></span>
<span id="cb100-385"><a href="nonlinear-regression.html#cb100-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-386"><a href="nonlinear-regression.html#cb100-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-387"><a href="nonlinear-regression.html#cb100-387" aria-hidden="true" tabindex="-1"></a>Ошибка по модели случайного леса равна <span class="fl">11.66</span>, что ниже, чем для бэггинга.</span>
<span id="cb100-388"><a href="nonlinear-regression.html#cb100-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-389"><a href="nonlinear-regression.html#cb100-389" aria-hidden="true" tabindex="-1"></a>Бустинг</span>
<span id="cb100-390"><a href="nonlinear-regression.html#cb100-390" aria-hidden="true" tabindex="-1"></a>Построим <span class="dv">5000</span> регрессионных деревьев с глубиной <span class="fl">4.</span></span>
<span id="cb100-391"><a href="nonlinear-regression.html#cb100-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-392"><a href="nonlinear-regression.html#cb100-392" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb100-393"><a href="nonlinear-regression.html#cb100-393" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb100-394"><a href="nonlinear-regression.html#cb100-394" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>)</span>
<span id="cb100-395"><a href="nonlinear-regression.html#cb100-395" aria-hidden="true" tabindex="-1"></a><span class="co"># график и таблица относительной важности переменных</span></span>
<span id="cb100-396"><a href="nonlinear-regression.html#cb100-396" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boost.boston)</span>
<span id="cb100-397"><a href="nonlinear-regression.html#cb100-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-398"><a href="nonlinear-regression.html#cb100-398" aria-hidden="true" tabindex="-1"></a><span class="co"># графики частной зависимости для двух наиболее важных предикторов</span></span>
<span id="cb100-399"><a href="nonlinear-regression.html#cb100-399" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb100-400"><a href="nonlinear-regression.html#cb100-400" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;rm&quot;</span>)</span>
<span id="cb100-401"><a href="nonlinear-regression.html#cb100-401" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boost.boston, <span class="at">i =</span> <span class="st">&quot;lstat&quot;</span>)</span>
<span id="cb100-402"><a href="nonlinear-regression.html#cb100-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-403"><a href="nonlinear-regression.html#cb100-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-404"><a href="nonlinear-regression.html#cb100-404" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb100-405"><a href="nonlinear-regression.html#cb100-405" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb100-406"><a href="nonlinear-regression.html#cb100-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-407"><a href="nonlinear-regression.html#cb100-407" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE на тестовой</span></span>
<span id="cb100-408"><a href="nonlinear-regression.html#cb100-408" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb100-409"><a href="nonlinear-regression.html#cb100-409" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb100-410"><a href="nonlinear-regression.html#cb100-410" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.84434</span></span>
<span id="cb100-411"><a href="nonlinear-regression.html#cb100-411" aria-hidden="true" tabindex="-1"></a>Настройку бустинга можно делать с помощью гиперпараметра λ (аргумент shrinkage). Установим его равным <span class="dv">0</span>.<span class="fl">2.</span></span>
<span id="cb100-412"><a href="nonlinear-regression.html#cb100-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-413"><a href="nonlinear-regression.html#cb100-413" aria-hidden="true" tabindex="-1"></a><span class="co"># меняем значение гиперпараметра (lambda) на 0.2 -- аргумент shrinkage</span></span>
<span id="cb100-414"><a href="nonlinear-regression.html#cb100-414" aria-hidden="true" tabindex="-1"></a>boost.boston <span class="ot">&lt;-</span> <span class="fu">gbm</span>(medv <span class="sc">~</span> ., <span class="at">data =</span> Boston[train, ], <span class="at">distribution =</span> <span class="st">&quot;gaussian&quot;</span>,</span>
<span id="cb100-415"><a href="nonlinear-regression.html#cb100-415" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n.trees =</span> <span class="dv">5000</span>, <span class="at">interaction.depth =</span> <span class="dv">4</span>, </span>
<span id="cb100-416"><a href="nonlinear-regression.html#cb100-416" aria-hidden="true" tabindex="-1"></a>                    <span class="at">shrinkage =</span> <span class="fl">0.2</span>, <span class="at">verbose =</span> F)</span>
<span id="cb100-417"><a href="nonlinear-regression.html#cb100-417" aria-hidden="true" tabindex="-1"></a><span class="co"># прогноз</span></span>
<span id="cb100-418"><a href="nonlinear-regression.html#cb100-418" aria-hidden="true" tabindex="-1"></a>yhat.boost <span class="ot">&lt;-</span> <span class="fu">predict</span>(boost.boston, <span class="at">newdata =</span> Boston[<span class="sc">-</span>train, ], <span class="at">n.trees =</span> <span class="dv">5000</span>)</span>
<span id="cb100-419"><a href="nonlinear-regression.html#cb100-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-420"><a href="nonlinear-regression.html#cb100-420" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE а тестовой</span></span>
<span id="cb100-421"><a href="nonlinear-regression.html#cb100-421" aria-hidden="true" tabindex="-1"></a>mse.test <span class="ot">&lt;-</span> <span class="fu">mean</span>((yhat.boost <span class="sc">-</span> boston.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb100-422"><a href="nonlinear-regression.html#cb100-422" aria-hidden="true" tabindex="-1"></a>mse.test</span>
<span id="cb100-423"><a href="nonlinear-regression.html#cb100-423" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 11.51109</span></span>
<span id="cb100-424"><a href="nonlinear-regression.html#cb100-424" aria-hidden="true" tabindex="-1"></a>Таким образом, изменив гиперпараметр, мы ещё немного снизили ошибку прогноза.</span></code></pre></div>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="next-part-3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="spline-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/35_nonlinear_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
