# Basic Statistics

## Definitions
**population** - all existing samples  
**sample** - subset of statistical population  
**simple random sample** - random subset  
**stratified sample** - fist clustering, than random sample from  
**cluster sample** - random choosing from several existing clusters  
**variables** - discret, continuous, ordinal (ранговая)  

## Probability
A standard French-suited deck of playing cards contains 52 cards; 13 each of hearts (♥), spades (♠), clubs (♦), and diamonds (♣). Assuming that you have a well-shuffled deck in front of you, the probability of drawing any given card is 1/52 ≈ 1.92%.  
Calculate the probability of drawing any of the four aces! That is, calculate the probability of drawing 🂡 or 🂱 or 🃁 or 🃑 using the sum rule and assign it to prob_to_draw_ace.  

```{r}
# Calculate the probability of drawing any of the four aces
prob_to_draw_ace <- 1/52 + 1/52 + 1/52 + 1/52
```
Cards and the product rule
Again, assuming that you have a well-shuffled deck in front of you, the probability of drawing any given card is 1/52 ≈ 1.92% . The probability of drawing any of the four aces is 1/52 + 1/52 + 1/52 + 1/52 = 4/52. Once an ace has been drawn, the probability of picking any of the remaining three is 3/51. If another ace is drawn the probability of picking any of the remaining two is 2/50, and so on.  
Use the product rule to calculate the probability of picking the four aces in a row from the top of a well-shuffled deck and assign it to prob_to_draw_four_aces.  
```{r}
# Calculate the probability of picking four aces in a row
prob_to_draw_four_aces <- 4/52 * 3/51 * 2/50 * 1/49
```

## Analysis of sample distribution
### Histogram
```{r, eval=TRUE}
# sample of random integers
v <- round(rnorm(n=50, sd=5, mean=100))

par(mfrow=c(1,2))
stripchart(v, method = "stack", pch=19, cex=2, offset=.5, at=.15,
           main = "Dotplot of random value", xlab = "Random value")

hist(v)

# add density
x <- density(v)$x
y <- (10/max(density(v)$y))*density(v)$y  # scale y to plot with histogram
lines(x, y, col="red", lwd=2)
```

### Outliers
Outliers are rare values that appear far away from the majority of the data. 
Outliers can bias the results and potentially lead to incorrect conclusions if not handled properly. 
One method for dealing with outliers is to simply remove them. 
However, removing data points can introduce other types of bias into the results, and potentially result in losing critical information. 
If outliers seem to have a lot of influence on the results, a nonparametric test such as the **Wilcoxon Signed Rank Test** may be appropriate to use instead. 
Outliers can be identified visually using a boxplot.  

### Normality
It is possible to use histogram to estimate normality of the distribution.  

```{r }
# QQ-plot - fit normal distibution
qqnorm(v); qqline(v)

var(v)     # variance: sd = sqrt(var)
sd(v)      # standard deviation

sd(v)/sqrt(length(v))  # standard error sd/sqrt(n)

# Z-score (standartization)
# transform distribution to mean=0, variance=1
# z = (x - mean(n))/sd
scale(v)     # z-score
vs <- scale(v)[,1]
vs

par(mfrow=c(1,2))
hist(v)
hist(vs)
```

## Confidence interval
```{r}
# sample of random integers
x <- round(rnorm(n=50, sd=5, mean=100))

# Confidence interval for normal distribution with p=0.95
m <- mean(x)
s <- sd(x)
n <- length(x)
error <- qnorm(0.95)*s/sqrt(n)
confidence <- c(m-error, m+error)
confidence

# Confidence interval for t-distribution with p=0.95
a <- 5
s <- 2
n <- 20
error <- qt(0.975,df=n-1)*s/sqrt(n)
# confidence interval
c(left=a-error, right=a+error)
```
